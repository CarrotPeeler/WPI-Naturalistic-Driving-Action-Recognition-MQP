config files: ['configs/MVITv2_B_32x3.yaml', 'DATA.PATH_TO_DATA_DIR', '.']
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
[06/23 20:56:10][INFO] train_net.py:  552: Train with config:
[06/23 20:56:10][INFO] train_net.py:  553: {'AUG': {'AA_TYPE': 'rand-m9-mstd0.5-inc1',
         'COLOR_JITTER': 0.4,
         'ENABLE': False,
         'GEN_MASK_LOADER': False,
         'INTERPOLATION': 'bicubic',
         'MASK_FRAMES': False,
         'MASK_RATIO': 0.0,
         'MASK_TUBE': False,
         'MASK_WINDOW_SIZE': [8, 7, 7],
         'MAX_MASK_PATCHES_PER_BLOCK': None,
         'NUM_SAMPLE': 1,
         'RE_COUNT': 1,
         'RE_MODE': 'pixel',
         'RE_PROB': 0.25,
         'RE_SPLIT': False},
 'AVA': {'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.9,
         'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv',
         'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/',
         'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'],
         'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'],
         'TRAIN_LISTS': ['train.csv'],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': [],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'GLOBAL_SYNC': False,
        'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'CONTRASTIVE': {'BN_MLP': False,
                 'BN_SYNC_MLP': False,
                 'DELTA_CLIPS_MAX': inf,
                 'DELTA_CLIPS_MIN': -inf,
                 'DIM': 128,
                 'INTERP_MEMORY': False,
                 'KNN_ON': True,
                 'LENGTH': 239975,
                 'LOCAL_SHUFFLE_BN': True,
                 'MEM_TYPE': '1d',
                 'MLP_DIM': 2048,
                 'MOCO_MULTI_VIEW_QUEUE': False,
                 'MOMENTUM': 0.5,
                 'MOMENTUM_ANNEALING': False,
                 'NUM_CLASSES_DOWNSTREAM': 400,
                 'NUM_MLP_LAYERS': 1,
                 'PREDICTOR_DEPTHS': [],
                 'QUEUE_LEN': 65536,
                 'SEQUENTIAL': False,
                 'SIMCLR_DIST_ON': True,
                 'SWAV_QEUE_LEN': 0,
                 'T': 0.07,
                 'TYPE': 'mem'},
 'DATA': {'COLOR_RND_GRAYSCALE': 0.0,
          'CROP_PROMPT': False,
          'DECODING_BACKEND': 'torchvision',
          'DECODING_SHORT_SIZE': 256,
          'DUMMY_LOAD': False,
          'ENSEMBLE_METHOD': 'sum',
          'IN22K_TRAINVAL': False,
          'IN22k_VAL_IN1K': '',
          'INPUT_CHANNEL_NUM': [3],
          'INV_UNIFORM_SAMPLE': False,
          'IN_VAL_CROP_RATIO': 0.875,
          'LOADER_CHUNK_OVERALL_SIZE': 0,
          'LOADER_CHUNK_SIZE': 0,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 16,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '',
          'PATH_TO_PRELOAD_IMDB': '',
          'RANDOM_FLIP': False,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 4,
          'SKIP_ROWS': 0,
          'SSL_BLUR_SIGMA_MAX': [0.0, 2.0],
          'SSL_BLUR_SIGMA_MIN': [0.0, 0.1],
          'SSL_COLOR_BRI_CON_SAT': [0.4, 0.4, 0.4],
          'SSL_COLOR_HUE': 0.1,
          'SSL_COLOR_JITTER': False,
          'SSL_MOCOV2_AUG': False,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 30,
          'TEST_CROP_SIZE': 224,
          'TIME_DIFF_PROB': 0.0,
          'TRAIN_CROP_NUM_SPATIAL': 1,
          'TRAIN_CROP_NUM_TEMPORAL': 1,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333],
          'TRAIN_JITTER_FPS': 0.0,
          'TRAIN_JITTER_MOTION_SHIFT': False,
          'TRAIN_JITTER_SCALES': [256, 320],
          'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0],
          'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
          'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                               [-0.5808, -0.0045, -0.814],
                               [-0.5836, -0.6948, 0.4203]],
          'USE_OFFSET_SAMPLING': False},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 4,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': False,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 10,
 'MASK': {'DECODER_DEPTH': 0,
          'DECODER_EMBED_DIM': 512,
          'DECODER_SEP_POS_EMBED': False,
          'DEC_KV_KERNEL': [],
          'DEC_KV_STRIDE': [],
          'ENABLE': False,
          'HEAD_TYPE': 'separate',
          'MAE_ON': False,
          'MAE_RND_MASK': False,
          'NORM_PRED_PIXEL': True,
          'PER_FRAME_MASKING': False,
          'PRED_HOG': False,
          'PRETRAIN_DEPTH': [15],
          'SCALE_INIT_BY_DEPTH': False,
          'TIME_STRIDE_LOSS': True},
 'MIXUP': {'ALPHA': 0.8,
           'CUTMIX_ALPHA': 1.0,
           'ENABLE': False,
           'LABEL_SMOOTH_VALUE': 0.1,
           'PROB': 1.0,
           'SWITCH_PROB': 0.5},
 'MODEL': {'ACT_CHECKPOINT': False,
           'ARCH': 'mvit',
           'DETACH_FINAL_FC': False,
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'FP16_ALLREDUCE': False,
           'FROZEN_BN': False,
           'HEAD_ACT': 'softmax',
           'LOSS_FUNC': 'soft_cross_entropy',
           'MODEL_NAME': 'MViT',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 16,
           'SINGLE_PATHWAY_ARCH': ['2d',
                                   'c2d',
                                   'i3d',
                                   'slow',
                                   'x3d',
                                   'mvit',
                                   'maskmvit']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'MVIT': {'CLS_EMBED_ON': True,
          'DEPTH': 24,
          'DIM_MUL': [[2, 2.0], [5, 2.0], [21, 2.0]],
          'DIM_MUL_IN_ATT': True,
          'DROPOUT_RATE': 0.0,
          'DROPPATH_RATE': 0.3,
          'EMBED_DIM': 96,
          'HEAD_INIT_SCALE': 1.0,
          'HEAD_MUL': [[2, 2.0], [5, 2.0], [21, 2.0]],
          'LAYER_SCALE_INIT_VALUE': 0.0,
          'MLP_RATIO': 4.0,
          'MODE': 'conv',
          'NORM': 'layernorm',
          'NORM_STEM': False,
          'NUM_HEADS': 1,
          'PATCH_2D': False,
          'PATCH_KERNEL': [3, 7, 7],
          'PATCH_PADDING': [1, 3, 3],
          'PATCH_STRIDE': [2, 4, 4],
          'POOL_FIRST': False,
          'POOL_KVQ_KERNEL': [3, 3, 3],
          'POOL_KV_STRIDE': [],
          'POOL_KV_STRIDE_ADAPTIVE': [1, 8, 8],
          'POOL_Q_STRIDE': [[0, 1, 1, 1],
                            [1, 1, 1, 1],
                            [2, 1, 2, 2],
                            [3, 1, 1, 1],
                            [4, 1, 1, 1],
                            [5, 1, 2, 2],
                            [6, 1, 1, 1],
                            [7, 1, 1, 1],
                            [8, 1, 1, 1],
                            [9, 1, 1, 1],
                            [10, 1, 1, 1],
                            [11, 1, 1, 1],
                            [12, 1, 1, 1],
                            [13, 1, 1, 1],
                            [14, 1, 1, 1],
                            [15, 1, 1, 1],
                            [16, 1, 1, 1],
                            [17, 1, 1, 1],
                            [18, 1, 1, 1],
                            [19, 1, 1, 1],
                            [20, 1, 1, 1],
                            [21, 1, 2, 2],
                            [22, 1, 1, 1],
                            [23, 1, 1, 1]],
          'QKV_BIAS': True,
          'REL_POS_SPATIAL': True,
          'REL_POS_TEMPORAL': True,
          'REL_POS_ZERO_INIT': False,
          'RESIDUAL_POOLING': True,
          'REV': {'BUFFER_LAYERS': [],
                  'ENABLE': False,
                  'PRE_Q_FUSION': 'avg',
                  'RESPATH_FUSE': 'concat',
                  'RES_PATH': 'conv'},
          'SEPARATE_QKV': False,
          'SEP_POS_EMBED': False,
          'USE_ABS_POS': False,
          'USE_FIXED_SINCOS_POS': False,
          'USE_MEAN_POOLING': False,
          'ZERO_DECAY_POS_CLS': False},
 'NONLOCAL': {'GROUP': [[1], [1], [1], [1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[]], [[]], [[]], [[]]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 2,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1], [1], [1], [1]],
            'SPATIAL_STRIDES': [[1], [2], [2], [2]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': False,
            'ZERO_INIT_FINAL_CONV': False},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 8,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 5},
 'SOLVER': {'BASE_LR': 0.0002,
            'BASE_LR_SCALE_NUM_SHARDS': True,
            'BETAS': (0.9, 0.999),
            'CLIP_GRAD_L2NORM': 1.0,
            'CLIP_GRAD_VAL': None,
            'COSINE_AFTER_WARMUP': True,
            'COSINE_END_LR': 2e-05,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LARS_ON': False,
            'LAYER_DECAY': 1.0,
            'LRS': [],
            'LR_POLICY': 'cosine',
            'MAX_EPOCH': 400,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'adamw',
            'STEPS': [],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 30.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 2e-05,
            'WEIGHT_DECAY': 0.0001,
            'ZERO_WD_1D_PARAM': True},
 'TASK': '',
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': False,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 2,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'kinetics',
          'ENABLE': False,
          'NUM_ENSEMBLE_VIEWS': 5,
          'NUM_SPATIAL_CROPS': 1,
          'NUM_TEMPORAL_CLIPS': [],
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 16,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': True,
           'CHECKPOINT_FILE_PATH': 'checkpoints/MViTv2_B_32x3_k400_f304025456.pyth',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_IN_INIT': False,
           'CHECKPOINT_PERIOD': 20,
           'CHECKPOINT_TYPE': 'pytorch',
           'DATASET': 'kinetics',
           'ENABLE': True,
           'EVAL_PERIOD': 5,
           'KILL_LOSS_EXPLOSION_FACTOR': 0.0,
           'MIXED_PRECISION': False},
 'VIS_MASK': CfgNode({'ENABLE': False}),
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[06/23 20:56:13][INFO] misc.py:  185: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=96, bias=True)
        )
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=96, bias=True)
        )
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
      )
      (4): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
      )
      (5): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (6): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (7): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (8): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (9): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (10): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (11): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (12): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (13): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (16): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (17): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (18): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (19): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (20): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (21): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (22): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
      (23): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): TransformerBasicHead(
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=16, bias=True)
      (act): Softmax(dim=1)
    )
  )
)
[06/23 20:56:13][INFO] misc.py:  187: Params: 50,897,968
[06/23 20:56:13][INFO] misc.py:  188: Mem: 0.38045549392700195 MB
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
[06/23 20:56:17][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 729 time(s)
[06/23 20:56:17][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 102 time(s)
[06/23 20:56:17][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 144 time(s)
[06/23 20:56:17][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 96 time(s)
[06/23 20:56:17][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 120 time(s)
[06/23 20:56:17][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 25 time(s)
[06/23 20:56:17][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 24 time(s)
[06/23 20:56:17][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[06/23 20:56:17][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.16.drop_path, module.blocks.17.drop_path, module.blocks.18.drop_path, module.blocks.19.drop_path, module.blocks.2.drop_path, module.blocks.20.drop_path, module.blocks.21.drop_path, module.blocks.22.drop_path, module.blocks.23.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[06/23 20:56:17][INFO] misc.py:  190: Flops: 92.63208983999999 G
[06/23 20:56:20][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 121 time(s)
[06/23 20:56:20][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 729 time(s)
[06/23 20:56:20][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 102 time(s)
[06/23 20:56:20][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 144 time(s)
[06/23 20:56:20][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 96 time(s)
[06/23 20:56:20][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 120 time(s)
[06/23 20:56:20][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 25 time(s)
[06/23 20:56:20][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 24 time(s)
[06/23 20:56:20][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[06/23 20:56:20][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.16.drop_path, module.blocks.17.drop_path, module.blocks.18.drop_path, module.blocks.19.drop_path, module.blocks.2.drop_path, module.blocks.20.drop_path, module.blocks.21.drop_path, module.blocks.22.drop_path, module.blocks.23.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[06/23 20:56:20][INFO] misc.py:  191: Activations: 357.084096 M
[06/23 20:56:20][INFO] misc.py:  196: nvidia-smi
Fri Jun 23 20:56:20 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.182.03   Driver Version: 470.182.03   CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA RTX A5000    Off  | 00000000:17:00.0 Off |                  Off |
| 30%   50C    P2    69W / 230W |   4179MiB / 24256MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA RTX A5000    Off  | 00000000:65:00.0 Off |                  Off |
| 30%   53C    P2    68W / 230W |   1360MiB / 24247MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      1550      G   /usr/lib/xorg/Xorg                  4MiB |
|    0   N/A  N/A    792206      C   /usr/bin/python3                 4171MiB |
|    1   N/A  N/A      1550      G   /usr/lib/xorg/Xorg                 23MiB |
|    1   N/A  N/A      2487      G   /usr/bin/gnome-shell                5MiB |
|    1   N/A  N/A    792207      C   /usr/bin/python3                 1327MiB |
+-----------------------------------------------------------------------------+
bn 0, non bn 246, zero 343, no grad 0
[06/23 20:56:20][INFO] train_net.py:  594: Load from given checkpoint file.
[06/23 20:56:20][INFO] checkpoint.py:  223: Loading network weights from checkpoints/MViTv2_B_32x3_k400_f304025456.pyth.
[06/23 20:56:20][INFO] checkpoint.py:  487: blocks.0.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/23 20:56:20][INFO] checkpoint.py:  487: blocks.1.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/23 20:56:20][INFO] checkpoint.py:  487: blocks.2.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/23 20:56:20][INFO] checkpoint.py:  487: blocks.3.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/23 20:56:20][INFO] checkpoint.py:  487: blocks.4.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/23 20:56:20][INFO] checkpoint.py:  487: blocks.5.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/23 20:56:20][INFO] checkpoint.py:  487: blocks.6.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/23 20:56:20][INFO] checkpoint.py:  487: blocks.7.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/23 20:56:20][INFO] checkpoint.py:  487: blocks.8.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/23 20:56:20][INFO] checkpoint.py:  487: blocks.9.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/23 20:56:20][INFO] checkpoint.py:  487: blocks.10.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/23 20:56:20][INFO] checkpoint.py:  487: blocks.11.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/23 20:56:20][INFO] checkpoint.py:  487: blocks.12.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/23 20:56:20][INFO] checkpoint.py:  487: blocks.13.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/23 20:56:20][INFO] checkpoint.py:  487: blocks.14.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/23 20:56:20][INFO] checkpoint.py:  487: blocks.15.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/23 20:56:20][INFO] checkpoint.py:  487: blocks.16.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/23 20:56:20][INFO] checkpoint.py:  487: blocks.17.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/23 20:56:20][INFO] checkpoint.py:  487: blocks.18.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/23 20:56:20][INFO] checkpoint.py:  487: blocks.19.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/23 20:56:20][INFO] checkpoint.py:  487: blocks.20.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/23 20:56:20][INFO] checkpoint.py:  487: blocks.21.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/23 20:56:20][INFO] checkpoint.py:  487: blocks.22.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/23 20:56:20][INFO] checkpoint.py:  487: blocks.23.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/23 20:56:20][INFO] checkpoint.py:  542: Network weights head.projection.weight not loaded.
[06/23 20:56:20][INFO] checkpoint.py:  542: Network weights head.projection.bias not loaded.
[06/23 20:56:20][INFO] checkpoint.py:  545: Network weights head.projection.weight not used.
[06/23 20:56:20][INFO] checkpoint.py:  545: Network weights head.projection.bias not used.
missing keys: ['head.projection.weight', 'head.projection.bias']
unexpected keys: []
[06/23 20:56:20][INFO] kinetics.py:   93: Constructing Kinetics train...
[06/23 20:56:20][INFO] kinetics.py:  169: Constructing kinetics dataloader (size: 1927 skip_rows 0) from train.csv 
[06/23 20:56:20][INFO] kinetics.py:   93: Constructing Kinetics val...
[06/23 20:56:20][INFO] kinetics.py:  169: Constructing kinetics dataloader (size: 482 skip_rows 0) from val.csv 
[06/23 20:56:20][INFO] train_net.py:  647: Start epoch: 1
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
[06/23 20:56:32][INFO] distributed.py: 1027: Reducer buckets have been rebuilt in this iteration.
[06/23 20:56:44][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.28871, "dt_data": 0.00058, "dt_net": 1.28812, "epoch": "1/400", "eta": "17:10:44", "gpu_mem": "17.84G", "grad_norm": 3.90385, "iter": "10/120", "loss": 2.80121, "lr": 0.0000204500, "top1_acc": 6.25000, "top1_err": 93.75000, "top5_acc": 31.25000, "top5_err": 68.75000}
[06/23 20:56:56][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.28003, "dt_data": 0.00036, "dt_net": 1.27967, "epoch": "1/400", "eta": "17:03:36", "gpu_mem": "17.84G", "grad_norm": 3.96904, "iter": "20/120", "loss": 2.75712, "lr": 0.0000209500, "top1_acc": 6.25000, "top1_err": 93.75000, "top5_acc": 37.50000, "top5_err": 62.50000}
[06/23 20:57:09][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.27858, "dt_data": 0.00052, "dt_net": 1.27806, "epoch": "1/400", "eta": "17:02:13", "gpu_mem": "17.84G", "grad_norm": 4.12987, "iter": "30/120", "loss": 2.80517, "lr": 0.0000214500, "top1_acc": 6.25000, "top1_err": 93.75000, "top5_acc": 34.37500, "top5_err": 65.62500}
[06/23 20:57:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.30468, "dt_data": 0.00040, "dt_net": 1.30428, "epoch": "1/400", "eta": "17:22:52", "gpu_mem": "17.84G", "grad_norm": 3.68879, "iter": "40/120", "loss": 2.80098, "lr": 0.0000219500, "top1_acc": 0.00000, "top1_err": 100.00000, "top5_acc": 31.25000, "top5_err": 68.75000}
[06/23 20:57:36][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.29723, "dt_data": 0.00035, "dt_net": 1.29687, "epoch": "1/400", "eta": "17:16:42", "gpu_mem": "17.84G", "grad_norm": 4.00924, "iter": "50/120", "loss": 2.79744, "lr": 0.0000224500, "top1_acc": 3.12500, "top1_err": 96.87500, "top5_acc": 34.37500, "top5_err": 65.62500}
[06/23 20:57:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.31753, "dt_data": 0.00035, "dt_net": 1.31718, "epoch": "1/400", "eta": "17:32:42", "gpu_mem": "17.84G", "grad_norm": 3.83934, "iter": "60/120", "loss": 2.72079, "lr": 0.0000229500, "top1_acc": 9.37500, "top1_err": 90.62500, "top5_acc": 46.87500, "top5_err": 53.12500}
[06/23 20:58:02][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.31750, "dt_data": 0.00036, "dt_net": 1.31714, "epoch": "1/400", "eta": "17:32:27", "gpu_mem": "17.84G", "grad_norm": 3.63895, "iter": "70/120", "loss": 2.78281, "lr": 0.0000234500, "top1_acc": 6.25000, "top1_err": 93.75000, "top5_acc": 31.25000, "top5_err": 68.75000}
[06/23 20:58:15][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.32048, "dt_data": 0.00035, "dt_net": 1.32012, "epoch": "1/400", "eta": "17:34:37", "gpu_mem": "17.84G", "grad_norm": 4.00332, "iter": "80/120", "loss": 2.76027, "lr": 0.0000239500, "top1_acc": 6.25000, "top1_err": 93.75000, "top5_acc": 37.50000, "top5_err": 62.50000}
[06/23 20:58:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.31820, "dt_data": 0.00034, "dt_net": 1.31786, "epoch": "1/400", "eta": "17:32:35", "gpu_mem": "17.84G", "grad_norm": 3.97589, "iter": "90/120", "loss": 2.69763, "lr": 0.0000244500, "top1_acc": 12.50000, "top1_err": 87.50000, "top5_acc": 50.00000, "top5_err": 50.00000}
[06/23 20:58:42][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.33795, "dt_data": 0.00035, "dt_net": 1.33761, "epoch": "1/400", "eta": "17:48:07", "gpu_mem": "17.84G", "grad_norm": 4.01735, "iter": "100/120", "loss": 2.70383, "lr": 0.0000249500, "top1_acc": 15.62500, "top1_err": 84.37500, "top5_acc": 43.75000, "top5_err": 56.25000}
[06/23 20:58:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.33248, "dt_data": 0.00038, "dt_net": 1.33210, "epoch": "1/400", "eta": "17:43:32", "gpu_mem": "17.84G", "grad_norm": 3.95409, "iter": "110/120", "loss": 2.70409, "lr": 0.0000254500, "top1_acc": 9.37500, "top1_err": 90.62500, "top5_acc": 50.00000, "top5_err": 50.00000}
[06/23 20:59:08][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.34719, "dt_data": 0.00021, "dt_net": 1.34698, "epoch": "1/400", "eta": "17:55:03", "gpu_mem": "17.84G", "grad_norm": 4.53849, "iter": "120/120", "loss": 2.73454, "lr": 0.0000259500, "top1_acc": 6.25000, "top1_err": 93.75000, "top5_acc": 40.62500, "top5_err": 59.37500}
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
[06/23 20:59:09][INFO] logging.py:  101: json_stats: {"RAM": "12.16/31.07G", "_type": "train_epoch", "dt": 0.82187, "dt_data": 0.82187, "dt_net": 1.34698, "epoch": "1/400", "eta": "10:55:49", "gpu_mem": "17.84G", "grad_norm": 4.53849, "loss": 2.75138, "lr": 0.0000259500, "top1_acc": 9.37500, "top1_err": 90.62500, "top5_acc": 38.54167, "top5_err": 61.45833}
[06/23 20:59:09][INFO] train_net.py:  708: Epoch 0 takes 168.72s. Epochs from 0 to 0 take 168.72s in average and 168.72s in median.
[06/23 20:59:09][INFO] train_net.py:  714: For epoch 0, each iteraction takes 1.41s in average. From epoch 0 to 0, each iteraction takes 1.41s in average.
[06/23 20:59:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.32971, "dt_data": 0.00039, "dt_net": 1.32932, "epoch": "2/400", "eta": "17:40:53", "gpu_mem": "17.84G", "grad_norm": 4.26307, "iter": "10/120", "loss": 2.66342, "lr": 0.0000264500, "top1_acc": 18.75000, "top1_err": 81.25000, "top5_acc": 53.12500, "top5_err": 46.87500}
[06/23 20:59:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.33158, "dt_data": 0.00031, "dt_net": 1.33127, "epoch": "2/400", "eta": "17:42:09", "gpu_mem": "17.84G", "grad_norm": 3.78936, "iter": "20/120", "loss": 2.62565, "lr": 0.0000269500, "top1_acc": 21.87500, "top1_err": 78.12500, "top5_acc": 56.25000, "top5_err": 43.75000}
[06/23 20:59:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.30758, "dt_data": 0.00040, "dt_net": 1.30718, "epoch": "2/400", "eta": "17:22:47", "gpu_mem": "17.84G", "grad_norm": 4.54740, "iter": "30/120", "loss": 2.65933, "lr": 0.0000274500, "top1_acc": 12.50000, "top1_err": 87.50000, "top5_acc": 56.25000, "top5_err": 43.75000}
[06/23 21:00:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.33856, "dt_data": 0.00033, "dt_net": 1.33823, "epoch": "2/400", "eta": "17:47:16", "gpu_mem": "17.84G", "grad_norm": 3.93221, "iter": "40/120", "loss": 2.64661, "lr": 0.0000279500, "top1_acc": 18.75000, "top1_err": 81.25000, "top5_acc": 53.12500, "top5_err": 46.87500}
[06/23 21:00:26][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.34389, "dt_data": 0.00205, "dt_net": 1.34185, "epoch": "2/400", "eta": "17:51:18", "gpu_mem": "17.84G", "grad_norm": 4.00384, "iter": "50/120", "loss": 2.62770, "lr": 0.0000284500, "top1_acc": 18.75000, "top1_err": 81.25000, "top5_acc": 53.12500, "top5_err": 46.87500}
[06/23 21:00:39][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.32208, "dt_data": 0.00031, "dt_net": 1.32176, "epoch": "2/400", "eta": "17:33:41", "gpu_mem": "17.84G", "grad_norm": 3.89311, "iter": "60/120", "loss": 2.59583, "lr": 0.0000289500, "top1_acc": 18.75000, "top1_err": 81.25000, "top5_acc": 59.37500, "top5_err": 40.62500}
[06/23 21:00:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.34523, "dt_data": 0.00040, "dt_net": 1.34482, "epoch": "2/400", "eta": "17:51:55", "gpu_mem": "17.84G", "grad_norm": 3.90736, "iter": "70/120", "loss": 2.55894, "lr": 0.0000294500, "top1_acc": 21.87500, "top1_err": 78.12500, "top5_acc": 62.50000, "top5_err": 37.50000}
[06/23 21:01:06][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.32633, "dt_data": 0.00037, "dt_net": 1.32596, "epoch": "2/400", "eta": "17:36:38", "gpu_mem": "17.84G", "grad_norm": 4.61543, "iter": "80/120", "loss": 2.61463, "lr": 0.0000299500, "top1_acc": 21.87500, "top1_err": 78.12500, "top5_acc": 59.37500, "top5_err": 40.62500}
[06/23 21:01:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.32607, "dt_data": 0.00037, "dt_net": 1.32570, "epoch": "2/400", "eta": "17:36:13", "gpu_mem": "17.84G", "grad_norm": 4.31963, "iter": "90/120", "loss": 2.50400, "lr": 0.0000304500, "top1_acc": 25.00000, "top1_err": 75.00000, "top5_acc": 68.75000, "top5_err": 31.25000}
[06/23 21:01:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.33842, "dt_data": 0.00032, "dt_net": 1.33810, "epoch": "2/400", "eta": "17:45:49", "gpu_mem": "17.84G", "grad_norm": 4.82551, "iter": "100/120", "loss": 2.52393, "lr": 0.0000309500, "top1_acc": 28.12500, "top1_err": 71.87500, "top5_acc": 71.87500, "top5_err": 28.12500}
[06/23 21:01:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.30323, "dt_data": 0.00035, "dt_net": 1.30288, "epoch": "2/400", "eta": "17:17:35", "gpu_mem": "17.84G", "grad_norm": 4.27524, "iter": "110/120", "loss": 2.45277, "lr": 0.0000314500, "top1_acc": 31.25000, "top1_err": 68.75000, "top5_acc": 68.75000, "top5_err": 31.25000}
[06/23 21:01:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.33663, "dt_data": 0.00025, "dt_net": 1.33638, "epoch": "2/400", "eta": "17:43:57", "gpu_mem": "17.84G", "grad_norm": 4.11507, "iter": "120/120", "loss": 2.46399, "lr": 0.0000319500, "top1_acc": 21.87500, "top1_err": 78.12500, "top5_acc": 68.75000, "top5_err": 31.25000}
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
[06/23 21:02:00][INFO] logging.py:  101: json_stats: {"RAM": "12.24/31.07G", "_type": "train_epoch", "dt": 0.80301, "dt_data": 0.80301, "dt_net": 1.33638, "epoch": "2/400", "eta": "10:39:10", "gpu_mem": "17.84G", "grad_norm": 4.11507, "loss": 2.57310, "lr": 0.0000319500, "top1_acc": 21.04167, "top1_err": 78.95833, "top5_acc": 61.25000, "top5_err": 38.75000}
[06/23 21:02:00][INFO] train_net.py:  708: Epoch 1 takes 170.95s. Epochs from 0 to 1 take 169.84s in average and 169.84s in median.
[06/23 21:02:00][INFO] train_net.py:  714: For epoch 1, each iteraction takes 1.42s in average. From epoch 0 to 1, each iteraction takes 1.42s in average.
[06/23 21:02:24][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.32886, "dt_data": 0.00036, "dt_net": 1.32850, "epoch": "3/400", "eta": "17:37:33", "gpu_mem": "17.84G", "grad_norm": 4.64136, "iter": "10/120", "loss": 2.43337, "lr": 0.0000324500, "top1_acc": 28.12500, "top1_err": 71.87500, "top5_acc": 68.75000, "top5_err": 31.25000}
[06/23 21:02:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.36343, "dt_data": 0.00030, "dt_net": 1.36313, "epoch": "3/400", "eta": "18:04:50", "gpu_mem": "17.84G", "grad_norm": 4.57445, "iter": "20/120", "loss": 2.42123, "lr": 0.0000329500, "top1_acc": 28.12500, "top1_err": 71.87500, "top5_acc": 75.00000, "top5_err": 25.00000}
[06/23 21:02:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.35543, "dt_data": 0.00033, "dt_net": 1.35509, "epoch": "3/400", "eta": "17:58:14", "gpu_mem": "17.84G", "grad_norm": 4.56346, "iter": "30/120", "loss": 2.36233, "lr": 0.0000334500, "top1_acc": 37.50000, "top1_err": 62.50000, "top5_acc": 71.87500, "top5_err": 28.12500}
[06/23 21:03:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.33559, "dt_data": 0.00032, "dt_net": 1.33527, "epoch": "3/400", "eta": "17:42:14", "gpu_mem": "17.84G", "grad_norm": 4.75741, "iter": "40/120", "loss": 2.42039, "lr": 0.0000339500, "top1_acc": 25.00000, "top1_err": 75.00000, "top5_acc": 68.75000, "top5_err": 31.25000}
[06/23 21:03:17][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.34619, "dt_data": 0.00033, "dt_net": 1.34586, "epoch": "3/400", "eta": "17:50:26", "gpu_mem": "17.84G", "grad_norm": 4.68500, "iter": "50/120", "loss": 2.32940, "lr": 0.0000344500, "top1_acc": 25.00000, "top1_err": 75.00000, "top5_acc": 75.00000, "top5_err": 25.00000}
[06/23 21:03:30][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.35964, "dt_data": 0.00033, "dt_net": 1.35931, "epoch": "3/400", "eta": "18:00:54", "gpu_mem": "17.84G", "grad_norm": 4.09418, "iter": "60/120", "loss": 2.43526, "lr": 0.0000349500, "top1_acc": 28.12500, "top1_err": 71.87500, "top5_acc": 71.87500, "top5_err": 28.12500}
[06/23 21:03:44][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.32961, "dt_data": 0.00032, "dt_net": 1.32928, "epoch": "3/400", "eta": "17:36:48", "gpu_mem": "17.84G", "grad_norm": 4.68924, "iter": "70/120", "loss": 2.37079, "lr": 0.0000354500, "top1_acc": 28.12500, "top1_err": 71.87500, "top5_acc": 71.87500, "top5_err": 28.12500}
[06/23 21:03:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.34219, "dt_data": 0.00033, "dt_net": 1.34186, "epoch": "3/400", "eta": "17:46:35", "gpu_mem": "17.84G", "grad_norm": 4.14609, "iter": "80/120", "loss": 2.28139, "lr": 0.0000359500, "top1_acc": 31.25000, "top1_err": 68.75000, "top5_acc": 78.12500, "top5_err": 21.87500}
[06/23 21:04:10][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.34522, "dt_data": 0.00037, "dt_net": 1.34485, "epoch": "3/400", "eta": "17:48:46", "gpu_mem": "17.84G", "grad_norm": 4.55994, "iter": "90/120", "loss": 2.29370, "lr": 0.0000364500, "top1_acc": 31.25000, "top1_err": 68.75000, "top5_acc": 81.25000, "top5_err": 18.75000}
[06/23 21:04:24][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.34413, "dt_data": 0.00037, "dt_net": 1.34376, "epoch": "3/400", "eta": "17:47:41", "gpu_mem": "17.84G", "grad_norm": 4.02951, "iter": "100/120", "loss": 2.26909, "lr": 0.0000369500, "top1_acc": 31.25000, "top1_err": 68.75000, "top5_acc": 78.12500, "top5_err": 21.87500}
[06/23 21:04:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.33730, "dt_data": 0.00035, "dt_net": 1.33695, "epoch": "3/400", "eta": "17:42:02", "gpu_mem": "17.84G", "grad_norm": 4.47795, "iter": "110/120", "loss": 2.27099, "lr": 0.0000374500, "top1_acc": 37.50000, "top1_err": 62.50000, "top5_acc": 75.00000, "top5_err": 25.00000}
[06/23 21:04:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.32593, "dt_data": 0.00022, "dt_net": 1.32571, "epoch": "3/400", "eta": "17:32:47", "gpu_mem": "17.84G", "grad_norm": 4.77742, "iter": "120/120", "loss": 2.17914, "lr": 0.0000379500, "top1_acc": 37.50000, "top1_err": 62.50000, "top5_acc": 81.25000, "top5_err": 18.75000}
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
[06/23 21:04:51][INFO] logging.py:  101: json_stats: {"RAM": "12.23/31.07G", "_type": "train_epoch", "dt": 0.78723, "dt_data": 0.78723, "dt_net": 1.32571, "epoch": "3/400", "eta": "10:25:01", "gpu_mem": "17.84G", "grad_norm": 4.77742, "loss": 2.33536, "lr": 0.0000379500, "top1_acc": 30.88542, "top1_err": 69.11458, "top5_acc": 71.87500, "top5_err": 28.12500}
[06/23 21:04:51][INFO] train_net.py:  708: Epoch 2 takes 171.19s. Epochs from 0 to 2 take 170.29s in average and 170.95s in median.
[06/23 21:04:51][INFO] train_net.py:  714: For epoch 2, each iteraction takes 1.43s in average. From epoch 0 to 2, each iteraction takes 1.42s in average.
[06/23 21:05:15][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.31480, "dt_data": 0.00037, "dt_net": 1.31442, "epoch": "4/400", "eta": "17:23:43", "gpu_mem": "17.84G", "grad_norm": 5.03566, "iter": "10/120", "loss": 2.20810, "lr": 0.0000384500, "top1_acc": 28.12500, "top1_err": 71.87500, "top5_acc": 78.12500, "top5_err": 21.87500}
[06/23 21:05:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.32047, "dt_data": 0.00030, "dt_net": 1.32016, "epoch": "4/400", "eta": "17:28:00", "gpu_mem": "17.84G", "grad_norm": 4.79291, "iter": "20/120", "loss": 2.24415, "lr": 0.0000389500, "top1_acc": 31.25000, "top1_err": 68.75000, "top5_acc": 78.12500, "top5_err": 21.87500}
[06/23 21:05:42][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.31640, "dt_data": 0.00029, "dt_net": 1.31610, "epoch": "4/400", "eta": "17:24:33", "gpu_mem": "17.84G", "grad_norm": 6.20554, "iter": "30/120", "loss": 2.16698, "lr": 0.0000394500, "top1_acc": 31.25000, "top1_err": 68.75000, "top5_acc": 81.25000, "top5_err": 18.75000}
[06/23 21:05:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.36435, "dt_data": 0.00032, "dt_net": 1.36402, "epoch": "4/400", "eta": "18:02:22", "gpu_mem": "17.84G", "grad_norm": 7.40174, "iter": "40/120", "loss": 2.03829, "lr": 0.0000399500, "top1_acc": 37.50000, "top1_err": 62.50000, "top5_acc": 81.25000, "top5_err": 18.75000}
[06/23 21:06:08][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.33413, "dt_data": 0.00036, "dt_net": 1.33377, "epoch": "4/400", "eta": "17:38:11", "gpu_mem": "17.84G", "grad_norm": 4.54915, "iter": "50/120", "loss": 2.16460, "lr": 0.0000404500, "top1_acc": 31.25000, "top1_err": 68.75000, "top5_acc": 81.25000, "top5_err": 18.75000}
[06/23 21:06:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.33799, "dt_data": 0.00047, "dt_net": 1.33752, "epoch": "4/400", "eta": "17:41:01", "gpu_mem": "17.84G", "grad_norm": 5.28170, "iter": "60/120", "loss": 2.03703, "lr": 0.0000409500, "top1_acc": 31.25000, "top1_err": 68.75000, "top5_acc": 87.50000, "top5_err": 12.50000}
[06/23 21:06:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.32058, "dt_data": 0.00033, "dt_net": 1.32025, "epoch": "4/400", "eta": "17:26:59", "gpu_mem": "17.84G", "grad_norm": 4.59473, "iter": "70/120", "loss": 2.15500, "lr": 0.0000414500, "top1_acc": 31.25000, "top1_err": 68.75000, "top5_acc": 87.50000, "top5_err": 12.50000}
