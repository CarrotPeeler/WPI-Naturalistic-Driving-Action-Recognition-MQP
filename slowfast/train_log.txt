config files: ['configs/SLOWFAST_8x8_R50.yaml', 'DATA.PATH_TO_DATA_DIR', '.']
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
[06/12 17:36:12][INFO] train_net.py:  552: Train with config:
[06/12 17:36:12][INFO] train_net.py:  553: {'AUG': {'AA_TYPE': 'rand-m9-mstd0.5-inc1',
         'COLOR_JITTER': 0.4,
         'ENABLE': False,
         'GEN_MASK_LOADER': False,
         'INTERPOLATION': 'bicubic',
         'MASK_FRAMES': False,
         'MASK_RATIO': 0.0,
         'MASK_TUBE': False,
         'MASK_WINDOW_SIZE': [8, 7, 7],
         'MAX_MASK_PATCHES_PER_BLOCK': None,
         'NUM_SAMPLE': 1,
         'RE_COUNT': 1,
         'RE_MODE': 'pixel',
         'RE_PROB': 0.25,
         'RE_SPLIT': False},
 'AVA': {'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.9,
         'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv',
         'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/',
         'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'],
         'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'],
         'TRAIN_LISTS': ['train.csv'],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': [],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'GLOBAL_SYNC': False,
        'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': True,
        'WEIGHT_DECAY': 0.0},
 'CONTRASTIVE': {'BN_MLP': False,
                 'BN_SYNC_MLP': False,
                 'DELTA_CLIPS_MAX': inf,
                 'DELTA_CLIPS_MIN': -inf,
                 'DIM': 128,
                 'INTERP_MEMORY': False,
                 'KNN_ON': True,
                 'LENGTH': 239975,
                 'LOCAL_SHUFFLE_BN': True,
                 'MEM_TYPE': '1d',
                 'MLP_DIM': 2048,
                 'MOCO_MULTI_VIEW_QUEUE': False,
                 'MOMENTUM': 0.5,
                 'MOMENTUM_ANNEALING': False,
                 'NUM_CLASSES_DOWNSTREAM': 400,
                 'NUM_MLP_LAYERS': 1,
                 'PREDICTOR_DEPTHS': [],
                 'QUEUE_LEN': 65536,
                 'SEQUENTIAL': False,
                 'SIMCLR_DIST_ON': True,
                 'SWAV_QEUE_LEN': 0,
                 'T': 0.07,
                 'TYPE': 'mem'},
 'DATA': {'COLOR_RND_GRAYSCALE': 0.0,
          'DECODING_BACKEND': 'torchvision',
          'DECODING_SHORT_SIZE': 256,
          'DUMMY_LOAD': False,
          'ENSEMBLE_METHOD': 'sum',
          'IN22K_TRAINVAL': False,
          'IN22k_VAL_IN1K': '',
          'INPUT_CHANNEL_NUM': [3, 3],
          'INV_UNIFORM_SAMPLE': False,
          'IN_VAL_CROP_RATIO': 0.875,
          'LOADER_CHUNK_OVERALL_SIZE': 0,
          'LOADER_CHUNK_SIZE': 0,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 16,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '',
          'PATH_TO_PRELOAD_IMDB': '',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 4,
          'SKIP_ROWS': 0,
          'SSL_BLUR_SIGMA_MAX': [0.0, 2.0],
          'SSL_BLUR_SIGMA_MIN': [0.0, 0.1],
          'SSL_COLOR_BRI_CON_SAT': [0.4, 0.4, 0.4],
          'SSL_COLOR_HUE': 0.1,
          'SSL_COLOR_JITTER': False,
          'SSL_MOCOV2_AUG': False,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 30,
          'TEST_CROP_SIZE': 256,
          'TIME_DIFF_PROB': 0.0,
          'TRAIN_CROP_NUM_SPATIAL': 1,
          'TRAIN_CROP_NUM_TEMPORAL': 1,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_ASPECT_RELATIVE': [],
          'TRAIN_JITTER_FPS': 0.0,
          'TRAIN_JITTER_MOTION_SHIFT': False,
          'TRAIN_JITTER_SCALES': [256, 320],
          'TRAIN_JITTER_SCALES_RELATIVE': [],
          'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
          'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                               [-0.5808, -0.0045, -0.814],
                               [-0.5836, -0.6948, 0.4203]],
          'USE_OFFSET_SAMPLING': False},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 4,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': False,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 10,
 'MASK': {'DECODER_DEPTH': 0,
          'DECODER_EMBED_DIM': 512,
          'DECODER_SEP_POS_EMBED': False,
          'DEC_KV_KERNEL': [],
          'DEC_KV_STRIDE': [],
          'ENABLE': False,
          'HEAD_TYPE': 'separate',
          'MAE_ON': False,
          'MAE_RND_MASK': False,
          'NORM_PRED_PIXEL': True,
          'PER_FRAME_MASKING': False,
          'PRED_HOG': False,
          'PRETRAIN_DEPTH': [15],
          'SCALE_INIT_BY_DEPTH': False,
          'TIME_STRIDE_LOSS': True},
 'MIXUP': {'ALPHA': 0.8,
           'CUTMIX_ALPHA': 1.0,
           'ENABLE': False,
           'LABEL_SMOOTH_VALUE': 0.1,
           'PROB': 1.0,
           'SWITCH_PROB': 0.5},
 'MODEL': {'ACT_CHECKPOINT': False,
           'ARCH': 'slowfast',
           'DETACH_FINAL_FC': False,
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'FP16_ALLREDUCE': False,
           'FROZEN_BN': False,
           'HEAD_ACT': 'softmax',
           'LOSS_FUNC': 'cross_entropy',
           'MODEL_NAME': 'SlowFast',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 16,
           'SINGLE_PATHWAY_ARCH': ['2d',
                                   'c2d',
                                   'i3d',
                                   'slow',
                                   'x3d',
                                   'mvit',
                                   'maskmvit']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'MVIT': {'CLS_EMBED_ON': True,
          'DEPTH': 16,
          'DIM_MUL': [],
          'DIM_MUL_IN_ATT': False,
          'DROPOUT_RATE': 0.0,
          'DROPPATH_RATE': 0.1,
          'EMBED_DIM': 96,
          'HEAD_INIT_SCALE': 1.0,
          'HEAD_MUL': [],
          'LAYER_SCALE_INIT_VALUE': 0.0,
          'MLP_RATIO': 4.0,
          'MODE': 'conv',
          'NORM': 'layernorm',
          'NORM_STEM': False,
          'NUM_HEADS': 1,
          'PATCH_2D': False,
          'PATCH_KERNEL': [3, 7, 7],
          'PATCH_PADDING': [2, 4, 4],
          'PATCH_STRIDE': [2, 4, 4],
          'POOL_FIRST': False,
          'POOL_KVQ_KERNEL': None,
          'POOL_KV_STRIDE': [],
          'POOL_KV_STRIDE_ADAPTIVE': None,
          'POOL_Q_STRIDE': [],
          'QKV_BIAS': True,
          'REL_POS_SPATIAL': False,
          'REL_POS_TEMPORAL': False,
          'REL_POS_ZERO_INIT': False,
          'RESIDUAL_POOLING': False,
          'REV': {'BUFFER_LAYERS': [],
                  'ENABLE': False,
                  'PRE_Q_FUSION': 'avg',
                  'RESPATH_FUSE': 'concat',
                  'RES_PATH': 'conv'},
          'SEPARATE_QKV': False,
          'SEP_POS_EMBED': False,
          'USE_ABS_POS': True,
          'USE_FIXED_SINCOS_POS': False,
          'USE_MEAN_POOLING': False,
          'ZERO_DECAY_POS_CLS': True},
 'NONLOCAL': {'GROUP': [[1, 1], [1, 1], [1, 1], [1, 1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[], []], [[], []], [[], []], [[], []]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 2,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3, 3], [4, 4], [6, 6], [3, 3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1, 1], [1, 1], [1, 1], [1, 1]],
            'SPATIAL_STRIDES': [[1, 1], [2, 2], [2, 2], [2, 2]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': True,
            'ZERO_INIT_FINAL_CONV': False},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 4,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 7},
 'SOLVER': {'BASE_LR': 0.002,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'BETAS': (0.9, 0.999),
            'CLIP_GRAD_L2NORM': None,
            'CLIP_GRAD_VAL': None,
            'COSINE_AFTER_WARMUP': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LARS_ON': False,
            'LAYER_DECAY': 1.0,
            'LRS': [],
            'LR_POLICY': 'cosine',
            'MAX_EPOCH': 300,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'sgd',
            'STEPS': [],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 30.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 2e-05,
            'WEIGHT_DECAY': 0.0001,
            'ZERO_WD_1D_PARAM': False},
 'TASK': '',
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': False,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 2,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'kinetics',
          'ENABLE': False,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 3,
          'NUM_TEMPORAL_CLIPS': [],
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 32,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': 'checkpoints/SLOWFAST_8x8_R50.pkl',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_IN_INIT': False,
           'CHECKPOINT_PERIOD': 20,
           'CHECKPOINT_TYPE': 'caffe2',
           'DATASET': 'kinetics',
           'ENABLE': True,
           'EVAL_PERIOD': 5,
           'KILL_LOSS_EXPLOSION_FACTOR': 0.0,
           'MIXED_PRECISION': False},
 'VIS_MASK': CfgNode({'ENABLE': False}),
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[06/12 17:36:14][INFO] misc.py:  185: Model:
DistributedDataParallel(
  (module): SlowFast(
    (s1): VideoModelStem(
      (pathway0_stem): ResNetBasicStem(
        (conv): Conv3d(3, 64, kernel_size=(1, 7, 7), stride=(1, 2, 2), padding=(0, 3, 3), bias=False)
        (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (pathway1_stem): ResNetBasicStem(
        (conv): Conv3d(3, 8, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
        (bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
    )
    (s1_fuse): FuseFastToSlow(
      (conv_f2s): Conv3d(8, 16, kernel_size=(7, 1, 1), stride=(4, 1, 1), padding=(3, 0, 0), bias=False)
      (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (s2): ResStage(
      (pathway0_res0): ResBlock(
        (branch1): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (branch2): BottleneckTransform(
          (a): Conv3d(80, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway0_res1): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway0_res2): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway1_res0): ResBlock(
        (branch1): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (branch1_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (branch2): BottleneckTransform(
          (a): Conv3d(8, 8, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(8, 8, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway1_res1): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(32, 8, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(8, 8, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway1_res2): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(32, 8, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(8, 8, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
    )
    (s2_fuse): FuseFastToSlow(
      (conv_f2s): Conv3d(32, 64, kernel_size=(7, 1, 1), stride=(4, 1, 1), padding=(3, 0, 0), bias=False)
      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
    (pathway1_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
    (s3): ResStage(
      (pathway0_res0): ResBlock(
        (branch1): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)
        (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (branch2): BottleneckTransform(
          (a): Conv3d(320, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway0_res1): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway0_res2): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway0_res3): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway1_res0): ResBlock(
        (branch1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)
        (branch1_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (branch2): BottleneckTransform(
          (a): Conv3d(32, 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(16, 16, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(16, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway1_res1): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(64, 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(16, 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(16, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway1_res2): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(64, 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(16, 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(16, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway1_res3): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(64, 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(16, 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(16, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
    )
    (s3_fuse): FuseFastToSlow(
      (conv_f2s): Conv3d(64, 128, kernel_size=(7, 1, 1), stride=(4, 1, 1), padding=(3, 0, 0), bias=False)
      (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (s4): ResStage(
      (pathway0_res0): ResBlock(
        (branch1): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)
        (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (branch2): BottleneckTransform(
          (a): Conv3d(640, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway0_res1): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway0_res2): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway0_res3): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway0_res4): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway0_res5): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway1_res0): ResBlock(
        (branch1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)
        (branch1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (branch2): BottleneckTransform(
          (a): Conv3d(64, 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(32, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway1_res1): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(128, 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(32, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway1_res2): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(128, 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(32, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway1_res3): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(128, 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(32, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway1_res4): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(128, 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(32, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway1_res5): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(128, 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(32, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
    )
    (s4_fuse): FuseFastToSlow(
      (conv_f2s): Conv3d(128, 256, kernel_size=(7, 1, 1), stride=(4, 1, 1), padding=(3, 0, 0), bias=False)
      (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (s5): ResStage(
      (pathway0_res0): ResBlock(
        (branch1): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)
        (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (branch2): BottleneckTransform(
          (a): Conv3d(1280, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway0_res1): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(2048, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway0_res2): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(2048, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway1_res0): ResBlock(
        (branch1): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)
        (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (branch2): BottleneckTransform(
          (a): Conv3d(128, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway1_res1): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(256, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway1_res2): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(256, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
    )
    (head): ResNetBasicHead(
      (predictors): ModuleList()
      (pathway0_avgpool): AvgPool3d(kernel_size=[4, 7, 7], stride=1, padding=0)
      (pathway1_avgpool): AvgPool3d(kernel_size=[16, 7, 7], stride=1, padding=0)
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=2304, out_features=16, bias=True)
      (act): Softmax(dim=4)
    )
  )
)
[06/12 17:36:14][INFO] misc.py:  187: Params: 33,681,368
[06/12 17:36:14][INFO] misc.py:  188: Mem: 0.25213193893432617 MB
[06/12 17:36:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 4 time(s)
[06/12 17:36:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 32 time(s)
[06/12 17:36:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 2 time(s)
[06/12 17:36:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 1 time(s)
[06/12 17:36:15][INFO] misc.py:  190: Flops: 25.290446848 G
[06/12 17:36:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::batch_norm encountered 110 time(s)
[06/12 17:36:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 4 time(s)
[06/12 17:36:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 32 time(s)
[06/12 17:36:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 2 time(s)
[06/12 17:36:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 1 time(s)
[06/12 17:36:15][INFO] misc.py:  191: Activations: 68.289552 M
[06/12 17:36:15][INFO] misc.py:  196: nvidia-smi
Mon Jun 12 17:36:15 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.182.03   Driver Version: 470.182.03   CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA RTX A5000    Off  | 00000000:17:00.0 Off |                  Off |
| 30%   35C    P2    61W / 230W |   2429MiB / 24256MiB |      7%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA RTX A5000    Off  | 00000000:65:00.0 Off |                  Off |
| 30%   36C    P2    65W / 230W |   1155MiB / 24247MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      1550      G   /usr/lib/xorg/Xorg                  4MiB |
|    0   N/A  N/A   4001895      C   /usr/bin/python3                 2421MiB |
|    1   N/A  N/A      1550      G   /usr/lib/xorg/Xorg                 21MiB |
|    1   N/A  N/A      2487      G   /usr/bin/gnome-shell                5MiB |
|    1   N/A  N/A   4001896      C   /usr/bin/python3                 1125MiB |
+-----------------------------------------------------------------------------+
bn 220, non bn 112, zero 0, no grad 0
[06/12 17:36:16][INFO] train_net.py:  594: Load from given checkpoint file.
[06/12 17:36:16][INFO] checkpoint.py:  223: Loading network weights from checkpoints/SLOWFAST_8x8_R50.pkl.
[06/12 17:36:16][INFO] checkpoint.py:  264: res_conv1_bn_b: (64,) => s1.pathway0_stem.bn.bias: (64,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res5_2_branch2a_bn_riv: (512,) => s5.pathway0_res2.branch2.a_bn.running_var: (512,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_1_branch2c_bn_riv: (128,) => s4.pathway1_res1.branch2.c_bn.running_var: (128,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res3_2_branch2b_bn_rm: (16,) => s3.pathway1_res2.branch2.b_bn.running_mean: (16,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res_conv1_bn_s: (64,) => s1.pathway0_stem.bn.weight: (64,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res3_3_branch2b_bn_riv: (16,) => s3.pathway1_res3.branch2.b_bn.running_var: (16,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res4_4_branch2b_w: (256, 256, 1, 3, 3) => s4.pathway0_res4.branch2.b.weight: (256, 256, 1, 3, 3)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res2_1_branch2b_w: (8, 8, 1, 3, 3) => s2.pathway1_res1.branch2.b.weight: (8, 8, 1, 3, 3)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res5_1_branch2b_bn_riv: (64,) => s5.pathway1_res1.branch2.b_bn.running_var: (64,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_2_branch2a_bn_riv: (32,) => s4.pathway1_res2.branch2.a_bn.running_var: (32,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res3_1_branch2c_bn_s: (512,) => s3.pathway0_res1.branch2.c_bn.weight: (512,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res5_1_branch2b_w: (512, 512, 1, 3, 3) => s5.pathway0_res1.branch2.b.weight: (512, 512, 1, 3, 3)
[06/12 17:36:16][INFO] checkpoint.py:  264: res3_0_branch2a_bn_riv: (128,) => s3.pathway0_res0.branch2.a_bn.running_var: (128,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res2_2_branch2a_bn_rm: (8,) => s2.pathway1_res2.branch2.a_bn.running_mean: (8,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res5_0_branch1_bn_rm: (256,) => s5.pathway1_res0.branch1_bn.running_mean: (256,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res2_1_branch2b_bn_rm: (8,) => s2.pathway1_res1.branch2.b_bn.running_mean: (8,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res3_3_branch2c_bn_riv: (64,) => s3.pathway1_res3.branch2.c_bn.running_var: (64,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res2_2_branch2b_bn_rm: (64,) => s2.pathway0_res2.branch2.b_bn.running_mean: (64,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_3_branch2c_bn_rm: (128,) => s4.pathway1_res3.branch2.c_bn.running_mean: (128,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res3_3_branch2c_bn_riv: (512,) => s3.pathway0_res3.branch2.c_bn.running_var: (512,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res5_0_branch2c_bn_riv: (2048,) => s5.pathway0_res0.branch2.c_bn.running_var: (2048,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res3_2_branch2a_w: (128, 512, 1, 1, 1) => s3.pathway0_res2.branch2.a.weight: (128, 512, 1, 1, 1)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_5_branch2b_w: (32, 32, 1, 3, 3) => s4.pathway1_res5.branch2.b.weight: (32, 32, 1, 3, 3)
[06/12 17:36:16][INFO] checkpoint.py:  264: res3_0_branch1_bn_b: (512,) => s3.pathway0_res0.branch1_bn.bias: (512,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_pool1_subsample_bn_rm: (16,) => s1_fuse.bn.running_mean: (16,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res5_2_branch2c_bn_riv: (256,) => s5.pathway1_res2.branch2.c_bn.running_var: (256,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res3_2_branch2c_w: (512, 128, 1, 1, 1) => s3.pathway0_res2.branch2.c.weight: (512, 128, 1, 1, 1)
[06/12 17:36:16][INFO] checkpoint.py:  264: res2_2_branch2a_bn_riv: (64,) => s2.pathway0_res2.branch2.a_bn.running_var: (64,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res5_2_branch2a_bn_rm: (512,) => s5.pathway0_res2.branch2.a_bn.running_mean: (512,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res3_2_branch2b_bn_b: (16,) => s3.pathway1_res2.branch2.b_bn.bias: (16,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res3_1_branch2a_bn_b: (16,) => s3.pathway1_res1.branch2.a_bn.bias: (16,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res4_5_branch2a_w: (256, 1024, 3, 1, 1) => s4.pathway0_res5.branch2.a.weight: (256, 1024, 3, 1, 1)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res5_0_branch2c_bn_riv: (256,) => s5.pathway1_res0.branch2.c_bn.running_var: (256,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res2_0_branch2a_w: (8, 8, 3, 1, 1) => s2.pathway1_res0.branch2.a.weight: (8, 8, 3, 1, 1)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_2_branch2c_w: (128, 32, 1, 1, 1) => s4.pathway1_res2.branch2.c.weight: (128, 32, 1, 1, 1)
[06/12 17:36:16][INFO] checkpoint.py:  264: res2_2_branch2a_bn_b: (64,) => s2.pathway0_res2.branch2.a_bn.bias: (64,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res5_2_branch2c_bn_rm: (256,) => s5.pathway1_res2.branch2.c_bn.running_mean: (256,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res2_2_branch2a_bn_s: (64,) => s2.pathway0_res2.branch2.a_bn.weight: (64,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_1_branch2b_w: (32, 32, 1, 3, 3) => s4.pathway1_res1.branch2.b.weight: (32, 32, 1, 3, 3)
[06/12 17:36:16][INFO] checkpoint.py:  264: res5_1_branch2c_w: (2048, 512, 1, 1, 1) => s5.pathway0_res1.branch2.c.weight: (2048, 512, 1, 1, 1)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res5_2_branch2a_bn_s: (64,) => s5.pathway1_res2.branch2.a_bn.weight: (64,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_0_branch2c_bn_s: (128,) => s4.pathway1_res0.branch2.c_bn.weight: (128,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res5_1_branch2c_bn_rm: (2048,) => s5.pathway0_res1.branch2.c_bn.running_mean: (2048,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res5_2_branch2a_bn_b: (64,) => s5.pathway1_res2.branch2.a_bn.bias: (64,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res3_0_branch2c_bn_riv: (64,) => s3.pathway1_res0.branch2.c_bn.running_var: (64,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_0_branch2c_bn_b: (128,) => s4.pathway1_res0.branch2.c_bn.bias: (128,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res4_0_branch2b_w: (256, 256, 1, 3, 3) => s4.pathway0_res0.branch2.b.weight: (256, 256, 1, 3, 3)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_2_branch2c_bn_rm: (128,) => s4.pathway1_res2.branch2.c_bn.running_mean: (128,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_1_branch2b_bn_riv: (32,) => s4.pathway1_res1.branch2.b_bn.running_var: (32,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res3_2_branch2a_bn_b: (128,) => s3.pathway0_res2.branch2.a_bn.bias: (128,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res2_1_branch2b_bn_b: (8,) => s2.pathway1_res1.branch2.b_bn.bias: (8,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res4_4_branch2b_bn_b: (256,) => s4.pathway0_res4.branch2.b_bn.bias: (256,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_0_branch1_bn_rm: (128,) => s4.pathway1_res0.branch1_bn.running_mean: (128,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res5_0_branch2b_bn_riv: (64,) => s5.pathway1_res0.branch2.b_bn.running_var: (64,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res3_1_branch2c_bn_b: (512,) => s3.pathway0_res1.branch2.c_bn.bias: (512,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res4_0_branch2c_bn_riv: (1024,) => s4.pathway0_res0.branch2.c_bn.running_var: (1024,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_1_branch2a_bn_s: (32,) => s4.pathway1_res1.branch2.a_bn.weight: (32,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res3_3_branch2b_bn_riv: (128,) => s3.pathway0_res3.branch2.b_bn.running_var: (128,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res5_1_branch2a_bn_riv: (512,) => s5.pathway0_res1.branch2.a_bn.running_var: (512,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res4_4_branch2b_bn_s: (256,) => s4.pathway0_res4.branch2.b_bn.weight: (256,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res5_0_branch1_bn_rm: (2048,) => s5.pathway0_res0.branch1_bn.running_mean: (2048,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_1_branch2a_bn_b: (32,) => s4.pathway1_res1.branch2.a_bn.bias: (32,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res3_3_branch2c_bn_subsample_bn_s: (128,) => s3_fuse.bn.weight: (128,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res4_4_branch2a_bn_rm: (256,) => s4.pathway0_res4.branch2.a_bn.running_mean: (256,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res3_0_branch1_w: (512, 320, 1, 1, 1) => s3.pathway0_res0.branch1.weight: (512, 320, 1, 1, 1)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res3_0_branch2b_bn_rm: (16,) => s3.pathway1_res0.branch2.b_bn.running_mean: (16,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res3_3_branch2c_bn_subsample_bn_b: (128,) => s3_fuse.bn.bias: (128,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res5_0_branch2a_bn_riv: (512,) => s5.pathway0_res0.branch2.a_bn.running_var: (512,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_4_branch2a_bn_riv: (32,) => s4.pathway1_res4.branch2.a_bn.running_var: (32,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res4_5_branch2c_bn_riv: (1024,) => s4.pathway0_res5.branch2.c_bn.running_var: (1024,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res2_0_branch2c_bn_riv: (32,) => s2.pathway1_res0.branch2.c_bn.running_var: (32,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res2_2_branch2c_bn_s: (32,) => s2.pathway1_res2.branch2.c_bn.weight: (32,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_3_branch2a_bn_riv: (32,) => s4.pathway1_res3.branch2.a_bn.running_var: (32,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_5_branch2a_bn_s: (32,) => s4.pathway1_res5.branch2.a_bn.weight: (32,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res2_0_branch2b_bn_b: (8,) => s2.pathway1_res0.branch2.b_bn.bias: (8,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res2_2_branch2c_bn_b: (32,) => s2.pathway1_res2.branch2.c_bn.bias: (32,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_4_branch2b_bn_rm: (32,) => s4.pathway1_res4.branch2.b_bn.running_mean: (32,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res2_2_branch2b_bn_b: (8,) => s2.pathway1_res2.branch2.b_bn.bias: (8,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res3_0_branch1_bn_rm: (512,) => s3.pathway0_res0.branch1_bn.running_mean: (512,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res4_1_branch2c_w: (1024, 256, 1, 1, 1) => s4.pathway0_res1.branch2.c.weight: (1024, 256, 1, 1, 1)
[06/12 17:36:16][INFO] checkpoint.py:  264: res2_1_branch2c_bn_riv: (256,) => s2.pathway0_res1.branch2.c_bn.running_var: (256,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res5_2_branch2b_w: (64, 64, 1, 3, 3) => s5.pathway1_res2.branch2.b.weight: (64, 64, 1, 3, 3)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res2_0_branch2c_w: (32, 8, 1, 1, 1) => s2.pathway1_res0.branch2.c.weight: (32, 8, 1, 1, 1)
[06/12 17:36:16][INFO] checkpoint.py:  264: res4_5_branch2c_w: (1024, 256, 1, 1, 1) => s4.pathway0_res5.branch2.c.weight: (1024, 256, 1, 1, 1)
[06/12 17:36:16][INFO] checkpoint.py:  264: res3_3_branch2c_bn_b: (512,) => s3.pathway0_res3.branch2.c_bn.bias: (512,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res3_2_branch2c_bn_rm: (64,) => s3.pathway1_res2.branch2.c_bn.running_mean: (64,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_0_branch1_bn_riv: (128,) => s4.pathway1_res0.branch1_bn.running_var: (128,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res5_1_branch2b_bn_b: (64,) => s5.pathway1_res1.branch2.b_bn.bias: (64,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res5_1_branch2b_w: (64, 64, 1, 3, 3) => s5.pathway1_res1.branch2.b.weight: (64, 64, 1, 3, 3)
[06/12 17:36:16][INFO] checkpoint.py:  264: res3_3_branch2c_bn_s: (512,) => s3.pathway0_res3.branch2.c_bn.weight: (512,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res3_2_branch2b_w: (128, 128, 1, 3, 3) => s3.pathway0_res2.branch2.b.weight: (128, 128, 1, 3, 3)
[06/12 17:36:16][INFO] checkpoint.py:  264: res5_1_branch2a_w: (512, 2048, 3, 1, 1) => s5.pathway0_res1.branch2.a.weight: (512, 2048, 3, 1, 1)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res3_3_branch2a_bn_riv: (16,) => s3.pathway1_res3.branch2.a_bn.running_var: (16,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res2_2_branch2c_w: (32, 8, 1, 1, 1) => s2.pathway1_res2.branch2.c.weight: (32, 8, 1, 1, 1)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_5_branch2c_bn_subsample_bn_b: (256,) => s4_fuse.bn.bias: (256,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res4_5_branch2b_bn_b: (256,) => s4.pathway0_res5.branch2.b_bn.bias: (256,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res3_2_branch2a_bn_riv: (16,) => s3.pathway1_res2.branch2.a_bn.running_var: (16,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res2_2_branch2a_w: (8, 32, 3, 1, 1) => s2.pathway1_res2.branch2.a.weight: (8, 32, 3, 1, 1)
[06/12 17:36:16][INFO] checkpoint.py:  264: res2_0_branch1_bn_s: (256,) => s2.pathway0_res0.branch1_bn.weight: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_0_branch2b_bn_s: (8,) => s2.pathway1_res0.branch2.b_bn.weight: (8,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_5_branch2c_bn_subsample_bn_s: (256,) => s4_fuse.bn.weight: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_5_branch2b_bn_s: (256,) => s4.pathway0_res5.branch2.b_bn.weight: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_1_branch2b_bn_rm: (16,) => s3.pathway1_res1.branch2.b_bn.running_mean: (16,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res5_2_branch2b_bn_riv: (64,) => s5.pathway1_res2.branch2.b_bn.running_var: (64,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_4_branch2c_bn_b: (1024,) => s4.pathway0_res4.branch2.c_bn.bias: (1024,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_1_branch2c_bn_b: (32,) => s2.pathway1_res1.branch2.c_bn.bias: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res3_3_branch2b_bn_s: (128,) => s3.pathway0_res3.branch2.b_bn.weight: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_2_branch2c_bn_riv: (64,) => s3.pathway1_res2.branch2.c_bn.running_var: (64,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res2_1_branch2a_bn_rm: (64,) => s2.pathway0_res1.branch2.a_bn.running_mean: (64,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_5_branch2c_bn_subsample_bn_rm: (256,) => s4_fuse.bn.running_mean: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res5_1_branch2b_bn_b: (512,) => s5.pathway0_res1.branch2.b_bn.bias: (512,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res3_1_branch2a_bn_riv: (128,) => s3.pathway0_res1.branch2.a_bn.running_var: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res5_1_branch2b_bn_s: (512,) => s5.pathway0_res1.branch2.b_bn.weight: (512,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_4_branch2c_w: (1024, 256, 1, 1, 1) => s4.pathway0_res4.branch2.c.weight: (1024, 256, 1, 1, 1)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_1_branch2c_w: (32, 8, 1, 1, 1) => s2.pathway1_res1.branch2.c.weight: (32, 8, 1, 1, 1)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res5_0_branch1_w: (256, 128, 1, 1, 1) => s5.pathway1_res0.branch1.weight: (256, 128, 1, 1, 1)
[06/12 17:36:17][INFO] checkpoint.py:  264: res2_2_branch2c_bn_riv: (256,) => s2.pathway0_res2.branch2.c_bn.running_var: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_5_branch2c_bn_subsample_w: (256, 128, 7, 1, 1) => s4_fuse.conv_f2s.weight: (256, 128, 7, 1, 1)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_3_branch2b_bn_rm: (256,) => s4.pathway0_res3.branch2.b_bn.running_mean: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res_conv1_bn_rm: (8,) => s1.pathway1_stem.bn.running_mean: (8,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_2_branch2b_bn_riv: (16,) => s3.pathway1_res2.branch2.b_bn.running_var: (16,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_2_branch2c_bn_b: (1024,) => s4.pathway0_res2.branch2.c_bn.bias: (1024,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res3_3_branch2a_bn_riv: (128,) => s3.pathway0_res3.branch2.a_bn.running_var: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_1_branch2a_w: (16, 64, 3, 1, 1) => s3.pathway1_res1.branch2.a.weight: (16, 64, 3, 1, 1)
[06/12 17:36:17][INFO] checkpoint.py:  264: res2_2_branch2a_w: (64, 256, 1, 1, 1) => s2.pathway0_res2.branch2.a.weight: (64, 256, 1, 1, 1)
[06/12 17:36:17][INFO] checkpoint.py:  264: res2_0_branch2c_bn_riv: (256,) => s2.pathway0_res0.branch2.c_bn.running_var: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res2_0_branch2b_bn_riv: (64,) => s2.pathway0_res0.branch2.b_bn.running_var: (64,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res5_2_branch2b_bn_riv: (512,) => s5.pathway0_res2.branch2.b_bn.running_var: (512,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_4_branch2a_bn_rm: (32,) => s4.pathway1_res4.branch2.a_bn.running_mean: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_0_branch2a_bn_s: (32,) => s4.pathway1_res0.branch2.a_bn.weight: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_4_branch2a_bn_s: (32,) => s4.pathway1_res4.branch2.a_bn.weight: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_1_branch2c_w: (64, 16, 1, 1, 1) => s3.pathway1_res1.branch2.c.weight: (64, 16, 1, 1, 1)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_3_branch2b_bn_rm: (32,) => s4.pathway1_res3.branch2.b_bn.running_mean: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_1_branch2a_bn_s: (256,) => s4.pathway0_res1.branch2.a_bn.weight: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res2_1_branch2c_bn_b: (256,) => s2.pathway0_res1.branch2.c_bn.bias: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res3_2_branch2b_bn_b: (128,) => s3.pathway0_res2.branch2.b_bn.bias: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res3_1_branch2b_bn_s: (128,) => s3.pathway0_res1.branch2.b_bn.weight: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_1_branch2a_bn_b: (256,) => s4.pathway0_res1.branch2.a_bn.bias: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res3_1_branch2a_bn_b: (128,) => s3.pathway0_res1.branch2.a_bn.bias: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_1_branch2a_w: (8, 32, 3, 1, 1) => s2.pathway1_res1.branch2.a.weight: (8, 32, 3, 1, 1)
[06/12 17:36:17][INFO] checkpoint.py:  264: res2_1_branch2c_bn_s: (256,) => s2.pathway0_res1.branch2.c_bn.weight: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_5_branch2b_bn_rm: (32,) => s4.pathway1_res5.branch2.b_bn.running_mean: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res3_2_branch2b_bn_s: (128,) => s3.pathway0_res2.branch2.b_bn.weight: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_2_branch2a_bn_rm: (16,) => s3.pathway1_res2.branch2.a_bn.running_mean: (16,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_1_branch2c_bn_s: (32,) => s2.pathway1_res1.branch2.c_bn.weight: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res5_2_branch2c_bn_riv: (2048,) => s5.pathway0_res2.branch2.c_bn.running_var: (2048,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res5_1_branch2c_bn_s: (2048,) => s5.pathway0_res1.branch2.c_bn.weight: (2048,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_3_branch2a_bn_rm: (32,) => s4.pathway1_res3.branch2.a_bn.running_mean: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res5_1_branch2c_bn_b: (2048,) => s5.pathway0_res1.branch2.c_bn.bias: (2048,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_5_branch2a_bn_riv: (32,) => s4.pathway1_res5.branch2.a_bn.running_var: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res2_1_branch2b_bn_rm: (64,) => s2.pathway0_res1.branch2.b_bn.running_mean: (64,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_3_branch2a_bn_s: (16,) => s3.pathway1_res3.branch2.a_bn.weight: (16,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res5_0_branch2c_bn_b: (2048,) => s5.pathway0_res0.branch2.c_bn.bias: (2048,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_0_branch2c_bn_b: (64,) => s3.pathway1_res0.branch2.c_bn.bias: (64,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_4_branch2b_bn_rm: (256,) => s4.pathway0_res4.branch2.b_bn.running_mean: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res5_1_branch2b_bn_rm: (512,) => s5.pathway0_res1.branch2.b_bn.running_mean: (512,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res5_0_branch2b_w: (512, 512, 1, 3, 3) => s5.pathway0_res0.branch2.b.weight: (512, 512, 1, 3, 3)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_1_branch2b_bn_riv: (8,) => s2.pathway1_res1.branch2.b_bn.running_var: (8,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_0_branch2c_bn_s: (64,) => s3.pathway1_res0.branch2.c_bn.weight: (64,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_1_branch2a_bn_s: (8,) => s2.pathway1_res1.branch2.a_bn.weight: (8,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_4_branch2a_bn_s: (256,) => s4.pathway0_res4.branch2.a_bn.weight: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_2_branch2b_bn_s: (16,) => s3.pathway1_res2.branch2.b_bn.weight: (16,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_0_branch2c_bn_rm: (128,) => s4.pathway1_res0.branch2.c_bn.running_mean: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_2_branch2b_bn_s: (256,) => s4.pathway0_res2.branch2.b_bn.weight: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_1_branch2a_bn_b: (8,) => s2.pathway1_res1.branch2.a_bn.bias: (8,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_4_branch2a_bn_b: (256,) => s4.pathway0_res4.branch2.a_bn.bias: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_5_branch2c_bn_subsample_bn_riv: (256,) => s4_fuse.bn.running_var: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_2_branch2b_bn_b: (256,) => s4.pathway0_res2.branch2.b_bn.bias: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res5_2_branch2c_w: (256, 64, 1, 1, 1) => s5.pathway1_res2.branch2.c.weight: (256, 64, 1, 1, 1)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_3_branch2c_bn_rm: (1024,) => s4.pathway0_res3.branch2.c_bn.running_mean: (1024,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_3_branch2a_bn_b: (32,) => s4.pathway1_res3.branch2.a_bn.bias: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_0_branch2c_w: (64, 16, 1, 1, 1) => s3.pathway1_res0.branch2.c.weight: (64, 16, 1, 1, 1)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_2_branch2a_w: (32, 128, 3, 1, 1) => s4.pathway1_res2.branch2.a.weight: (32, 128, 3, 1, 1)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_5_branch2b_w: (256, 256, 1, 3, 3) => s4.pathway0_res5.branch2.b.weight: (256, 256, 1, 3, 3)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_3_branch2a_bn_s: (32,) => s4.pathway1_res3.branch2.a_bn.weight: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_3_branch2c_bn_riv: (1024,) => s4.pathway0_res3.branch2.c_bn.running_var: (1024,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_2_branch2a_bn_rm: (32,) => s4.pathway1_res2.branch2.a_bn.running_mean: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res3_2_branch2a_bn_rm: (128,) => s3.pathway0_res2.branch2.a_bn.running_mean: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_2_branch2c_bn_rm: (1024,) => s4.pathway0_res2.branch2.c_bn.running_mean: (1024,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_0_branch2c_bn_rm: (1024,) => s4.pathway0_res0.branch2.c_bn.running_mean: (1024,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res5_1_branch2c_bn_riv: (256,) => s5.pathway1_res1.branch2.c_bn.running_var: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_4_branch2c_bn_rm: (128,) => s4.pathway1_res4.branch2.c_bn.running_mean: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res3_0_branch2a_bn_s: (128,) => s3.pathway0_res0.branch2.a_bn.weight: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_0_branch2b_bn_riv: (16,) => s3.pathway1_res0.branch2.b_bn.running_var: (16,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_3_branch2c_bn_subsample_bn_rm: (128,) => s3_fuse.bn.running_mean: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res3_0_branch2a_bn_b: (128,) => s3.pathway0_res0.branch2.a_bn.bias: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_4_branch2a_w: (256, 1024, 3, 1, 1) => s4.pathway0_res4.branch2.a.weight: (256, 1024, 3, 1, 1)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_2_branch2c_bn_riv: (32,) => s2.pathway1_res2.branch2.c_bn.running_var: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_3_branch2a_bn_rm: (16,) => s3.pathway1_res3.branch2.a_bn.running_mean: (16,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_2_branch2b_w: (8, 8, 1, 3, 3) => s2.pathway1_res2.branch2.b.weight: (8, 8, 1, 3, 3)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_0_branch2a_bn_rm: (8,) => s2.pathway1_res0.branch2.a_bn.running_mean: (8,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_0_branch2c_bn_rm: (64,) => s3.pathway1_res0.branch2.c_bn.running_mean: (64,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_5_branch2a_bn_rm: (256,) => s4.pathway0_res5.branch2.a_bn.running_mean: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_4_branch2b_bn_s: (32,) => s4.pathway1_res4.branch2.b_bn.weight: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res5_0_branch2b_bn_riv: (512,) => s5.pathway0_res0.branch2.b_bn.running_var: (512,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_1_branch2b_bn_b: (32,) => s4.pathway1_res1.branch2.b_bn.bias: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res3_1_branch2c_bn_rm: (512,) => s3.pathway0_res1.branch2.c_bn.running_mean: (512,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_4_branch2b_bn_b: (32,) => s4.pathway1_res4.branch2.b_bn.bias: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res3_1_branch2a_bn_s: (128,) => s3.pathway0_res1.branch2.a_bn.weight: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_3_branch2c_bn_b: (64,) => s3.pathway1_res3.branch2.c_bn.bias: (64,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_1_branch2b_bn_s: (32,) => s4.pathway1_res1.branch2.b_bn.weight: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_4_branch2a_bn_b: (32,) => s4.pathway1_res4.branch2.a_bn.bias: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res5_1_branch2a_bn_s: (512,) => s5.pathway0_res1.branch2.a_bn.weight: (512,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_0_branch2a_bn_riv: (256,) => s4.pathway0_res0.branch2.a_bn.running_var: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res5_1_branch2a_bn_b: (512,) => s5.pathway0_res1.branch2.a_bn.bias: (512,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_2_branch2b_bn_riv: (256,) => s4.pathway0_res2.branch2.b_bn.running_var: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_2_branch2b_bn_rm: (8,) => s2.pathway1_res2.branch2.b_bn.running_mean: (8,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res3_0_branch2c_w: (512, 128, 1, 1, 1) => s3.pathway0_res0.branch2.c.weight: (512, 128, 1, 1, 1)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_0_branch2a_bn_s: (16,) => s3.pathway1_res0.branch2.a_bn.weight: (16,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_2_branch2c_bn_riv: (128,) => s4.pathway1_res2.branch2.c_bn.running_var: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_0_branch2a_bn_b: (16,) => s3.pathway1_res0.branch2.a_bn.bias: (16,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_1_branch2a_bn_riv: (16,) => s3.pathway1_res1.branch2.a_bn.running_var: (16,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_0_branch2b_bn_riv: (8,) => s2.pathway1_res0.branch2.b_bn.running_var: (8,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_1_branch2a_bn_s: (16,) => s3.pathway1_res1.branch2.a_bn.weight: (16,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_5_branch2b_bn_riv: (256,) => s4.pathway0_res5.branch2.b_bn.running_var: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res5_2_branch2b_bn_rm: (512,) => s5.pathway0_res2.branch2.b_bn.running_mean: (512,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_3_branch2c_bn_s: (64,) => s3.pathway1_res3.branch2.c_bn.weight: (64,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_0_branch1_bn_riv: (32,) => s2.pathway1_res0.branch1_bn.running_var: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res2_2_branch2b_bn_riv: (64,) => s2.pathway0_res2.branch2.b_bn.running_var: (64,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res2_0_branch1_bn_rm: (256,) => s2.pathway0_res0.branch1_bn.running_mean: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res2_2_branch2b_w: (64, 64, 1, 3, 3) => s2.pathway0_res2.branch2.b.weight: (64, 64, 1, 3, 3)
[06/12 17:36:17][INFO] checkpoint.py:  264: res2_1_branch2a_bn_riv: (64,) => s2.pathway0_res1.branch2.a_bn.running_var: (64,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_2_branch2b_bn_rm: (32,) => s4.pathway1_res2.branch2.b_bn.running_mean: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_2_branch2a_bn_riv: (256,) => s4.pathway0_res2.branch2.a_bn.running_var: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_2_branch2c_bn_s: (1024,) => s4.pathway0_res2.branch2.c_bn.weight: (1024,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res3_3_branch2a_bn_s: (128,) => s3.pathway0_res3.branch2.a_bn.weight: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_0_branch2a_bn_riv: (8,) => s2.pathway1_res0.branch2.a_bn.running_var: (8,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res3_0_branch2b_w: (128, 128, 1, 3, 3) => s3.pathway0_res0.branch2.b.weight: (128, 128, 1, 3, 3)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_5_branch2a_bn_riv: (256,) => s4.pathway0_res5.branch2.a_bn.running_var: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_3_branch2b_bn_rm: (16,) => s3.pathway1_res3.branch2.b_bn.running_mean: (16,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_0_branch1_bn_s: (32,) => s2.pathway1_res0.branch1_bn.weight: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_0_branch2b_bn_riv: (256,) => s4.pathway0_res0.branch2.b_bn.running_var: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_0_branch2b_bn_riv: (32,) => s4.pathway1_res0.branch2.b_bn.running_var: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_0_branch2b_bn_b: (16,) => s3.pathway1_res0.branch2.b_bn.bias: (16,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_0_branch1_bn_b: (32,) => s2.pathway1_res0.branch1_bn.bias: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res5_0_branch1_bn_s: (256,) => s5.pathway1_res0.branch1_bn.weight: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res5_1_branch2b_bn_s: (64,) => s5.pathway1_res1.branch2.b_bn.weight: (64,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_0_branch1_bn_riv: (64,) => s3.pathway1_res0.branch1_bn.running_var: (64,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_2_branch2c_bn_subsample_bn_s: (64,) => s2_fuse.bn.weight: (64,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res5_0_branch2c_w: (2048, 512, 1, 1, 1) => s5.pathway0_res0.branch2.c.weight: (2048, 512, 1, 1, 1)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_5_branch2c_bn_s: (128,) => s4.pathway1_res5.branch2.c_bn.weight: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res5_0_branch2b_bn_rm: (64,) => s5.pathway1_res0.branch2.b_bn.running_mean: (64,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_5_branch2b_bn_s: (32,) => s4.pathway1_res5.branch2.b_bn.weight: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_5_branch2b_bn_riv: (32,) => s4.pathway1_res5.branch2.b_bn.running_var: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res5_2_branch2a_w: (512, 2048, 3, 1, 1) => s5.pathway0_res2.branch2.a.weight: (512, 2048, 3, 1, 1)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res5_1_branch2a_w: (64, 256, 3, 1, 1) => s5.pathway1_res1.branch2.a.weight: (64, 256, 3, 1, 1)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_3_branch2b_bn_riv: (32,) => s4.pathway1_res3.branch2.b_bn.running_var: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_2_branch2c_bn_subsample_bn_b: (64,) => s2_fuse.bn.bias: (64,)
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
!! pred_b: (400,) does not match head.projection.bias: (16,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_5_branch2c_bn_b: (128,) => s4.pathway1_res5.branch2.c_bn.bias: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_5_branch2b_bn_b: (32,) => s4.pathway1_res5.branch2.b_bn.bias: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res2_0_branch2c_bn_rm: (256,) => s2.pathway0_res0.branch2.c_bn.running_mean: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res5_0_branch1_w: (2048, 1280, 1, 1, 1) => s5.pathway0_res0.branch1.weight: (2048, 1280, 1, 1, 1)
[06/12 17:36:17][INFO] checkpoint.py:  264: res2_2_branch2c_bn_b: (256,) => s2.pathway0_res2.branch2.c_bn.bias: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_5_branch2c_bn_b: (1024,) => s4.pathway0_res5.branch2.c_bn.bias: (1024,)
!! pred_w: (400, 2304) does not match head.projection.weight: (16, 2304)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_2_branch2c_bn_subsample_bn_rm: (64,) => s2_fuse.bn.running_mean: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res2_0_branch2c_bn_b: (32,) => s2.pathway1_res0.branch2.c_bn.bias: (32,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_3_branch2b_bn_s: (256,) => s4.pathway0_res3.branch2.b_bn.weight: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_2_branch2c_bn_riv: (512,) => s3.pathway0_res2.branch2.c_bn.running_var: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res5_0_branch2a_w: (512, 1280, 3, 1, 1) => s5.pathway0_res0.branch2.a.weight: (512, 1280, 3, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res2_0_branch2c_bn_s: (32,) => s2.pathway1_res0.branch2.c_bn.weight: (32,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res2_1_branch2a_bn_rm: (8,) => s2.pathway1_res1.branch2.a_bn.running_mean: (8,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res2_0_branch2b_bn_rm: (64,) => s2.pathway0_res0.branch2.b_bn.running_mean: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res2_2_branch2a_bn_rm: (64,) => s2.pathway0_res2.branch2.a_bn.running_mean: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res3_0_branch2a_bn_riv: (16,) => s3.pathway1_res0.branch2.a_bn.running_var: (16,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res4_5_branch2a_bn_rm: (32,) => s4.pathway1_res5.branch2.a_bn.running_mean: (32,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res3_0_branch2b_bn_s: (16,) => s3.pathway1_res0.branch2.b_bn.weight: (16,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res3_2_branch2a_bn_b: (16,) => s3.pathway1_res2.branch2.a_bn.bias: (16,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res5_2_branch2b_bn_b: (64,) => s5.pathway1_res2.branch2.b_bn.bias: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res5_1_branch2a_bn_rm: (512,) => s5.pathway0_res1.branch2.a_bn.running_mean: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res4_0_branch2a_bn_b: (32,) => s4.pathway1_res0.branch2.a_bn.bias: (32,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res5_2_branch2b_w: (512, 512, 1, 3, 3) => s5.pathway0_res2.branch2.b.weight: (512, 512, 1, 3, 3)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res2_2_branch2a_bn_riv: (8,) => s2.pathway1_res2.branch2.a_bn.running_var: (8,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res2_1_branch2c_bn_riv: (32,) => s2.pathway1_res1.branch2.c_bn.running_var: (32,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res5_2_branch2b_bn_s: (64,) => s5.pathway1_res2.branch2.b_bn.weight: (64,)
Not loaded {'head.projection.bias', 'head.projection.weight'}
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res5_1_branch2a_bn_rm: (64,) => s5.pathway1_res1.branch2.a_bn.running_mean: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_0_branch2c_bn_b: (1024,) => s4.pathway0_res0.branch2.c_bn.bias: (1024,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_2_branch2a_w: (256, 1024, 3, 1, 1) => s4.pathway0_res2.branch2.a.weight: (256, 1024, 3, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res3_0_branch2a_w: (16, 32, 3, 1, 1) => s3.pathway1_res0.branch2.a.weight: (16, 32, 3, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_0_branch2c_bn_s: (1024,) => s4.pathway0_res0.branch2.c_bn.weight: (1024,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_3_branch2b_bn_b: (128,) => s3.pathway0_res3.branch2.b_bn.bias: (128,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res5_1_branch2c_bn_riv: (2048,) => s5.pathway0_res1.branch2.c_bn.running_var: (2048,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res3_0_branch1_w: (64, 32, 1, 1, 1) => s3.pathway1_res0.branch1.weight: (64, 32, 1, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_1_branch2a_bn_riv: (256,) => s4.pathway0_res1.branch2.a_bn.running_var: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: conv1_w: (64, 3, 1, 7, 7) => s1.pathway0_stem.conv.weight: (64, 3, 1, 7, 7)
[06/12 17:36:18][INFO] checkpoint.py:  264: res2_0_branch1_bn_riv: (256,) => s2.pathway0_res0.branch1_bn.running_var: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_2_branch2c_bn_rm: (512,) => s3.pathway0_res2.branch2.c_bn.running_mean: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_4_branch2c_bn_s: (1024,) => s4.pathway0_res4.branch2.c_bn.weight: (1024,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_1_branch2c_bn_b: (1024,) => s4.pathway0_res1.branch2.c_bn.bias: (1024,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res5_0_branch2b_bn_rm: (512,) => s5.pathway0_res0.branch2.b_bn.running_mean: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res5_1_branch2c_bn_s: (256,) => s5.pathway1_res1.branch2.c_bn.weight: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res2_1_branch2c_bn_rm: (32,) => s2.pathway1_res1.branch2.c_bn.running_mean: (32,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_4_branch2b_bn_riv: (256,) => s4.pathway0_res4.branch2.b_bn.running_var: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_1_branch2c_bn_s: (1024,) => s4.pathway0_res1.branch2.c_bn.weight: (1024,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_1_branch2c_bn_riv: (1024,) => s4.pathway0_res1.branch2.c_bn.running_var: (1024,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res5_1_branch2c_bn_b: (256,) => s5.pathway1_res1.branch2.c_bn.bias: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_5_branch2b_bn_rm: (256,) => s4.pathway0_res5.branch2.b_bn.running_mean: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res4_5_branch2a_w: (32, 128, 3, 1, 1) => s4.pathway1_res5.branch2.a.weight: (32, 128, 3, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res5_0_branch2a_bn_b: (64,) => s5.pathway1_res0.branch2.a_bn.bias: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_1_branch2b_bn_rm: (128,) => s3.pathway0_res1.branch2.b_bn.running_mean: (128,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_pool1_subsample_bn_riv: (16,) => s1_fuse.bn.running_var: (16,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_1_branch2a_bn_rm: (256,) => s4.pathway0_res1.branch2.a_bn.running_mean: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res5_0_branch2a_bn_s: (64,) => s5.pathway1_res0.branch2.a_bn.weight: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res2_1_branch2c_w: (256, 64, 1, 1, 1) => s2.pathway0_res1.branch2.c.weight: (256, 64, 1, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res3_1_branch2b_bn_s: (16,) => s3.pathway1_res1.branch2.b_bn.weight: (16,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res2_0_branch2a_bn_riv: (64,) => s2.pathway0_res0.branch2.a_bn.running_var: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res5_0_branch2a_bn_rm: (512,) => s5.pathway0_res0.branch2.a_bn.running_mean: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_0_branch2c_bn_riv: (512,) => s3.pathway0_res0.branch2.c_bn.running_var: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_2_branch2c_bn_s: (512,) => s3.pathway0_res2.branch2.c_bn.weight: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res3_1_branch2b_bn_b: (16,) => s3.pathway1_res1.branch2.b_bn.bias: (16,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res3_2_branch2a_bn_s: (16,) => s3.pathway1_res2.branch2.a_bn.weight: (16,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res4_4_branch2c_bn_s: (128,) => s4.pathway1_res4.branch2.c_bn.weight: (128,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res2_2_branch2b_bn_riv: (8,) => s2.pathway1_res2.branch2.b_bn.running_var: (8,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res5_0_branch2a_bn_b: (512,) => s5.pathway0_res0.branch2.a_bn.bias: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res4_4_branch2c_bn_b: (128,) => s4.pathway1_res4.branch2.c_bn.bias: (128,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_1_branch2b_bn_b: (128,) => s3.pathway0_res1.branch2.b_bn.bias: (128,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_2_branch2a_bn_s: (128,) => s3.pathway0_res2.branch2.a_bn.weight: (128,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res4_1_branch2a_bn_rm: (32,) => s4.pathway1_res1.branch2.a_bn.running_mean: (32,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res5_0_branch2a_bn_s: (512,) => s5.pathway0_res0.branch2.a_bn.weight: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res5_2_branch2c_bn_b: (256,) => s5.pathway1_res2.branch2.c_bn.bias: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res4_0_branch2b_bn_rm: (32,) => s4.pathway1_res0.branch2.b_bn.running_mean: (32,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res4_0_branch1_w: (128, 64, 1, 1, 1) => s4.pathway1_res0.branch1.weight: (128, 64, 1, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_0_branch2b_bn_s: (256,) => s4.pathway0_res0.branch2.b_bn.weight: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_2_branch2a_bn_b: (256,) => s4.pathway0_res2.branch2.a_bn.bias: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res5_2_branch2b_bn_s: (512,) => s5.pathway0_res2.branch2.b_bn.weight: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_3_branch2c_bn_s: (1024,) => s4.pathway0_res3.branch2.c_bn.weight: (1024,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_2_branch2a_bn_s: (256,) => s4.pathway0_res2.branch2.a_bn.weight: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res5_2_branch2b_bn_b: (512,) => s5.pathway0_res2.branch2.b_bn.bias: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res2_0_branch1_bn_rm: (32,) => s2.pathway1_res0.branch1_bn.running_mean: (32,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_1_branch2a_w: (128, 512, 1, 1, 1) => s3.pathway0_res1.branch2.a.weight: (128, 512, 1, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_3_branch2c_bn_b: (1024,) => s4.pathway0_res3.branch2.c_bn.bias: (1024,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_0_branch2b_bn_rm: (128,) => s3.pathway0_res0.branch2.b_bn.running_mean: (128,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res5_0_branch2b_bn_b: (512,) => s5.pathway0_res0.branch2.b_bn.bias: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res5_2_branch2a_bn_b: (512,) => s5.pathway0_res2.branch2.a_bn.bias: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res5_0_branch1_bn_riv: (256,) => s5.pathway1_res0.branch1_bn.running_var: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res3_0_branch1_bn_b: (64,) => s3.pathway1_res0.branch1_bn.bias: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res4_1_branch2c_bn_b: (128,) => s4.pathway1_res1.branch2.c_bn.bias: (128,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_3_branch2a_bn_b: (128,) => s3.pathway0_res3.branch2.a_bn.bias: (128,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res4_0_branch2c_w: (128, 32, 1, 1, 1) => s4.pathway1_res0.branch2.c.weight: (128, 32, 1, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: res5_2_branch2a_bn_s: (512,) => s5.pathway0_res2.branch2.a_bn.weight: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res3_0_branch1_bn_s: (64,) => s3.pathway1_res0.branch1_bn.weight: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res4_1_branch2c_bn_s: (128,) => s4.pathway1_res1.branch2.c_bn.weight: (128,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res2_0_branch1_bn_b: (256,) => s2.pathway0_res0.branch1_bn.bias: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_1_branch2b_bn_riv: (256,) => s4.pathway0_res1.branch2.b_bn.running_var: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_0_branch2b_bn_rm: (256,) => s4.pathway0_res0.branch2.b_bn.running_mean: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_0_branch1_bn_s: (1024,) => s4.pathway0_res0.branch1_bn.weight: (1024,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res3_2_branch2c_w: (64, 16, 1, 1, 1) => s3.pathway1_res2.branch2.c.weight: (64, 16, 1, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_2_branch2a_bn_rm: (256,) => s4.pathway0_res2.branch2.a_bn.running_mean: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res4_0_branch1_bn_b: (128,) => s4.pathway1_res0.branch1_bn.bias: (128,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res2_0_branch2b_w: (64, 64, 1, 3, 3) => s2.pathway0_res0.branch2.b.weight: (64, 64, 1, 3, 3)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res5_0_branch2c_w: (256, 64, 1, 1, 1) => s5.pathway1_res0.branch2.c.weight: (256, 64, 1, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_0_branch1_bn_b: (1024,) => s4.pathway0_res0.branch1_bn.bias: (1024,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_1_branch2c_bn_rm: (1024,) => s4.pathway0_res1.branch2.c_bn.running_mean: (1024,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res4_2_branch2b_bn_riv: (32,) => s4.pathway1_res2.branch2.b_bn.running_var: (32,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_3_branch2a_bn_rm: (256,) => s4.pathway0_res3.branch2.a_bn.running_mean: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res5_0_branch2b_bn_b: (64,) => s5.pathway1_res0.branch2.b_bn.bias: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res4_1_branch2a_w: (32, 128, 3, 1, 1) => s4.pathway1_res1.branch2.a.weight: (32, 128, 3, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_2_branch2b_w: (256, 256, 1, 3, 3) => s4.pathway0_res2.branch2.b.weight: (256, 256, 1, 3, 3)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_1_branch2c_w: (512, 128, 1, 1, 1) => s3.pathway0_res1.branch2.c.weight: (512, 128, 1, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_0_branch1_bn_s: (512,) => s3.pathway0_res0.branch1_bn.weight: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res3_1_branch2b_w: (16, 16, 1, 3, 3) => s3.pathway1_res1.branch2.b.weight: (16, 16, 1, 3, 3)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res5_0_branch2a_w: (64, 128, 3, 1, 1) => s5.pathway1_res0.branch2.a.weight: (64, 128, 3, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res5_2_branch2a_bn_rm: (64,) => s5.pathway1_res2.branch2.a_bn.running_mean: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res4_1_branch2c_w: (128, 32, 1, 1, 1) => s4.pathway1_res1.branch2.c.weight: (128, 32, 1, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res3_2_branch2c_bn_s: (64,) => s3.pathway1_res2.branch2.c_bn.weight: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_1_branch2b_bn_rm: (256,) => s4.pathway0_res1.branch2.b_bn.running_mean: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_3_branch2b_bn_rm: (128,) => s3.pathway0_res3.branch2.b_bn.running_mean: (128,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_0_branch2b_bn_b: (256,) => s4.pathway0_res0.branch2.b_bn.bias: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res3_2_branch2c_bn_b: (64,) => s3.pathway1_res2.branch2.c_bn.bias: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res5_1_branch2a_bn_riv: (64,) => s5.pathway1_res1.branch2.a_bn.running_var: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_1_branch2c_bn_riv: (512,) => s3.pathway0_res1.branch2.c_bn.running_var: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_0_branch2c_bn_b: (512,) => s3.pathway0_res0.branch2.c_bn.bias: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_0_branch2a_bn_rm: (128,) => s3.pathway0_res0.branch2.a_bn.running_mean: (128,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res5_0_branch2c_bn_s: (2048,) => s5.pathway0_res0.branch2.c_bn.weight: (2048,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res5_1_branch2a_bn_b: (64,) => s5.pathway1_res1.branch2.a_bn.bias: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_2_branch2b_bn_rm: (256,) => s4.pathway0_res2.branch2.b_bn.running_mean: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res5_2_branch2c_w: (2048, 512, 1, 1, 1) => s5.pathway0_res2.branch2.c.weight: (2048, 512, 1, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_0_branch2c_bn_s: (512,) => s3.pathway0_res0.branch2.c_bn.weight: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res2_0_branch2a_w: (64, 80, 1, 1, 1) => s2.pathway0_res0.branch2.a.weight: (64, 80, 1, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res5_1_branch2a_bn_s: (64,) => s5.pathway1_res1.branch2.a_bn.weight: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_3_branch2a_bn_riv: (256,) => s4.pathway0_res3.branch2.a_bn.running_var: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res3_1_branch2c_bn_s: (64,) => s3.pathway1_res1.branch2.c_bn.weight: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res5_2_branch2c_bn_s: (256,) => s5.pathway1_res2.branch2.c_bn.weight: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res4_4_branch2a_w: (32, 128, 3, 1, 1) => s4.pathway1_res4.branch2.a.weight: (32, 128, 3, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res3_1_branch2c_bn_b: (64,) => s3.pathway1_res1.branch2.c_bn.bias: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_3_branch2c_w: (128, 32, 1, 1, 1) => s4.pathway1_res3.branch2.c.weight: (128, 32, 1, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_0_branch2b_w: (32, 32, 1, 3, 3) => s4.pathway1_res0.branch2.b.weight: (32, 32, 1, 3, 3)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_2_branch2c_w: (256, 64, 1, 1, 1) => s2.pathway0_res2.branch2.c.weight: (256, 64, 1, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res5_2_branch2a_bn_riv: (64,) => s5.pathway1_res2.branch2.a_bn.running_var: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_0_branch2b_bn_b: (32,) => s4.pathway1_res0.branch2.b_bn.bias: (32,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_0_branch2c_bn_riv: (128,) => s4.pathway1_res0.branch2.c_bn.running_var: (128,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_0_branch2b_bn_s: (32,) => s4.pathway1_res0.branch2.b_bn.weight: (32,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res3_0_branch2b_w: (16, 16, 1, 3, 3) => s3.pathway1_res0.branch2.b.weight: (16, 16, 1, 3, 3)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_3_branch2a_w: (32, 128, 3, 1, 1) => s4.pathway1_res3.branch2.a.weight: (32, 128, 3, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: res3_0_branch2b_bn_riv: (128,) => s3.pathway0_res0.branch2.b_bn.running_var: (128,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res3_0_branch2a_w: (128, 320, 1, 1, 1) => s3.pathway0_res0.branch2.a.weight: (128, 320, 1, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_0_branch2a_bn_s: (64,) => s2.pathway0_res0.branch2.a_bn.weight: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res3_1_branch2c_bn_rm: (64,) => s3.pathway1_res1.branch2.c_bn.running_mean: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res_conv1_bn_b: (8,) => s1.pathway1_stem.bn.bias: (8,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_3_branch2a_bn_b: (256,) => s4.pathway0_res3.branch2.a_bn.bias: (256,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_1_branch2a_bn_s: (64,) => s2.pathway0_res1.branch2.a_bn.weight: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res3_0_branch2c_bn_rm: (512,) => s3.pathway0_res0.branch2.c_bn.running_mean: (512,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res2_1_branch2b_bn_s: (8,) => s2.pathway1_res1.branch2.b_bn.weight: (8,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res3_2_branch2c_bn_b: (512,) => s3.pathway0_res2.branch2.c_bn.bias: (512,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_0_branch2a_bn_b: (64,) => s2.pathway0_res0.branch2.a_bn.bias: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_1_branch2b_bn_s: (256,) => s4.pathway0_res1.branch2.b_bn.weight: (256,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res3_2_branch2b_w: (16, 16, 1, 3, 3) => s3.pathway1_res2.branch2.b.weight: (16, 16, 1, 3, 3)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res_conv1_bn_s: (8,) => s1.pathway1_stem.bn.weight: (8,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res2_0_branch2b_bn_rm: (8,) => s2.pathway1_res0.branch2.b_bn.running_mean: (8,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_1_branch2a_bn_b: (64,) => s2.pathway0_res1.branch2.a_bn.bias: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_2_branch2c_w: (1024, 256, 1, 1, 1) => s4.pathway0_res2.branch2.c.weight: (1024, 256, 1, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: res3_1_branch2b_w: (128, 128, 1, 3, 3) => s3.pathway0_res1.branch2.b.weight: (128, 128, 1, 3, 3)
[06/12 17:36:19][INFO] checkpoint.py:  264: res3_1_branch2a_bn_rm: (128,) => s3.pathway0_res1.branch2.a_bn.running_mean: (128,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res3_3_branch2c_w: (512, 128, 1, 1, 1) => s3.pathway0_res3.branch2.c.weight: (512, 128, 1, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_1_branch2a_bn_riv: (32,) => s4.pathway1_res1.branch2.a_bn.running_var: (32,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_4_branch2b_w: (32, 32, 1, 3, 3) => s4.pathway1_res4.branch2.b.weight: (32, 32, 1, 3, 3)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_0_branch2a_bn_rm: (64,) => s2.pathway0_res0.branch2.a_bn.running_mean: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_0_branch2b_bn_b: (64,) => s2.pathway0_res0.branch2.b_bn.bias: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_0_branch2a_bn_s: (256,) => s4.pathway0_res0.branch2.a_bn.weight: (256,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res3_3_branch2a_w: (128, 512, 1, 1, 1) => s3.pathway0_res3.branch2.a.weight: (128, 512, 1, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_4_branch2c_w: (128, 32, 1, 1, 1) => s4.pathway1_res4.branch2.c.weight: (128, 32, 1, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: res3_1_branch2b_bn_riv: (128,) => s3.pathway0_res1.branch2.b_bn.running_var: (128,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_0_branch2b_bn_s: (64,) => s2.pathway0_res0.branch2.b_bn.weight: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_0_branch2a_bn_b: (256,) => s4.pathway0_res0.branch2.a_bn.bias: (256,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res5_0_branch2c_bn_s: (256,) => s5.pathway1_res0.branch2.c_bn.weight: (256,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_5_branch2c_bn_rm: (128,) => s4.pathway1_res5.branch2.c_bn.running_mean: (128,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res3_3_branch2c_bn_subsample_w: (128, 64, 7, 1, 1) => s3_fuse.conv_f2s.weight: (128, 64, 7, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_0_branch2c_bn_b: (256,) => s2.pathway0_res0.branch2.c_bn.bias: (256,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res2_2_branch2c_bn_rm: (32,) => s2.pathway1_res2.branch2.c_bn.running_mean: (32,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res5_0_branch2b_bn_s: (512,) => s5.pathway0_res0.branch2.b_bn.weight: (512,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res5_0_branch2a_bn_rm: (64,) => s5.pathway1_res0.branch2.a_bn.running_mean: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res5_2_branch2c_bn_rm: (2048,) => s5.pathway0_res2.branch2.c_bn.running_mean: (2048,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_0_branch2c_bn_s: (256,) => s2.pathway0_res0.branch2.c_bn.weight: (256,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_3_branch2b_w: (256, 256, 1, 3, 3) => s4.pathway0_res3.branch2.b.weight: (256, 256, 1, 3, 3)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res5_0_branch2a_bn_riv: (64,) => s5.pathway1_res0.branch2.a_bn.running_var: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res3_0_branch2b_bn_b: (128,) => s3.pathway0_res0.branch2.b_bn.bias: (128,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res3_1_branch2c_bn_riv: (64,) => s3.pathway1_res1.branch2.c_bn.running_var: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_1_branch2b_bn_b: (256,) => s4.pathway0_res1.branch2.b_bn.bias: (256,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_0_branch2a_bn_rm: (256,) => s4.pathway0_res0.branch2.a_bn.running_mean: (256,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_3_branch2c_bn_s: (128,) => s4.pathway1_res3.branch2.c_bn.weight: (128,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_0_branch1_w: (256, 80, 1, 1, 1) => s2.pathway0_res0.branch1.weight: (256, 80, 1, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res5_0_branch2c_bn_b: (256,) => s5.pathway1_res0.branch2.c_bn.bias: (256,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_1_branch2c_bn_rm: (256,) => s2.pathway0_res1.branch2.c_bn.running_mean: (256,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res3_0_branch2b_bn_s: (128,) => s3.pathway0_res0.branch2.b_bn.weight: (128,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res3_3_branch2b_w: (16, 16, 1, 3, 3) => s3.pathway1_res3.branch2.b.weight: (16, 16, 1, 3, 3)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_0_branch2a_bn_rm: (32,) => s4.pathway1_res0.branch2.a_bn.running_mean: (32,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res3_3_branch2c_bn_rm: (64,) => s3.pathway1_res3.branch2.c_bn.running_mean: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_3_branch2c_bn_b: (128,) => s4.pathway1_res3.branch2.c_bn.bias: (128,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_2_branch2a_bn_s: (32,) => s4.pathway1_res2.branch2.a_bn.weight: (32,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_5_branch2c_bn_rm: (1024,) => s4.pathway0_res5.branch2.c_bn.running_mean: (1024,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_2_branch2a_bn_b: (32,) => s4.pathway1_res2.branch2.a_bn.bias: (32,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res_conv1_bn_riv: (64,) => s1.pathway0_stem.bn.running_var: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res5_0_branch1_bn_b: (256,) => s5.pathway1_res0.branch1_bn.bias: (256,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_4_branch2c_bn_riv: (128,) => s4.pathway1_res4.branch2.c_bn.running_var: (128,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_0_branch2a_w: (32, 64, 3, 1, 1) => s4.pathway1_res0.branch2.a.weight: (32, 64, 3, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_5_branch2c_bn_riv: (128,) => s4.pathway1_res5.branch2.c_bn.running_var: (128,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_4_branch2a_bn_riv: (256,) => s4.pathway0_res4.branch2.a_bn.running_var: (256,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res2_1_branch2a_bn_riv: (8,) => s2.pathway1_res1.branch2.a_bn.running_var: (8,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res5_1_branch2c_w: (256, 64, 1, 1, 1) => s5.pathway1_res1.branch2.c.weight: (256, 64, 1, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: res5_1_branch2b_bn_riv: (512,) => s5.pathway0_res1.branch2.b_bn.running_var: (512,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res2_0_branch2c_bn_rm: (32,) => s2.pathway1_res0.branch2.c_bn.running_mean: (32,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res3_3_branch2c_bn_subsample_bn_riv: (128,) => s3_fuse.bn.running_var: (128,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res5_2_branch2c_bn_s: (2048,) => s5.pathway0_res2.branch2.c_bn.weight: (2048,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res3_3_branch2a_bn_b: (16,) => s3.pathway1_res3.branch2.a_bn.bias: (16,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_0_branch2c_w: (256, 64, 1, 1, 1) => s2.pathway0_res0.branch2.c.weight: (256, 64, 1, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: res5_2_branch2c_bn_b: (2048,) => s5.pathway0_res2.branch2.c_bn.bias: (2048,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_5_branch2a_bn_b: (32,) => s4.pathway1_res5.branch2.a_bn.bias: (32,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res5_0_branch2b_w: (64, 64, 1, 3, 3) => s5.pathway1_res0.branch2.b.weight: (64, 64, 1, 3, 3)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_5_branch2c_w: (128, 32, 1, 1, 1) => s4.pathway1_res5.branch2.c.weight: (128, 32, 1, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res2_2_branch2a_bn_s: (8,) => s2.pathway1_res2.branch2.a_bn.weight: (8,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_3_branch2a_bn_s: (256,) => s4.pathway0_res3.branch2.a_bn.weight: (256,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_3_branch2b_bn_riv: (256,) => s4.pathway0_res3.branch2.b_bn.running_var: (256,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_2_branch2c_bn_riv: (1024,) => s4.pathway0_res2.branch2.c_bn.running_var: (1024,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_1_branch2b_w: (256, 256, 1, 3, 3) => s4.pathway0_res1.branch2.b.weight: (256, 256, 1, 3, 3)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res5_2_branch2b_bn_rm: (64,) => s5.pathway1_res2.branch2.b_bn.running_mean: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_1_branch2a_w: (64, 256, 1, 1, 1) => s2.pathway0_res1.branch2.a.weight: (64, 256, 1, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_0_branch1_w: (1024, 640, 1, 1, 1) => s4.pathway0_res0.branch1.weight: (1024, 640, 1, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_2_branch2b_bn_b: (32,) => s4.pathway1_res2.branch2.b_bn.bias: (32,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_2_branch2b_w: (32, 32, 1, 3, 3) => s4.pathway1_res2.branch2.b.weight: (32, 32, 1, 3, 3)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res_conv1_bn_riv: (8,) => s1.pathway1_stem.bn.running_var: (8,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res3_3_branch2b_bn_s: (16,) => s3.pathway1_res3.branch2.b_bn.weight: (16,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_2_branch2b_bn_s: (32,) => s4.pathway1_res2.branch2.b_bn.weight: (32,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res3_3_branch2c_bn_rm: (512,) => s3.pathway0_res3.branch2.c_bn.running_mean: (512,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_0_branch2a_bn_riv: (32,) => s4.pathway1_res0.branch2.a_bn.running_var: (32,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res3_2_branch2b_bn_riv: (128,) => s3.pathway0_res2.branch2.b_bn.running_var: (128,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res3_3_branch2b_bn_b: (16,) => s3.pathway1_res3.branch2.b_bn.bias: (16,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res2_0_branch2b_w: (8, 8, 1, 3, 3) => s2.pathway1_res0.branch2.b.weight: (8, 8, 1, 3, 3)
[06/12 17:36:19][INFO] checkpoint.py:  264: res3_3_branch2a_bn_rm: (128,) => s3.pathway0_res3.branch2.a_bn.running_mean: (128,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res5_0_branch1_bn_riv: (2048,) => s5.pathway0_res0.branch1_bn.running_var: (2048,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_4_branch2c_bn_riv: (1024,) => s4.pathway0_res4.branch2.c_bn.running_var: (1024,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_1_branch2b_bn_rm: (32,) => s4.pathway1_res1.branch2.b_bn.running_mean: (32,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_2_branch2b_bn_s: (64,) => s2.pathway0_res2.branch2.b_bn.weight: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res_conv1_bn_rm: (64,) => s1.pathway0_stem.bn.running_mean: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res3_2_branch2b_bn_rm: (128,) => s3.pathway0_res2.branch2.b_bn.running_mean: (128,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_2_branch2b_bn_b: (64,) => s2.pathway0_res2.branch2.b_bn.bias: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_2_branch2c_bn_s: (256,) => s2.pathway0_res2.branch2.c_bn.weight: (256,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_1_branch2c_bn_rm: (128,) => s4.pathway1_res1.branch2.c_bn.running_mean: (128,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_conv1_w: (8, 3, 5, 7, 7) => s1.pathway1_stem.conv.weight: (8, 3, 5, 7, 7)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_0_branch1_bn_rm: (1024,) => s4.pathway0_res0.branch1_bn.running_mean: (1024,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_0_branch1_bn_riv: (1024,) => s4.pathway0_res0.branch1_bn.running_var: (1024,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res5_0_branch1_bn_s: (2048,) => s5.pathway0_res0.branch1_bn.weight: (2048,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_0_branch2c_w: (1024, 256, 1, 1, 1) => s4.pathway0_res0.branch2.c.weight: (1024, 256, 1, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_1_branch2b_bn_b: (64,) => s2.pathway0_res1.branch2.b_bn.bias: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res5_0_branch2c_bn_rm: (2048,) => s5.pathway0_res0.branch2.c_bn.running_mean: (2048,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res5_0_branch1_bn_b: (2048,) => s5.pathway0_res0.branch1_bn.bias: (2048,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_0_branch2a_w: (256, 640, 3, 1, 1) => s4.pathway0_res0.branch2.a.weight: (256, 640, 3, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_4_branch2c_bn_rm: (1024,) => s4.pathway0_res4.branch2.c_bn.running_mean: (1024,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_1_branch2b_bn_s: (64,) => s2.pathway0_res1.branch2.b_bn.weight: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res5_0_branch2c_bn_rm: (256,) => s5.pathway1_res0.branch2.c_bn.running_mean: (256,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res3_1_branch2a_bn_rm: (16,) => s3.pathway1_res1.branch2.a_bn.running_mean: (16,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_3_branch2b_w: (32, 32, 1, 3, 3) => s4.pathway1_res3.branch2.b.weight: (32, 32, 1, 3, 3)
[06/12 17:36:19][INFO] checkpoint.py:  264: res3_0_branch1_bn_riv: (512,) => s3.pathway0_res0.branch1_bn.running_var: (512,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res2_2_branch2a_bn_b: (8,) => s2.pathway1_res2.branch2.a_bn.bias: (8,)
[06/12 17:36:20][INFO] checkpoint.py:  264: res4_3_branch2c_w: (1024, 256, 1, 1, 1) => s4.pathway0_res3.branch2.c.weight: (1024, 256, 1, 1, 1)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res5_0_branch2b_bn_s: (64,) => s5.pathway1_res0.branch2.b_bn.weight: (64,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res5_1_branch2b_bn_rm: (64,) => s5.pathway1_res1.branch2.b_bn.running_mean: (64,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res4_3_branch2b_bn_s: (32,) => s4.pathway1_res3.branch2.b_bn.weight: (32,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_pool1_subsample_bn_s: (16,) => s1_fuse.bn.weight: (16,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res2_2_branch2b_bn_s: (8,) => s2.pathway1_res2.branch2.b_bn.weight: (8,)
[06/12 17:36:20][INFO] checkpoint.py:  264: res2_1_branch2b_w: (64, 64, 1, 3, 3) => s2.pathway0_res1.branch2.b.weight: (64, 64, 1, 3, 3)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res5_1_branch2c_bn_rm: (256,) => s5.pathway1_res1.branch2.c_bn.running_mean: (256,)
[06/12 17:36:20][INFO] checkpoint.py:  264: res3_2_branch2a_bn_riv: (128,) => s3.pathway0_res2.branch2.a_bn.running_var: (128,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res4_3_branch2b_bn_b: (32,) => s4.pathway1_res3.branch2.b_bn.bias: (32,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_pool1_subsample_bn_b: (16,) => s1_fuse.bn.bias: (16,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res4_0_branch1_bn_s: (128,) => s4.pathway1_res0.branch1_bn.weight: (128,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res4_4_branch2b_bn_riv: (32,) => s4.pathway1_res4.branch2.b_bn.running_var: (32,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res3_0_branch1_bn_rm: (64,) => s3.pathway1_res0.branch1_bn.running_mean: (64,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res3_0_branch2a_bn_rm: (16,) => s3.pathway1_res0.branch2.a_bn.running_mean: (16,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res4_3_branch2c_bn_riv: (128,) => s4.pathway1_res3.branch2.c_bn.running_var: (128,)
[06/12 17:36:20][INFO] checkpoint.py:  264: res2_2_branch2c_bn_rm: (256,) => s2.pathway0_res2.branch2.c_bn.running_mean: (256,)
[06/12 17:36:20][WARNING] checkpoint.py:  273: !! pred_b: (400,) does not match head.projection.bias: (16,)
[06/12 17:36:20][INFO] checkpoint.py:  264: res3_3_branch2b_w: (128, 128, 1, 3, 3) => s3.pathway0_res3.branch2.b.weight: (128, 128, 1, 3, 3)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res3_2_branch2a_w: (16, 64, 3, 1, 1) => s3.pathway1_res2.branch2.a.weight: (16, 64, 3, 1, 1)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res4_2_branch2c_bn_s: (128,) => s4.pathway1_res2.branch2.c_bn.weight: (128,)
[06/12 17:36:20][INFO] checkpoint.py:  264: res2_1_branch2b_bn_riv: (64,) => s2.pathway0_res1.branch2.b_bn.running_var: (64,)
[06/12 17:36:20][WARNING] checkpoint.py:  273: !! pred_w: (400, 2304) does not match head.projection.weight: (16, 2304)
[06/12 17:36:20][INFO] checkpoint.py:  264: res4_3_branch2a_w: (256, 1024, 3, 1, 1) => s4.pathway0_res3.branch2.a.weight: (256, 1024, 3, 1, 1)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res2_2_branch2c_bn_subsample_bn_riv: (64,) => s2_fuse.bn.running_var: (64,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res3_3_branch2a_w: (16, 64, 3, 1, 1) => s3.pathway1_res3.branch2.a.weight: (16, 64, 3, 1, 1)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res3_1_branch2b_bn_riv: (16,) => s3.pathway1_res1.branch2.b_bn.running_var: (16,)
[06/12 17:36:20][INFO] checkpoint.py:  264: res4_1_branch2a_w: (256, 1024, 3, 1, 1) => s4.pathway0_res1.branch2.a.weight: (256, 1024, 3, 1, 1)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res2_0_branch1_w: (32, 8, 1, 1, 1) => s2.pathway1_res0.branch1.weight: (32, 8, 1, 1, 1)
[06/12 17:36:20][INFO] checkpoint.py:  264: res4_5_branch2c_bn_s: (1024,) => s4.pathway0_res5.branch2.c_bn.weight: (1024,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res4_2_branch2c_bn_b: (128,) => s4.pathway1_res2.branch2.c_bn.bias: (128,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res2_0_branch2a_bn_s: (8,) => s2.pathway1_res0.branch2.a_bn.weight: (8,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res2_2_branch2c_bn_subsample_w: (64, 32, 7, 1, 1) => s2_fuse.conv_f2s.weight: (64, 32, 7, 1, 1)
[06/12 17:36:20][INFO] checkpoint.py:  264: res4_5_branch2a_bn_s: (256,) => s4.pathway0_res5.branch2.a_bn.weight: (256,)
[06/12 17:36:20][INFO] checkpoint.py:  264: res4_3_branch2b_bn_b: (256,) => s4.pathway0_res3.branch2.b_bn.bias: (256,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res5_2_branch2a_w: (64, 256, 3, 1, 1) => s5.pathway1_res2.branch2.a.weight: (64, 256, 3, 1, 1)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_pool1_subsample_w: (16, 8, 7, 1, 1) => s1_fuse.conv_f2s.weight: (16, 8, 7, 1, 1)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res2_0_branch2a_bn_b: (8,) => s2.pathway1_res0.branch2.a_bn.bias: (8,)
[06/12 17:36:20][INFO] checkpoint.py:  264: res4_5_branch2a_bn_b: (256,) => s4.pathway0_res5.branch2.a_bn.bias: (256,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res3_3_branch2c_w: (64, 16, 1, 1, 1) => s3.pathway1_res3.branch2.c.weight: (64, 16, 1, 1, 1)
[06/12 17:36:20][WARNING] checkpoint.py:  293: Not loaded {'head.projection.weight', 'head.projection.bias'}
[06/12 17:36:20][INFO] kinetics.py:   93: Constructing Kinetics train...
[06/12 17:36:20][INFO] kinetics.py:  169: Constructing kinetics dataloader (size: 1927 skip_rows 0) from train.csv 
[06/12 17:36:20][INFO] kinetics.py:   93: Constructing Kinetics val...
[06/12 17:36:20][INFO] kinetics.py:  169: Constructing kinetics dataloader (size: 482 skip_rows 0) from val.csv 
[06/12 17:36:20][INFO] kinetics.py:   93: Constructing Kinetics train...
[06/12 17:36:20][INFO] kinetics.py:  169: Constructing kinetics dataloader (size: 1927 skip_rows 0) from train.csv 
[06/12 17:36:20][INFO] train_net.py:  647: Start epoch: 1
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
[06/12 17:36:34][INFO] distributed.py: 1027: Reducer buckets have been rebuilt in this iteration.
[06/12 17:36:39][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.45639, "dt_data": 0.00051, "dt_net": 0.45587, "epoch": "1/300", "eta": "2:16:50", "gpu_mem": "10.06G", "grad_norm": 4.12284, "iter": "10/60", "loss": 2.78378, "lr": 0.0000296553, "top1_acc": 0.00000, "top1_err": 95.31250, "top5_acc": 25.00000, "top5_err": 68.75000}
[06/12 17:36:44][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47410, "dt_data": 0.00097, "dt_net": 0.47313, "epoch": "1/300", "eta": "2:22:04", "gpu_mem": "10.06G", "grad_norm": 4.31403, "iter": "20/60", "loss": 2.78490, "lr": 0.0000403834, "top1_acc": 3.12500, "top1_err": 96.87500, "top5_acc": 28.12500, "top5_err": 75.00000}
[06/12 17:36:51][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.24170, "dt_data": 0.78708, "dt_net": 0.45461, "epoch": "1/300", "eta": "6:11:53", "gpu_mem": "10.06G", "grad_norm": 4.09940, "iter": "30/60", "loss": 2.77739, "lr": 0.0000511115, "top1_acc": 6.25000, "top1_err": 93.75000, "top5_acc": 25.00000, "top5_err": 71.87500}
[06/12 17:36:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.70641, "dt_data": 0.25449, "dt_net": 0.45192, "epoch": "1/300", "eta": "3:31:27", "gpu_mem": "10.06G", "grad_norm": 4.16123, "iter": "40/60", "loss": 2.80939, "lr": 0.0000618396, "top1_acc": 3.12500, "top1_err": 95.31250, "top5_acc": 25.00000, "top5_err": 75.00000}
[06/12 17:37:03][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.45969, "dt_data": 0.00036, "dt_net": 0.45933, "epoch": "1/300", "eta": "2:17:31", "gpu_mem": "10.06G", "grad_norm": 4.43483, "iter": "50/60", "loss": 2.79011, "lr": 0.0000725676, "top1_acc": 6.25000, "top1_err": 93.75000, "top5_acc": 31.25000, "top5_err": 70.31250}
[06/12 17:37:09][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46214, "dt_data": 0.00966, "dt_net": 0.45248, "epoch": "1/300", "eta": "2:18:10", "gpu_mem": "10.06G", "grad_norm": 3.99545, "iter": "60/60", "loss": 2.79089, "lr": 0.0000832957, "top1_acc": 6.25000, "top1_err": 93.75000, "top5_acc": 31.25000, "top5_err": 68.75000}
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
[06/12 17:37:09][INFO] logging.py:  101: json_stats: {"RAM": "13.62/31.07G", "_type": "train_epoch", "dt": 0.72225, "dt_data": 0.72225, "dt_net": 0.45248, "epoch": "1/300", "eta": "3:35:56", "gpu_mem": "10.06G", "grad_norm": 3.99545, "loss": 2.79020, "lr": 0.0000832957, "top1_acc": 5.41667, "top1_err": 94.63542, "top5_acc": 28.33333, "top5_err": 71.82292}
[06/12 17:37:09][INFO] train_net.py:  708: Epoch 0 takes 49.42s. Epochs from 0 to 0 take 49.42s in average and 49.42s in median.
[06/12 17:37:09][INFO] train_net.py:  714: For epoch 0, each iteraction takes 0.82s in average. From epoch 0 to 0, each iteraction takes 0.82s in average.
[06/12 17:37:27][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.45771, "dt_data": 0.00086, "dt_net": 0.45684, "epoch": "2/300", "eta": "2:16:46", "gpu_mem": "10.06G", "grad_norm": 3.95223, "iter": "10/60", "loss": 2.79238, "lr": 0.0000940238, "top1_acc": 12.50000, "top1_err": 92.18750, "top5_acc": 31.25000, "top5_err": 65.62500}
[06/12 17:37:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46307, "dt_data": 0.00072, "dt_net": 0.46236, "epoch": "2/300", "eta": "2:18:18", "gpu_mem": "10.06G", "grad_norm": 4.20276, "iter": "20/60", "loss": 2.76313, "lr": 0.0001047519, "top1_acc": 12.50000, "top1_err": 90.62500, "top5_acc": 37.50000, "top5_err": 62.50000}
[06/12 17:37:39][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46157, "dt_data": 0.00043, "dt_net": 0.46114, "epoch": "2/300", "eta": "2:17:46", "gpu_mem": "10.06G", "grad_norm": 4.02394, "iter": "30/60", "loss": 2.77126, "lr": 0.0001154800, "top1_acc": 12.50000, "top1_err": 92.18750, "top5_acc": 37.50000, "top5_err": 67.18750}
[06/12 17:37:45][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46460, "dt_data": 0.00049, "dt_net": 0.46411, "epoch": "2/300", "eta": "2:18:36", "gpu_mem": "10.06G", "grad_norm": 4.08904, "iter": "40/60", "loss": 2.76371, "lr": 0.0001262081, "top1_acc": 6.25000, "top1_err": 93.75000, "top5_acc": 37.50000, "top5_err": 65.62500}
[06/12 17:37:51][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46341, "dt_data": 0.00043, "dt_net": 0.46298, "epoch": "2/300", "eta": "2:18:10", "gpu_mem": "10.06G", "grad_norm": 4.01286, "iter": "50/60", "loss": 2.78046, "lr": 0.0001369362, "top1_acc": 9.37500, "top1_err": 90.62500, "top5_acc": 28.12500, "top5_err": 70.31250}
[06/12 17:37:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46158, "dt_data": 0.00017, "dt_net": 0.46141, "epoch": "2/300", "eta": "2:17:33", "gpu_mem": "10.06G", "grad_norm": 4.04497, "iter": "60/60", "loss": 2.75056, "lr": 0.0001476643, "top1_acc": 6.25000, "top1_err": 93.75000, "top5_acc": 40.62500, "top5_err": 60.93750}
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
[06/12 17:37:57][INFO] logging.py:  101: json_stats: {"RAM": "13.63/31.07G", "_type": "train_epoch", "dt": 0.69301, "dt_data": 0.69301, "dt_net": 0.46141, "epoch": "2/300", "eta": "3:26:30", "gpu_mem": "10.06G", "grad_norm": 4.04497, "loss": 2.76828, "lr": 0.0001476643, "top1_acc": 9.16667, "top1_err": 92.34375, "top5_acc": 35.52083, "top5_err": 65.67708}
[06/12 17:37:57][INFO] train_net.py:  708: Epoch 1 takes 48.03s. Epochs from 0 to 1 take 48.72s in average and 48.72s in median.
[06/12 17:37:57][INFO] train_net.py:  714: For epoch 1, each iteraction takes 0.80s in average. From epoch 0 to 1, each iteraction takes 0.81s in average.
[06/12 17:38:15][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46371, "dt_data": 0.00050, "dt_net": 0.46321, "epoch": "3/300", "eta": "2:18:06", "gpu_mem": "10.06G", "grad_norm": 3.97290, "iter": "10/60", "loss": 2.74186, "lr": 0.0001583924, "top1_acc": 15.62500, "top1_err": 92.18750, "top5_acc": 40.62500, "top5_err": 60.93750}
[06/12 17:38:20][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47421, "dt_data": 0.00055, "dt_net": 0.47366, "epoch": "3/300", "eta": "2:21:09", "gpu_mem": "10.06G", "grad_norm": 4.17168, "iter": "20/60", "loss": 2.75374, "lr": 0.0001691205, "top1_acc": 6.25000, "top1_err": 93.75000, "top5_acc": 34.37500, "top5_err": 60.93750}
[06/12 17:38:27][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46584, "dt_data": 0.00032, "dt_net": 0.46552, "epoch": "3/300", "eta": "2:18:35", "gpu_mem": "10.06G", "grad_norm": 3.96912, "iter": "30/60", "loss": 2.74696, "lr": 0.0001798486, "top1_acc": 6.25000, "top1_err": 90.62500, "top5_acc": 43.75000, "top5_err": 59.37500}
[06/12 17:38:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46777, "dt_data": 0.00044, "dt_net": 0.46733, "epoch": "3/300", "eta": "2:19:04", "gpu_mem": "10.06G", "grad_norm": 3.98427, "iter": "40/60", "loss": 2.75525, "lr": 0.0001905767, "top1_acc": 6.25000, "top1_err": 93.75000, "top5_acc": 40.62500, "top5_err": 64.06250}
[06/12 17:38:39][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47354, "dt_data": 0.00047, "dt_net": 0.47307, "epoch": "3/300", "eta": "2:20:43", "gpu_mem": "10.06G", "grad_norm": 4.05722, "iter": "50/60", "loss": 2.74171, "lr": 0.0002013048, "top1_acc": 12.50000, "top1_err": 90.62500, "top5_acc": 43.75000, "top5_err": 60.93750}
[06/12 17:38:45][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46262, "dt_data": 0.00019, "dt_net": 0.46242, "epoch": "3/300", "eta": "2:17:23", "gpu_mem": "10.06G", "grad_norm": 4.29163, "iter": "60/60", "loss": 2.73560, "lr": 0.0002120328, "top1_acc": 12.50000, "top1_err": 87.50000, "top5_acc": 43.75000, "top5_err": 57.81250}
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
[06/12 17:38:46][INFO] logging.py:  101: json_stats: {"RAM": "13.63/31.07G", "_type": "train_epoch", "dt": 0.71249, "dt_data": 0.71249, "dt_net": 0.46242, "epoch": "3/300", "eta": "3:31:36", "gpu_mem": "10.06G", "grad_norm": 4.29163, "loss": 2.75039, "lr": 0.0002120328, "top1_acc": 9.58333, "top1_err": 90.57292, "top5_acc": 39.89583, "top5_err": 61.19792}
[06/12 17:38:46][INFO] train_net.py:  708: Epoch 2 takes 48.83s. Epochs from 0 to 2 take 48.76s in average and 48.83s in median.
[06/12 17:38:46][INFO] train_net.py:  714: For epoch 2, each iteraction takes 0.81s in average. From epoch 0 to 2, each iteraction takes 0.81s in average.
[06/12 17:39:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46977, "dt_data": 0.00073, "dt_net": 0.46903, "epoch": "4/300", "eta": "2:19:26", "gpu_mem": "10.06G", "grad_norm": 3.87860, "iter": "10/60", "loss": 2.70494, "lr": 0.0002227609, "top1_acc": 12.50000, "top1_err": 87.50000, "top5_acc": 46.87500, "top5_err": 48.43750}
[06/12 17:39:10][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47526, "dt_data": 0.00478, "dt_net": 0.47048, "epoch": "4/300", "eta": "2:20:59", "gpu_mem": "10.06G", "grad_norm": 4.01322, "iter": "20/60", "loss": 2.73062, "lr": 0.0002334890, "top1_acc": 12.50000, "top1_err": 89.06250, "top5_acc": 43.75000, "top5_err": 57.81250}
[06/12 17:39:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47231, "dt_data": 0.00054, "dt_net": 0.47177, "epoch": "4/300", "eta": "2:20:02", "gpu_mem": "10.06G", "grad_norm": 4.03024, "iter": "30/60", "loss": 2.70269, "lr": 0.0002442171, "top1_acc": 12.50000, "top1_err": 85.93750, "top5_acc": 43.75000, "top5_err": 54.68750}
[06/12 17:39:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47578, "dt_data": 0.00080, "dt_net": 0.47498, "epoch": "4/300", "eta": "2:20:59", "gpu_mem": "10.06G", "grad_norm": 4.06779, "iter": "40/60", "loss": 2.71247, "lr": 0.0002549452, "top1_acc": 15.62500, "top1_err": 82.81250, "top5_acc": 46.87500, "top5_err": 54.68750}
[06/12 17:39:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47035, "dt_data": 0.00065, "dt_net": 0.46970, "epoch": "4/300", "eta": "2:19:18", "gpu_mem": "10.06G", "grad_norm": 4.36242, "iter": "50/60", "loss": 2.71390, "lr": 0.0002656733, "top1_acc": 18.75000, "top1_err": 87.50000, "top5_acc": 50.00000, "top5_err": 59.37500}
[06/12 17:39:34][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46608, "dt_data": 0.00020, "dt_net": 0.46589, "epoch": "4/300", "eta": "2:17:57", "gpu_mem": "10.06G", "grad_norm": 4.32140, "iter": "60/60", "loss": 2.70710, "lr": 0.0002764014, "top1_acc": 9.37500, "top1_err": 85.93750, "top5_acc": 43.75000, "top5_err": 53.12500}
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
[06/12 17:39:35][INFO] logging.py:  101: json_stats: {"RAM": "13.64/31.07G", "_type": "train_epoch", "dt": 0.71073, "dt_data": 0.71073, "dt_net": 0.46589, "epoch": "4/300", "eta": "3:30:21", "gpu_mem": "10.06G", "grad_norm": 4.32140, "loss": 2.70801, "lr": 0.0002764014, "top1_acc": 13.22917, "top1_err": 86.04167, "top5_acc": 46.87500, "top5_err": 52.81250}
[06/12 17:39:35][INFO] train_net.py:  708: Epoch 3 takes 48.53s. Epochs from 0 to 3 take 48.70s in average and 48.68s in median.
[06/12 17:39:35][INFO] train_net.py:  714: For epoch 3, each iteraction takes 0.81s in average. From epoch 0 to 3, each iteraction takes 0.81s in average.
[06/12 17:39:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.57704, "dt_data": 0.00041, "dt_net": 0.57663, "epoch": "5/300", "eta": "2:50:42", "gpu_mem": "10.06G", "grad_norm": 4.19166, "iter": "10/60", "loss": 2.69528, "lr": 0.0002871295, "top1_acc": 12.50000, "top1_err": 84.37500, "top5_acc": 50.00000, "top5_err": 45.31250}
[06/12 17:39:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47238, "dt_data": 0.00086, "dt_net": 0.47151, "epoch": "5/300", "eta": "2:19:39", "gpu_mem": "10.06G", "grad_norm": 4.16792, "iter": "20/60", "loss": 2.68844, "lr": 0.0002978576, "top1_acc": 18.75000, "top1_err": 85.93750, "top5_acc": 53.12500, "top5_err": 48.43750}
[06/12 17:40:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.23411, "dt_data": 0.00039, "dt_net": 1.23372, "epoch": "5/300", "eta": "6:04:40", "gpu_mem": "10.06G", "grad_norm": 4.41587, "iter": "30/60", "loss": 2.67326, "lr": 0.0003085857, "top1_acc": 21.87500, "top1_err": 79.68750, "top5_acc": 59.37500, "top5_err": 45.31250}
[06/12 17:40:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47335, "dt_data": 0.00044, "dt_net": 0.47291, "epoch": "5/300", "eta": "2:19:47", "gpu_mem": "10.06G", "grad_norm": 4.23051, "iter": "40/60", "loss": 2.63860, "lr": 0.0003193138, "top1_acc": 18.75000, "top1_err": 78.12500, "top5_acc": 59.37500, "top5_err": 45.31250}
[06/12 17:40:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47090, "dt_data": 0.00070, "dt_net": 0.47020, "epoch": "5/300", "eta": "2:18:59", "gpu_mem": "10.06G", "grad_norm": 4.19429, "iter": "50/60", "loss": 2.62242, "lr": 0.0003300419, "top1_acc": 21.87500, "top1_err": 82.81250, "top5_acc": 56.25000, "top5_err": 43.75000}
[06/12 17:40:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46770, "dt_data": 0.00017, "dt_net": 0.46753, "epoch": "5/300", "eta": "2:17:58", "gpu_mem": "10.06G", "grad_norm": 4.45399, "iter": "60/60", "loss": 2.63888, "lr": 0.0003407699, "top1_acc": 25.00000, "top1_err": 81.25000, "top5_acc": 50.00000, "top5_err": 46.87500}
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
[06/12 17:40:23][INFO] logging.py:  101: json_stats: {"RAM": "13.64/31.07G", "_type": "train_epoch", "dt": 0.70455, "dt_data": 0.70455, "dt_net": 0.46753, "epoch": "5/300", "eta": "3:27:49", "gpu_mem": "10.06G", "grad_norm": 4.45399, "loss": 2.65622, "lr": 0.0003407699, "top1_acc": 19.37500, "top1_err": 81.40625, "top5_acc": 54.16667, "top5_err": 46.30208}
[06/12 17:40:23][INFO] train_net.py:  708: Epoch 4 takes 48.55s. Epochs from 0 to 4 take 48.67s in average and 48.55s in median.
[06/12 17:40:23][INFO] train_net.py:  714: For epoch 4, each iteraction takes 0.81s in average. From epoch 0 to 4, each iteraction takes 0.81s in average.
[06/12 17:40:23][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
[06/12 17:41:26][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "5/300", "eta": "0:00:00", "gpu_mem": "10.06G", "iter": "10/16", "time_diff": 0.13002, "top1_acc": 23.43750, "top1_err": 76.56250, "top5_acc": 64.06250, "top5_err": 35.93750}
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
[06/12 17:41:29][INFO] logging.py:  101: json_stats: {"RAM": "13.81/31.07G", "_type": "val_epoch", "epoch": "5/300", "gpu_mem": "10.06G", "min_top1_err": 74.89627, "min_top5_err": 36.51452, "time_diff": 0.61318, "top1_acc": 25.10373, "top1_err": 74.89627, "top5_acc": 63.48548, "top5_err": 36.51452}
[06/12 17:41:47][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46125, "dt_data": 0.00036, "dt_net": 0.46088, "epoch": "6/300", "eta": "2:15:59", "gpu_mem": "10.07G", "grad_norm": 4.52382, "iter": "10/60", "loss": 2.60584, "lr": 0.0003514980, "top1_acc": 28.12500, "top1_err": 78.12500, "top5_acc": 62.50000, "top5_err": 40.62500}
[06/12 17:41:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46738, "dt_data": 0.00057, "dt_net": 0.46681, "epoch": "6/300", "eta": "2:17:43", "gpu_mem": "10.07G", "grad_norm": 4.52295, "iter": "20/60", "loss": 2.58732, "lr": 0.0003622261, "top1_acc": 15.62500, "top1_err": 81.25000, "top5_acc": 56.25000, "top5_err": 42.18750}
[06/12 17:41:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46900, "dt_data": 0.00059, "dt_net": 0.46840, "epoch": "6/300", "eta": "2:18:07", "gpu_mem": "10.07G", "grad_norm": 4.14952, "iter": "30/60", "loss": 2.57775, "lr": 0.0003729542, "top1_acc": 18.75000, "top1_err": 78.12500, "top5_acc": 56.25000, "top5_err": 43.75000}
[06/12 17:42:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46461, "dt_data": 0.00068, "dt_net": 0.46393, "epoch": "6/300", "eta": "2:16:45", "gpu_mem": "10.07G", "grad_norm": 4.19577, "iter": "40/60", "loss": 2.53862, "lr": 0.0003836823, "top1_acc": 25.00000, "top1_err": 71.87500, "top5_acc": 53.12500, "top5_err": 39.06250}
[06/12 17:42:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47466, "dt_data": 0.00066, "dt_net": 0.47400, "epoch": "6/300", "eta": "2:19:37", "gpu_mem": "10.07G", "grad_norm": 4.62729, "iter": "50/60", "loss": 2.53543, "lr": 0.0003944104, "top1_acc": 25.00000, "top1_err": 75.00000, "top5_acc": 68.75000, "top5_err": 35.93750}
[06/12 17:42:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46499, "dt_data": 0.00017, "dt_net": 0.46481, "epoch": "6/300", "eta": "2:16:42", "gpu_mem": "10.07G", "grad_norm": 4.98415, "iter": "60/60", "loss": 2.49090, "lr": 0.0004051385, "top1_acc": 28.12500, "top1_err": 73.43750, "top5_acc": 62.50000, "top5_err": 37.50000}
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
[06/12 17:42:17][INFO] logging.py:  101: json_stats: {"RAM": "13.63/31.07G", "_type": "train_epoch", "dt": 0.68921, "dt_data": 0.68921, "dt_net": 0.46481, "epoch": "6/300", "eta": "3:22:37", "gpu_mem": "10.07G", "grad_norm": 4.98415, "loss": 2.55808, "lr": 0.0004051385, "top1_acc": 23.64583, "top1_err": 76.40625, "top5_acc": 60.10417, "top5_err": 39.53125}
[06/12 17:42:17][INFO] train_net.py:  708: Epoch 5 takes 48.55s. Epochs from 0 to 5 take 48.65s in average and 48.55s in median.
[06/12 17:42:17][INFO] train_net.py:  714: For epoch 5, each iteraction takes 0.81s in average. From epoch 0 to 5, each iteraction takes 0.81s in average.
[06/12 17:42:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.84780, "dt_data": 0.00048, "dt_net": 0.84732, "epoch": "7/300", "eta": "4:09:06", "gpu_mem": "10.07G", "grad_norm": 4.72869, "iter": "10/60", "loss": 2.53460, "lr": 0.0004158666, "top1_acc": 25.00000, "top1_err": 78.12500, "top5_acc": 59.37500, "top5_err": 39.06250}
[06/12 17:42:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47400, "dt_data": 0.00054, "dt_net": 0.47346, "epoch": "7/300", "eta": "2:19:11", "gpu_mem": "10.07G", "grad_norm": 4.32962, "iter": "20/60", "loss": 2.41805, "lr": 0.0004265947, "top1_acc": 28.12500, "top1_err": 68.75000, "top5_acc": 68.75000, "top5_err": 31.25000}
[06/12 17:42:47][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.87793, "dt_data": 0.00047, "dt_net": 0.87746, "epoch": "7/300", "eta": "4:17:40", "gpu_mem": "10.07G", "grad_norm": 4.76018, "iter": "30/60", "loss": 2.38837, "lr": 0.0004373228, "top1_acc": 31.25000, "top1_err": 68.75000, "top5_acc": 68.75000, "top5_err": 31.25000}
[06/12 17:42:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48536, "dt_data": 0.00037, "dt_net": 0.48499, "epoch": "7/300", "eta": "2:22:22", "gpu_mem": "10.07G", "grad_norm": 4.56071, "iter": "40/60", "loss": 2.40491, "lr": 0.0004480509, "top1_acc": 31.25000, "top1_err": 70.31250, "top5_acc": 65.62500, "top5_err": 34.37500}
[06/12 17:42:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.84751, "dt_data": 0.00031, "dt_net": 0.84720, "epoch": "7/300", "eta": "4:08:27", "gpu_mem": "10.07G", "grad_norm": 4.54466, "iter": "50/60", "loss": 2.22899, "lr": 0.0004587790, "top1_acc": 34.37500, "top1_err": 67.18750, "top5_acc": 78.12500, "top5_err": 21.87500}
[06/12 17:43:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46855, "dt_data": 0.00021, "dt_net": 0.46834, "epoch": "7/300", "eta": "2:17:17", "gpu_mem": "10.07G", "grad_norm": 5.18365, "iter": "60/60", "loss": 2.37168, "lr": 0.0004695070, "top1_acc": 28.12500, "top1_err": 73.43750, "top5_acc": 71.87500, "top5_err": 28.12500}
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
[06/12 17:43:06][INFO] logging.py:  101: json_stats: {"RAM": "13.63/31.07G", "_type": "train_epoch", "dt": 0.70850, "dt_data": 0.70850, "dt_net": 0.46834, "epoch": "7/300", "eta": "3:27:34", "gpu_mem": "10.07G", "grad_norm": 5.18365, "loss": 2.39805, "lr": 0.0004695070, "top1_acc": 30.20833, "top1_err": 71.04167, "top5_acc": 67.70833, "top5_err": 31.45833}
[06/12 17:43:06][INFO] train_net.py:  708: Epoch 6 takes 48.59s. Epochs from 0 to 6 take 48.64s in average and 48.55s in median.
[06/12 17:43:06][INFO] train_net.py:  714: For epoch 6, each iteraction takes 0.81s in average. From epoch 0 to 6, each iteraction takes 0.81s in average.
[06/12 17:43:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47448, "dt_data": 0.00049, "dt_net": 0.47399, "epoch": "8/300", "eta": "2:18:56", "gpu_mem": "10.07G", "grad_norm": 4.73937, "iter": "10/60", "loss": 2.34351, "lr": 0.0004802351, "top1_acc": 28.12500, "top1_err": 76.56250, "top5_acc": 71.87500, "top5_err": 26.56250}
[06/12 17:43:29][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47033, "dt_data": 0.00052, "dt_net": 0.46981, "epoch": "8/300", "eta": "2:17:39", "gpu_mem": "10.07G", "grad_norm": 4.32174, "iter": "20/60", "loss": 2.19643, "lr": 0.0004909632, "top1_acc": 34.37500, "top1_err": 62.50000, "top5_acc": 75.00000, "top5_err": 25.00000}
[06/12 17:43:36][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.66720, "dt_data": 0.19654, "dt_net": 0.47065, "epoch": "8/300", "eta": "3:15:09", "gpu_mem": "10.07G", "grad_norm": 4.77123, "iter": "30/60", "loss": 2.24609, "lr": 0.0005016913, "top1_acc": 31.25000, "top1_err": 67.18750, "top5_acc": 78.12500, "top5_err": 25.00000}
[06/12 17:43:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47245, "dt_data": 0.00046, "dt_net": 0.47198, "epoch": "8/300", "eta": "2:18:06", "gpu_mem": "10.07G", "grad_norm": 4.77870, "iter": "40/60", "loss": 2.19645, "lr": 0.0005124194, "top1_acc": 31.25000, "top1_err": 68.75000, "top5_acc": 81.25000, "top5_err": 21.87500}
[06/12 17:43:48][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.98840, "dt_data": 0.51618, "dt_net": 0.47221, "epoch": "8/300", "eta": "4:48:46", "gpu_mem": "10.07G", "grad_norm": 4.36400, "iter": "50/60", "loss": 2.14163, "lr": 0.0005231475, "top1_acc": 34.37500, "top1_err": 59.37500, "top5_acc": 78.12500, "top5_err": 18.75000}
[06/12 17:43:54][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46856, "dt_data": 0.00018, "dt_net": 0.46838, "epoch": "8/300", "eta": "2:16:49", "gpu_mem": "10.07G", "grad_norm": 4.47812, "iter": "60/60", "loss": 2.13242, "lr": 0.0005338756, "top1_acc": 34.37500, "top1_err": 67.18750, "top5_acc": 81.25000, "top5_err": 21.87500}
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
[06/12 17:43:54][INFO] logging.py:  101: json_stats: {"RAM": "13.64/31.07G", "_type": "train_epoch", "dt": 0.71555, "dt_data": 0.71555, "dt_net": 0.46838, "epoch": "8/300", "eta": "3:28:55", "gpu_mem": "10.07G", "grad_norm": 4.47812, "loss": 2.22011, "lr": 0.0005338756, "top1_acc": 34.47917, "top1_err": 66.25000, "top5_acc": 75.72917, "top5_err": 24.11458}
[06/12 17:43:54][INFO] train_net.py:  708: Epoch 7 takes 48.64s. Epochs from 0 to 7 take 48.64s in average and 48.57s in median.
[06/12 17:43:54][INFO] train_net.py:  714: For epoch 7, each iteraction takes 0.81s in average. From epoch 0 to 7, each iteraction takes 0.81s in average.
[06/12 17:44:12][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.73015, "dt_data": 0.00042, "dt_net": 0.72973, "epoch": "9/300", "eta": "3:33:04", "gpu_mem": "10.07G", "grad_norm": 4.96290, "iter": "10/60", "loss": 2.10088, "lr": 0.0005446037, "top1_acc": 31.25000, "top1_err": 64.06250, "top5_acc": 75.00000, "top5_err": 20.31250}
[06/12 17:44:18][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47844, "dt_data": 0.00043, "dt_net": 0.47800, "epoch": "9/300", "eta": "2:19:32", "gpu_mem": "10.07G", "grad_norm": 4.81587, "iter": "20/60", "loss": 2.11028, "lr": 0.0005553318, "top1_acc": 34.37500, "top1_err": 62.50000, "top5_acc": 81.25000, "top5_err": 17.18750}
[06/12 17:44:24][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.06684, "dt_data": 0.00042, "dt_net": 1.06642, "epoch": "9/300", "eta": "5:10:58", "gpu_mem": "10.07G", "grad_norm": 4.79441, "iter": "30/60", "loss": 2.00627, "lr": 0.0005660599, "top1_acc": 40.62500, "top1_err": 59.37500, "top5_acc": 87.50000, "top5_err": 17.18750}
[06/12 17:44:30][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47335, "dt_data": 0.00038, "dt_net": 0.47297, "epoch": "9/300", "eta": "2:17:54", "gpu_mem": "10.07G", "grad_norm": 5.80420, "iter": "40/60", "loss": 2.04583, "lr": 0.0005767880, "top1_acc": 43.75000, "top1_err": 62.50000, "top5_acc": 81.25000, "top5_err": 21.87500}
[06/12 17:44:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.00090, "dt_data": 0.00056, "dt_net": 1.00034, "epoch": "9/300", "eta": "4:51:25", "gpu_mem": "10.07G", "grad_norm": 5.41226, "iter": "50/60", "loss": 2.01209, "lr": 0.0005875161, "top1_acc": 37.50000, "top1_err": 62.50000, "top5_acc": 81.25000, "top5_err": 23.43750}
[06/12 17:44:42][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47112, "dt_data": 0.00030, "dt_net": 0.47082, "epoch": "9/300", "eta": "2:17:05", "gpu_mem": "10.07G", "grad_norm": 5.30998, "iter": "60/60", "loss": 2.06951, "lr": 0.0005982441, "top1_acc": 34.37500, "top1_err": 62.50000, "top5_acc": 81.25000, "top5_err": 15.62500}
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision-0.14.1a0+5e8e2f1-py3.8-linux-x86_64.egg/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
[06/12 17:44:43][INFO] logging.py:  101: json_stats: {"RAM": "13.63/31.07G", "_type": "train_epoch", "dt": 0.70926, "dt_data": 0.70926, "dt_net": 0.47082, "epoch": "9/300", "eta": "3:26:22", "gpu_mem": "10.07G", "grad_norm": 5.30998, "loss": 2.04545, "lr": 0.0005982441, "top1_acc": 38.22917, "top1_err": 61.87500, "top5_acc": 80.62500, "top5_err": 19.89583}
[06/12 17:44:43][INFO] train_net.py:  708: Epoch 8 takes 48.62s. Epochs from 0 to 8 take 48.64s in average and 48.59s in median.
[06/12 17:44:43][INFO] train_net.py:  714: For epoch 8, each iteraction takes 0.81s in average. From epoch 0 to 8, each iteraction takes 0.81s in average.
[06/12 17:45:00][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47084, "dt_data": 0.00061, "dt_net": 0.47023, "epoch": "10/300", "eta": "2:16:56", "gpu_mem": "10.07G", "grad_norm": 6.58038, "iter": "10/60", "loss": 1.89881, "lr": 0.0006089722, "top1_acc": 43.75000, "top1_err": 56.25000, "top5_acc": 81.25000, "top5_err": 15.62500}
[06/12 17:45:06][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48264, "dt_data": 0.00056, "dt_net": 0.48208, "epoch": "10/300", "eta": "2:20:17", "gpu_mem": "10.07G", "grad_norm": 5.16328, "iter": "20/60", "loss": 1.89636, "lr": 0.0006197003, "top1_acc": 43.75000, "top1_err": 57.81250, "top5_acc": 81.25000, "top5_err": 18.75000}
