[06/29 23:21:12][INFO] train_net.py:  612: Train with config:
[06/29 23:21:12][INFO] train_net.py:  613: {'AUG': {'AA_TYPE': 'rand-m9-mstd0.5-inc1',
         'COLOR_JITTER': 0.4,
         'ENABLE': False,
         'GEN_MASK_LOADER': False,
         'INTERPOLATION': 'bicubic',
         'MASK_FRAMES': False,
         'MASK_RATIO': 0.0,
         'MASK_TUBE': False,
         'MASK_WINDOW_SIZE': [8, 7, 7],
         'MAX_MASK_PATCHES_PER_BLOCK': None,
         'NUM_SAMPLE': 1,
         'RE_COUNT': 1,
         'RE_MODE': 'pixel',
         'RE_PROB': 0.25,
         'RE_SPLIT': False},
 'AVA': {'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.9,
         'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv',
         'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/',
         'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'],
         'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'],
         'TRAIN_LISTS': ['train.csv'],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': [],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'GLOBAL_SYNC': False,
        'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'CONTRASTIVE': {'BN_MLP': False,
                 'BN_SYNC_MLP': False,
                 'DELTA_CLIPS_MAX': inf,
                 'DELTA_CLIPS_MIN': -inf,
                 'DIM': 128,
                 'INTERP_MEMORY': False,
                 'KNN_ON': True,
                 'LENGTH': 239975,
                 'LOCAL_SHUFFLE_BN': True,
                 'MEM_TYPE': '1d',
                 'MLP_DIM': 2048,
                 'MOCO_MULTI_VIEW_QUEUE': False,
                 'MOMENTUM': 0.5,
                 'MOMENTUM_ANNEALING': False,
                 'NUM_CLASSES_DOWNSTREAM': 400,
                 'NUM_MLP_LAYERS': 1,
                 'PREDICTOR_DEPTHS': [],
                 'QUEUE_LEN': 65536,
                 'SEQUENTIAL': False,
                 'SIMCLR_DIST_ON': True,
                 'SWAV_QEUE_LEN': 0,
                 'T': 0.07,
                 'TYPE': 'mem'},
 'DATA': {'CAM_VIEWS_METHODS': ['crop', 'noise_crop'],
          'COLOR_RND_GRAYSCALE': 0.0,
          'CROP_PROMPT': False,
          'DECODING_BACKEND': 'torchvision',
          'DECODING_SHORT_SIZE': 256,
          'DUMMY_LOAD': False,
          'ENSEMBLE_METHOD': 'sum',
          'IN22K_TRAINVAL': False,
          'IN22k_VAL_IN1K': '',
          'INPUT_CHANNEL_NUM': [3],
          'INV_UNIFORM_SAMPLE': False,
          'IN_VAL_CROP_RATIO': 0.875,
          'LOADER_CHUNK_OVERALL_SIZE': 0,
          'LOADER_CHUNK_SIZE': 0,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 16,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '',
          'PATH_TO_PRELOAD_IMDB': '',
          'RANDOM_FLIP': False,
          'RETURN_CROPPING_PARAMS': False,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 4,
          'SKIP_ROWS': 0,
          'SSL_BLUR_SIGMA_MAX': [0.0, 2.0],
          'SSL_BLUR_SIGMA_MIN': [0.0, 0.1],
          'SSL_COLOR_BRI_CON_SAT': [0.4, 0.4, 0.4],
          'SSL_COLOR_HUE': 0.1,
          'SSL_COLOR_JITTER': False,
          'SSL_MOCOV2_AUG': False,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 30,
          'TEST_CROP_SIZE': 224,
          'TIME_DIFF_PROB': 0.0,
          'TRAIN_CROP_NUM_SPATIAL': 1,
          'TRAIN_CROP_NUM_TEMPORAL': 1,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333],
          'TRAIN_JITTER_FPS': 0.0,
          'TRAIN_JITTER_MOTION_SHIFT': False,
          'TRAIN_JITTER_SCALES': [256, 320],
          'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0],
          'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
          'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                               [-0.5808, -0.0045, -0.814],
                               [-0.5836, -0.6948, 0.4203]],
          'USE_OFFSET_SAMPLING': False},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 4,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': False,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 10,
 'MASK': {'DECODER_DEPTH': 0,
          'DECODER_EMBED_DIM': 512,
          'DECODER_SEP_POS_EMBED': False,
          'DEC_KV_KERNEL': [],
          'DEC_KV_STRIDE': [],
          'ENABLE': False,
          'HEAD_TYPE': 'separate',
          'MAE_ON': False,
          'MAE_RND_MASK': False,
          'NORM_PRED_PIXEL': True,
          'PER_FRAME_MASKING': False,
          'PRED_HOG': False,
          'PRETRAIN_DEPTH': [15],
          'SCALE_INIT_BY_DEPTH': False,
          'TIME_STRIDE_LOSS': True},
 'MIXUP': {'ALPHA': 0.8,
           'CUTMIX_ALPHA': 1.0,
           'ENABLE': False,
           'LABEL_SMOOTH_VALUE': 0.1,
           'PROB': 1.0,
           'SWITCH_PROB': 0.5},
 'MODEL': {'ACT_CHECKPOINT': False,
           'ARCH': 'mvit',
           'DETACH_FINAL_FC': False,
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'FP16_ALLREDUCE': False,
           'FROZEN_BN': False,
           'HEAD_ACT': 'softmax',
           'LOSS_FUNC': 'soft_cross_entropy',
           'MODEL_NAME': 'MViT',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 16,
           'SINGLE_PATHWAY_ARCH': ['2d',
                                   'c2d',
                                   'i3d',
                                   'slow',
                                   'x3d',
                                   'mvit',
                                   'maskmvit']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'MVIT': {'CLS_EMBED_ON': True,
          'DEPTH': 24,
          'DIM_MUL': [[2, 2.0], [5, 2.0], [21, 2.0]],
          'DIM_MUL_IN_ATT': True,
          'DROPOUT_RATE': 0.0,
          'DROPPATH_RATE': 0.3,
          'EMBED_DIM': 96,
          'HEAD_INIT_SCALE': 1.0,
          'HEAD_MUL': [[2, 2.0], [5, 2.0], [21, 2.0]],
          'LAYER_SCALE_INIT_VALUE': 0.0,
          'MLP_RATIO': 4.0,
          'MODE': 'conv',
          'NORM': 'layernorm',
          'NORM_STEM': False,
          'NUM_HEADS': 1,
          'PATCH_2D': False,
          'PATCH_KERNEL': [3, 7, 7],
          'PATCH_PADDING': [1, 3, 3],
          'PATCH_STRIDE': [2, 4, 4],
          'POOL_FIRST': False,
          'POOL_KVQ_KERNEL': [3, 3, 3],
          'POOL_KV_STRIDE': [],
          'POOL_KV_STRIDE_ADAPTIVE': [1, 8, 8],
          'POOL_Q_STRIDE': [[0, 1, 1, 1],
                            [1, 1, 1, 1],
                            [2, 1, 2, 2],
                            [3, 1, 1, 1],
                            [4, 1, 1, 1],
                            [5, 1, 2, 2],
                            [6, 1, 1, 1],
                            [7, 1, 1, 1],
                            [8, 1, 1, 1],
                            [9, 1, 1, 1],
                            [10, 1, 1, 1],
                            [11, 1, 1, 1],
                            [12, 1, 1, 1],
                            [13, 1, 1, 1],
                            [14, 1, 1, 1],
                            [15, 1, 1, 1],
                            [16, 1, 1, 1],
                            [17, 1, 1, 1],
                            [18, 1, 1, 1],
                            [19, 1, 1, 1],
                            [20, 1, 1, 1],
                            [21, 1, 2, 2],
                            [22, 1, 1, 1],
                            [23, 1, 1, 1]],
          'QKV_BIAS': True,
          'REL_POS_SPATIAL': True,
          'REL_POS_TEMPORAL': True,
          'REL_POS_ZERO_INIT': False,
          'RESIDUAL_POOLING': True,
          'REV': {'BUFFER_LAYERS': [],
                  'ENABLE': False,
                  'PRE_Q_FUSION': 'avg',
                  'RESPATH_FUSE': 'concat',
                  'RES_PATH': 'conv'},
          'SEPARATE_QKV': False,
          'SEP_POS_EMBED': False,
          'USE_ABS_POS': False,
          'USE_FIXED_SINCOS_POS': False,
          'USE_MEAN_POOLING': False,
          'ZERO_DECAY_POS_CLS': False},
 'NONLOCAL': {'GROUP': [[1], [1], [1], [1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[]], [[]], [[]], [[]]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 2,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'PROMPT': {'ENABLE': True,
            'GPU': None,
            'IMAGE_FOLDER': './visual_prompting/save/images/mvitv2-b_fixed_patch',
            'LEARNING_RATE': 0.2,
            'METHOD': 'fixed_patch',
            'MODEL_FOLDER': './visual_prompting/save/models/mvitv2-b_fixed_patch',
            'MOMENTUM': 0.9,
            'PRINT_GRADS': False,
            'PROMPT_SAVE_FREQ': 5,
            'PROMPT_SIZE': 224,
            'RESUME': None,
            'START_EPOCH': 1,
            'WARMUP': 30,
            'WEIGHT_DECAY': 0.001},
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1], [1], [1], [1]],
            'SPATIAL_STRIDES': [[1], [2], [2], [2]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': False,
            'ZERO_INIT_FINAL_CONV': False},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 8,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 5},
 'SOLVER': {'BASE_LR': 0.0002,
            'BASE_LR_SCALE_NUM_SHARDS': True,
            'BETAS': (0.9, 0.999),
            'CLIP_GRAD_L2NORM': 1.0,
            'CLIP_GRAD_VAL': None,
            'COSINE_AFTER_WARMUP': True,
            'COSINE_END_LR': 2e-05,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LARS_ON': False,
            'LAYER_DECAY': 1.0,
            'LRS': [],
            'LR_POLICY': 'cosine',
            'MAX_EPOCH': 400,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'adamw',
            'STEPS': [],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 30.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 2e-05,
            'WEIGHT_DECAY': 0.0001,
            'ZERO_WD_1D_PARAM': True},
 'TASK': '',
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': False,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 2,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'kinetics',
          'ENABLE': False,
          'NUM_ENSEMBLE_VIEWS': 5,
          'NUM_SPATIAL_CROPS': 1,
          'NUM_TEMPORAL_CLIPS': [],
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 16,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': True,
           'CHECKPOINT_FILE_PATH': 'checkpoints/mvitv2-b_no_rand_flip_best_epoch_00160.pyth',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_IN_INIT': False,
           'CHECKPOINT_PERIOD': 20,
           'CHECKPOINT_TYPE': 'pytorch',
           'DATASET': 'kinetics',
           'ENABLE': True,
           'EVAL_PERIOD': 5,
           'KILL_LOSS_EXPLOSION_FACTOR': 0.0,
           'MIXED_PRECISION': False},
 'VIS_MASK': CfgNode({'ENABLE': False}),
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[06/29 23:21:14][INFO] misc.py:  185: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=96, bias=True)
        )
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=96, bias=True)
        )
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
      )
      (4): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
      )
      (5): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (6): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (7): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (8): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (9): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (10): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (11): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (12): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (13): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (16): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (17): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (18): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (19): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (20): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (21): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (22): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
      (23): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): TransformerBasicHead(
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=16, bias=True)
      (act): Softmax(dim=1)
    )
  )
)
[06/29 23:21:14][INFO] misc.py:  187: Params: 50,897,968
[06/29 23:21:14][INFO] misc.py:  188: Mem: 0.38045549392700195 MB
[06/29 23:21:18][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 729 time(s)
[06/29 23:21:18][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 102 time(s)
[06/29 23:21:18][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 144 time(s)
[06/29 23:21:18][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 96 time(s)
[06/29 23:21:18][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 120 time(s)
[06/29 23:21:18][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 25 time(s)
[06/29 23:21:18][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 24 time(s)
[06/29 23:21:18][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[06/29 23:21:18][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.16.drop_path, module.blocks.17.drop_path, module.blocks.18.drop_path, module.blocks.19.drop_path, module.blocks.2.drop_path, module.blocks.20.drop_path, module.blocks.21.drop_path, module.blocks.22.drop_path, module.blocks.23.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[06/29 23:21:18][INFO] misc.py:  190: Flops: 92.63208983999999 G
[06/29 23:21:21][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 121 time(s)
[06/29 23:21:21][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 729 time(s)
[06/29 23:21:21][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 102 time(s)
[06/29 23:21:21][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 144 time(s)
[06/29 23:21:21][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 96 time(s)
[06/29 23:21:21][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 120 time(s)
[06/29 23:21:21][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 25 time(s)
[06/29 23:21:21][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 24 time(s)
[06/29 23:21:21][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[06/29 23:21:21][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.16.drop_path, module.blocks.17.drop_path, module.blocks.18.drop_path, module.blocks.19.drop_path, module.blocks.2.drop_path, module.blocks.20.drop_path, module.blocks.21.drop_path, module.blocks.22.drop_path, module.blocks.23.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[06/29 23:21:21][INFO] misc.py:  191: Activations: 357.084096 M
[06/29 23:21:21][INFO] misc.py:  196: nvidia-smi
[06/29 23:21:22][INFO] train_net.py:  654: Load from given checkpoint file.
[06/29 23:21:22][INFO] checkpoint.py:  223: Loading network weights from checkpoints/mvitv2-b_no_rand_flip_best_epoch_00160.pyth.
[06/29 23:21:22][INFO] kinetics.py:   93: Constructing Kinetics train...
[06/29 23:21:22][INFO] kinetics.py:  169: Constructing kinetics dataloader (size: 1927 skip_rows 0) from train.csv 
[06/29 23:21:22][INFO] kinetics.py:   93: Constructing Kinetics val...
[06/29 23:21:22][INFO] kinetics.py:  169: Constructing kinetics dataloader (size: 482 skip_rows 0) from val.csv 
[06/29 23:21:22][INFO] train_net.py:  751: Start epoch: 1
[06/29 23:21:33][INFO] distributed.py: 1027: Reducer buckets have been rebuilt in this iteration.
[06/29 23:21:45][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.34170, "dt_data": 0.00037, "dt_net": 1.34134, "epoch": "1/400", "eta": "17:53:08", "gpu_mem": "17.91G", "grad_norm": 10.19325, "iter": "10/120", "loss": 1.81484, "lr": 0.0000204500, "top1_acc": 43.75000, "top1_err": 56.25000, "top5_acc": 81.25000, "top5_err": 18.75000}
[06/29 23:21:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.33352, "dt_data": 0.00043, "dt_net": 1.33309, "epoch": "1/400", "eta": "17:46:22", "gpu_mem": "17.91G", "grad_norm": 15.18155, "iter": "20/120", "loss": 1.36911, "lr": 0.0000209500, "top1_acc": 56.25000, "top1_err": 43.75000, "top5_acc": 87.50000, "top5_err": 12.50000}
[06/29 23:22:12][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38110, "dt_data": 0.00050, "dt_net": 1.38060, "epoch": "1/400", "eta": "18:24:11", "gpu_mem": "17.91G", "grad_norm": 11.12695, "iter": "30/120", "loss": 1.30614, "lr": 0.0000214500, "top1_acc": 59.37500, "top1_err": 40.62500, "top5_acc": 81.25000, "top5_err": 18.75000}
[06/29 23:22:26][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38716, "dt_data": 0.00054, "dt_net": 1.38663, "epoch": "1/400", "eta": "18:28:48", "gpu_mem": "17.91G", "grad_norm": 13.75281, "iter": "40/120", "loss": 1.09205, "lr": 0.0000219500, "top1_acc": 62.50000, "top1_err": 37.50000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:22:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.36403, "dt_data": 0.00112, "dt_net": 1.36291, "epoch": "1/400", "eta": "18:10:05", "gpu_mem": "17.91G", "grad_norm": 10.53844, "iter": "50/120", "loss": 1.20816, "lr": 0.0000224500, "top1_acc": 62.50000, "top1_err": 37.50000, "top5_acc": 87.50000, "top5_err": 12.50000}
[06/29 23:22:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.36085, "dt_data": 0.00044, "dt_net": 1.36042, "epoch": "1/400", "eta": "18:07:19", "gpu_mem": "17.91G", "grad_norm": 13.51685, "iter": "60/120", "loss": 0.86443, "lr": 0.0000229500, "top1_acc": 65.62500, "top1_err": 34.37500, "top5_acc": 90.62500, "top5_err": 9.37500}
[06/29 23:23:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39341, "dt_data": 0.00042, "dt_net": 1.39299, "epoch": "1/400", "eta": "18:33:06", "gpu_mem": "17.91G", "grad_norm": 9.71961, "iter": "70/120", "loss": 0.82584, "lr": 0.0000234500, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 87.50000, "top5_err": 12.50000}
[06/29 23:23:21][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38631, "dt_data": 0.00043, "dt_net": 1.38588, "epoch": "1/400", "eta": "18:27:11", "gpu_mem": "17.91G", "grad_norm": 10.50487, "iter": "80/120", "loss": 1.10016, "lr": 0.0000239500, "top1_acc": 65.62500, "top1_err": 34.37500, "top5_acc": 87.50000, "top5_err": 12.50000}
[06/29 23:23:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.37593, "dt_data": 0.00040, "dt_net": 1.37553, "epoch": "1/400", "eta": "18:18:40", "gpu_mem": "17.91G", "grad_norm": 8.50525, "iter": "90/120", "loss": 0.81493, "lr": 0.0000244500, "top1_acc": 71.87500, "top1_err": 28.12500, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:23:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.36638, "dt_data": 0.00040, "dt_net": 1.36599, "epoch": "1/400", "eta": "18:10:49", "gpu_mem": "17.91G", "grad_norm": 15.83193, "iter": "100/120", "loss": 0.82040, "lr": 0.0000249500, "top1_acc": 71.87500, "top1_err": 28.12500, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:24:03][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.37186, "dt_data": 0.00042, "dt_net": 1.37144, "epoch": "1/400", "eta": "18:14:58", "gpu_mem": "17.91G", "grad_norm": 4.23161, "iter": "110/120", "loss": 0.56802, "lr": 0.0000254500, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:24:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39622, "dt_data": 0.00026, "dt_net": 1.39596, "epoch": "1/400", "eta": "18:34:11", "gpu_mem": "17.91G", "grad_norm": 10.15897, "iter": "120/120", "loss": 0.51622, "lr": 0.0000259500, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:24:17][INFO] logging.py:  101: json_stats: {"RAM": "13.49/31.07G", "_type": "train_epoch", "dt": 0.80304, "dt_data": 0.80304, "dt_net": 1.39596, "epoch": "1/400", "eta": "10:40:48", "gpu_mem": "17.91G", "grad_norm": 10.15897, "loss": 1.09414, "lr": 0.0000259500, "top1_acc": 65.52083, "top1_err": 34.47917, "top5_acc": 89.01042, "top5_err": 10.98958}
[06/29 23:24:17][INFO] train_net.py:  813: Epoch 0 takes 175.23s. Epochs from 0 to 0 take 175.23s in average and 175.23s in median.
[06/29 23:24:17][INFO] train_net.py:  819: For epoch 0, each iteraction takes 1.46s in average. From epoch 0 to 0, each iteraction takes 1.46s in average.
[06/29 23:24:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.35893, "dt_data": 0.00039, "dt_net": 1.35855, "epoch": "2/400", "eta": "18:04:12", "gpu_mem": "17.91G", "grad_norm": 5.59618, "iter": "10/120", "loss": 0.59169, "lr": 0.0000264500, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:24:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.34598, "dt_data": 0.00041, "dt_net": 1.34556, "epoch": "2/400", "eta": "17:53:38", "gpu_mem": "17.91G", "grad_norm": 7.37608, "iter": "20/120", "loss": 0.41384, "lr": 0.0000269500, "top1_acc": 84.37500, "top1_err": 15.62500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/29 23:25:08][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38967, "dt_data": 0.00041, "dt_net": 1.38925, "epoch": "2/400", "eta": "18:28:15", "gpu_mem": "17.91G", "grad_norm": 13.05266, "iter": "30/120", "loss": 0.60820, "lr": 0.0000274500, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:25:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38918, "dt_data": 0.00042, "dt_net": 1.38876, "epoch": "2/400", "eta": "18:27:38", "gpu_mem": "17.91G", "grad_norm": 13.30916, "iter": "40/120", "loss": 0.83926, "lr": 0.0000279500, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:25:36][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38965, "dt_data": 0.00040, "dt_net": 1.38924, "epoch": "2/400", "eta": "18:27:46", "gpu_mem": "17.91G", "grad_norm": 14.53618, "iter": "50/120", "loss": 0.69527, "lr": 0.0000284500, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:25:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.37791, "dt_data": 0.00055, "dt_net": 1.37736, "epoch": "2/400", "eta": "18:18:11", "gpu_mem": "17.91G", "grad_norm": 5.90306, "iter": "60/120", "loss": 0.73664, "lr": 0.0000289500, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:26:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.40723, "dt_data": 0.00041, "dt_net": 1.40682, "epoch": "2/400", "eta": "18:41:19", "gpu_mem": "17.91G", "grad_norm": 1.74069, "iter": "70/120", "loss": 0.61546, "lr": 0.0000294500, "top1_acc": 84.37500, "top1_err": 15.62500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/29 23:26:18][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39550, "dt_data": 0.00046, "dt_net": 1.39503, "epoch": "2/400", "eta": "18:31:44", "gpu_mem": "17.91G", "grad_norm": 12.55875, "iter": "80/120", "loss": 0.42631, "lr": 0.0000299500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:26:32][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39625, "dt_data": 0.00041, "dt_net": 1.39584, "epoch": "2/400", "eta": "18:32:06", "gpu_mem": "17.91G", "grad_norm": 2.77622, "iter": "90/120", "loss": 0.56367, "lr": 0.0000304500, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:26:45][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.40704, "dt_data": 0.00042, "dt_net": 1.40662, "epoch": "2/400", "eta": "18:40:28", "gpu_mem": "17.91G", "grad_norm": 11.68810, "iter": "100/120", "loss": 0.51078, "lr": 0.0000309500, "top1_acc": 84.37500, "top1_err": 15.62500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/29 23:26:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38168, "dt_data": 0.00053, "dt_net": 1.38114, "epoch": "2/400", "eta": "18:20:02", "gpu_mem": "17.91G", "grad_norm": 15.32766, "iter": "110/120", "loss": 0.53946, "lr": 0.0000314500, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:27:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.35884, "dt_data": 0.00026, "dt_net": 1.35858, "epoch": "2/400", "eta": "18:01:38", "gpu_mem": "17.91G", "grad_norm": 7.31498, "iter": "120/120", "loss": 0.36439, "lr": 0.0000319500, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/29 23:27:14][INFO] logging.py:  101: json_stats: {"RAM": "13.49/31.07G", "_type": "train_epoch", "dt": 0.78643, "dt_data": 0.78643, "dt_net": 1.35858, "epoch": "2/400", "eta": "10:25:58", "gpu_mem": "17.91G", "grad_norm": 7.31498, "loss": 0.61401, "lr": 0.0000319500, "top1_acc": 80.31250, "top1_err": 19.68750, "top5_acc": 95.62500, "top5_err": 4.37500}
[06/29 23:27:14][INFO] train_net.py:  813: Epoch 1 takes 176.56s. Epochs from 0 to 1 take 175.90s in average and 175.90s in median.
[06/29 23:27:14][INFO] train_net.py:  819: For epoch 1, each iteraction takes 1.47s in average. From epoch 0 to 1, each iteraction takes 1.47s in average.
[06/29 23:27:38][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39396, "dt_data": 0.00068, "dt_net": 1.39327, "epoch": "3/400", "eta": "18:29:21", "gpu_mem": "17.91G", "grad_norm": 6.69982, "iter": "10/120", "loss": 0.40068, "lr": 0.0000324500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:27:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.35539, "dt_data": 0.00075, "dt_net": 1.35464, "epoch": "3/400", "eta": "17:58:26", "gpu_mem": "17.91G", "grad_norm": 16.47097, "iter": "20/120", "loss": 0.48297, "lr": 0.0000329500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:28:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.36889, "dt_data": 0.00044, "dt_net": 1.36845, "epoch": "3/400", "eta": "18:08:57", "gpu_mem": "17.91G", "grad_norm": 3.26926, "iter": "30/120", "loss": 0.40688, "lr": 0.0000334500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:28:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39847, "dt_data": 0.00043, "dt_net": 1.39804, "epoch": "3/400", "eta": "18:32:15", "gpu_mem": "17.91G", "grad_norm": 5.52985, "iter": "40/120", "loss": 0.32856, "lr": 0.0000339500, "top1_acc": 90.62500, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:28:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39429, "dt_data": 0.00046, "dt_net": 1.39383, "epoch": "3/400", "eta": "18:28:41", "gpu_mem": "17.91G", "grad_norm": 12.63799, "iter": "50/120", "loss": 0.60741, "lr": 0.0000344500, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/29 23:28:47][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39715, "dt_data": 0.00040, "dt_net": 1.39675, "epoch": "3/400", "eta": "18:30:44", "gpu_mem": "17.91G", "grad_norm": 3.04372, "iter": "60/120", "loss": 0.60650, "lr": 0.0000349500, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:29:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.42027, "dt_data": 0.00046, "dt_net": 1.41981, "epoch": "3/400", "eta": "18:48:52", "gpu_mem": "17.91G", "grad_norm": 9.18051, "iter": "70/120", "loss": 0.61131, "lr": 0.0000354500, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:29:15][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38531, "dt_data": 0.00041, "dt_net": 1.38490, "epoch": "3/400", "eta": "18:20:51", "gpu_mem": "17.91G", "grad_norm": 2.11383, "iter": "80/120", "loss": 0.54499, "lr": 0.0000359500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:29:29][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.37013, "dt_data": 0.00038, "dt_net": 1.36975, "epoch": "3/400", "eta": "18:08:34", "gpu_mem": "17.91G", "grad_norm": 6.33528, "iter": "90/120", "loss": 0.41657, "lr": 0.0000364500, "top1_acc": 84.37500, "top1_err": 15.62500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:29:42][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.37211, "dt_data": 0.00070, "dt_net": 1.37141, "epoch": "3/400", "eta": "18:09:54", "gpu_mem": "17.91G", "grad_norm": 8.13820, "iter": "100/120", "loss": 0.49917, "lr": 0.0000369500, "top1_acc": 84.37500, "top1_err": 15.62500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/29 23:29:56][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.37365, "dt_data": 0.00039, "dt_net": 1.37326, "epoch": "3/400", "eta": "18:10:54", "gpu_mem": "17.91G", "grad_norm": 6.44172, "iter": "110/120", "loss": 0.35870, "lr": 0.0000374500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:30:10][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.40554, "dt_data": 0.00028, "dt_net": 1.40526, "epoch": "3/400", "eta": "18:35:59", "gpu_mem": "17.91G", "grad_norm": 3.61747, "iter": "120/120", "loss": 0.37304, "lr": 0.0000379500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/29 23:30:11][INFO] logging.py:  101: json_stats: {"RAM": "13.50/31.07G", "_type": "train_epoch", "dt": 0.77537, "dt_data": 0.77537, "dt_net": 1.40526, "epoch": "3/400", "eta": "10:15:36", "gpu_mem": "17.91G", "grad_norm": 3.61747, "loss": 0.50083, "lr": 0.0000379500, "top1_acc": 84.21875, "top1_err": 15.78125, "top5_acc": 95.20833, "top5_err": 4.79167}
[06/29 23:30:11][INFO] train_net.py:  813: Epoch 2 takes 177.05s. Epochs from 0 to 2 take 176.28s in average and 176.56s in median.
[06/29 23:30:11][INFO] train_net.py:  819: For epoch 2, each iteraction takes 1.48s in average. From epoch 0 to 2, each iteraction takes 1.47s in average.
[06/29 23:30:34][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.36102, "dt_data": 0.00037, "dt_net": 1.36065, "epoch": "4/400", "eta": "18:00:25", "gpu_mem": "17.91G", "grad_norm": 1.52248, "iter": "10/120", "loss": 0.48487, "lr": 0.0000384500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:30:48][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38467, "dt_data": 0.00039, "dt_net": 1.38428, "epoch": "4/400", "eta": "18:18:58", "gpu_mem": "17.91G", "grad_norm": 5.27031, "iter": "20/120", "loss": 0.52912, "lr": 0.0000389500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:31:02][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38165, "dt_data": 0.00040, "dt_net": 1.38125, "epoch": "4/400", "eta": "18:16:20", "gpu_mem": "17.91G", "grad_norm": 1.28065, "iter": "30/120", "loss": 0.40954, "lr": 0.0000394500, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:31:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.37391, "dt_data": 0.00038, "dt_net": 1.37353, "epoch": "4/400", "eta": "18:09:58", "gpu_mem": "17.91G", "grad_norm": 6.45163, "iter": "40/120", "loss": 0.26997, "lr": 0.0000399500, "top1_acc": 90.62500, "top1_err": 9.37500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/29 23:31:30][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38752, "dt_data": 0.00041, "dt_net": 1.38711, "epoch": "4/400", "eta": "18:20:32", "gpu_mem": "17.91G", "grad_norm": 1.51386, "iter": "50/120", "loss": 0.27733, "lr": 0.0000404500, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/29 23:31:44][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.37062, "dt_data": 0.00041, "dt_net": 1.37021, "epoch": "4/400", "eta": "18:06:53", "gpu_mem": "17.91G", "grad_norm": 2.17432, "iter": "60/120", "loss": 0.42374, "lr": 0.0000409500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/29 23:31:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.37565, "dt_data": 0.00052, "dt_net": 1.37513, "epoch": "4/400", "eta": "18:10:39", "gpu_mem": "17.91G", "grad_norm": 4.88037, "iter": "70/120", "loss": 0.35557, "lr": 0.0000414500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:32:12][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.42102, "dt_data": 0.00040, "dt_net": 1.42062, "epoch": "4/400", "eta": "18:46:23", "gpu_mem": "17.91G", "grad_norm": 4.93436, "iter": "80/120", "loss": 0.46498, "lr": 0.0000419500, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:32:26][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39386, "dt_data": 0.00040, "dt_net": 1.39346, "epoch": "4/400", "eta": "18:24:38", "gpu_mem": "17.91G", "grad_norm": 4.15603, "iter": "90/120", "loss": 0.45804, "lr": 0.0000424500, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:32:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39974, "dt_data": 0.00040, "dt_net": 1.39933, "epoch": "4/400", "eta": "18:29:03", "gpu_mem": "17.91G", "grad_norm": 1.20004, "iter": "100/120", "loss": 0.56534, "lr": 0.0000429500, "top1_acc": 84.37500, "top1_err": 15.62500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/29 23:32:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39575, "dt_data": 0.00046, "dt_net": 1.39528, "epoch": "4/400", "eta": "18:25:39", "gpu_mem": "17.91G", "grad_norm": 12.41329, "iter": "110/120", "loss": 0.28448, "lr": 0.0000434500, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:33:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.36588, "dt_data": 0.00026, "dt_net": 1.36561, "epoch": "4/400", "eta": "18:01:46", "gpu_mem": "17.91G", "grad_norm": 2.92156, "iter": "120/120", "loss": 0.37474, "lr": 0.0000439500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:33:08][INFO] logging.py:  101: json_stats: {"RAM": "13.49/31.07G", "_type": "train_epoch", "dt": 0.77631, "dt_data": 0.77631, "dt_net": 1.36561, "epoch": "4/400", "eta": "10:14:48", "gpu_mem": "17.91G", "grad_norm": 2.92156, "loss": 0.43221, "lr": 0.0000439500, "top1_acc": 86.30208, "top1_err": 13.69792, "top5_acc": 96.04167, "top5_err": 3.95833}
[06/29 23:33:08][INFO] train_net.py:  813: Epoch 3 takes 177.09s. Epochs from 0 to 3 take 176.48s in average and 176.81s in median.
[06/29 23:33:08][INFO] train_net.py:  819: For epoch 3, each iteraction takes 1.48s in average. From epoch 0 to 3, each iteraction takes 1.47s in average.
[06/29 23:33:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38531, "dt_data": 0.00043, "dt_net": 1.38488, "epoch": "5/400", "eta": "18:16:55", "gpu_mem": "17.91G", "grad_norm": 12.81682, "iter": "10/120", "loss": 0.38924, "lr": 0.0000444500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/29 23:33:45][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.34533, "dt_data": 0.00044, "dt_net": 1.34489, "epoch": "5/400", "eta": "17:45:03", "gpu_mem": "17.91G", "grad_norm": 7.46990, "iter": "20/120", "loss": 0.37492, "lr": 0.0000449500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:33:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.36780, "dt_data": 0.00042, "dt_net": 1.36738, "epoch": "5/400", "eta": "18:02:37", "gpu_mem": "17.91G", "grad_norm": 6.69682, "iter": "30/120", "loss": 0.57853, "lr": 0.0000454500, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:34:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.42352, "dt_data": 0.00043, "dt_net": 1.42310, "epoch": "5/400", "eta": "18:46:28", "gpu_mem": "17.91G", "grad_norm": 1.38324, "iter": "40/120", "loss": 0.33676, "lr": 0.0000459500, "top1_acc": 90.62500, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:34:27][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.37980, "dt_data": 0.00039, "dt_net": 1.37941, "epoch": "5/400", "eta": "18:11:39", "gpu_mem": "17.91G", "grad_norm": 5.73496, "iter": "50/120", "loss": 0.33847, "lr": 0.0000464500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:34:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39302, "dt_data": 0.00042, "dt_net": 1.39260, "epoch": "5/400", "eta": "18:21:52", "gpu_mem": "17.91G", "grad_norm": 9.89316, "iter": "60/120", "loss": 0.43171, "lr": 0.0000469500, "top1_acc": 84.37500, "top1_err": 15.62500, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:34:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.40946, "dt_data": 0.00038, "dt_net": 1.40908, "epoch": "5/400", "eta": "18:34:39", "gpu_mem": "17.91G", "grad_norm": 3.90472, "iter": "70/120", "loss": 0.43770, "lr": 0.0000474500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/29 23:35:09][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39410, "dt_data": 0.00052, "dt_net": 1.39358, "epoch": "5/400", "eta": "18:22:16", "gpu_mem": "17.91G", "grad_norm": 2.33992, "iter": "80/120", "loss": 0.48751, "lr": 0.0000479500, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:35:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39611, "dt_data": 0.00039, "dt_net": 1.39572, "epoch": "5/400", "eta": "18:23:37", "gpu_mem": "17.91G", "grad_norm": 6.78081, "iter": "90/120", "loss": 0.30305, "lr": 0.0000484500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:35:36][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38270, "dt_data": 0.00045, "dt_net": 1.38224, "epoch": "5/400", "eta": "18:12:47", "gpu_mem": "17.91G", "grad_norm": 5.57891, "iter": "100/120", "loss": 0.54000, "lr": 0.0000489500, "top1_acc": 84.37500, "top1_err": 15.62500, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:35:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.34615, "dt_data": 0.00050, "dt_net": 1.34565, "epoch": "5/400", "eta": "17:43:41", "gpu_mem": "17.91G", "grad_norm": 6.77446, "iter": "110/120", "loss": 0.46577, "lr": 0.0000494500, "top1_acc": 84.37500, "top1_err": 15.62500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/29 23:36:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.41022, "dt_data": 0.00027, "dt_net": 1.40994, "epoch": "5/400", "eta": "18:34:04", "gpu_mem": "17.91G", "grad_norm": 8.39230, "iter": "120/120", "loss": 0.35110, "lr": 0.0000499500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/29 23:36:05][INFO] logging.py:  101: json_stats: {"RAM": "13.49/31.07G", "_type": "train_epoch", "dt": 0.78813, "dt_data": 0.78813, "dt_net": 1.40994, "epoch": "5/400", "eta": "10:22:35", "gpu_mem": "17.91G", "grad_norm": 8.39230, "loss": 0.41829, "lr": 0.0000499500, "top1_acc": 86.25000, "top1_err": 13.75000, "top5_acc": 96.09375, "top5_err": 3.90625}
[06/29 23:36:05][INFO] train_net.py:  813: Epoch 4 takes 177.00s. Epochs from 0 to 4 take 176.59s in average and 177.00s in median.
[06/29 23:36:05][INFO] train_net.py:  819: For epoch 4, each iteraction takes 1.47s in average. From epoch 0 to 4, each iteraction takes 1.47s in average.
[06/29 23:36:18][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "5/400", "eta": "0:00:06", "gpu_mem": "17.91G", "iter": "10/31", "time_diff": 0.31761, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:36:22][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "5/400", "eta": "0:00:03", "gpu_mem": "17.91G", "iter": "20/31", "time_diff": 0.31788, "top1_acc": 90.62500, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:36:25][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "5/400", "eta": "0:00:00", "gpu_mem": "17.91G", "iter": "30/31", "time_diff": 0.30982, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:36:25][INFO] logging.py:  101: json_stats: {"RAM": "13.48/31.07G", "_type": "val_epoch", "epoch": "5/400", "gpu_mem": "17.91G", "min_top1_err": 16.59751, "min_top5_err": 2.90456, "time_diff": 0.60128, "top1_acc": 83.40249, "top1_err": 16.59751, "top5_acc": 97.09544, "top5_err": 2.90456}
[06/29 23:36:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38024, "dt_data": 0.00035, "dt_net": 1.37989, "epoch": "6/400", "eta": "18:10:09", "gpu_mem": "17.91G", "grad_norm": 3.54884, "iter": "10/120", "loss": 0.41813, "lr": 0.0000504500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:37:03][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38689, "dt_data": 0.00065, "dt_net": 1.38624, "epoch": "6/400", "eta": "18:15:10", "gpu_mem": "17.91G", "grad_norm": 5.02826, "iter": "20/120", "loss": 0.26957, "lr": 0.0000509500, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:37:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.35848, "dt_data": 0.00049, "dt_net": 1.35799, "epoch": "6/400", "eta": "17:52:31", "gpu_mem": "17.91G", "grad_norm": 1.54866, "iter": "30/120", "loss": 0.43455, "lr": 0.0000514500, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:37:30][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.40241, "dt_data": 0.00039, "dt_net": 1.40202, "epoch": "6/400", "eta": "18:26:58", "gpu_mem": "17.91G", "grad_norm": 7.34633, "iter": "40/120", "loss": 0.42437, "lr": 0.0000519500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/29 23:37:44][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39402, "dt_data": 0.00041, "dt_net": 1.39361, "epoch": "6/400", "eta": "18:20:06", "gpu_mem": "17.91G", "grad_norm": 10.05320, "iter": "50/120", "loss": 0.30208, "lr": 0.0000524500, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/29 23:37:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39777, "dt_data": 0.00054, "dt_net": 1.39723, "epoch": "6/400", "eta": "18:22:50", "gpu_mem": "17.91G", "grad_norm": 4.53446, "iter": "60/120", "loss": 0.37193, "lr": 0.0000529500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:38:12][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.36967, "dt_data": 0.00041, "dt_net": 1.36926, "epoch": "6/400", "eta": "18:00:26", "gpu_mem": "17.91G", "grad_norm": 4.33228, "iter": "70/120", "loss": 0.37223, "lr": 0.0000534500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:38:26][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39642, "dt_data": 0.00048, "dt_net": 1.39594, "epoch": "6/400", "eta": "18:21:18", "gpu_mem": "17.91G", "grad_norm": 0.26037, "iter": "80/120", "loss": 0.34349, "lr": 0.0000539500, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:38:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.41592, "dt_data": 0.00038, "dt_net": 1.41553, "epoch": "6/400", "eta": "18:36:27", "gpu_mem": "17.91G", "grad_norm": 4.18794, "iter": "90/120", "loss": 0.22848, "lr": 0.0000544500, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:38:54][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.37710, "dt_data": 0.00041, "dt_net": 1.37668, "epoch": "6/400", "eta": "18:05:36", "gpu_mem": "17.91G", "grad_norm": 9.17037, "iter": "100/120", "loss": 0.41227, "lr": 0.0000549500, "top1_acc": 84.37500, "top1_err": 15.62500, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:39:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.41602, "dt_data": 0.00057, "dt_net": 1.41545, "epoch": "6/400", "eta": "18:36:03", "gpu_mem": "17.91G", "grad_norm": 3.67942, "iter": "110/120", "loss": 0.34827, "lr": 0.0000554500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:39:21][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.36274, "dt_data": 0.00025, "dt_net": 1.36249, "epoch": "6/400", "eta": "17:53:50", "gpu_mem": "17.91G", "grad_norm": 1.23766, "iter": "120/120", "loss": 0.41281, "lr": 0.0000559500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:39:22][INFO] logging.py:  101: json_stats: {"RAM": "13.50/31.07G", "_type": "train_epoch", "dt": 0.77654, "dt_data": 0.77653, "dt_net": 1.36249, "epoch": "6/400", "eta": "10:11:52", "gpu_mem": "17.91G", "grad_norm": 1.23766, "loss": 0.39370, "lr": 0.0000559500, "top1_acc": 87.13542, "top1_err": 12.86458, "top5_acc": 95.93750, "top5_err": 4.06250}
[06/29 23:39:22][INFO] train_net.py:  813: Epoch 5 takes 176.58s. Epochs from 0 to 5 take 176.59s in average and 176.79s in median.
[06/29 23:39:22][INFO] train_net.py:  819: For epoch 5, each iteraction takes 1.47s in average. From epoch 0 to 5, each iteraction takes 1.47s in average.
[06/29 23:39:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.36088, "dt_data": 0.00044, "dt_net": 1.36045, "epoch": "7/400", "eta": "17:52:09", "gpu_mem": "17.91G", "grad_norm": 2.59628, "iter": "10/120", "loss": 0.36142, "lr": 0.0000564500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/29 23:40:00][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.34109, "dt_data": 0.00037, "dt_net": 1.34071, "epoch": "7/400", "eta": "17:36:19", "gpu_mem": "17.91G", "grad_norm": 2.79178, "iter": "20/120", "loss": 0.30527, "lr": 0.0000569500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:40:14][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.36777, "dt_data": 0.00046, "dt_net": 1.36731, "epoch": "7/400", "eta": "17:57:07", "gpu_mem": "17.91G", "grad_norm": 2.18427, "iter": "30/120", "loss": 0.27637, "lr": 0.0000574500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:40:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.40701, "dt_data": 0.00041, "dt_net": 1.40660, "epoch": "7/400", "eta": "18:27:47", "gpu_mem": "17.91G", "grad_norm": 6.74257, "iter": "40/120", "loss": 0.39936, "lr": 0.0000579500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/29 23:40:42][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.37781, "dt_data": 0.00049, "dt_net": 1.37731, "epoch": "7/400", "eta": "18:04:33", "gpu_mem": "17.91G", "grad_norm": 2.07004, "iter": "50/120", "loss": 0.36571, "lr": 0.0000584500, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:40:56][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38243, "dt_data": 0.00065, "dt_net": 1.38177, "epoch": "7/400", "eta": "18:07:58", "gpu_mem": "17.91G", "grad_norm": 1.20398, "iter": "60/120", "loss": 0.54163, "lr": 0.0000589500, "top1_acc": 84.37500, "top1_err": 15.62500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:41:09][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.40227, "dt_data": 0.00041, "dt_net": 1.40186, "epoch": "7/400", "eta": "18:23:21", "gpu_mem": "17.91G", "grad_norm": 0.92986, "iter": "70/120", "loss": 0.25239, "lr": 0.0000594500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:41:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39131, "dt_data": 0.00045, "dt_net": 1.39086, "epoch": "7/400", "eta": "18:14:29", "gpu_mem": "17.91G", "grad_norm": 5.97402, "iter": "80/120", "loss": 0.24743, "lr": 0.0000599500, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:41:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.37862, "dt_data": 0.00036, "dt_net": 1.37826, "epoch": "7/400", "eta": "18:04:17", "gpu_mem": "17.91G", "grad_norm": 2.85454, "iter": "90/120", "loss": 0.38347, "lr": 0.0000604500, "top1_acc": 90.62500, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:41:51][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39568, "dt_data": 0.00074, "dt_net": 1.39494, "epoch": "7/400", "eta": "18:17:27", "gpu_mem": "17.91G", "grad_norm": 6.77396, "iter": "100/120", "loss": 0.33638, "lr": 0.0000609500, "top1_acc": 84.37500, "top1_err": 15.62500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:42:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.34950, "dt_data": 0.00070, "dt_net": 1.34878, "epoch": "7/400", "eta": "17:40:55", "gpu_mem": "17.91G", "grad_norm": 5.62456, "iter": "110/120", "loss": 0.45524, "lr": 0.0000614500, "top1_acc": 84.37500, "top1_err": 15.62500, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:42:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.36189, "dt_data": 0.00027, "dt_net": 1.36162, "epoch": "7/400", "eta": "17:50:26", "gpu_mem": "17.91G", "grad_norm": 3.18767, "iter": "120/120", "loss": 0.48012, "lr": 0.0000619500, "top1_acc": 84.37500, "top1_err": 15.62500, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:42:20][INFO] logging.py:  101: json_stats: {"RAM": "13.49/31.07G", "_type": "train_epoch", "dt": 0.78399, "dt_data": 0.78399, "dt_net": 1.36162, "epoch": "7/400", "eta": "10:16:11", "gpu_mem": "17.91G", "grad_norm": 3.18767, "loss": 0.39183, "lr": 0.0000619500, "top1_acc": 86.82292, "top1_err": 13.17708, "top5_acc": 96.30208, "top5_err": 3.69792}
[06/29 23:42:20][INFO] train_net.py:  813: Epoch 6 takes 177.68s. Epochs from 0 to 6 take 176.74s in average and 177.00s in median.
[06/29 23:42:20][INFO] train_net.py:  819: For epoch 6, each iteraction takes 1.48s in average. From epoch 0 to 6, each iteraction takes 1.47s in average.
[06/29 23:42:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.32004, "dt_data": 0.00043, "dt_net": 1.31961, "epoch": "8/400", "eta": "17:17:20", "gpu_mem": "17.91G", "grad_norm": 4.72489, "iter": "10/120", "loss": 0.33377, "lr": 0.0000624500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/29 23:42:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.36107, "dt_data": 0.00040, "dt_net": 1.36067, "epoch": "8/400", "eta": "17:49:20", "gpu_mem": "17.91G", "grad_norm": 1.63858, "iter": "20/120", "loss": 0.47242, "lr": 0.0000629500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:43:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39520, "dt_data": 0.00049, "dt_net": 1.39471, "epoch": "8/400", "eta": "18:15:55", "gpu_mem": "17.91G", "grad_norm": 3.05448, "iter": "30/120", "loss": 0.33516, "lr": 0.0000634500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/29 23:43:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38746, "dt_data": 0.00050, "dt_net": 1.38696, "epoch": "8/400", "eta": "18:09:36", "gpu_mem": "17.91G", "grad_norm": 2.48888, "iter": "40/120", "loss": 0.34510, "lr": 0.0000639500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:43:39][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38330, "dt_data": 0.00071, "dt_net": 1.38259, "epoch": "8/400", "eta": "18:06:07", "gpu_mem": "17.91G", "grad_norm": 0.33691, "iter": "50/120", "loss": 0.24779, "lr": 0.0000644500, "top1_acc": 90.62500, "top1_err": 9.37500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/29 23:43:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.44502, "dt_data": 0.00042, "dt_net": 1.44460, "epoch": "8/400", "eta": "18:54:20", "gpu_mem": "17.91G", "grad_norm": 6.19943, "iter": "60/120", "loss": 0.34256, "lr": 0.0000649500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/29 23:44:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39360, "dt_data": 0.00044, "dt_net": 1.39317, "epoch": "8/400", "eta": "18:13:44", "gpu_mem": "17.91G", "grad_norm": 6.36095, "iter": "70/120", "loss": 0.32661, "lr": 0.0000654500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:44:21][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38379, "dt_data": 0.00042, "dt_net": 1.38338, "epoch": "8/400", "eta": "18:05:49", "gpu_mem": "17.91G", "grad_norm": 1.68929, "iter": "80/120", "loss": 0.58281, "lr": 0.0000659500, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:44:34][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39750, "dt_data": 0.00049, "dt_net": 1.39701, "epoch": "8/400", "eta": "18:16:20", "gpu_mem": "17.91G", "grad_norm": 5.47545, "iter": "90/120", "loss": 0.39515, "lr": 0.0000664500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:44:48][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.34765, "dt_data": 0.00044, "dt_net": 1.34721, "epoch": "8/400", "eta": "17:37:00", "gpu_mem": "17.91G", "grad_norm": 1.66662, "iter": "100/120", "loss": 0.42616, "lr": 0.0000669500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:45:02][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.33602, "dt_data": 0.00047, "dt_net": 1.33555, "epoch": "8/400", "eta": "17:27:39", "gpu_mem": "17.91G", "grad_norm": 3.16703, "iter": "110/120", "loss": 0.29159, "lr": 0.0000674500, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:45:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.37797, "dt_data": 0.00026, "dt_net": 1.37771, "epoch": "8/400", "eta": "18:00:19", "gpu_mem": "17.91G", "grad_norm": 2.20203, "iter": "120/120", "loss": 0.29021, "lr": 0.0000679500, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:45:17][INFO] logging.py:  101: json_stats: {"RAM": "13.53/31.07G", "_type": "train_epoch", "dt": 0.78473, "dt_data": 0.78473, "dt_net": 1.37771, "epoch": "8/400", "eta": "10:15:12", "gpu_mem": "17.91G", "grad_norm": 2.20203, "loss": 0.39801, "lr": 0.0000679500, "top1_acc": 87.08333, "top1_err": 12.91667, "top5_acc": 96.19792, "top5_err": 3.80208}
[06/29 23:45:17][INFO] train_net.py:  813: Epoch 7 takes 177.19s. Epochs from 0 to 7 take 176.80s in average and 177.02s in median.
[06/29 23:45:17][INFO] train_net.py:  819: For epoch 7, each iteraction takes 1.48s in average. From epoch 0 to 7, each iteraction takes 1.47s in average.
[06/29 23:45:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.40346, "dt_data": 0.00043, "dt_net": 1.40304, "epoch": "9/400", "eta": "18:20:04", "gpu_mem": "17.91G", "grad_norm": 1.24078, "iter": "10/120", "loss": 0.37053, "lr": 0.0000684500, "top1_acc": 90.62500, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:45:54][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.36570, "dt_data": 0.00040, "dt_net": 1.36530, "epoch": "9/400", "eta": "17:50:15", "gpu_mem": "17.91G", "grad_norm": 0.68321, "iter": "20/120", "loss": 0.31661, "lr": 0.0000689500, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/29 23:46:08][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.37620, "dt_data": 0.00043, "dt_net": 1.37578, "epoch": "9/400", "eta": "17:58:15", "gpu_mem": "17.91G", "grad_norm": 2.24420, "iter": "30/120", "loss": 0.30038, "lr": 0.0000694500, "top1_acc": 90.62500, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:46:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38738, "dt_data": 0.00041, "dt_net": 1.38697, "epoch": "9/400", "eta": "18:06:46", "gpu_mem": "17.91G", "grad_norm": 2.47440, "iter": "40/120", "loss": 0.34736, "lr": 0.0000699500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/29 23:46:36][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39763, "dt_data": 0.00041, "dt_net": 1.39722, "epoch": "9/400", "eta": "18:14:34", "gpu_mem": "17.91G", "grad_norm": 2.08259, "iter": "50/120", "loss": 0.31406, "lr": 0.0000704500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:46:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39378, "dt_data": 0.00053, "dt_net": 1.39325, "epoch": "9/400", "eta": "18:11:19", "gpu_mem": "17.91G", "grad_norm": 4.25354, "iter": "60/120", "loss": 0.28039, "lr": 0.0000709500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/29 23:47:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38540, "dt_data": 0.00041, "dt_net": 1.38499, "epoch": "9/400", "eta": "18:04:32", "gpu_mem": "17.91G", "grad_norm": 2.84230, "iter": "70/120", "loss": 0.35497, "lr": 0.0000714500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:47:18][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39992, "dt_data": 0.00042, "dt_net": 1.39950, "epoch": "9/400", "eta": "18:15:40", "gpu_mem": "17.91G", "grad_norm": 4.51564, "iter": "80/120", "loss": 0.38513, "lr": 0.0000719500, "top1_acc": 90.62500, "top1_err": 9.37500, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:47:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.37549, "dt_data": 0.00064, "dt_net": 1.37484, "epoch": "9/400", "eta": "17:56:19", "gpu_mem": "17.91G", "grad_norm": 2.24101, "iter": "90/120", "loss": 0.37516, "lr": 0.0000724500, "top1_acc": 84.37500, "top1_err": 15.62500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/29 23:47:45][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.34480, "dt_data": 0.00054, "dt_net": 1.34426, "epoch": "9/400", "eta": "17:32:04", "gpu_mem": "17.91G", "grad_norm": 5.18849, "iter": "100/120", "loss": 0.21320, "lr": 0.0000729500, "top1_acc": 90.62500, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:47:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.36688, "dt_data": 0.00049, "dt_net": 1.36639, "epoch": "9/400", "eta": "17:49:07", "gpu_mem": "17.91G", "grad_norm": 6.37709, "iter": "110/120", "loss": 0.36796, "lr": 0.0000734500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:48:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.36323, "dt_data": 0.00027, "dt_net": 1.36296, "epoch": "9/400", "eta": "17:46:02", "gpu_mem": "17.91G", "grad_norm": 3.00708, "iter": "120/120", "loss": 0.38979, "lr": 0.0000739500, "top1_acc": 90.62500, "top1_err": 9.37500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/29 23:48:14][INFO] logging.py:  101: json_stats: {"RAM": "13.53/31.07G", "_type": "train_epoch", "dt": 0.78137, "dt_data": 0.78137, "dt_net": 1.36296, "epoch": "9/400", "eta": "10:11:00", "gpu_mem": "17.91G", "grad_norm": 3.00708, "loss": 0.35901, "lr": 0.0000739500, "top1_acc": 88.17708, "top1_err": 11.82292, "top5_acc": 96.30208, "top5_err": 3.69792}
[06/29 23:48:14][INFO] train_net.py:  813: Epoch 8 takes 176.74s. Epochs from 0 to 8 take 176.79s in average and 177.00s in median.
[06/29 23:48:14][INFO] train_net.py:  819: For epoch 8, each iteraction takes 1.47s in average. From epoch 0 to 8, each iteraction takes 1.47s in average.
[06/29 23:48:38][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.35710, "dt_data": 0.00044, "dt_net": 1.35665, "epoch": "10/400", "eta": "17:41:01", "gpu_mem": "17.91G", "grad_norm": 0.97557, "iter": "10/120", "loss": 0.07484, "lr": 0.0000744500, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:48:51][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.36189, "dt_data": 0.00040, "dt_net": 1.36149, "epoch": "10/400", "eta": "17:44:32", "gpu_mem": "17.91G", "grad_norm": 4.47877, "iter": "20/120", "loss": 0.27882, "lr": 0.0000749500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:49:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39987, "dt_data": 0.00042, "dt_net": 1.39945, "epoch": "10/400", "eta": "18:13:59", "gpu_mem": "17.91G", "grad_norm": 5.91664, "iter": "30/120", "loss": 0.18440, "lr": 0.0000754500, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:49:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.40016, "dt_data": 0.00042, "dt_net": 1.39974, "epoch": "10/400", "eta": "18:13:59", "gpu_mem": "17.91G", "grad_norm": 6.71044, "iter": "40/120", "loss": 0.48827, "lr": 0.0000759500, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/29 23:49:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.42491, "dt_data": 0.00041, "dt_net": 1.42450, "epoch": "10/400", "eta": "18:33:05", "gpu_mem": "17.91G", "grad_norm": 1.84619, "iter": "50/120", "loss": 0.24982, "lr": 0.0000764500, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:49:47][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39968, "dt_data": 0.00048, "dt_net": 1.39919, "epoch": "10/400", "eta": "18:13:09", "gpu_mem": "17.91G", "grad_norm": 4.68746, "iter": "60/120", "loss": 0.17834, "lr": 0.0000769500, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:50:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.36800, "dt_data": 0.00045, "dt_net": 1.36756, "epoch": "10/400", "eta": "17:48:10", "gpu_mem": "17.91G", "grad_norm": 2.44591, "iter": "70/120", "loss": 0.43935, "lr": 0.0000774500, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:50:14][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.37119, "dt_data": 0.00053, "dt_net": 1.37067, "epoch": "10/400", "eta": "17:50:26", "gpu_mem": "17.91G", "grad_norm": 2.69481, "iter": "80/120", "loss": 0.34953, "lr": 0.0000779500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:50:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38447, "dt_data": 0.00041, "dt_net": 1.38406, "epoch": "10/400", "eta": "18:00:34", "gpu_mem": "17.91G", "grad_norm": 3.70465, "iter": "90/120", "loss": 0.31102, "lr": 0.0000784500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:50:42][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.42092, "dt_data": 0.00083, "dt_net": 1.42008, "epoch": "10/400", "eta": "18:28:47", "gpu_mem": "17.91G", "grad_norm": 1.91952, "iter": "100/120", "loss": 0.31971, "lr": 0.0000789500, "top1_acc": 90.62500, "top1_err": 9.37500, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:50:56][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.37296, "dt_data": 0.00072, "dt_net": 1.37224, "epoch": "10/400", "eta": "17:51:08", "gpu_mem": "17.91G", "grad_norm": 5.35131, "iter": "110/120", "loss": 0.35939, "lr": 0.0000794500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:51:10][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.37489, "dt_data": 0.00027, "dt_net": 1.37462, "epoch": "10/400", "eta": "17:52:24", "gpu_mem": "17.91G", "grad_norm": 2.46280, "iter": "120/120", "loss": 0.25729, "lr": 0.0000799500, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:51:10][INFO] logging.py:  101: json_stats: {"RAM": "13.56/31.07G", "_type": "train_epoch", "dt": 0.78685, "dt_data": 0.78685, "dt_net": 1.37462, "epoch": "10/400", "eta": "10:13:43", "gpu_mem": "17.91G", "grad_norm": 2.46280, "loss": 0.32808, "lr": 0.0000799500, "top1_acc": 88.59375, "top1_err": 11.40625, "top5_acc": 97.18750, "top5_err": 2.81250}
[06/29 23:51:10][INFO] train_net.py:  813: Epoch 9 takes 176.82s. Epochs from 0 to 9 take 176.79s in average and 176.91s in median.
[06/29 23:51:10][INFO] train_net.py:  819: For epoch 9, each iteraction takes 1.47s in average. From epoch 0 to 9, each iteraction takes 1.47s in average.
[06/29 23:51:24][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "10/400", "eta": "0:00:06", "gpu_mem": "17.91G", "iter": "10/31", "time_diff": 0.31835, "top1_acc": 84.37500, "top1_err": 15.62500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:51:27][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "10/400", "eta": "0:00:03", "gpu_mem": "17.91G", "iter": "20/31", "time_diff": 0.32572, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:51:30][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "10/400", "eta": "0:00:00", "gpu_mem": "17.91G", "iter": "30/31", "time_diff": 0.31116, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:51:31][INFO] logging.py:  101: json_stats: {"RAM": "13.61/31.07G", "_type": "val_epoch", "epoch": "10/400", "gpu_mem": "17.91G", "min_top1_err": 16.59751, "min_top5_err": 2.07469, "time_diff": 0.61565, "top1_acc": 83.40249, "top1_err": 16.59751, "top5_acc": 97.92531, "top5_err": 2.07469}
[06/29 23:51:54][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39259, "dt_data": 0.00042, "dt_net": 1.39217, "epoch": "11/400", "eta": "18:05:59", "gpu_mem": "17.91G", "grad_norm": 1.97467, "iter": "10/120", "loss": 0.31359, "lr": 0.0000804500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/29 23:52:08][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.37412, "dt_data": 0.00042, "dt_net": 1.37370, "epoch": "11/400", "eta": "17:51:21", "gpu_mem": "17.91G", "grad_norm": 3.00792, "iter": "20/120", "loss": 0.25214, "lr": 0.0000809500, "top1_acc": 90.62500, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:52:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38172, "dt_data": 0.00045, "dt_net": 1.38126, "epoch": "11/400", "eta": "17:57:02", "gpu_mem": "17.91G", "grad_norm": 4.64728, "iter": "30/120", "loss": 0.22894, "lr": 0.0000814500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:52:36][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.40224, "dt_data": 0.00043, "dt_net": 1.40181, "epoch": "11/400", "eta": "18:12:48", "gpu_mem": "17.91G", "grad_norm": 1.08309, "iter": "40/120", "loss": 0.38283, "lr": 0.0000819500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:52:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38390, "dt_data": 0.00052, "dt_net": 1.38338, "epoch": "11/400", "eta": "17:58:17", "gpu_mem": "17.91G", "grad_norm": 0.68112, "iter": "50/120", "loss": 0.22601, "lr": 0.0000824500, "top1_acc": 90.62500, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:53:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.37656, "dt_data": 0.00040, "dt_net": 1.37615, "epoch": "11/400", "eta": "17:52:20", "gpu_mem": "17.91G", "grad_norm": 4.38363, "iter": "60/120", "loss": 0.31262, "lr": 0.0000829500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:53:17][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39774, "dt_data": 0.00040, "dt_net": 1.39735, "epoch": "11/400", "eta": "18:08:36", "gpu_mem": "17.91G", "grad_norm": 3.39112, "iter": "70/120", "loss": 0.31189, "lr": 0.0000834500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:53:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.40353, "dt_data": 0.00049, "dt_net": 1.40304, "epoch": "11/400", "eta": "18:12:52", "gpu_mem": "17.91G", "grad_norm": 2.54590, "iter": "80/120", "loss": 0.40867, "lr": 0.0000839500, "top1_acc": 84.37500, "top1_err": 15.62500, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:53:45][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.37979, "dt_data": 0.00049, "dt_net": 1.37930, "epoch": "11/400", "eta": "17:54:10", "gpu_mem": "17.91G", "grad_norm": 2.63583, "iter": "90/120", "loss": 0.27941, "lr": 0.0000844500, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:53:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39255, "dt_data": 0.00040, "dt_net": 1.39215, "epoch": "11/400", "eta": "18:03:52", "gpu_mem": "17.91G", "grad_norm": 2.71190, "iter": "100/120", "loss": 0.45462, "lr": 0.0000849500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/29 23:54:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.37744, "dt_data": 0.00042, "dt_net": 1.37702, "epoch": "11/400", "eta": "17:51:52", "gpu_mem": "17.91G", "grad_norm": 2.63607, "iter": "110/120", "loss": 0.21330, "lr": 0.0000854500, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:54:27][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.36202, "dt_data": 0.00025, "dt_net": 1.36176, "epoch": "11/400", "eta": "17:39:38", "gpu_mem": "17.91G", "grad_norm": 1.57579, "iter": "120/120", "loss": 0.20982, "lr": 0.0000859500, "top1_acc": 90.62500, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:54:27][INFO] logging.py:  101: json_stats: {"RAM": "13.92/31.07G", "_type": "train_epoch", "dt": 0.78293, "dt_data": 0.78293, "dt_net": 1.36176, "epoch": "11/400", "eta": "10:09:05", "gpu_mem": "17.91G", "grad_norm": 1.57579, "loss": 0.34228, "lr": 0.0000859500, "top1_acc": 88.64583, "top1_err": 11.35417, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/29 23:54:27][INFO] train_net.py:  813: Epoch 10 takes 176.33s. Epochs from 0 to 10 take 176.75s in average and 176.82s in median.
[06/29 23:54:27][INFO] train_net.py:  819: For epoch 10, each iteraction takes 1.47s in average. From epoch 0 to 10, each iteraction takes 1.47s in average.
[06/29 23:54:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.37458, "dt_data": 0.00051, "dt_net": 1.37407, "epoch": "12/400", "eta": "17:49:11", "gpu_mem": "17.91G", "grad_norm": 5.74363, "iter": "10/120", "loss": 0.33577, "lr": 0.0000864500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:55:06][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.36596, "dt_data": 0.00078, "dt_net": 1.36518, "epoch": "12/400", "eta": "17:42:15", "gpu_mem": "17.91G", "grad_norm": 4.74708, "iter": "20/120", "loss": 0.33203, "lr": 0.0000869500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:55:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.37669, "dt_data": 0.00084, "dt_net": 1.37585, "epoch": "12/400", "eta": "17:50:22", "gpu_mem": "17.91G", "grad_norm": 1.44320, "iter": "30/120", "loss": 0.16205, "lr": 0.0000874500, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:55:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39744, "dt_data": 0.00038, "dt_net": 1.39706, "epoch": "12/400", "eta": "18:06:16", "gpu_mem": "17.91G", "grad_norm": 10.02747, "iter": "40/120", "loss": 0.42124, "lr": 0.0000879500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:55:47][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.42194, "dt_data": 0.00038, "dt_net": 1.42157, "epoch": "12/400", "eta": "18:25:05", "gpu_mem": "17.91G", "grad_norm": 4.14216, "iter": "50/120", "loss": 0.32224, "lr": 0.0000884500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:56:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.41914, "dt_data": 0.00041, "dt_net": 1.41872, "epoch": "12/400", "eta": "18:22:40", "gpu_mem": "17.91G", "grad_norm": 4.63179, "iter": "60/120", "loss": 0.36831, "lr": 0.0000889500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:56:15][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.36055, "dt_data": 0.00047, "dt_net": 1.36007, "epoch": "12/400", "eta": "17:36:55", "gpu_mem": "17.91G", "grad_norm": 0.14605, "iter": "70/120", "loss": 0.27976, "lr": 0.0000894500, "top1_acc": 90.62500, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:56:29][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.37962, "dt_data": 0.00059, "dt_net": 1.37903, "epoch": "12/400", "eta": "17:51:30", "gpu_mem": "17.91G", "grad_norm": 2.00764, "iter": "80/120", "loss": 0.33300, "lr": 0.0000899500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:56:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39950, "dt_data": 0.00049, "dt_net": 1.39900, "epoch": "12/400", "eta": "18:06:42", "gpu_mem": "17.91G", "grad_norm": 6.10096, "iter": "90/120", "loss": 0.14076, "lr": 0.0000904500, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:56:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.40405, "dt_data": 0.00042, "dt_net": 1.40363, "epoch": "12/400", "eta": "18:10:00", "gpu_mem": "17.91G", "grad_norm": 1.31298, "iter": "100/120", "loss": 0.40168, "lr": 0.0000909500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:57:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.40280, "dt_data": 0.00064, "dt_net": 1.40216, "epoch": "12/400", "eta": "18:08:48", "gpu_mem": "17.91G", "grad_norm": 3.74602, "iter": "110/120", "loss": 0.22065, "lr": 0.0000914500, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:57:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.36237, "dt_data": 0.00026, "dt_net": 1.36211, "epoch": "12/400", "eta": "17:37:11", "gpu_mem": "17.91G", "grad_norm": 0.10709, "iter": "120/120", "loss": 0.30452, "lr": 0.0000919500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:57:25][INFO] logging.py:  101: json_stats: {"RAM": "13.51/31.07G", "_type": "train_epoch", "dt": 0.79994, "dt_data": 0.79994, "dt_net": 1.36211, "epoch": "12/400", "eta": "10:20:43", "gpu_mem": "17.91G", "grad_norm": 0.10709, "loss": 0.33280, "lr": 0.0000919500, "top1_acc": 89.11458, "top1_err": 10.88542, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/29 23:57:25][INFO] train_net.py:  813: Epoch 11 takes 177.97s. Epochs from 0 to 11 take 176.85s in average and 176.91s in median.
[06/29 23:57:25][INFO] train_net.py:  819: For epoch 11, each iteraction takes 1.48s in average. From epoch 0 to 11, each iteraction takes 1.47s in average.
[06/29 23:57:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.36270, "dt_data": 0.00047, "dt_net": 1.36222, "epoch": "13/400", "eta": "17:37:13", "gpu_mem": "17.91G", "grad_norm": 5.99124, "iter": "10/120", "loss": 0.35815, "lr": 0.0000924500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:58:03][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39009, "dt_data": 0.00039, "dt_net": 1.38970, "epoch": "13/400", "eta": "17:58:14", "gpu_mem": "17.91G", "grad_norm": 7.27569, "iter": "20/120", "loss": 0.34968, "lr": 0.0000929500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:58:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39538, "dt_data": 0.00064, "dt_net": 1.39474, "epoch": "13/400", "eta": "18:02:07", "gpu_mem": "17.91G", "grad_norm": 4.12527, "iter": "30/120", "loss": 0.29761, "lr": 0.0000934500, "top1_acc": 90.62500, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/29 23:58:25][INFO] train_net.py:  612: Train with config:
[06/29 23:58:25][INFO] train_net.py:  613: {'AUG': {'AA_TYPE': 'rand-m9-mstd0.5-inc1',
         'COLOR_JITTER': 0.4,
         'ENABLE': False,
         'GEN_MASK_LOADER': False,
         'INTERPOLATION': 'bicubic',
         'MASK_FRAMES': False,
         'MASK_RATIO': 0.0,
         'MASK_TUBE': False,
         'MASK_WINDOW_SIZE': [8, 7, 7],
         'MAX_MASK_PATCHES_PER_BLOCK': None,
         'NUM_SAMPLE': 1,
         'RE_COUNT': 1,
         'RE_MODE': 'pixel',
         'RE_PROB': 0.25,
         'RE_SPLIT': False},
 'AVA': {'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.9,
         'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv',
         'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/',
         'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'],
         'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'],
         'TRAIN_LISTS': ['train.csv'],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': [],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'GLOBAL_SYNC': False,
        'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'CONTRASTIVE': {'BN_MLP': False,
                 'BN_SYNC_MLP': False,
                 'DELTA_CLIPS_MAX': inf,
                 'DELTA_CLIPS_MIN': -inf,
                 'DIM': 128,
                 'INTERP_MEMORY': False,
                 'KNN_ON': True,
                 'LENGTH': 239975,
                 'LOCAL_SHUFFLE_BN': True,
                 'MEM_TYPE': '1d',
                 'MLP_DIM': 2048,
                 'MOCO_MULTI_VIEW_QUEUE': False,
                 'MOMENTUM': 0.5,
                 'MOMENTUM_ANNEALING': False,
                 'NUM_CLASSES_DOWNSTREAM': 400,
                 'NUM_MLP_LAYERS': 1,
                 'PREDICTOR_DEPTHS': [],
                 'QUEUE_LEN': 65536,
                 'SEQUENTIAL': False,
                 'SIMCLR_DIST_ON': True,
                 'SWAV_QEUE_LEN': 0,
                 'T': 0.07,
                 'TYPE': 'mem'},
 'DATA': {'CAM_VIEWS_METHODS': ['crop', 'noise_crop'],
          'COLOR_RND_GRAYSCALE': 0.0,
          'CROP_PROMPT': False,
          'DECODING_BACKEND': 'torchvision',
          'DECODING_SHORT_SIZE': 256,
          'DUMMY_LOAD': False,
          'ENSEMBLE_METHOD': 'sum',
          'IN22K_TRAINVAL': False,
          'IN22k_VAL_IN1K': '',
          'INPUT_CHANNEL_NUM': [3],
          'INV_UNIFORM_SAMPLE': False,
          'IN_VAL_CROP_RATIO': 0.875,
          'LOADER_CHUNK_OVERALL_SIZE': 0,
          'LOADER_CHUNK_SIZE': 0,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 16,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '',
          'PATH_TO_PRELOAD_IMDB': '',
          'RANDOM_FLIP': False,
          'RETURN_CROPPING_PARAMS': False,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 4,
          'SKIP_ROWS': 0,
          'SSL_BLUR_SIGMA_MAX': [0.0, 2.0],
          'SSL_BLUR_SIGMA_MIN': [0.0, 0.1],
          'SSL_COLOR_BRI_CON_SAT': [0.4, 0.4, 0.4],
          'SSL_COLOR_HUE': 0.1,
          'SSL_COLOR_JITTER': False,
          'SSL_MOCOV2_AUG': False,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 30,
          'TEST_CROP_SIZE': 224,
          'TIME_DIFF_PROB': 0.0,
          'TRAIN_CROP_NUM_SPATIAL': 1,
          'TRAIN_CROP_NUM_TEMPORAL': 1,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333],
          'TRAIN_JITTER_FPS': 0.0,
          'TRAIN_JITTER_MOTION_SHIFT': False,
          'TRAIN_JITTER_SCALES': [256, 320],
          'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0],
          'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
          'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                               [-0.5808, -0.0045, -0.814],
                               [-0.5836, -0.6948, 0.4203]],
          'USE_OFFSET_SAMPLING': False},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 4,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': False,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 10,
 'MASK': {'DECODER_DEPTH': 0,
          'DECODER_EMBED_DIM': 512,
          'DECODER_SEP_POS_EMBED': False,
          'DEC_KV_KERNEL': [],
          'DEC_KV_STRIDE': [],
          'ENABLE': False,
          'HEAD_TYPE': 'separate',
          'MAE_ON': False,
          'MAE_RND_MASK': False,
          'NORM_PRED_PIXEL': True,
          'PER_FRAME_MASKING': False,
          'PRED_HOG': False,
          'PRETRAIN_DEPTH': [15],
          'SCALE_INIT_BY_DEPTH': False,
          'TIME_STRIDE_LOSS': True},
 'MIXUP': {'ALPHA': 0.8,
           'CUTMIX_ALPHA': 1.0,
           'ENABLE': False,
           'LABEL_SMOOTH_VALUE': 0.1,
           'PROB': 1.0,
           'SWITCH_PROB': 0.5},
 'MODEL': {'ACT_CHECKPOINT': False,
           'ARCH': 'mvit',
           'DETACH_FINAL_FC': False,
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'FP16_ALLREDUCE': False,
           'FROZEN_BN': False,
           'HEAD_ACT': 'softmax',
           'LOSS_FUNC': 'soft_cross_entropy',
           'MODEL_NAME': 'MViT',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 16,
           'SINGLE_PATHWAY_ARCH': ['2d',
                                   'c2d',
                                   'i3d',
                                   'slow',
                                   'x3d',
                                   'mvit',
                                   'maskmvit']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'MVIT': {'CLS_EMBED_ON': True,
          'DEPTH': 24,
          'DIM_MUL': [[2, 2.0], [5, 2.0], [21, 2.0]],
          'DIM_MUL_IN_ATT': True,
          'DROPOUT_RATE': 0.0,
          'DROPPATH_RATE': 0.3,
          'EMBED_DIM': 96,
          'HEAD_INIT_SCALE': 1.0,
          'HEAD_MUL': [[2, 2.0], [5, 2.0], [21, 2.0]],
          'LAYER_SCALE_INIT_VALUE': 0.0,
          'MLP_RATIO': 4.0,
          'MODE': 'conv',
          'NORM': 'layernorm',
          'NORM_STEM': False,
          'NUM_HEADS': 1,
          'PATCH_2D': False,
          'PATCH_KERNEL': [3, 7, 7],
          'PATCH_PADDING': [1, 3, 3],
          'PATCH_STRIDE': [2, 4, 4],
          'POOL_FIRST': False,
          'POOL_KVQ_KERNEL': [3, 3, 3],
          'POOL_KV_STRIDE': [],
          'POOL_KV_STRIDE_ADAPTIVE': [1, 8, 8],
          'POOL_Q_STRIDE': [[0, 1, 1, 1],
                            [1, 1, 1, 1],
                            [2, 1, 2, 2],
                            [3, 1, 1, 1],
                            [4, 1, 1, 1],
                            [5, 1, 2, 2],
                            [6, 1, 1, 1],
                            [7, 1, 1, 1],
                            [8, 1, 1, 1],
                            [9, 1, 1, 1],
                            [10, 1, 1, 1],
                            [11, 1, 1, 1],
                            [12, 1, 1, 1],
                            [13, 1, 1, 1],
                            [14, 1, 1, 1],
                            [15, 1, 1, 1],
                            [16, 1, 1, 1],
                            [17, 1, 1, 1],
                            [18, 1, 1, 1],
                            [19, 1, 1, 1],
                            [20, 1, 1, 1],
                            [21, 1, 2, 2],
                            [22, 1, 1, 1],
                            [23, 1, 1, 1]],
          'QKV_BIAS': True,
          'REL_POS_SPATIAL': True,
          'REL_POS_TEMPORAL': True,
          'REL_POS_ZERO_INIT': False,
          'RESIDUAL_POOLING': True,
          'REV': {'BUFFER_LAYERS': [],
                  'ENABLE': False,
                  'PRE_Q_FUSION': 'avg',
                  'RESPATH_FUSE': 'concat',
                  'RES_PATH': 'conv'},
          'SEPARATE_QKV': False,
          'SEP_POS_EMBED': False,
          'USE_ABS_POS': False,
          'USE_FIXED_SINCOS_POS': False,
          'USE_MEAN_POOLING': False,
          'ZERO_DECAY_POS_CLS': False},
 'NONLOCAL': {'GROUP': [[1], [1], [1], [1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[]], [[]], [[]], [[]]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 2,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'PROMPT': {'ENABLE': True,
            'GPU': None,
            'IMAGE_FOLDER': './visual_prompting/save/images/mvitv2-b_fixed_patch',
            'LEARNING_RATE': 0.2,
            'METHOD': 'fixed_patch',
            'MODEL_FOLDER': './visual_prompting/save/models/mvitv2-b_fixed_patch',
            'MOMENTUM': 0.9,
            'PRINT_GRADS': False,
            'PROMPT_SAVE_FREQ': 5,
            'PROMPT_SIZE': 224,
            'RESUME': None,
            'START_EPOCH': 1,
            'WARMUP': 30,
            'WEIGHT_DECAY': 0.0001},
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1], [1], [1], [1]],
            'SPATIAL_STRIDES': [[1], [2], [2], [2]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': False,
            'ZERO_INIT_FINAL_CONV': False},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 8,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 5},
 'SOLVER': {'BASE_LR': 0.0002,
            'BASE_LR_SCALE_NUM_SHARDS': True,
            'BETAS': (0.9, 0.999),
            'CLIP_GRAD_L2NORM': 1.0,
            'CLIP_GRAD_VAL': None,
            'COSINE_AFTER_WARMUP': True,
            'COSINE_END_LR': 2e-05,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LARS_ON': False,
            'LAYER_DECAY': 1.0,
            'LRS': [],
            'LR_POLICY': 'cosine',
            'MAX_EPOCH': 400,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'adamw',
            'STEPS': [],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 30.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 2e-05,
            'WEIGHT_DECAY': 0.0001,
            'ZERO_WD_1D_PARAM': True},
 'TASK': '',
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': False,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 2,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'kinetics',
          'ENABLE': False,
          'NUM_ENSEMBLE_VIEWS': 5,
          'NUM_SPATIAL_CROPS': 1,
          'NUM_TEMPORAL_CLIPS': [],
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 16,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': True,
           'CHECKPOINT_FILE_PATH': 'checkpoints/mvitv2-b_no_rand_flip_best_epoch_00160.pyth',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_IN_INIT': False,
           'CHECKPOINT_PERIOD': 1,
           'CHECKPOINT_TYPE': 'pytorch',
           'DATASET': 'kinetics',
           'ENABLE': True,
           'EVAL_PERIOD': 1,
           'KILL_LOSS_EXPLOSION_FACTOR': 0.0,
           'MIXED_PRECISION': False},
 'VIS_MASK': CfgNode({'ENABLE': False}),
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[06/29 23:58:27][INFO] misc.py:  185: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=96, bias=True)
        )
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=96, bias=True)
        )
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
      )
      (4): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
      )
      (5): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (6): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (7): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (8): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (9): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (10): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (11): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (12): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (13): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (16): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (17): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (18): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (19): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (20): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (21): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (22): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
      (23): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): TransformerBasicHead(
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=16, bias=True)
      (act): Softmax(dim=1)
    )
  )
)
[06/29 23:58:27][INFO] misc.py:  187: Params: 50,897,968
[06/29 23:58:27][INFO] misc.py:  188: Mem: 0.38045549392700195 MB
[06/29 23:58:31][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 729 time(s)
[06/29 23:58:31][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 102 time(s)
[06/29 23:58:31][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 144 time(s)
[06/29 23:58:31][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 96 time(s)
[06/29 23:58:31][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 120 time(s)
[06/29 23:58:31][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 25 time(s)
[06/29 23:58:31][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 24 time(s)
[06/29 23:58:31][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[06/29 23:58:31][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.16.drop_path, module.blocks.17.drop_path, module.blocks.18.drop_path, module.blocks.19.drop_path, module.blocks.2.drop_path, module.blocks.20.drop_path, module.blocks.21.drop_path, module.blocks.22.drop_path, module.blocks.23.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[06/29 23:58:31][INFO] misc.py:  190: Flops: 92.63208983999999 G
[06/29 23:58:34][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 121 time(s)
[06/29 23:58:34][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 729 time(s)
[06/29 23:58:34][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 102 time(s)
[06/29 23:58:34][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 144 time(s)
[06/29 23:58:34][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 96 time(s)
[06/29 23:58:34][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 120 time(s)
[06/29 23:58:34][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 25 time(s)
[06/29 23:58:34][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 24 time(s)
[06/29 23:58:34][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[06/29 23:58:34][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.16.drop_path, module.blocks.17.drop_path, module.blocks.18.drop_path, module.blocks.19.drop_path, module.blocks.2.drop_path, module.blocks.20.drop_path, module.blocks.21.drop_path, module.blocks.22.drop_path, module.blocks.23.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[06/29 23:58:34][INFO] misc.py:  191: Activations: 357.084096 M
[06/29 23:58:34][INFO] misc.py:  196: nvidia-smi
[06/29 23:58:34][INFO] train_net.py:  654: Load from given checkpoint file.
[06/29 23:58:34][INFO] checkpoint.py:  223: Loading network weights from checkpoints/mvitv2-b_no_rand_flip_best_epoch_00160.pyth.
[06/29 23:58:35][INFO] kinetics.py:   93: Constructing Kinetics train...
[06/29 23:58:35][INFO] kinetics.py:  169: Constructing kinetics dataloader (size: 1927 skip_rows 0) from train.csv 
[06/29 23:58:35][INFO] kinetics.py:   93: Constructing Kinetics val...
[06/29 23:58:35][INFO] kinetics.py:  169: Constructing kinetics dataloader (size: 482 skip_rows 0) from val.csv 
[06/29 23:58:35][INFO] train_net.py:  751: Start epoch: 1
[06/29 23:58:46][INFO] distributed.py: 1027: Reducer buckets have been rebuilt in this iteration.
[06/29 23:58:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.35246, "dt_data": 0.00036, "dt_net": 1.35210, "epoch": "1/400", "eta": "18:01:44", "gpu_mem": "17.91G", "grad_norm": 10.19769, "iter": "10/120", "loss": 1.81485, "lr": 0.0000204500, "top1_acc": 43.75000, "top1_err": 56.25000, "top5_acc": 81.25000, "top5_err": 18.75000}
[06/29 23:59:12][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.36404, "dt_data": 0.00040, "dt_net": 1.36364, "epoch": "1/400", "eta": "18:10:46", "gpu_mem": "17.91G", "grad_norm": 15.19761, "iter": "20/120", "loss": 1.37212, "lr": 0.0000209500, "top1_acc": 56.25000, "top1_err": 43.75000, "top5_acc": 87.50000, "top5_err": 12.50000}
[06/29 23:59:26][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39135, "dt_data": 0.00037, "dt_net": 1.39098, "epoch": "1/400", "eta": "18:32:22", "gpu_mem": "17.91G", "grad_norm": 11.91821, "iter": "30/120", "loss": 1.29942, "lr": 0.0000214500, "top1_acc": 56.25000, "top1_err": 43.75000, "top5_acc": 81.25000, "top5_err": 18.75000}
[06/29 23:59:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39852, "dt_data": 0.00039, "dt_net": 1.39813, "epoch": "1/400", "eta": "18:37:53", "gpu_mem": "17.91G", "grad_norm": 12.49059, "iter": "40/120", "loss": 1.12894, "lr": 0.0000219500, "top1_acc": 62.50000, "top1_err": 37.50000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/29 23:59:54][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.41144, "dt_data": 0.00044, "dt_net": 1.41100, "epoch": "1/400", "eta": "18:47:58", "gpu_mem": "17.91G", "grad_norm": 11.03754, "iter": "50/120", "loss": 1.27611, "lr": 0.0000224500, "top1_acc": 59.37500, "top1_err": 40.62500, "top5_acc": 87.50000, "top5_err": 12.50000}
[06/30 00:00:08][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39319, "dt_data": 0.00047, "dt_net": 1.39271, "epoch": "1/400", "eta": "18:33:09", "gpu_mem": "17.91G", "grad_norm": 11.51944, "iter": "60/120", "loss": 0.93403, "lr": 0.0000229500, "top1_acc": 65.62500, "top1_err": 34.37500, "top5_acc": 90.62500, "top5_err": 9.37500}
[06/30 00:00:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.40413, "dt_data": 0.00041, "dt_net": 1.40372, "epoch": "1/400", "eta": "18:41:40", "gpu_mem": "17.91G", "grad_norm": 9.28745, "iter": "70/120", "loss": 0.88958, "lr": 0.0000234500, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 87.50000, "top5_err": 12.50000}
[06/30 00:00:36][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.41997, "dt_data": 0.00039, "dt_net": 1.41958, "epoch": "1/400", "eta": "18:54:05", "gpu_mem": "17.91G", "grad_norm": 8.95506, "iter": "80/120", "loss": 1.21507, "lr": 0.0000239500, "top1_acc": 65.62500, "top1_err": 34.37500, "top5_acc": 87.50000, "top5_err": 12.50000}
[06/30 00:00:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.37043, "dt_data": 0.00056, "dt_net": 1.36985, "epoch": "1/400", "eta": "18:14:17", "gpu_mem": "17.91G", "grad_norm": 7.75377, "iter": "90/120", "loss": 1.01174, "lr": 0.0000244500, "top1_acc": 68.75000, "top1_err": 31.25000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:01:03][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.36689, "dt_data": 0.00042, "dt_net": 1.36648, "epoch": "1/400", "eta": "18:11:14", "gpu_mem": "17.91G", "grad_norm": 8.36162, "iter": "100/120", "loss": 0.81197, "lr": 0.0000249500, "top1_acc": 68.75000, "top1_err": 31.25000, "top5_acc": 90.62500, "top5_err": 9.37500}
[06/30 00:01:17][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39592, "dt_data": 0.00042, "dt_net": 1.39550, "epoch": "1/400", "eta": "18:34:10", "gpu_mem": "17.91G", "grad_norm": 5.13500, "iter": "110/120", "loss": 0.72178, "lr": 0.0000254500, "top1_acc": 71.87500, "top1_err": 28.12500, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:01:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.36313, "dt_data": 0.00026, "dt_net": 1.36287, "epoch": "1/400", "eta": "18:07:46", "gpu_mem": "17.91G", "grad_norm": 7.55266, "iter": "120/120", "loss": 0.66473, "lr": 0.0000259500, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:01:32][INFO] logging.py:  101: json_stats: {"RAM": "13.52/31.07G", "_type": "train_epoch", "dt": 0.81216, "dt_data": 0.81216, "dt_net": 1.36287, "epoch": "1/400", "eta": "10:48:04", "gpu_mem": "17.91G", "grad_norm": 7.55266, "loss": 1.15781, "lr": 0.0000259500, "top1_acc": 63.95833, "top1_err": 36.04167, "top5_acc": 88.17708, "top5_err": 11.82292}
[06/30 00:01:32][INFO] train_net.py:  813: Epoch 0 takes 176.85s. Epochs from 0 to 0 take 176.85s in average and 176.85s in median.
[06/30 00:01:32][INFO] train_net.py:  819: For epoch 0, each iteraction takes 1.47s in average. From epoch 0 to 0, each iteraction takes 1.47s in average.
[06/30 00:03:28][INFO] train_net.py:  612: Train with config:
[06/30 00:03:28][INFO] train_net.py:  613: {'AUG': {'AA_TYPE': 'rand-m9-mstd0.5-inc1',
         'COLOR_JITTER': 0.4,
         'ENABLE': False,
         'GEN_MASK_LOADER': False,
         'INTERPOLATION': 'bicubic',
         'MASK_FRAMES': False,
         'MASK_RATIO': 0.0,
         'MASK_TUBE': False,
         'MASK_WINDOW_SIZE': [8, 7, 7],
         'MAX_MASK_PATCHES_PER_BLOCK': None,
         'NUM_SAMPLE': 1,
         'RE_COUNT': 1,
         'RE_MODE': 'pixel',
         'RE_PROB': 0.25,
         'RE_SPLIT': False},
 'AVA': {'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.9,
         'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv',
         'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/',
         'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'],
         'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'],
         'TRAIN_LISTS': ['train.csv'],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': [],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'GLOBAL_SYNC': False,
        'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'CONTRASTIVE': {'BN_MLP': False,
                 'BN_SYNC_MLP': False,
                 'DELTA_CLIPS_MAX': inf,
                 'DELTA_CLIPS_MIN': -inf,
                 'DIM': 128,
                 'INTERP_MEMORY': False,
                 'KNN_ON': True,
                 'LENGTH': 239975,
                 'LOCAL_SHUFFLE_BN': True,
                 'MEM_TYPE': '1d',
                 'MLP_DIM': 2048,
                 'MOCO_MULTI_VIEW_QUEUE': False,
                 'MOMENTUM': 0.5,
                 'MOMENTUM_ANNEALING': False,
                 'NUM_CLASSES_DOWNSTREAM': 400,
                 'NUM_MLP_LAYERS': 1,
                 'PREDICTOR_DEPTHS': [],
                 'QUEUE_LEN': 65536,
                 'SEQUENTIAL': False,
                 'SIMCLR_DIST_ON': True,
                 'SWAV_QEUE_LEN': 0,
                 'T': 0.07,
                 'TYPE': 'mem'},
 'DATA': {'CAM_VIEWS_METHODS': ['crop', 'noise_crop'],
          'COLOR_RND_GRAYSCALE': 0.0,
          'CROP_PROMPT': False,
          'DECODING_BACKEND': 'torchvision',
          'DECODING_SHORT_SIZE': 256,
          'DUMMY_LOAD': False,
          'ENSEMBLE_METHOD': 'sum',
          'IN22K_TRAINVAL': False,
          'IN22k_VAL_IN1K': '',
          'INPUT_CHANNEL_NUM': [3],
          'INV_UNIFORM_SAMPLE': False,
          'IN_VAL_CROP_RATIO': 0.875,
          'LOADER_CHUNK_OVERALL_SIZE': 0,
          'LOADER_CHUNK_SIZE': 0,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 16,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '',
          'PATH_TO_PRELOAD_IMDB': '',
          'RANDOM_FLIP': False,
          'RETURN_CROPPING_PARAMS': False,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 4,
          'SKIP_ROWS': 0,
          'SSL_BLUR_SIGMA_MAX': [0.0, 2.0],
          'SSL_BLUR_SIGMA_MIN': [0.0, 0.1],
          'SSL_COLOR_BRI_CON_SAT': [0.4, 0.4, 0.4],
          'SSL_COLOR_HUE': 0.1,
          'SSL_COLOR_JITTER': False,
          'SSL_MOCOV2_AUG': False,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 30,
          'TEST_CROP_SIZE': 224,
          'TIME_DIFF_PROB': 0.0,
          'TRAIN_CROP_NUM_SPATIAL': 1,
          'TRAIN_CROP_NUM_TEMPORAL': 1,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333],
          'TRAIN_JITTER_FPS': 0.0,
          'TRAIN_JITTER_MOTION_SHIFT': False,
          'TRAIN_JITTER_SCALES': [256, 320],
          'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0],
          'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
          'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                               [-0.5808, -0.0045, -0.814],
                               [-0.5836, -0.6948, 0.4203]],
          'USE_OFFSET_SAMPLING': False},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 4,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': False,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 10,
 'MASK': {'DECODER_DEPTH': 0,
          'DECODER_EMBED_DIM': 512,
          'DECODER_SEP_POS_EMBED': False,
          'DEC_KV_KERNEL': [],
          'DEC_KV_STRIDE': [],
          'ENABLE': False,
          'HEAD_TYPE': 'separate',
          'MAE_ON': False,
          'MAE_RND_MASK': False,
          'NORM_PRED_PIXEL': True,
          'PER_FRAME_MASKING': False,
          'PRED_HOG': False,
          'PRETRAIN_DEPTH': [15],
          'SCALE_INIT_BY_DEPTH': False,
          'TIME_STRIDE_LOSS': True},
 'MIXUP': {'ALPHA': 0.8,
           'CUTMIX_ALPHA': 1.0,
           'ENABLE': False,
           'LABEL_SMOOTH_VALUE': 0.1,
           'PROB': 1.0,
           'SWITCH_PROB': 0.5},
 'MODEL': {'ACT_CHECKPOINT': False,
           'ARCH': 'mvit',
           'DETACH_FINAL_FC': False,
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'FP16_ALLREDUCE': False,
           'FROZEN_BN': False,
           'HEAD_ACT': 'softmax',
           'LOSS_FUNC': 'soft_cross_entropy',
           'MODEL_NAME': 'MViT',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 16,
           'SINGLE_PATHWAY_ARCH': ['2d',
                                   'c2d',
                                   'i3d',
                                   'slow',
                                   'x3d',
                                   'mvit',
                                   'maskmvit']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'MVIT': {'CLS_EMBED_ON': True,
          'DEPTH': 24,
          'DIM_MUL': [[2, 2.0], [5, 2.0], [21, 2.0]],
          'DIM_MUL_IN_ATT': True,
          'DROPOUT_RATE': 0.0,
          'DROPPATH_RATE': 0.3,
          'EMBED_DIM': 96,
          'HEAD_INIT_SCALE': 1.0,
          'HEAD_MUL': [[2, 2.0], [5, 2.0], [21, 2.0]],
          'LAYER_SCALE_INIT_VALUE': 0.0,
          'MLP_RATIO': 4.0,
          'MODE': 'conv',
          'NORM': 'layernorm',
          'NORM_STEM': False,
          'NUM_HEADS': 1,
          'PATCH_2D': False,
          'PATCH_KERNEL': [3, 7, 7],
          'PATCH_PADDING': [1, 3, 3],
          'PATCH_STRIDE': [2, 4, 4],
          'POOL_FIRST': False,
          'POOL_KVQ_KERNEL': [3, 3, 3],
          'POOL_KV_STRIDE': [],
          'POOL_KV_STRIDE_ADAPTIVE': [1, 8, 8],
          'POOL_Q_STRIDE': [[0, 1, 1, 1],
                            [1, 1, 1, 1],
                            [2, 1, 2, 2],
                            [3, 1, 1, 1],
                            [4, 1, 1, 1],
                            [5, 1, 2, 2],
                            [6, 1, 1, 1],
                            [7, 1, 1, 1],
                            [8, 1, 1, 1],
                            [9, 1, 1, 1],
                            [10, 1, 1, 1],
                            [11, 1, 1, 1],
                            [12, 1, 1, 1],
                            [13, 1, 1, 1],
                            [14, 1, 1, 1],
                            [15, 1, 1, 1],
                            [16, 1, 1, 1],
                            [17, 1, 1, 1],
                            [18, 1, 1, 1],
                            [19, 1, 1, 1],
                            [20, 1, 1, 1],
                            [21, 1, 2, 2],
                            [22, 1, 1, 1],
                            [23, 1, 1, 1]],
          'QKV_BIAS': True,
          'REL_POS_SPATIAL': True,
          'REL_POS_TEMPORAL': True,
          'REL_POS_ZERO_INIT': False,
          'RESIDUAL_POOLING': True,
          'REV': {'BUFFER_LAYERS': [],
                  'ENABLE': False,
                  'PRE_Q_FUSION': 'avg',
                  'RESPATH_FUSE': 'concat',
                  'RES_PATH': 'conv'},
          'SEPARATE_QKV': False,
          'SEP_POS_EMBED': False,
          'USE_ABS_POS': False,
          'USE_FIXED_SINCOS_POS': False,
          'USE_MEAN_POOLING': False,
          'ZERO_DECAY_POS_CLS': False},
 'NONLOCAL': {'GROUP': [[1], [1], [1], [1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[]], [[]], [[]], [[]]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 2,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'PROMPT': {'ENABLE': True,
            'GPU': None,
            'IMAGE_FOLDER': './visual_prompting/save/images/mvitv2-b_fixed_patch',
            'LEARNING_RATE': 0.2,
            'METHOD': 'fixed_patch',
            'MODEL_FOLDER': './visual_prompting/save/models/mvitv2-b_fixed_patch',
            'MOMENTUM': 0.9,
            'PRINT_GRADS': False,
            'PROMPT_SAVE_FREQ': 5,
            'PROMPT_SIZE': 224,
            'RESUME': None,
            'START_EPOCH': 1,
            'WARMUP': 30,
            'WEIGHT_DECAY': 0.0001},
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1], [1], [1], [1]],
            'SPATIAL_STRIDES': [[1], [2], [2], [2]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': False,
            'ZERO_INIT_FINAL_CONV': False},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 8,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 5},
 'SOLVER': {'BASE_LR': 0.0002,
            'BASE_LR_SCALE_NUM_SHARDS': True,
            'BETAS': (0.9, 0.999),
            'CLIP_GRAD_L2NORM': 1.0,
            'CLIP_GRAD_VAL': None,
            'COSINE_AFTER_WARMUP': True,
            'COSINE_END_LR': 2e-05,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LARS_ON': False,
            'LAYER_DECAY': 1.0,
            'LRS': [],
            'LR_POLICY': 'cosine',
            'MAX_EPOCH': 400,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'adamw',
            'STEPS': [],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 30.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 2e-05,
            'WEIGHT_DECAY': 0.0001,
            'ZERO_WD_1D_PARAM': True},
 'TASK': '',
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': False,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 2,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'kinetics',
          'ENABLE': False,
          'NUM_ENSEMBLE_VIEWS': 5,
          'NUM_SPATIAL_CROPS': 1,
          'NUM_TEMPORAL_CLIPS': [],
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 16,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': True,
           'CHECKPOINT_FILE_PATH': 'checkpoints/mvitv2-b_no_rand_flip_best_epoch_00160.pyth',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_IN_INIT': False,
           'CHECKPOINT_PERIOD': 1,
           'CHECKPOINT_TYPE': 'pytorch',
           'DATASET': 'kinetics',
           'ENABLE': True,
           'EVAL_PERIOD': 1,
           'KILL_LOSS_EXPLOSION_FACTOR': 0.0,
           'MIXED_PRECISION': False},
 'VIS_MASK': CfgNode({'ENABLE': False}),
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[06/30 00:03:30][INFO] misc.py:  185: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=96, bias=True)
        )
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=96, bias=True)
        )
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
      )
      (4): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
      )
      (5): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (6): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (7): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (8): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (9): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (10): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (11): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (12): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (13): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (16): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (17): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (18): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (19): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (20): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (21): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (22): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
      (23): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): TransformerBasicHead(
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=16, bias=True)
      (act): Softmax(dim=1)
    )
  )
)
[06/30 00:03:30][INFO] misc.py:  187: Params: 50,897,968
[06/30 00:03:30][INFO] misc.py:  188: Mem: 0.38045549392700195 MB
[06/30 00:03:34][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 729 time(s)
[06/30 00:03:34][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 102 time(s)
[06/30 00:03:34][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 144 time(s)
[06/30 00:03:34][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 96 time(s)
[06/30 00:03:34][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 120 time(s)
[06/30 00:03:34][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 25 time(s)
[06/30 00:03:34][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 24 time(s)
[06/30 00:03:34][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[06/30 00:03:34][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.16.drop_path, module.blocks.17.drop_path, module.blocks.18.drop_path, module.blocks.19.drop_path, module.blocks.2.drop_path, module.blocks.20.drop_path, module.blocks.21.drop_path, module.blocks.22.drop_path, module.blocks.23.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[06/30 00:03:34][INFO] misc.py:  190: Flops: 92.63208983999999 G
[06/30 00:03:37][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 121 time(s)
[06/30 00:03:37][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 729 time(s)
[06/30 00:03:37][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 102 time(s)
[06/30 00:03:37][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 144 time(s)
[06/30 00:03:37][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 96 time(s)
[06/30 00:03:37][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 120 time(s)
[06/30 00:03:37][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 25 time(s)
[06/30 00:03:37][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 24 time(s)
[06/30 00:03:37][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[06/30 00:03:37][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.16.drop_path, module.blocks.17.drop_path, module.blocks.18.drop_path, module.blocks.19.drop_path, module.blocks.2.drop_path, module.blocks.20.drop_path, module.blocks.21.drop_path, module.blocks.22.drop_path, module.blocks.23.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[06/30 00:03:37][INFO] misc.py:  191: Activations: 357.084096 M
[06/30 00:03:37][INFO] misc.py:  196: nvidia-smi
[06/30 00:03:37][INFO] train_net.py:  628: Load from last checkpoint.
[06/30 00:03:37][INFO] checkpoint.py:  223: Loading network weights from ./checkpoints/checkpoint_epoch_00001.pyth.
[06/30 00:03:38][INFO] kinetics.py:   93: Constructing Kinetics train...
[06/30 00:03:38][INFO] kinetics.py:  169: Constructing kinetics dataloader (size: 1927 skip_rows 0) from train.csv 
[06/30 00:03:38][INFO] kinetics.py:   93: Constructing Kinetics val...
[06/30 00:03:38][INFO] kinetics.py:  169: Constructing kinetics dataloader (size: 482 skip_rows 0) from val.csv 
[06/30 00:03:38][INFO] train_net.py:  751: Start epoch: 2
[06/30 00:03:50][INFO] distributed.py: 1027: Reducer buckets have been rebuilt in this iteration.
[06/30 00:04:02][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.33928, "dt_data": 0.00041, "dt_net": 1.33887, "epoch": "2/400", "eta": "17:48:31", "gpu_mem": "17.92G", "grad_norm": 7.92241, "iter": "10/120", "loss": 1.12310, "lr": 0.0000264500, "top1_acc": 65.62500, "top1_err": 34.37500, "top5_acc": 90.62500, "top5_err": 9.37500}
[06/30 00:04:15][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.33690, "dt_data": 0.00041, "dt_net": 1.33649, "epoch": "2/400", "eta": "17:46:23", "gpu_mem": "17.92G", "grad_norm": 9.08980, "iter": "20/120", "loss": 0.91954, "lr": 0.0000269500, "top1_acc": 71.87500, "top1_err": 28.12500, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:04:29][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38715, "dt_data": 0.00040, "dt_net": 1.38674, "epoch": "2/400", "eta": "18:26:15", "gpu_mem": "17.92G", "grad_norm": 11.95958, "iter": "30/120", "loss": 0.91415, "lr": 0.0000274500, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:04:42][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38161, "dt_data": 0.00038, "dt_net": 1.38123, "epoch": "2/400", "eta": "18:21:36", "gpu_mem": "17.92G", "grad_norm": 10.86019, "iter": "40/120", "loss": 0.73187, "lr": 0.0000279500, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:04:56][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39885, "dt_data": 0.00061, "dt_net": 1.39824, "epoch": "2/400", "eta": "18:35:06", "gpu_mem": "17.92G", "grad_norm": 20.66561, "iter": "50/120", "loss": 0.86505, "lr": 0.0000284500, "top1_acc": 71.87500, "top1_err": 28.12500, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:05:10][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39724, "dt_data": 0.00028, "dt_net": 1.39696, "epoch": "2/400", "eta": "18:33:36", "gpu_mem": "17.92G", "grad_norm": 11.22608, "iter": "60/120", "loss": 0.79234, "lr": 0.0000289500, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:05:24][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39191, "dt_data": 0.00038, "dt_net": 1.39153, "epoch": "2/400", "eta": "18:29:07", "gpu_mem": "17.92G", "grad_norm": 6.94275, "iter": "70/120", "loss": 0.47913, "lr": 0.0000294500, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/30 00:05:38][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38904, "dt_data": 0.00041, "dt_net": 1.38862, "epoch": "2/400", "eta": "18:26:36", "gpu_mem": "17.92G", "grad_norm": 13.59364, "iter": "80/120", "loss": 0.76104, "lr": 0.0000299500, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:05:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39728, "dt_data": 0.00042, "dt_net": 1.39686, "epoch": "2/400", "eta": "18:32:55", "gpu_mem": "17.92G", "grad_norm": 7.47270, "iter": "90/120", "loss": 0.63689, "lr": 0.0000304500, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:06:06][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.40105, "dt_data": 0.00037, "dt_net": 1.40067, "epoch": "2/400", "eta": "18:35:42", "gpu_mem": "17.92G", "grad_norm": 5.54585, "iter": "100/120", "loss": 0.59139, "lr": 0.0000309500, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:06:20][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.40371, "dt_data": 0.00049, "dt_net": 1.40322, "epoch": "2/400", "eta": "18:37:35", "gpu_mem": "17.92G", "grad_norm": 15.07964, "iter": "110/120", "loss": 0.73234, "lr": 0.0000314500, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/30 00:06:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.36527, "dt_data": 0.00033, "dt_net": 1.36493, "epoch": "2/400", "eta": "18:06:45", "gpu_mem": "17.92G", "grad_norm": 12.33038, "iter": "120/120", "loss": 0.57139, "lr": 0.0000319500, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:06:34][INFO] logging.py:  101: json_stats: {"RAM": "14.19/31.07G", "_type": "train_epoch", "dt": 0.82220, "dt_data": 0.82220, "dt_net": 1.36493, "epoch": "2/400", "eta": "10:54:26", "gpu_mem": "17.92G", "grad_norm": 12.33038, "loss": 0.77188, "lr": 0.0000319500, "top1_acc": 75.72917, "top1_err": 24.27083, "top5_acc": 92.86458, "top5_err": 7.13542}
[06/30 00:06:34][INFO] train_net.py:  813: Epoch 1 takes 176.31s. Epochs from 1 to 1 take 176.31s in average and 176.31s in median.
[06/30 00:06:34][INFO] train_net.py:  819: For epoch 1, each iteraction takes 1.47s in average. From epoch 1 to 1, each iteraction takes 1.47s in average.
[06/30 00:06:49][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "2/400", "eta": "0:00:07", "gpu_mem": "17.92G", "iter": "10/31", "time_diff": 0.33620, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/30 00:06:52][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "2/400", "eta": "0:00:03", "gpu_mem": "17.92G", "iter": "20/31", "time_diff": 0.32193, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/30 00:06:55][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "2/400", "eta": "0:00:00", "gpu_mem": "17.92G", "iter": "30/31", "time_diff": 0.30967, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/30 00:06:56][INFO] logging.py:  101: json_stats: {"RAM": "14.20/31.07G", "_type": "val_epoch", "epoch": "2/400", "gpu_mem": "17.92G", "min_top1_err": 24.68880, "min_top5_err": 3.94191, "time_diff": 0.61082, "top1_acc": 75.31120, "top1_err": 24.68880, "top5_acc": 96.05809, "top5_err": 3.94191}
[06/30 00:07:20][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38696, "dt_data": 0.00036, "dt_net": 1.38660, "epoch": "3/400", "eta": "18:23:47", "gpu_mem": "17.92G", "grad_norm": 9.08471, "iter": "10/120", "loss": 0.59567, "lr": 0.0000324500, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/30 00:07:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39011, "dt_data": 0.00068, "dt_net": 1.38943, "epoch": "3/400", "eta": "18:26:04", "gpu_mem": "17.92G", "grad_norm": 7.92565, "iter": "20/120", "loss": 0.67306, "lr": 0.0000329500, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:07:47][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.41919, "dt_data": 0.00042, "dt_net": 1.41877, "epoch": "3/400", "eta": "18:48:57", "gpu_mem": "17.92G", "grad_norm": 9.82397, "iter": "30/120", "loss": 0.67857, "lr": 0.0000334500, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:08:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.37875, "dt_data": 0.00073, "dt_net": 1.37802, "epoch": "3/400", "eta": "18:16:33", "gpu_mem": "17.92G", "grad_norm": 5.35253, "iter": "40/120", "loss": 0.66960, "lr": 0.0000339500, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/30 00:08:15][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39741, "dt_data": 0.00050, "dt_net": 1.39691, "epoch": "3/400", "eta": "18:31:10", "gpu_mem": "17.92G", "grad_norm": 5.39636, "iter": "50/120", "loss": 0.73238, "lr": 0.0000344500, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/30 00:08:29][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.40382, "dt_data": 0.00040, "dt_net": 1.40342, "epoch": "3/400", "eta": "18:36:02", "gpu_mem": "17.92G", "grad_norm": 12.35716, "iter": "60/120", "loss": 0.61393, "lr": 0.0000349500, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:08:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39921, "dt_data": 0.00046, "dt_net": 1.39874, "epoch": "3/400", "eta": "18:32:08", "gpu_mem": "17.92G", "grad_norm": 12.34886, "iter": "70/120", "loss": 0.66905, "lr": 0.0000354500, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:08:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38382, "dt_data": 0.00042, "dt_net": 1.38339, "epoch": "3/400", "eta": "18:19:40", "gpu_mem": "17.92G", "grad_norm": 6.57649, "iter": "80/120", "loss": 0.72024, "lr": 0.0000359500, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:09:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38088, "dt_data": 0.00063, "dt_net": 1.38025, "epoch": "3/400", "eta": "18:17:06", "gpu_mem": "17.92G", "grad_norm": 8.54747, "iter": "90/120", "loss": 0.51779, "lr": 0.0000364500, "top1_acc": 84.37500, "top1_err": 15.62500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/30 00:09:24][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39041, "dt_data": 0.00041, "dt_net": 1.39000, "epoch": "3/400", "eta": "18:24:27", "gpu_mem": "17.92G", "grad_norm": 11.85066, "iter": "100/120", "loss": 0.69467, "lr": 0.0000369500, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:09:38][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.37987, "dt_data": 0.00041, "dt_net": 1.37946, "epoch": "3/400", "eta": "18:15:51", "gpu_mem": "17.92G", "grad_norm": 7.26249, "iter": "110/120", "loss": 0.46677, "lr": 0.0000374500, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:09:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.35624, "dt_data": 0.00028, "dt_net": 1.35596, "epoch": "3/400", "eta": "17:56:51", "gpu_mem": "17.92G", "grad_norm": 4.16768, "iter": "120/120", "loss": 0.44641, "lr": 0.0000379500, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:09:53][INFO] logging.py:  101: json_stats: {"RAM": "14.21/31.07G", "_type": "train_epoch", "dt": 0.78698, "dt_data": 0.78698, "dt_net": 1.35596, "epoch": "3/400", "eta": "10:24:50", "gpu_mem": "17.92G", "grad_norm": 4.16768, "loss": 0.66942, "lr": 0.0000379500, "top1_acc": 78.64583, "top1_err": 21.35417, "top5_acc": 94.47917, "top5_err": 5.52083}
[06/30 00:09:53][INFO] train_net.py:  813: Epoch 2 takes 176.78s. Epochs from 1 to 2 take 176.54s in average and 176.54s in median.
[06/30 00:09:53][INFO] train_net.py:  819: For epoch 2, each iteraction takes 1.47s in average. From epoch 1 to 2, each iteraction takes 1.47s in average.
[06/30 00:10:06][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "3/400", "eta": "0:00:06", "gpu_mem": "17.92G", "iter": "10/31", "time_diff": 0.31503, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/30 00:10:09][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "3/400", "eta": "0:00:03", "gpu_mem": "17.92G", "iter": "20/31", "time_diff": 0.31743, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:10:12][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "3/400", "eta": "0:00:00", "gpu_mem": "17.92G", "iter": "30/31", "time_diff": 0.30998, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/30 00:10:13][INFO] logging.py:  101: json_stats: {"RAM": "14.22/31.07G", "_type": "val_epoch", "epoch": "3/400", "gpu_mem": "17.92G", "min_top1_err": 21.57676, "min_top5_err": 3.52697, "time_diff": 0.59630, "top1_acc": 78.42324, "top1_err": 21.57676, "top5_acc": 96.47303, "top5_err": 3.52697}
[06/30 00:10:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.32269, "dt_data": 0.00041, "dt_net": 1.32228, "epoch": "4/400", "eta": "17:29:59", "gpu_mem": "17.92G", "grad_norm": 12.28468, "iter": "10/120", "loss": 0.62266, "lr": 0.0000384500, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:10:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.35222, "dt_data": 0.00042, "dt_net": 1.35180, "epoch": "4/400", "eta": "17:53:12", "gpu_mem": "17.92G", "grad_norm": 3.44201, "iter": "20/120", "loss": 0.63990, "lr": 0.0000389500, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/30 00:11:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.40868, "dt_data": 0.00042, "dt_net": 1.40826, "epoch": "4/400", "eta": "18:37:47", "gpu_mem": "17.92G", "grad_norm": 24.65898, "iter": "30/120", "loss": 0.52520, "lr": 0.0000394500, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:11:18][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39697, "dt_data": 0.00043, "dt_net": 1.39653, "epoch": "4/400", "eta": "18:28:15", "gpu_mem": "17.92G", "grad_norm": 4.39450, "iter": "40/120", "loss": 0.53112, "lr": 0.0000399500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/30 00:11:32][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.40863, "dt_data": 0.00057, "dt_net": 1.40806, "epoch": "4/400", "eta": "18:37:16", "gpu_mem": "17.92G", "grad_norm": 8.77838, "iter": "50/120", "loss": 0.58956, "lr": 0.0000404500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/30 00:11:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.37156, "dt_data": 0.00038, "dt_net": 1.37118, "epoch": "4/400", "eta": "18:07:39", "gpu_mem": "17.92G", "grad_norm": 6.87665, "iter": "60/120", "loss": 0.52254, "lr": 0.0000409500, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/30 00:13:47][INFO] train_net.py:  612: Train with config:
[06/30 00:13:47][INFO] train_net.py:  613: {'AUG': {'AA_TYPE': 'rand-m9-mstd0.5-inc1',
         'COLOR_JITTER': 0.4,
         'ENABLE': False,
         'GEN_MASK_LOADER': False,
         'INTERPOLATION': 'bicubic',
         'MASK_FRAMES': False,
         'MASK_RATIO': 0.0,
         'MASK_TUBE': False,
         'MASK_WINDOW_SIZE': [8, 7, 7],
         'MAX_MASK_PATCHES_PER_BLOCK': None,
         'NUM_SAMPLE': 1,
         'RE_COUNT': 1,
         'RE_MODE': 'pixel',
         'RE_PROB': 0.25,
         'RE_SPLIT': False},
 'AVA': {'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.9,
         'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv',
         'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/',
         'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'],
         'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'],
         'TRAIN_LISTS': ['train.csv'],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': [],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'GLOBAL_SYNC': False,
        'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'CONTRASTIVE': {'BN_MLP': False,
                 'BN_SYNC_MLP': False,
                 'DELTA_CLIPS_MAX': inf,
                 'DELTA_CLIPS_MIN': -inf,
                 'DIM': 128,
                 'INTERP_MEMORY': False,
                 'KNN_ON': True,
                 'LENGTH': 239975,
                 'LOCAL_SHUFFLE_BN': True,
                 'MEM_TYPE': '1d',
                 'MLP_DIM': 2048,
                 'MOCO_MULTI_VIEW_QUEUE': False,
                 'MOMENTUM': 0.5,
                 'MOMENTUM_ANNEALING': False,
                 'NUM_CLASSES_DOWNSTREAM': 400,
                 'NUM_MLP_LAYERS': 1,
                 'PREDICTOR_DEPTHS': [],
                 'QUEUE_LEN': 65536,
                 'SEQUENTIAL': False,
                 'SIMCLR_DIST_ON': True,
                 'SWAV_QEUE_LEN': 0,
                 'T': 0.07,
                 'TYPE': 'mem'},
 'DATA': {'CAM_VIEWS_METHODS': ['crop', 'noise_crop'],
          'COLOR_RND_GRAYSCALE': 0.0,
          'CROP_PROMPT': False,
          'DECODING_BACKEND': 'torchvision',
          'DECODING_SHORT_SIZE': 256,
          'DUMMY_LOAD': False,
          'ENSEMBLE_METHOD': 'sum',
          'IN22K_TRAINVAL': False,
          'IN22k_VAL_IN1K': '',
          'INPUT_CHANNEL_NUM': [3],
          'INV_UNIFORM_SAMPLE': False,
          'IN_VAL_CROP_RATIO': 0.875,
          'LOADER_CHUNK_OVERALL_SIZE': 0,
          'LOADER_CHUNK_SIZE': 0,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 16,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '',
          'PATH_TO_PRELOAD_IMDB': '',
          'RANDOM_FLIP': False,
          'RETURN_CROPPING_PARAMS': False,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 4,
          'SKIP_ROWS': 0,
          'SSL_BLUR_SIGMA_MAX': [0.0, 2.0],
          'SSL_BLUR_SIGMA_MIN': [0.0, 0.1],
          'SSL_COLOR_BRI_CON_SAT': [0.4, 0.4, 0.4],
          'SSL_COLOR_HUE': 0.1,
          'SSL_COLOR_JITTER': False,
          'SSL_MOCOV2_AUG': False,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 30,
          'TEST_CROP_SIZE': 224,
          'TIME_DIFF_PROB': 0.0,
          'TRAIN_CROP_NUM_SPATIAL': 1,
          'TRAIN_CROP_NUM_TEMPORAL': 1,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333],
          'TRAIN_JITTER_FPS': 0.0,
          'TRAIN_JITTER_MOTION_SHIFT': False,
          'TRAIN_JITTER_SCALES': [256, 320],
          'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0],
          'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
          'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                               [-0.5808, -0.0045, -0.814],
                               [-0.5836, -0.6948, 0.4203]],
          'USE_OFFSET_SAMPLING': False},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 4,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': False,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 10,
 'MASK': {'DECODER_DEPTH': 0,
          'DECODER_EMBED_DIM': 512,
          'DECODER_SEP_POS_EMBED': False,
          'DEC_KV_KERNEL': [],
          'DEC_KV_STRIDE': [],
          'ENABLE': False,
          'HEAD_TYPE': 'separate',
          'MAE_ON': False,
          'MAE_RND_MASK': False,
          'NORM_PRED_PIXEL': True,
          'PER_FRAME_MASKING': False,
          'PRED_HOG': False,
          'PRETRAIN_DEPTH': [15],
          'SCALE_INIT_BY_DEPTH': False,
          'TIME_STRIDE_LOSS': True},
 'MIXUP': {'ALPHA': 0.8,
           'CUTMIX_ALPHA': 1.0,
           'ENABLE': False,
           'LABEL_SMOOTH_VALUE': 0.1,
           'PROB': 1.0,
           'SWITCH_PROB': 0.5},
 'MODEL': {'ACT_CHECKPOINT': False,
           'ARCH': 'mvit',
           'DETACH_FINAL_FC': False,
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'FP16_ALLREDUCE': False,
           'FROZEN_BN': False,
           'HEAD_ACT': 'softmax',
           'LOSS_FUNC': 'soft_cross_entropy',
           'MODEL_NAME': 'MViT',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 16,
           'SINGLE_PATHWAY_ARCH': ['2d',
                                   'c2d',
                                   'i3d',
                                   'slow',
                                   'x3d',
                                   'mvit',
                                   'maskmvit']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'MVIT': {'CLS_EMBED_ON': True,
          'DEPTH': 24,
          'DIM_MUL': [[2, 2.0], [5, 2.0], [21, 2.0]],
          'DIM_MUL_IN_ATT': True,
          'DROPOUT_RATE': 0.0,
          'DROPPATH_RATE': 0.3,
          'EMBED_DIM': 96,
          'HEAD_INIT_SCALE': 1.0,
          'HEAD_MUL': [[2, 2.0], [5, 2.0], [21, 2.0]],
          'LAYER_SCALE_INIT_VALUE': 0.0,
          'MLP_RATIO': 4.0,
          'MODE': 'conv',
          'NORM': 'layernorm',
          'NORM_STEM': False,
          'NUM_HEADS': 1,
          'PATCH_2D': False,
          'PATCH_KERNEL': [3, 7, 7],
          'PATCH_PADDING': [1, 3, 3],
          'PATCH_STRIDE': [2, 4, 4],
          'POOL_FIRST': False,
          'POOL_KVQ_KERNEL': [3, 3, 3],
          'POOL_KV_STRIDE': [],
          'POOL_KV_STRIDE_ADAPTIVE': [1, 8, 8],
          'POOL_Q_STRIDE': [[0, 1, 1, 1],
                            [1, 1, 1, 1],
                            [2, 1, 2, 2],
                            [3, 1, 1, 1],
                            [4, 1, 1, 1],
                            [5, 1, 2, 2],
                            [6, 1, 1, 1],
                            [7, 1, 1, 1],
                            [8, 1, 1, 1],
                            [9, 1, 1, 1],
                            [10, 1, 1, 1],
                            [11, 1, 1, 1],
                            [12, 1, 1, 1],
                            [13, 1, 1, 1],
                            [14, 1, 1, 1],
                            [15, 1, 1, 1],
                            [16, 1, 1, 1],
                            [17, 1, 1, 1],
                            [18, 1, 1, 1],
                            [19, 1, 1, 1],
                            [20, 1, 1, 1],
                            [21, 1, 2, 2],
                            [22, 1, 1, 1],
                            [23, 1, 1, 1]],
          'QKV_BIAS': True,
          'REL_POS_SPATIAL': True,
          'REL_POS_TEMPORAL': True,
          'REL_POS_ZERO_INIT': False,
          'RESIDUAL_POOLING': True,
          'REV': {'BUFFER_LAYERS': [],
                  'ENABLE': False,
                  'PRE_Q_FUSION': 'avg',
                  'RESPATH_FUSE': 'concat',
                  'RES_PATH': 'conv'},
          'SEPARATE_QKV': False,
          'SEP_POS_EMBED': False,
          'USE_ABS_POS': False,
          'USE_FIXED_SINCOS_POS': False,
          'USE_MEAN_POOLING': False,
          'ZERO_DECAY_POS_CLS': False},
 'NONLOCAL': {'GROUP': [[1], [1], [1], [1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[]], [[]], [[]], [[]]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 2,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'PROMPT': {'ENABLE': True,
            'GPU': None,
            'IMAGE_FOLDER': './visual_prompting/save/images/mvitv2-b_fixed_patch',
            'LEARNING_RATE': 0.2,
            'METHOD': 'fixed_patch',
            'MODEL_FOLDER': './visual_prompting/save/models/mvitv2-b_fixed_patch',
            'MOMENTUM': 0.9,
            'PRINT_GRADS': False,
            'PROMPT_SAVE_FREQ': 1,
            'PROMPT_SIZE': 224,
            'RESUME': None,
            'START_EPOCH': 1,
            'WARMUP': 30,
            'WEIGHT_DECAY': 0.0001},
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1], [1], [1], [1]],
            'SPATIAL_STRIDES': [[1], [2], [2], [2]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': False,
            'ZERO_INIT_FINAL_CONV': False},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 8,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 5},
 'SOLVER': {'BASE_LR': 0.0002,
            'BASE_LR_SCALE_NUM_SHARDS': True,
            'BETAS': (0.9, 0.999),
            'CLIP_GRAD_L2NORM': 1.0,
            'CLIP_GRAD_VAL': None,
            'COSINE_AFTER_WARMUP': True,
            'COSINE_END_LR': 2e-05,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LARS_ON': False,
            'LAYER_DECAY': 1.0,
            'LRS': [],
            'LR_POLICY': 'cosine',
            'MAX_EPOCH': 400,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'adamw',
            'STEPS': [],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 30.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 2e-05,
            'WEIGHT_DECAY': 0.0001,
            'ZERO_WD_1D_PARAM': True},
 'TASK': '',
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': False,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 2,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'kinetics',
          'ENABLE': False,
          'NUM_ENSEMBLE_VIEWS': 5,
          'NUM_SPATIAL_CROPS': 1,
          'NUM_TEMPORAL_CLIPS': [],
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 16,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': True,
           'CHECKPOINT_FILE_PATH': 'checkpoints/mvitv2-b_no_rand_flip_best_epoch_00160.pyth',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_IN_INIT': False,
           'CHECKPOINT_PERIOD': 20,
           'CHECKPOINT_TYPE': 'pytorch',
           'DATASET': 'kinetics',
           'ENABLE': True,
           'EVAL_PERIOD': 5,
           'KILL_LOSS_EXPLOSION_FACTOR': 0.0,
           'MIXED_PRECISION': False},
 'VIS_MASK': CfgNode({'ENABLE': False}),
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[06/30 00:13:49][INFO] misc.py:  185: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=96, bias=True)
        )
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=96, bias=True)
        )
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
      )
      (4): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
      )
      (5): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (6): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (7): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (8): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (9): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (10): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (11): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (12): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (13): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (16): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (17): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (18): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (19): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (20): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (21): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (22): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
      (23): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): TransformerBasicHead(
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=16, bias=True)
      (act): Softmax(dim=1)
    )
  )
)
[06/30 00:13:49][INFO] misc.py:  187: Params: 50,897,968
[06/30 00:13:49][INFO] misc.py:  188: Mem: 0.38045549392700195 MB
[06/30 00:13:54][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 729 time(s)
[06/30 00:13:54][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 102 time(s)
[06/30 00:13:54][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 144 time(s)
[06/30 00:13:54][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 96 time(s)
[06/30 00:13:54][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 120 time(s)
[06/30 00:13:54][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 25 time(s)
[06/30 00:13:54][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 24 time(s)
[06/30 00:13:54][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[06/30 00:13:54][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.16.drop_path, module.blocks.17.drop_path, module.blocks.18.drop_path, module.blocks.19.drop_path, module.blocks.2.drop_path, module.blocks.20.drop_path, module.blocks.21.drop_path, module.blocks.22.drop_path, module.blocks.23.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[06/30 00:13:54][INFO] misc.py:  190: Flops: 92.63208983999999 G
[06/30 00:13:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 121 time(s)
[06/30 00:13:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 729 time(s)
[06/30 00:13:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 102 time(s)
[06/30 00:13:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 144 time(s)
[06/30 00:13:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 96 time(s)
[06/30 00:13:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 120 time(s)
[06/30 00:13:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 25 time(s)
[06/30 00:13:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 24 time(s)
[06/30 00:13:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[06/30 00:13:56][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.16.drop_path, module.blocks.17.drop_path, module.blocks.18.drop_path, module.blocks.19.drop_path, module.blocks.2.drop_path, module.blocks.20.drop_path, module.blocks.21.drop_path, module.blocks.22.drop_path, module.blocks.23.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[06/30 00:13:57][INFO] misc.py:  191: Activations: 357.084096 M
[06/30 00:13:57][INFO] misc.py:  196: nvidia-smi
[06/30 00:13:57][INFO] train_net.py:  654: Load from given checkpoint file.
[06/30 00:13:57][INFO] checkpoint.py:  223: Loading network weights from checkpoints/mvitv2-b_no_rand_flip_best_epoch_00160.pyth.
[06/30 00:13:57][INFO] kinetics.py:   93: Constructing Kinetics train...
[06/30 00:13:57][INFO] kinetics.py:  169: Constructing kinetics dataloader (size: 1927 skip_rows 0) from train.csv 
[06/30 00:13:57][INFO] kinetics.py:   93: Constructing Kinetics val...
[06/30 00:13:57][INFO] kinetics.py:  169: Constructing kinetics dataloader (size: 482 skip_rows 0) from val.csv 
[06/30 00:13:57][INFO] train_net.py:  751: Start epoch: 1
[06/30 00:14:14][INFO] train_net.py:  612: Train with config:
[06/30 00:14:14][INFO] train_net.py:  613: {'AUG': {'AA_TYPE': 'rand-m9-mstd0.5-inc1',
         'COLOR_JITTER': 0.4,
         'ENABLE': False,
         'GEN_MASK_LOADER': False,
         'INTERPOLATION': 'bicubic',
         'MASK_FRAMES': False,
         'MASK_RATIO': 0.0,
         'MASK_TUBE': False,
         'MASK_WINDOW_SIZE': [8, 7, 7],
         'MAX_MASK_PATCHES_PER_BLOCK': None,
         'NUM_SAMPLE': 1,
         'RE_COUNT': 1,
         'RE_MODE': 'pixel',
         'RE_PROB': 0.25,
         'RE_SPLIT': False},
 'AVA': {'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.9,
         'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv',
         'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/',
         'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'],
         'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'],
         'TRAIN_LISTS': ['train.csv'],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': [],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'GLOBAL_SYNC': False,
        'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'CONTRASTIVE': {'BN_MLP': False,
                 'BN_SYNC_MLP': False,
                 'DELTA_CLIPS_MAX': inf,
                 'DELTA_CLIPS_MIN': -inf,
                 'DIM': 128,
                 'INTERP_MEMORY': False,
                 'KNN_ON': True,
                 'LENGTH': 239975,
                 'LOCAL_SHUFFLE_BN': True,
                 'MEM_TYPE': '1d',
                 'MLP_DIM': 2048,
                 'MOCO_MULTI_VIEW_QUEUE': False,
                 'MOMENTUM': 0.5,
                 'MOMENTUM_ANNEALING': False,
                 'NUM_CLASSES_DOWNSTREAM': 400,
                 'NUM_MLP_LAYERS': 1,
                 'PREDICTOR_DEPTHS': [],
                 'QUEUE_LEN': 65536,
                 'SEQUENTIAL': False,
                 'SIMCLR_DIST_ON': True,
                 'SWAV_QEUE_LEN': 0,
                 'T': 0.07,
                 'TYPE': 'mem'},
 'DATA': {'CAM_VIEWS_METHODS': ['crop', 'noise_crop'],
          'COLOR_RND_GRAYSCALE': 0.0,
          'CROP_PROMPT': False,
          'DECODING_BACKEND': 'torchvision',
          'DECODING_SHORT_SIZE': 256,
          'DUMMY_LOAD': False,
          'ENSEMBLE_METHOD': 'sum',
          'IN22K_TRAINVAL': False,
          'IN22k_VAL_IN1K': '',
          'INPUT_CHANNEL_NUM': [3],
          'INV_UNIFORM_SAMPLE': False,
          'IN_VAL_CROP_RATIO': 0.875,
          'LOADER_CHUNK_OVERALL_SIZE': 0,
          'LOADER_CHUNK_SIZE': 0,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 16,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '',
          'PATH_TO_PRELOAD_IMDB': '',
          'RANDOM_FLIP': False,
          'RETURN_CROPPING_PARAMS': False,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 4,
          'SKIP_ROWS': 0,
          'SSL_BLUR_SIGMA_MAX': [0.0, 2.0],
          'SSL_BLUR_SIGMA_MIN': [0.0, 0.1],
          'SSL_COLOR_BRI_CON_SAT': [0.4, 0.4, 0.4],
          'SSL_COLOR_HUE': 0.1,
          'SSL_COLOR_JITTER': False,
          'SSL_MOCOV2_AUG': False,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 30,
          'TEST_CROP_SIZE': 224,
          'TIME_DIFF_PROB': 0.0,
          'TRAIN_CROP_NUM_SPATIAL': 1,
          'TRAIN_CROP_NUM_TEMPORAL': 1,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333],
          'TRAIN_JITTER_FPS': 0.0,
          'TRAIN_JITTER_MOTION_SHIFT': False,
          'TRAIN_JITTER_SCALES': [256, 320],
          'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0],
          'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
          'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                               [-0.5808, -0.0045, -0.814],
                               [-0.5836, -0.6948, 0.4203]],
          'USE_OFFSET_SAMPLING': False},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 4,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': False,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 10,
 'MASK': {'DECODER_DEPTH': 0,
          'DECODER_EMBED_DIM': 512,
          'DECODER_SEP_POS_EMBED': False,
          'DEC_KV_KERNEL': [],
          'DEC_KV_STRIDE': [],
          'ENABLE': False,
          'HEAD_TYPE': 'separate',
          'MAE_ON': False,
          'MAE_RND_MASK': False,
          'NORM_PRED_PIXEL': True,
          'PER_FRAME_MASKING': False,
          'PRED_HOG': False,
          'PRETRAIN_DEPTH': [15],
          'SCALE_INIT_BY_DEPTH': False,
          'TIME_STRIDE_LOSS': True},
 'MIXUP': {'ALPHA': 0.8,
           'CUTMIX_ALPHA': 1.0,
           'ENABLE': False,
           'LABEL_SMOOTH_VALUE': 0.1,
           'PROB': 1.0,
           'SWITCH_PROB': 0.5},
 'MODEL': {'ACT_CHECKPOINT': False,
           'ARCH': 'mvit',
           'DETACH_FINAL_FC': False,
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'FP16_ALLREDUCE': False,
           'FROZEN_BN': False,
           'HEAD_ACT': 'softmax',
           'LOSS_FUNC': 'soft_cross_entropy',
           'MODEL_NAME': 'MViT',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 16,
           'SINGLE_PATHWAY_ARCH': ['2d',
                                   'c2d',
                                   'i3d',
                                   'slow',
                                   'x3d',
                                   'mvit',
                                   'maskmvit']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'MVIT': {'CLS_EMBED_ON': True,
          'DEPTH': 24,
          'DIM_MUL': [[2, 2.0], [5, 2.0], [21, 2.0]],
          'DIM_MUL_IN_ATT': True,
          'DROPOUT_RATE': 0.0,
          'DROPPATH_RATE': 0.3,
          'EMBED_DIM': 96,
          'HEAD_INIT_SCALE': 1.0,
          'HEAD_MUL': [[2, 2.0], [5, 2.0], [21, 2.0]],
          'LAYER_SCALE_INIT_VALUE': 0.0,
          'MLP_RATIO': 4.0,
          'MODE': 'conv',
          'NORM': 'layernorm',
          'NORM_STEM': False,
          'NUM_HEADS': 1,
          'PATCH_2D': False,
          'PATCH_KERNEL': [3, 7, 7],
          'PATCH_PADDING': [1, 3, 3],
          'PATCH_STRIDE': [2, 4, 4],
          'POOL_FIRST': False,
          'POOL_KVQ_KERNEL': [3, 3, 3],
          'POOL_KV_STRIDE': [],
          'POOL_KV_STRIDE_ADAPTIVE': [1, 8, 8],
          'POOL_Q_STRIDE': [[0, 1, 1, 1],
                            [1, 1, 1, 1],
                            [2, 1, 2, 2],
                            [3, 1, 1, 1],
                            [4, 1, 1, 1],
                            [5, 1, 2, 2],
                            [6, 1, 1, 1],
                            [7, 1, 1, 1],
                            [8, 1, 1, 1],
                            [9, 1, 1, 1],
                            [10, 1, 1, 1],
                            [11, 1, 1, 1],
                            [12, 1, 1, 1],
                            [13, 1, 1, 1],
                            [14, 1, 1, 1],
                            [15, 1, 1, 1],
                            [16, 1, 1, 1],
                            [17, 1, 1, 1],
                            [18, 1, 1, 1],
                            [19, 1, 1, 1],
                            [20, 1, 1, 1],
                            [21, 1, 2, 2],
                            [22, 1, 1, 1],
                            [23, 1, 1, 1]],
          'QKV_BIAS': True,
          'REL_POS_SPATIAL': True,
          'REL_POS_TEMPORAL': True,
          'REL_POS_ZERO_INIT': False,
          'RESIDUAL_POOLING': True,
          'REV': {'BUFFER_LAYERS': [],
                  'ENABLE': False,
                  'PRE_Q_FUSION': 'avg',
                  'RESPATH_FUSE': 'concat',
                  'RES_PATH': 'conv'},
          'SEPARATE_QKV': False,
          'SEP_POS_EMBED': False,
          'USE_ABS_POS': False,
          'USE_FIXED_SINCOS_POS': False,
          'USE_MEAN_POOLING': False,
          'ZERO_DECAY_POS_CLS': False},
 'NONLOCAL': {'GROUP': [[1], [1], [1], [1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[]], [[]], [[]], [[]]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 2,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'PROMPT': {'ENABLE': True,
            'GPU': None,
            'IMAGE_FOLDER': './visual_prompting/save/images/mvitv2-b_fixed_patch',
            'LEARNING_RATE': 0.2,
            'METHOD': 'fixed_patch',
            'MODEL_FOLDER': './visual_prompting/save/models/mvitv2-b_fixed_patch',
            'MOMENTUM': 0.9,
            'PRINT_GRADS': False,
            'PROMPT_SAVE_FREQ': 1,
            'PROMPT_SIZE': 224,
            'RESUME': None,
            'START_EPOCH': 1,
            'WARMUP': 30,
            'WEIGHT_DECAY': 0.0001},
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1], [1], [1], [1]],
            'SPATIAL_STRIDES': [[1], [2], [2], [2]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': False,
            'ZERO_INIT_FINAL_CONV': False},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 8,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 5},
 'SOLVER': {'BASE_LR': 0.0002,
            'BASE_LR_SCALE_NUM_SHARDS': True,
            'BETAS': (0.9, 0.999),
            'CLIP_GRAD_L2NORM': 1.0,
            'CLIP_GRAD_VAL': None,
            'COSINE_AFTER_WARMUP': True,
            'COSINE_END_LR': 2e-05,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LARS_ON': False,
            'LAYER_DECAY': 1.0,
            'LRS': [],
            'LR_POLICY': 'cosine',
            'MAX_EPOCH': 400,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'adamw',
            'STEPS': [],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 30.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 2e-05,
            'WEIGHT_DECAY': 0.0001,
            'ZERO_WD_1D_PARAM': True},
 'TASK': '',
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': False,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 2,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'kinetics',
          'ENABLE': False,
          'NUM_ENSEMBLE_VIEWS': 5,
          'NUM_SPATIAL_CROPS': 1,
          'NUM_TEMPORAL_CLIPS': [],
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 16,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': True,
           'CHECKPOINT_FILE_PATH': 'checkpoints/mvitv2-b_no_rand_flip_best_epoch_00160.pyth',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_IN_INIT': False,
           'CHECKPOINT_PERIOD': 20,
           'CHECKPOINT_TYPE': 'pytorch',
           'DATASET': 'kinetics',
           'ENABLE': True,
           'EVAL_PERIOD': 1,
           'KILL_LOSS_EXPLOSION_FACTOR': 0.0,
           'MIXED_PRECISION': False},
 'VIS_MASK': CfgNode({'ENABLE': False}),
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[06/30 00:14:16][INFO] misc.py:  185: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=96, bias=True)
        )
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=96, bias=True)
        )
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
      )
      (4): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
      )
      (5): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (6): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (7): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (8): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (9): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (10): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (11): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (12): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (13): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (16): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (17): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (18): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (19): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (20): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (21): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (22): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
      (23): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): TransformerBasicHead(
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=16, bias=True)
      (act): Softmax(dim=1)
    )
  )
)
[06/30 00:14:16][INFO] misc.py:  187: Params: 50,897,968
[06/30 00:14:16][INFO] misc.py:  188: Mem: 0.38045549392700195 MB
[06/30 00:14:20][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 729 time(s)
[06/30 00:14:20][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 102 time(s)
[06/30 00:14:20][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 144 time(s)
[06/30 00:14:20][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 96 time(s)
[06/30 00:14:20][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 120 time(s)
[06/30 00:14:20][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 25 time(s)
[06/30 00:14:20][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 24 time(s)
[06/30 00:14:20][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[06/30 00:14:20][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.16.drop_path, module.blocks.17.drop_path, module.blocks.18.drop_path, module.blocks.19.drop_path, module.blocks.2.drop_path, module.blocks.20.drop_path, module.blocks.21.drop_path, module.blocks.22.drop_path, module.blocks.23.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[06/30 00:14:20][INFO] misc.py:  190: Flops: 92.63208983999999 G
[06/30 00:14:23][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 121 time(s)
[06/30 00:14:23][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 729 time(s)
[06/30 00:14:23][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 102 time(s)
[06/30 00:14:23][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 144 time(s)
[06/30 00:14:23][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 96 time(s)
[06/30 00:14:23][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 120 time(s)
[06/30 00:14:23][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 25 time(s)
[06/30 00:14:23][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 24 time(s)
[06/30 00:14:23][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[06/30 00:14:23][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.16.drop_path, module.blocks.17.drop_path, module.blocks.18.drop_path, module.blocks.19.drop_path, module.blocks.2.drop_path, module.blocks.20.drop_path, module.blocks.21.drop_path, module.blocks.22.drop_path, module.blocks.23.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[06/30 00:14:23][INFO] misc.py:  191: Activations: 357.084096 M
[06/30 00:14:23][INFO] misc.py:  196: nvidia-smi
[06/30 00:14:24][INFO] train_net.py:  654: Load from given checkpoint file.
[06/30 00:14:24][INFO] checkpoint.py:  223: Loading network weights from checkpoints/mvitv2-b_no_rand_flip_best_epoch_00160.pyth.
[06/30 00:14:24][INFO] kinetics.py:   93: Constructing Kinetics train...
[06/30 00:14:24][INFO] kinetics.py:  169: Constructing kinetics dataloader (size: 1927 skip_rows 0) from train.csv 
[06/30 00:14:24][INFO] kinetics.py:   93: Constructing Kinetics val...
[06/30 00:14:24][INFO] kinetics.py:  169: Constructing kinetics dataloader (size: 482 skip_rows 0) from val.csv 
[06/30 00:14:24][INFO] train_net.py:  751: Start epoch: 1
[06/30 00:14:35][INFO] distributed.py: 1027: Reducer buckets have been rebuilt in this iteration.
[06/30 00:14:47][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.30790, "dt_data": 0.00038, "dt_net": 1.30752, "epoch": "1/400", "eta": "17:26:06", "gpu_mem": "17.91G", "grad_norm": 10.19673, "iter": "10/120", "loss": 1.81485, "lr": 0.0000204500, "top1_acc": 43.75000, "top1_err": 56.25000, "top5_acc": 81.25000, "top5_err": 18.75000}
[06/30 00:15:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.36456, "dt_data": 0.00038, "dt_net": 1.36417, "epoch": "1/400", "eta": "18:11:11", "gpu_mem": "17.91G", "grad_norm": 15.19532, "iter": "20/120", "loss": 1.37205, "lr": 0.0000209500, "top1_acc": 56.25000, "top1_err": 43.75000, "top5_acc": 87.50000, "top5_err": 12.50000}
[06/30 00:15:14][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.31844, "dt_data": 0.00038, "dt_net": 1.31806, "epoch": "1/400", "eta": "17:34:05", "gpu_mem": "17.91G", "grad_norm": 11.91219, "iter": "30/120", "loss": 1.29956, "lr": 0.0000214500, "top1_acc": 56.25000, "top1_err": 43.75000, "top5_acc": 81.25000, "top5_err": 18.75000}
[06/30 00:15:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38113, "dt_data": 0.00043, "dt_net": 1.38070, "epoch": "1/400", "eta": "18:23:58", "gpu_mem": "17.91G", "grad_norm": 12.47917, "iter": "40/120", "loss": 1.12881, "lr": 0.0000219500, "top1_acc": 62.50000, "top1_err": 37.50000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:15:42][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.37220, "dt_data": 0.00053, "dt_net": 1.37166, "epoch": "1/400", "eta": "18:16:36", "gpu_mem": "17.91G", "grad_norm": 11.05056, "iter": "50/120", "loss": 1.27575, "lr": 0.0000224500, "top1_acc": 59.37500, "top1_err": 40.62500, "top5_acc": 87.50000, "top5_err": 12.50000}
[06/30 00:15:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39195, "dt_data": 0.00054, "dt_net": 1.39141, "epoch": "1/400", "eta": "18:32:09", "gpu_mem": "17.91G", "grad_norm": 11.47585, "iter": "60/120", "loss": 0.93421, "lr": 0.0000229500, "top1_acc": 65.62500, "top1_err": 34.37500, "top5_acc": 90.62500, "top5_err": 9.37500}
[06/30 00:16:09][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38721, "dt_data": 0.00044, "dt_net": 1.38676, "epoch": "1/400", "eta": "18:28:08", "gpu_mem": "17.91G", "grad_norm": 9.29009, "iter": "70/120", "loss": 0.88946, "lr": 0.0000234500, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 87.50000, "top5_err": 12.50000}
[06/30 00:16:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39975, "dt_data": 0.00038, "dt_net": 1.39937, "epoch": "1/400", "eta": "18:37:56", "gpu_mem": "17.91G", "grad_norm": 8.95617, "iter": "80/120", "loss": 1.21529, "lr": 0.0000239500, "top1_acc": 65.62500, "top1_err": 34.37500, "top5_acc": 87.50000, "top5_err": 12.50000}
[06/30 00:16:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.41641, "dt_data": 0.00046, "dt_net": 1.41595, "epoch": "1/400", "eta": "18:51:00", "gpu_mem": "17.91G", "grad_norm": 7.73098, "iter": "90/120", "loss": 1.01151, "lr": 0.0000244500, "top1_acc": 68.75000, "top1_err": 31.25000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:16:51][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38036, "dt_data": 0.00038, "dt_net": 1.37998, "epoch": "1/400", "eta": "18:21:59", "gpu_mem": "17.91G", "grad_norm": 8.33380, "iter": "100/120", "loss": 0.81126, "lr": 0.0000249500, "top1_acc": 68.75000, "top1_err": 31.25000, "top5_acc": 90.62500, "top5_err": 9.37500}
[06/30 00:17:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.37731, "dt_data": 0.00043, "dt_net": 1.37687, "epoch": "1/400", "eta": "18:19:19", "gpu_mem": "17.91G", "grad_norm": 5.12726, "iter": "110/120", "loss": 0.72182, "lr": 0.0000254500, "top1_acc": 71.87500, "top1_err": 28.12500, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:17:18][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.35964, "dt_data": 0.00026, "dt_net": 1.35938, "epoch": "1/400", "eta": "18:04:59", "gpu_mem": "17.91G", "grad_norm": 7.54440, "iter": "120/120", "loss": 0.66396, "lr": 0.0000259500, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:17:19][INFO] logging.py:  101: json_stats: {"RAM": "13.37/31.07G", "_type": "train_epoch", "dt": 0.80018, "dt_data": 0.80018, "dt_net": 1.35938, "epoch": "1/400", "eta": "10:38:31", "gpu_mem": "17.91G", "grad_norm": 7.54440, "loss": 1.15768, "lr": 0.0000259500, "top1_acc": 63.95833, "top1_err": 36.04167, "top5_acc": 88.17708, "top5_err": 11.82292}
[06/30 00:17:19][INFO] train_net.py:  813: Epoch 0 takes 175.37s. Epochs from 0 to 0 take 175.37s in average and 175.37s in median.
[06/30 00:17:19][INFO] train_net.py:  819: For epoch 0, each iteraction takes 1.46s in average. From epoch 0 to 0, each iteraction takes 1.46s in average.
[06/30 00:17:33][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "1/400", "eta": "0:00:07", "gpu_mem": "17.91G", "iter": "10/31", "time_diff": 0.33384, "top1_acc": 68.75000, "top1_err": 31.25000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/30 00:17:36][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "1/400", "eta": "0:00:03", "gpu_mem": "17.91G", "iter": "20/31", "time_diff": 0.32338, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/30 00:17:39][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "1/400", "eta": "0:00:00", "gpu_mem": "17.91G", "iter": "30/31", "time_diff": 0.30990, "top1_acc": 68.75000, "top1_err": 31.25000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:17:40][INFO] logging.py:  101: json_stats: {"RAM": "13.86/31.07G", "_type": "val_epoch", "epoch": "1/400", "gpu_mem": "17.91G", "min_top1_err": 26.97095, "min_top5_err": 4.35685, "time_diff": 0.58545, "top1_acc": 73.02905, "top1_err": 26.97095, "top5_acc": 95.64315, "top5_err": 4.35685}
[06/30 00:18:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38401, "dt_data": 0.00042, "dt_net": 1.38359, "epoch": "2/400", "eta": "18:24:12", "gpu_mem": "17.91G", "grad_norm": 4.27131, "iter": "10/120", "loss": 0.80457, "lr": 0.0000264500, "top1_acc": 71.87500, "top1_err": 28.12500, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:18:18][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.36196, "dt_data": 0.00046, "dt_net": 1.36150, "epoch": "2/400", "eta": "18:06:23", "gpu_mem": "17.91G", "grad_norm": 15.76054, "iter": "20/120", "loss": 0.76482, "lr": 0.0000269500, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:18:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38622, "dt_data": 0.00042, "dt_net": 1.38580, "epoch": "2/400", "eta": "18:25:30", "gpu_mem": "17.91G", "grad_norm": 18.34161, "iter": "30/120", "loss": 0.53241, "lr": 0.0000274500, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/30 00:18:45][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39357, "dt_data": 0.00052, "dt_net": 1.39305, "epoch": "2/400", "eta": "18:31:08", "gpu_mem": "17.91G", "grad_norm": 6.50522, "iter": "40/120", "loss": 0.62128, "lr": 0.0000279500, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/30 00:18:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38119, "dt_data": 0.00081, "dt_net": 1.38036, "epoch": "2/400", "eta": "18:21:02", "gpu_mem": "17.91G", "grad_norm": 11.94263, "iter": "50/120", "loss": 0.83079, "lr": 0.0000284500, "top1_acc": 68.75000, "top1_err": 31.25000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:19:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39842, "dt_data": 0.00038, "dt_net": 1.39804, "epoch": "2/400", "eta": "18:34:32", "gpu_mem": "17.91G", "grad_norm": 7.67271, "iter": "60/120", "loss": 0.87694, "lr": 0.0000289500, "top1_acc": 68.75000, "top1_err": 31.25000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:19:27][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39230, "dt_data": 0.00048, "dt_net": 1.39181, "epoch": "2/400", "eta": "18:29:25", "gpu_mem": "17.91G", "grad_norm": 9.76217, "iter": "70/120", "loss": 0.72762, "lr": 0.0000294500, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 90.62500, "top5_err": 9.37500}
[06/30 00:19:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.36633, "dt_data": 0.00041, "dt_net": 1.36592, "epoch": "2/400", "eta": "18:08:30", "gpu_mem": "17.91G", "grad_norm": 14.86631, "iter": "80/120", "loss": 0.91734, "lr": 0.0000299500, "top1_acc": 68.75000, "top1_err": 31.25000, "top5_acc": 87.50000, "top5_err": 12.50000}
[06/30 00:19:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38487, "dt_data": 0.00041, "dt_net": 1.38447, "epoch": "2/400", "eta": "18:23:03", "gpu_mem": "17.91G", "grad_norm": 10.36732, "iter": "90/120", "loss": 0.55760, "lr": 0.0000304500, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/30 00:20:09][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.41362, "dt_data": 0.00045, "dt_net": 1.41316, "epoch": "2/400", "eta": "18:45:42", "gpu_mem": "17.91G", "grad_norm": 8.84529, "iter": "100/120", "loss": 0.65823, "lr": 0.0000309500, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:20:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.37683, "dt_data": 0.00047, "dt_net": 1.37635, "epoch": "2/400", "eta": "18:16:11", "gpu_mem": "17.91G", "grad_norm": 5.62181, "iter": "110/120", "loss": 0.68095, "lr": 0.0000314500, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/30 00:20:36][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39737, "dt_data": 0.00026, "dt_net": 1.39711, "epoch": "2/400", "eta": "18:32:18", "gpu_mem": "17.91G", "grad_norm": 10.04731, "iter": "120/120", "loss": 0.74103, "lr": 0.0000319500, "top1_acc": 71.87500, "top1_err": 28.12500, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:20:37][INFO] logging.py:  101: json_stats: {"RAM": "13.36/31.07G", "_type": "train_epoch", "dt": 0.80571, "dt_data": 0.80571, "dt_net": 1.39711, "epoch": "2/400", "eta": "10:41:19", "gpu_mem": "17.91G", "grad_norm": 10.04731, "loss": 0.75356, "lr": 0.0000319500, "top1_acc": 75.88542, "top1_err": 24.11458, "top5_acc": 93.28125, "top5_err": 6.71875}
[06/30 00:20:37][INFO] train_net.py:  813: Epoch 1 takes 177.09s. Epochs from 0 to 1 take 176.23s in average and 176.23s in median.
[06/30 00:20:37][INFO] train_net.py:  819: For epoch 1, each iteraction takes 1.48s in average. From epoch 0 to 1, each iteraction takes 1.47s in average.
[06/30 00:20:50][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "2/400", "eta": "0:00:06", "gpu_mem": "17.91G", "iter": "10/31", "time_diff": 0.32928, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/30 00:20:54][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "2/400", "eta": "0:00:03", "gpu_mem": "17.91G", "iter": "20/31", "time_diff": 0.31963, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/30 00:20:57][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "2/400", "eta": "0:00:00", "gpu_mem": "17.91G", "iter": "30/31", "time_diff": 0.30976, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/30 00:20:57][INFO] logging.py:  101: json_stats: {"RAM": "13.36/31.07G", "_type": "val_epoch", "epoch": "2/400", "gpu_mem": "17.91G", "min_top1_err": 21.36929, "min_top5_err": 3.52697, "time_diff": 0.60936, "top1_acc": 78.63071, "top1_err": 21.36929, "top5_acc": 96.47303, "top5_err": 3.52697}
[06/30 00:21:21][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.35280, "dt_data": 0.00067, "dt_net": 1.35213, "epoch": "3/400", "eta": "17:56:35", "gpu_mem": "17.91G", "grad_norm": 11.62201, "iter": "10/120", "loss": 0.65185, "lr": 0.0000324500, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/30 00:21:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39048, "dt_data": 0.00043, "dt_net": 1.39004, "epoch": "3/400", "eta": "18:26:21", "gpu_mem": "17.91G", "grad_norm": 6.50532, "iter": "20/120", "loss": 0.76000, "lr": 0.0000329500, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:21:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.37834, "dt_data": 0.01127, "dt_net": 1.36707, "epoch": "3/400", "eta": "18:16:28", "gpu_mem": "17.91G", "grad_norm": 11.86626, "iter": "30/120", "loss": 0.68769, "lr": 0.0000334500, "top1_acc": 84.37500, "top1_err": 15.62500, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/30 00:22:03][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.38660, "dt_data": 0.00043, "dt_net": 1.38617, "epoch": "3/400", "eta": "18:22:48", "gpu_mem": "17.91G", "grad_norm": 7.65872, "iter": "40/120", "loss": 0.53950, "lr": 0.0000339500, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/30 00:22:51][INFO] train_net.py:  612: Train with config:
[06/30 00:22:51][INFO] train_net.py:  613: {'AUG': {'AA_TYPE': 'rand-m9-mstd0.5-inc1',
         'COLOR_JITTER': 0.4,
         'ENABLE': False,
         'GEN_MASK_LOADER': False,
         'INTERPOLATION': 'bicubic',
         'MASK_FRAMES': False,
         'MASK_RATIO': 0.0,
         'MASK_TUBE': False,
         'MASK_WINDOW_SIZE': [8, 7, 7],
         'MAX_MASK_PATCHES_PER_BLOCK': None,
         'NUM_SAMPLE': 1,
         'RE_COUNT': 1,
         'RE_MODE': 'pixel',
         'RE_PROB': 0.25,
         'RE_SPLIT': False},
 'AVA': {'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.9,
         'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv',
         'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/',
         'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'],
         'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'],
         'TRAIN_LISTS': ['train.csv'],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': [],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'GLOBAL_SYNC': False,
        'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'CONTRASTIVE': {'BN_MLP': False,
                 'BN_SYNC_MLP': False,
                 'DELTA_CLIPS_MAX': inf,
                 'DELTA_CLIPS_MIN': -inf,
                 'DIM': 128,
                 'INTERP_MEMORY': False,
                 'KNN_ON': True,
                 'LENGTH': 239975,
                 'LOCAL_SHUFFLE_BN': True,
                 'MEM_TYPE': '1d',
                 'MLP_DIM': 2048,
                 'MOCO_MULTI_VIEW_QUEUE': False,
                 'MOMENTUM': 0.5,
                 'MOMENTUM_ANNEALING': False,
                 'NUM_CLASSES_DOWNSTREAM': 400,
                 'NUM_MLP_LAYERS': 1,
                 'PREDICTOR_DEPTHS': [],
                 'QUEUE_LEN': 65536,
                 'SEQUENTIAL': False,
                 'SIMCLR_DIST_ON': True,
                 'SWAV_QEUE_LEN': 0,
                 'T': 0.07,
                 'TYPE': 'mem'},
 'DATA': {'CAM_VIEWS_METHODS': ['crop', 'noise_crop'],
          'COLOR_RND_GRAYSCALE': 0.0,
          'CROP_PROMPT': False,
          'DECODING_BACKEND': 'torchvision',
          'DECODING_SHORT_SIZE': 256,
          'DUMMY_LOAD': False,
          'ENSEMBLE_METHOD': 'sum',
          'IN22K_TRAINVAL': False,
          'IN22k_VAL_IN1K': '',
          'INPUT_CHANNEL_NUM': [3],
          'INV_UNIFORM_SAMPLE': False,
          'IN_VAL_CROP_RATIO': 0.875,
          'LOADER_CHUNK_OVERALL_SIZE': 0,
          'LOADER_CHUNK_SIZE': 0,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 16,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '',
          'PATH_TO_PRELOAD_IMDB': '',
          'RANDOM_FLIP': False,
          'RETURN_CROPPING_PARAMS': False,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 4,
          'SKIP_ROWS': 0,
          'SSL_BLUR_SIGMA_MAX': [0.0, 2.0],
          'SSL_BLUR_SIGMA_MIN': [0.0, 0.1],
          'SSL_COLOR_BRI_CON_SAT': [0.4, 0.4, 0.4],
          'SSL_COLOR_HUE': 0.1,
          'SSL_COLOR_JITTER': False,
          'SSL_MOCOV2_AUG': False,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 30,
          'TEST_CROP_SIZE': 224,
          'TIME_DIFF_PROB': 0.0,
          'TRAIN_CROP_NUM_SPATIAL': 1,
          'TRAIN_CROP_NUM_TEMPORAL': 1,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333],
          'TRAIN_JITTER_FPS': 0.0,
          'TRAIN_JITTER_MOTION_SHIFT': False,
          'TRAIN_JITTER_SCALES': [256, 320],
          'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0],
          'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
          'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                               [-0.5808, -0.0045, -0.814],
                               [-0.5836, -0.6948, 0.4203]],
          'USE_OFFSET_SAMPLING': False},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 4,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': False,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 10,
 'MASK': {'DECODER_DEPTH': 0,
          'DECODER_EMBED_DIM': 512,
          'DECODER_SEP_POS_EMBED': False,
          'DEC_KV_KERNEL': [],
          'DEC_KV_STRIDE': [],
          'ENABLE': False,
          'HEAD_TYPE': 'separate',
          'MAE_ON': False,
          'MAE_RND_MASK': False,
          'NORM_PRED_PIXEL': True,
          'PER_FRAME_MASKING': False,
          'PRED_HOG': False,
          'PRETRAIN_DEPTH': [15],
          'SCALE_INIT_BY_DEPTH': False,
          'TIME_STRIDE_LOSS': True},
 'MIXUP': {'ALPHA': 0.8,
           'CUTMIX_ALPHA': 1.0,
           'ENABLE': False,
           'LABEL_SMOOTH_VALUE': 0.1,
           'PROB': 1.0,
           'SWITCH_PROB': 0.5},
 'MODEL': {'ACT_CHECKPOINT': False,
           'ARCH': 'mvit',
           'DETACH_FINAL_FC': False,
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'FP16_ALLREDUCE': False,
           'FROZEN_BN': False,
           'HEAD_ACT': 'softmax',
           'LOSS_FUNC': 'soft_cross_entropy',
           'MODEL_NAME': 'MViT',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 16,
           'SINGLE_PATHWAY_ARCH': ['2d',
                                   'c2d',
                                   'i3d',
                                   'slow',
                                   'x3d',
                                   'mvit',
                                   'maskmvit']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'MVIT': {'CLS_EMBED_ON': True,
          'DEPTH': 24,
          'DIM_MUL': [[2, 2.0], [5, 2.0], [21, 2.0]],
          'DIM_MUL_IN_ATT': True,
          'DROPOUT_RATE': 0.0,
          'DROPPATH_RATE': 0.3,
          'EMBED_DIM': 96,
          'HEAD_INIT_SCALE': 1.0,
          'HEAD_MUL': [[2, 2.0], [5, 2.0], [21, 2.0]],
          'LAYER_SCALE_INIT_VALUE': 0.0,
          'MLP_RATIO': 4.0,
          'MODE': 'conv',
          'NORM': 'layernorm',
          'NORM_STEM': False,
          'NUM_HEADS': 1,
          'PATCH_2D': False,
          'PATCH_KERNEL': [3, 7, 7],
          'PATCH_PADDING': [1, 3, 3],
          'PATCH_STRIDE': [2, 4, 4],
          'POOL_FIRST': False,
          'POOL_KVQ_KERNEL': [3, 3, 3],
          'POOL_KV_STRIDE': [],
          'POOL_KV_STRIDE_ADAPTIVE': [1, 8, 8],
          'POOL_Q_STRIDE': [[0, 1, 1, 1],
                            [1, 1, 1, 1],
                            [2, 1, 2, 2],
                            [3, 1, 1, 1],
                            [4, 1, 1, 1],
                            [5, 1, 2, 2],
                            [6, 1, 1, 1],
                            [7, 1, 1, 1],
                            [8, 1, 1, 1],
                            [9, 1, 1, 1],
                            [10, 1, 1, 1],
                            [11, 1, 1, 1],
                            [12, 1, 1, 1],
                            [13, 1, 1, 1],
                            [14, 1, 1, 1],
                            [15, 1, 1, 1],
                            [16, 1, 1, 1],
                            [17, 1, 1, 1],
                            [18, 1, 1, 1],
                            [19, 1, 1, 1],
                            [20, 1, 1, 1],
                            [21, 1, 2, 2],
                            [22, 1, 1, 1],
                            [23, 1, 1, 1]],
          'QKV_BIAS': True,
          'REL_POS_SPATIAL': True,
          'REL_POS_TEMPORAL': True,
          'REL_POS_ZERO_INIT': False,
          'RESIDUAL_POOLING': True,
          'REV': {'BUFFER_LAYERS': [],
                  'ENABLE': False,
                  'PRE_Q_FUSION': 'avg',
                  'RESPATH_FUSE': 'concat',
                  'RES_PATH': 'conv'},
          'SEPARATE_QKV': False,
          'SEP_POS_EMBED': False,
          'USE_ABS_POS': False,
          'USE_FIXED_SINCOS_POS': False,
          'USE_MEAN_POOLING': False,
          'ZERO_DECAY_POS_CLS': False},
 'NONLOCAL': {'GROUP': [[1], [1], [1], [1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[]], [[]], [[]], [[]]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 2,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'PROMPT': {'ENABLE': True,
            'GPU': None,
            'IMAGE_FOLDER': './visual_prompting/save/images/mvitv2-b_fixed_patch',
            'LEARNING_RATE': 0.2,
            'METHOD': 'fixed_patch',
            'MODEL_FOLDER': './visual_prompting/save/models/mvitv2-b_fixed_patch',
            'MOMENTUM': 0.9,
            'PRINT_GRADS': False,
            'PROMPT_SAVE_FREQ': 5,
            'PROMPT_SIZE': 224,
            'RESUME': None,
            'START_EPOCH': 1,
            'WARMUP': 30,
            'WEIGHT_DECAY': 0.0001},
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1], [1], [1], [1]],
            'SPATIAL_STRIDES': [[1], [2], [2], [2]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': False,
            'ZERO_INIT_FINAL_CONV': False},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 8,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 5},
 'SOLVER': {'BASE_LR': 0.0002,
            'BASE_LR_SCALE_NUM_SHARDS': True,
            'BETAS': (0.9, 0.999),
            'CLIP_GRAD_L2NORM': 1.0,
            'CLIP_GRAD_VAL': None,
            'COSINE_AFTER_WARMUP': True,
            'COSINE_END_LR': 2e-05,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LARS_ON': False,
            'LAYER_DECAY': 1.0,
            'LRS': [],
            'LR_POLICY': 'cosine',
            'MAX_EPOCH': 400,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'adamw',
            'STEPS': [],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 30.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 2e-05,
            'WEIGHT_DECAY': 0.0001,
            'ZERO_WD_1D_PARAM': True},
 'TASK': '',
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': False,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 2,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'kinetics',
          'ENABLE': False,
          'NUM_ENSEMBLE_VIEWS': 5,
          'NUM_SPATIAL_CROPS': 1,
          'NUM_TEMPORAL_CLIPS': [],
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 16,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': True,
           'CHECKPOINT_FILE_PATH': 'checkpoints/mvitv2-b_no_rand_flip_best_epoch_00160.pyth',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_IN_INIT': False,
           'CHECKPOINT_PERIOD': 20,
           'CHECKPOINT_TYPE': 'pytorch',
           'DATASET': 'kinetics',
           'ENABLE': True,
           'EVAL_PERIOD': 5,
           'KILL_LOSS_EXPLOSION_FACTOR': 0.0,
           'MIXED_PRECISION': False},
 'VIS_MASK': CfgNode({'ENABLE': False}),
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[06/30 00:22:53][INFO] misc.py:  185: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=96, bias=True)
        )
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=96, bias=True)
        )
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
      )
      (4): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
      )
      (5): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (6): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (7): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (8): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (9): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (10): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (11): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (12): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (13): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (16): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (17): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (18): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (19): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (20): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (21): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (22): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
      (23): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): TransformerBasicHead(
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=16, bias=True)
      (act): Softmax(dim=1)
    )
  )
)
[06/30 00:22:53][INFO] misc.py:  187: Params: 50,897,968
[06/30 00:22:53][INFO] misc.py:  188: Mem: 0.38045549392700195 MB
[06/30 00:22:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 729 time(s)
[06/30 00:22:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 102 time(s)
[06/30 00:22:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 144 time(s)
[06/30 00:22:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 96 time(s)
[06/30 00:22:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 120 time(s)
[06/30 00:22:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 25 time(s)
[06/30 00:22:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 24 time(s)
[06/30 00:22:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[06/30 00:22:57][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.16.drop_path, module.blocks.17.drop_path, module.blocks.18.drop_path, module.blocks.19.drop_path, module.blocks.2.drop_path, module.blocks.20.drop_path, module.blocks.21.drop_path, module.blocks.22.drop_path, module.blocks.23.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[06/30 00:22:57][INFO] misc.py:  190: Flops: 92.63208983999999 G
[06/30 00:23:00][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 121 time(s)
[06/30 00:23:00][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 729 time(s)
[06/30 00:23:00][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 102 time(s)
[06/30 00:23:00][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 144 time(s)
[06/30 00:23:00][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 96 time(s)
[06/30 00:23:00][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 120 time(s)
[06/30 00:23:00][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 25 time(s)
[06/30 00:23:00][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 24 time(s)
[06/30 00:23:00][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[06/30 00:23:00][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.16.drop_path, module.blocks.17.drop_path, module.blocks.18.drop_path, module.blocks.19.drop_path, module.blocks.2.drop_path, module.blocks.20.drop_path, module.blocks.21.drop_path, module.blocks.22.drop_path, module.blocks.23.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[06/30 00:23:00][INFO] misc.py:  191: Activations: 357.084096 M
[06/30 00:23:00][INFO] misc.py:  196: nvidia-smi
[06/30 00:23:01][INFO] train_net.py:  654: Load from given checkpoint file.
[06/30 00:23:01][INFO] checkpoint.py:  223: Loading network weights from checkpoints/mvitv2-b_no_rand_flip_best_epoch_00160.pyth.
[06/30 00:23:01][INFO] kinetics.py:   93: Constructing Kinetics train...
[06/30 00:23:01][INFO] kinetics.py:  169: Constructing kinetics dataloader (size: 1927 skip_rows 0) from train.csv 
[06/30 00:23:01][INFO] kinetics.py:   93: Constructing Kinetics val...
[06/30 00:23:01][INFO] kinetics.py:  169: Constructing kinetics dataloader (size: 482 skip_rows 0) from val.csv 
[06/30 00:23:01][INFO] train_net.py:  751: Start epoch: 1
[06/30 00:23:13][INFO] distributed.py: 1027: Reducer buckets have been rebuilt in this iteration.
