[06/12 15:02:47][INFO] test_net.py:  205: Test with config:
[06/12 15:02:47][INFO] test_net.py:  206: AUG:
  AA_TYPE: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  ENABLE: False
  GEN_MASK_LOADER: False
  INTERPOLATION: bicubic
  MASK_FRAMES: False
  MASK_RATIO: 0.0
  MASK_TUBE: False
  MASK_WINDOW_SIZE: [8, 7, 7]
  MAX_MASK_PATCHES_PER_BLOCK: None
  NUM_SAMPLE: 1
  RE_COUNT: 1
  RE_MODE: pixel
  RE_PROB: 0.25
  RE_SPLIT: False
AVA:
  ANNOTATION_DIR: /mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/
  BGR: False
  DETECTION_SCORE_THRESH: 0.9
  EXCLUSION_FILE: ava_val_excluded_timestamps_v2.2.csv
  FRAME_DIR: /mnt/fair-flash3-east/ava_trainval_frames.img/
  FRAME_LIST_DIR: /mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/
  FULL_TEST_ON_VAL: False
  GROUNDTRUTH_FILE: ava_val_v2.2.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: ava_action_list_v2.2_for_activitynet_2019.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['val.csv']
  TEST_PREDICT_BOX_LISTS: ['ava_val_predicted_boxes.csv']
  TRAIN_GT_BOX_LISTS: ['ava_train_v2.2.csv']
  TRAIN_LISTS: ['train.csv']
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: []
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  GLOBAL_SYNC: False
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: False
  WEIGHT_DECAY: 0.0
CONTRASTIVE:
  BN_MLP: False
  BN_SYNC_MLP: False
  DELTA_CLIPS_MAX: inf
  DELTA_CLIPS_MIN: -inf
  DIM: 128
  INTERP_MEMORY: False
  KNN_ON: True
  LENGTH: 239975
  LOCAL_SHUFFLE_BN: True
  MEM_TYPE: 1d
  MLP_DIM: 2048
  MOCO_MULTI_VIEW_QUEUE: False
  MOMENTUM: 0.5
  MOMENTUM_ANNEALING: False
  NUM_CLASSES_DOWNSTREAM: 400
  NUM_MLP_LAYERS: 1
  PREDICTOR_DEPTHS: []
  QUEUE_LEN: 65536
  SEQUENTIAL: False
  SIMCLR_DIST_ON: True
  SWAV_QEUE_LEN: 0
  T: 0.07
  TYPE: mem
DATA:
  COLOR_RND_GRAYSCALE: 0.0
  DECODING_BACKEND: torchvision
  DECODING_SHORT_SIZE: 256
  DUMMY_LOAD: False
  ENSEMBLE_METHOD: sum
  IN22K_TRAINVAL: False
  IN22k_VAL_IN1K: 
  INPUT_CHANNEL_NUM: [3]
  INV_UNIFORM_SAMPLE: False
  IN_VAL_CROP_RATIO: 0.875
  LOADER_CHUNK_OVERALL_SIZE: 0
  LOADER_CHUNK_SIZE: 0
  MEAN: [0.45, 0.45, 0.45]
  MULTI_LABEL: False
  NUM_FRAMES: 16
  PATH_LABEL_SEPARATOR:  
  PATH_PREFIX: 
  PATH_TO_DATA_DIR: 
  PATH_TO_PRELOAD_IMDB: 
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 4
  SKIP_ROWS: 0
  SSL_BLUR_SIGMA_MAX: [0.0, 2.0]
  SSL_BLUR_SIGMA_MIN: [0.0, 0.1]
  SSL_COLOR_BRI_CON_SAT: [0.4, 0.4, 0.4]
  SSL_COLOR_HUE: 0.1
  SSL_COLOR_JITTER: False
  SSL_MOCOV2_AUG: False
  STD: [0.225, 0.225, 0.225]
  TARGET_FPS: 30
  TEST_CROP_SIZE: 224
  TIME_DIFF_PROB: 0.0
  TRAIN_CROP_NUM_SPATIAL: 1
  TRAIN_CROP_NUM_TEMPORAL: 1
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_ASPECT_RELATIVE: [0.75, 1.3333]
  TRAIN_JITTER_FPS: 0.0
  TRAIN_JITTER_MOTION_SHIFT: False
  TRAIN_JITTER_SCALES: [256, 320]
  TRAIN_JITTER_SCALES_RELATIVE: [0.08, 1.0]
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  USE_OFFSET_SAMPLING: False
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 8
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.7
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: False
  FPS: 30
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: 
  LABEL_FILE_PATH: 
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 900
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: -1
DETECTION:
  ALIGNED: True
  ENABLE: False
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
LOG_MODEL_INFO: True
LOG_PERIOD: 500
MASK:
  DECODER_DEPTH: 0
  DECODER_EMBED_DIM: 512
  DECODER_SEP_POS_EMBED: False
  DEC_KV_KERNEL: []
  DEC_KV_STRIDE: []
  ENABLE: False
  HEAD_TYPE: separate
  MAE_ON: False
  MAE_RND_MASK: False
  NORM_PRED_PIXEL: True
  PER_FRAME_MASKING: False
  PRED_HOG: False
  PRETRAIN_DEPTH: [15]
  SCALE_INIT_BY_DEPTH: False
  TIME_STRIDE_LOSS: True
MIXUP:
  ALPHA: 0.8
  CUTMIX_ALPHA: 1.0
  ENABLE: False
  LABEL_SMOOTH_VALUE: 0.1
  PROB: 1.0
  SWITCH_PROB: 0.5
MODEL:
  ACT_CHECKPOINT: False
  ARCH: mvit
  DETACH_FINAL_FC: False
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  FC_INIT_STD: 0.01
  FP16_ALLREDUCE: False
  FROZEN_BN: False
  HEAD_ACT: softmax
  LOSS_FUNC: soft_cross_entropy
  MODEL_NAME: MViT
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 16
  SINGLE_PATHWAY_ARCH: ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'maskmvit']
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
MVIT:
  CLS_EMBED_ON: True
  DEPTH: 24
  DIM_MUL: [[2, 2.0], [5, 2.0], [21, 2.0]]
  DIM_MUL_IN_ATT: True
  DROPOUT_RATE: 0.0
  DROPPATH_RATE: 0.3
  EMBED_DIM: 96
  HEAD_INIT_SCALE: 1.0
  HEAD_MUL: [[2, 2.0], [5, 2.0], [21, 2.0]]
  LAYER_SCALE_INIT_VALUE: 0.0
  MLP_RATIO: 4.0
  MODE: conv
  NORM: layernorm
  NORM_STEM: False
  NUM_HEADS: 1
  PATCH_2D: False
  PATCH_KERNEL: [3, 7, 7]
  PATCH_PADDING: [1, 3, 3]
  PATCH_STRIDE: [2, 4, 4]
  POOL_FIRST: False
  POOL_KVQ_KERNEL: [3, 3, 3]
  POOL_KV_STRIDE: []
  POOL_KV_STRIDE_ADAPTIVE: [1, 8, 8]
  POOL_Q_STRIDE: [[0, 1, 1, 1], [1, 1, 1, 1], [2, 1, 2, 2], [3, 1, 1, 1], [4, 1, 1, 1], [5, 1, 2, 2], [6, 1, 1, 1], [7, 1, 1, 1], [8, 1, 1, 1], [9, 1, 1, 1], [10, 1, 1, 1], [11, 1, 1, 1], [12, 1, 1, 1], [13, 1, 1, 1], [14, 1, 1, 1], [15, 1, 1, 1], [16, 1, 1, 1], [17, 1, 1, 1], [18, 1, 1, 1], [19, 1, 1, 1], [20, 1, 1, 1], [21, 1, 2, 2], [22, 1, 1, 1], [23, 1, 1, 1]]
  QKV_BIAS: True
  REL_POS_SPATIAL: True
  REL_POS_TEMPORAL: True
  REL_POS_ZERO_INIT: False
  RESIDUAL_POOLING: True
  REV:
    BUFFER_LAYERS: []
    ENABLE: False
    PRE_Q_FUSION: avg
    RESPATH_FUSE: concat
    RES_PATH: conv
  SEPARATE_QKV: False
  SEP_POS_EMBED: False
  USE_ABS_POS: False
  USE_FIXED_SINCOS_POS: False
  USE_MEAN_POOLING: False
  ZERO_DECAY_POS_CLS: False
NONLOCAL:
  GROUP: [[1], [1], [1], [1]]
  INSTANTIATION: dot_product
  LOCATION: [[[]], [[]], [[]], [[]]]
  POOL: [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]
NUM_GPUS: 1
NUM_SHARDS: 1
OUTPUT_DIR: .
RESNET:
  DEPTH: 50
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3], [4], [6], [3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1], [1], [1], [1]]
  SPATIAL_STRIDES: [[1], [2], [2], [2]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: False
  ZERO_INIT_FINAL_CONV: False
RNG_SEED: 0
SHARD_ID: 0
SLOWFAST:
  ALPHA: 8
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 5
SOLVER:
  BASE_LR: 0.0002
  BASE_LR_SCALE_NUM_SHARDS: True
  BETAS: (0.9, 0.999)
  CLIP_GRAD_L2NORM: 1.0
  CLIP_GRAD_VAL: None
  COSINE_AFTER_WARMUP: True
  COSINE_END_LR: 2e-05
  DAMPENING: 0.0
  GAMMA: 0.1
  LARS_ON: False
  LAYER_DECAY: 1.0
  LRS: []
  LR_POLICY: cosine
  MAX_EPOCH: 300
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: adamw
  STEPS: []
  STEP_SIZE: 1
  WARMUP_EPOCHS: 30.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 2e-05
  WEIGHT_DECAY: 0.0001
  ZERO_WD_1D_PARAM: True
TASK: 
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: 
  CONFUSION_MATRIX:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: False
  HISTOGRAM:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: 
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: False
    TOPK_PREDS: 1
  PREDICTIONS_PATH: 
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  BATCH_SIZE: 1
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_TYPE: pytorch
  DATASET: kinetics
  ENABLE: True
  NUM_ENSEMBLE_VIEWS: 1
  NUM_SPATIAL_CROPS: 1
  NUM_TEMPORAL_CLIPS: [1]
  SAVE_RESULTS_PATH: 
TRAIN:
  AUTO_RESUME: True
  BATCH_SIZE: 16
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: False
  CHECKPOINT_FILE_PATH: checkpoints/MViTv2_B_32x3_k400_f304025456.pyth
  CHECKPOINT_INFLATE: False
  CHECKPOINT_IN_INIT: False
  CHECKPOINT_PERIOD: 20
  CHECKPOINT_TYPE: pytorch
  DATASET: kinetics
  ENABLE: False
  EVAL_PERIOD: 5
  KILL_LOSS_EXPLOSION_FACTOR: 0.0
  MIXED_PRECISION: False
VIS_MASK:
  ENABLE: False
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[06/12 15:02:49][INFO] misc.py:  185: Model:
MViT(
  (patch_embed): PatchEmbed(
    (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
  )
  (blocks): ModuleList(
    (0): MultiScaleBlock(
      (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=96, out_features=288, bias=True)
        (proj): Linear(in_features=96, out_features=96, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=96, out_features=384, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=384, out_features=96, bias=True)
      )
    )
    (1): MultiScaleBlock(
      (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=96, out_features=288, bias=True)
        (proj): Linear(in_features=96, out_features=96, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=96, out_features=384, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=384, out_features=96, bias=True)
      )
    )
    (2): MultiScaleBlock(
      (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=96, out_features=576, bias=True)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=768, out_features=192, bias=True)
      )
      (proj): Linear(in_features=96, out_features=192, bias=True)
      (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (3): MultiScaleBlock(
      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=192, out_features=576, bias=True)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=768, out_features=192, bias=True)
      )
    )
    (4): MultiScaleBlock(
      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=192, out_features=576, bias=True)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=768, out_features=192, bias=True)
      )
    )
    (5): MultiScaleBlock(
      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=192, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
      (proj): Linear(in_features=192, out_features=384, bias=True)
      (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (6): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (7): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (8): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (9): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (10): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (11): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (12): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (13): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (14): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (15): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (16): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (17): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (18): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (19): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (20): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (21): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=2304, bias=True)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
      )
      (proj): Linear(in_features=384, out_features=768, bias=True)
      (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (22): MultiScaleBlock(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
      )
    )
    (23): MultiScaleBlock(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  (head): TransformerBasicHead(
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=768, out_features=16, bias=True)
    (act): Softmax(dim=1)
  )
)
[06/12 15:02:49][INFO] misc.py:  187: Params: 50,897,968
[06/12 15:02:49][INFO] misc.py:  188: Mem: 0.19084548950195312 MB
[06/12 15:02:52][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 729 time(s)
[06/12 15:02:52][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 102 time(s)
[06/12 15:02:52][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 144 time(s)
[06/12 15:02:52][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 96 time(s)
[06/12 15:02:52][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 120 time(s)
[06/12 15:02:52][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 25 time(s)
[06/12 15:02:52][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 24 time(s)
[06/12 15:02:52][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[06/12 15:02:52][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
blocks.1.drop_path, blocks.10.drop_path, blocks.11.drop_path, blocks.12.drop_path, blocks.13.drop_path, blocks.14.drop_path, blocks.15.drop_path, blocks.16.drop_path, blocks.17.drop_path, blocks.18.drop_path, blocks.19.drop_path, blocks.2.drop_path, blocks.20.drop_path, blocks.21.drop_path, blocks.22.drop_path, blocks.23.drop_path, blocks.3.drop_path, blocks.4.drop_path, blocks.5.drop_path, blocks.6.drop_path, blocks.7.drop_path, blocks.8.drop_path, blocks.9.drop_path
[06/12 15:02:52][INFO] misc.py:  190: Flops: 92.63208983999999 G
[06/12 15:02:54][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 121 time(s)
[06/12 15:02:54][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 729 time(s)
[06/12 15:02:54][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 102 time(s)
[06/12 15:02:54][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 144 time(s)
[06/12 15:02:54][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 96 time(s)
[06/12 15:02:54][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 120 time(s)
[06/12 15:02:54][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 25 time(s)
[06/12 15:02:54][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 24 time(s)
[06/12 15:02:54][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[06/12 15:02:54][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
blocks.1.drop_path, blocks.10.drop_path, blocks.11.drop_path, blocks.12.drop_path, blocks.13.drop_path, blocks.14.drop_path, blocks.15.drop_path, blocks.16.drop_path, blocks.17.drop_path, blocks.18.drop_path, blocks.19.drop_path, blocks.2.drop_path, blocks.20.drop_path, blocks.21.drop_path, blocks.22.drop_path, blocks.23.drop_path, blocks.3.drop_path, blocks.4.drop_path, blocks.5.drop_path, blocks.6.drop_path, blocks.7.drop_path, blocks.8.drop_path, blocks.9.drop_path
[06/12 15:02:54][INFO] misc.py:  191: Activations: 357.084096 M
[06/12 15:02:54][INFO] misc.py:  196: nvidia-smi
[06/12 15:02:54][INFO] misc.py:  185: Model:
MViT(
  (patch_embed): PatchEmbed(
    (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
  )
  (blocks): ModuleList(
    (0): MultiScaleBlock(
      (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=96, out_features=288, bias=True)
        (proj): Linear(in_features=96, out_features=96, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=96, out_features=384, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=384, out_features=96, bias=True)
      )
    )
    (1): MultiScaleBlock(
      (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=96, out_features=288, bias=True)
        (proj): Linear(in_features=96, out_features=96, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=96, out_features=384, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=384, out_features=96, bias=True)
      )
    )
    (2): MultiScaleBlock(
      (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=96, out_features=576, bias=True)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=768, out_features=192, bias=True)
      )
      (proj): Linear(in_features=96, out_features=192, bias=True)
      (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (3): MultiScaleBlock(
      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=192, out_features=576, bias=True)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=768, out_features=192, bias=True)
      )
    )
    (4): MultiScaleBlock(
      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=192, out_features=576, bias=True)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=768, out_features=192, bias=True)
      )
    )
    (5): MultiScaleBlock(
      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=192, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
      (proj): Linear(in_features=192, out_features=384, bias=True)
      (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (6): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (7): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (8): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (9): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (10): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (11): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (12): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (13): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (14): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (15): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (16): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (17): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (18): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (19): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (20): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (21): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=2304, bias=True)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
      )
      (proj): Linear(in_features=384, out_features=768, bias=True)
      (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (22): MultiScaleBlock(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
      )
    )
    (23): MultiScaleBlock(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  (head): TransformerBasicHead(
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=768, out_features=16, bias=True)
    (act): Softmax(dim=1)
  )
)
[06/12 15:02:54][INFO] misc.py:  187: Params: 50,897,968
[06/12 15:02:54][INFO] misc.py:  188: Mem: 2.495626449584961 MB
[06/12 15:02:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 729 time(s)
[06/12 15:02:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 102 time(s)
[06/12 15:02:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 144 time(s)
[06/12 15:02:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 96 time(s)
[06/12 15:02:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 120 time(s)
[06/12 15:02:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 25 time(s)
[06/12 15:02:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 24 time(s)
[06/12 15:02:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[06/12 15:02:56][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
blocks.1.drop_path, blocks.10.drop_path, blocks.11.drop_path, blocks.12.drop_path, blocks.13.drop_path, blocks.14.drop_path, blocks.15.drop_path, blocks.16.drop_path, blocks.17.drop_path, blocks.18.drop_path, blocks.19.drop_path, blocks.2.drop_path, blocks.20.drop_path, blocks.21.drop_path, blocks.22.drop_path, blocks.23.drop_path, blocks.3.drop_path, blocks.4.drop_path, blocks.5.drop_path, blocks.6.drop_path, blocks.7.drop_path, blocks.8.drop_path, blocks.9.drop_path
[06/12 15:02:56][INFO] misc.py:  190: Flops: 92.63208983999999 G
[06/12 15:02:59][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 121 time(s)
[06/12 15:02:59][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 729 time(s)
[06/12 15:02:59][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 102 time(s)
[06/12 15:02:59][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 144 time(s)
[06/12 15:02:59][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 96 time(s)
[06/12 15:02:59][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 120 time(s)
[06/12 15:02:59][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 25 time(s)
[06/12 15:02:59][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 24 time(s)
[06/12 15:02:59][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[06/12 15:02:59][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
blocks.1.drop_path, blocks.10.drop_path, blocks.11.drop_path, blocks.12.drop_path, blocks.13.drop_path, blocks.14.drop_path, blocks.15.drop_path, blocks.16.drop_path, blocks.17.drop_path, blocks.18.drop_path, blocks.19.drop_path, blocks.2.drop_path, blocks.20.drop_path, blocks.21.drop_path, blocks.22.drop_path, blocks.23.drop_path, blocks.3.drop_path, blocks.4.drop_path, blocks.5.drop_path, blocks.6.drop_path, blocks.7.drop_path, blocks.8.drop_path, blocks.9.drop_path
[06/12 15:02:59][INFO] misc.py:  191: Activations: 357.084096 M
[06/12 15:02:59][INFO] misc.py:  196: nvidia-smi
[06/12 15:02:59][INFO] checkpoint.py:  223: Loading network weights from checkpoints/MViTv2_B_32x3_k400_f304025456.pyth.
[06/12 15:02:59][INFO] checkpoint.py:  487: blocks.0.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/12 15:02:59][INFO] checkpoint.py:  487: blocks.1.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/12 15:02:59][INFO] checkpoint.py:  487: blocks.2.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/12 15:02:59][INFO] checkpoint.py:  487: blocks.3.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/12 15:02:59][INFO] checkpoint.py:  487: blocks.4.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/12 15:02:59][INFO] checkpoint.py:  487: blocks.5.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/12 15:02:59][INFO] checkpoint.py:  487: blocks.6.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/12 15:02:59][INFO] checkpoint.py:  487: blocks.7.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/12 15:02:59][INFO] checkpoint.py:  487: blocks.8.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/12 15:02:59][INFO] checkpoint.py:  487: blocks.9.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/12 15:02:59][INFO] checkpoint.py:  487: blocks.10.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/12 15:02:59][INFO] checkpoint.py:  487: blocks.11.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/12 15:02:59][INFO] checkpoint.py:  487: blocks.12.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/12 15:02:59][INFO] checkpoint.py:  487: blocks.13.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/12 15:02:59][INFO] checkpoint.py:  487: blocks.14.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/12 15:02:59][INFO] checkpoint.py:  487: blocks.15.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/12 15:02:59][INFO] checkpoint.py:  487: blocks.16.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/12 15:02:59][INFO] checkpoint.py:  487: blocks.17.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/12 15:02:59][INFO] checkpoint.py:  487: blocks.18.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/12 15:02:59][INFO] checkpoint.py:  487: blocks.19.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/12 15:02:59][INFO] checkpoint.py:  487: blocks.20.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/12 15:02:59][INFO] checkpoint.py:  487: blocks.21.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/12 15:02:59][INFO] checkpoint.py:  487: blocks.22.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/12 15:02:59][INFO] checkpoint.py:  487: blocks.23.attn.rel_pos_t reshaped from torch.Size([31, 96]) to torch.Size([15, 96])
[06/12 15:02:59][INFO] checkpoint.py:  542: Network weights head.projection.weight not loaded.
[06/12 15:02:59][INFO] checkpoint.py:  542: Network weights head.projection.bias not loaded.
[06/12 15:02:59][INFO] checkpoint.py:  545: Network weights head.projection.weight not used.
[06/12 15:02:59][INFO] checkpoint.py:  545: Network weights head.projection.bias not used.
[06/12 15:02:59][INFO] kinetics.py:   93: Constructing Kinetics test...
[06/12 15:02:59][INFO] kinetics.py:  169: Constructing kinetics dataloader (size: 14214 skip_rows 0) from test.csv 
[06/12 15:02:59][INFO] test_net.py:  234: Testing model for 14214 iterations
[06/12 15:03:26][INFO] logging.py:  101: json_stats: {"cur_iter": "500", "eta": "0:10:34", "split": "test_iter", "time_diff": 0.04626}
[06/12 15:03:51][INFO] logging.py:  101: json_stats: {"cur_iter": "1000", "eta": "0:10:21", "split": "test_iter", "time_diff": 0.04700}
[06/12 15:04:17][INFO] logging.py:  101: json_stats: {"cur_iter": "1500", "eta": "0:10:05", "split": "test_iter", "time_diff": 0.04765}
[06/12 15:06:04][INFO] test_net.py:  205: Test with config:
[06/12 15:06:04][INFO] test_net.py:  206: AUG:
  AA_TYPE: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  ENABLE: False
  GEN_MASK_LOADER: False
  INTERPOLATION: bicubic
  MASK_FRAMES: False
  MASK_RATIO: 0.0
  MASK_TUBE: False
  MASK_WINDOW_SIZE: [8, 7, 7]
  MAX_MASK_PATCHES_PER_BLOCK: None
  NUM_SAMPLE: 1
  RE_COUNT: 1
  RE_MODE: pixel
  RE_PROB: 0.25
  RE_SPLIT: False
AVA:
  ANNOTATION_DIR: /mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/
  BGR: False
  DETECTION_SCORE_THRESH: 0.9
  EXCLUSION_FILE: ava_val_excluded_timestamps_v2.2.csv
  FRAME_DIR: /mnt/fair-flash3-east/ava_trainval_frames.img/
  FRAME_LIST_DIR: /mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/
  FULL_TEST_ON_VAL: False
  GROUNDTRUTH_FILE: ava_val_v2.2.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: ava_action_list_v2.2_for_activitynet_2019.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['val.csv']
  TEST_PREDICT_BOX_LISTS: ['ava_val_predicted_boxes.csv']
  TRAIN_GT_BOX_LISTS: ['ava_train_v2.2.csv']
  TRAIN_LISTS: ['train.csv']
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: []
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  GLOBAL_SYNC: False
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: False
  WEIGHT_DECAY: 0.0
CONTRASTIVE:
  BN_MLP: False
  BN_SYNC_MLP: False
  DELTA_CLIPS_MAX: inf
  DELTA_CLIPS_MIN: -inf
  DIM: 128
  INTERP_MEMORY: False
  KNN_ON: True
  LENGTH: 239975
  LOCAL_SHUFFLE_BN: True
  MEM_TYPE: 1d
  MLP_DIM: 2048
  MOCO_MULTI_VIEW_QUEUE: False
  MOMENTUM: 0.5
  MOMENTUM_ANNEALING: False
  NUM_CLASSES_DOWNSTREAM: 400
  NUM_MLP_LAYERS: 1
  PREDICTOR_DEPTHS: []
  QUEUE_LEN: 65536
  SEQUENTIAL: False
  SIMCLR_DIST_ON: True
  SWAV_QEUE_LEN: 0
  T: 0.07
  TYPE: mem
DATA:
  COLOR_RND_GRAYSCALE: 0.0
  DECODING_BACKEND: torchvision
  DECODING_SHORT_SIZE: 256
  DUMMY_LOAD: False
  ENSEMBLE_METHOD: sum
  IN22K_TRAINVAL: False
  IN22k_VAL_IN1K: 
  INPUT_CHANNEL_NUM: [3]
  INV_UNIFORM_SAMPLE: False
  IN_VAL_CROP_RATIO: 0.875
  LOADER_CHUNK_OVERALL_SIZE: 0
  LOADER_CHUNK_SIZE: 0
  MEAN: [0.45, 0.45, 0.45]
  MULTI_LABEL: False
  NUM_FRAMES: 16
  PATH_LABEL_SEPARATOR:  
  PATH_PREFIX: 
  PATH_TO_DATA_DIR: 
  PATH_TO_PRELOAD_IMDB: 
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 4
  SKIP_ROWS: 0
  SSL_BLUR_SIGMA_MAX: [0.0, 2.0]
  SSL_BLUR_SIGMA_MIN: [0.0, 0.1]
  SSL_COLOR_BRI_CON_SAT: [0.4, 0.4, 0.4]
  SSL_COLOR_HUE: 0.1
  SSL_COLOR_JITTER: False
  SSL_MOCOV2_AUG: False
  STD: [0.225, 0.225, 0.225]
  TARGET_FPS: 30
  TEST_CROP_SIZE: 224
  TIME_DIFF_PROB: 0.0
  TRAIN_CROP_NUM_SPATIAL: 1
  TRAIN_CROP_NUM_TEMPORAL: 1
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_ASPECT_RELATIVE: [0.75, 1.3333]
  TRAIN_JITTER_FPS: 0.0
  TRAIN_JITTER_MOTION_SHIFT: False
  TRAIN_JITTER_SCALES: [256, 320]
  TRAIN_JITTER_SCALES_RELATIVE: [0.08, 1.0]
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  USE_OFFSET_SAMPLING: False
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 8
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.7
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: False
  FPS: 30
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: 
  LABEL_FILE_PATH: 
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 900
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: -1
DETECTION:
  ALIGNED: True
  ENABLE: False
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
LOG_MODEL_INFO: True
LOG_PERIOD: 500
MASK:
  DECODER_DEPTH: 0
  DECODER_EMBED_DIM: 512
  DECODER_SEP_POS_EMBED: False
  DEC_KV_KERNEL: []
  DEC_KV_STRIDE: []
  ENABLE: False
  HEAD_TYPE: separate
  MAE_ON: False
  MAE_RND_MASK: False
  NORM_PRED_PIXEL: True
  PER_FRAME_MASKING: False
  PRED_HOG: False
  PRETRAIN_DEPTH: [15]
  SCALE_INIT_BY_DEPTH: False
  TIME_STRIDE_LOSS: True
MIXUP:
  ALPHA: 0.8
  CUTMIX_ALPHA: 1.0
  ENABLE: False
  LABEL_SMOOTH_VALUE: 0.1
  PROB: 1.0
  SWITCH_PROB: 0.5
MODEL:
  ACT_CHECKPOINT: False
  ARCH: mvit
  DETACH_FINAL_FC: False
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  FC_INIT_STD: 0.01
  FP16_ALLREDUCE: False
  FROZEN_BN: False
  HEAD_ACT: softmax
  LOSS_FUNC: soft_cross_entropy
  MODEL_NAME: MViT
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 16
  SINGLE_PATHWAY_ARCH: ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'maskmvit']
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
MVIT:
  CLS_EMBED_ON: True
  DEPTH: 24
  DIM_MUL: [[2, 2.0], [5, 2.0], [21, 2.0]]
  DIM_MUL_IN_ATT: True
  DROPOUT_RATE: 0.0
  DROPPATH_RATE: 0.3
  EMBED_DIM: 96
  HEAD_INIT_SCALE: 1.0
  HEAD_MUL: [[2, 2.0], [5, 2.0], [21, 2.0]]
  LAYER_SCALE_INIT_VALUE: 0.0
  MLP_RATIO: 4.0
  MODE: conv
  NORM: layernorm
  NORM_STEM: False
  NUM_HEADS: 1
  PATCH_2D: False
  PATCH_KERNEL: [3, 7, 7]
  PATCH_PADDING: [1, 3, 3]
  PATCH_STRIDE: [2, 4, 4]
  POOL_FIRST: False
  POOL_KVQ_KERNEL: [3, 3, 3]
  POOL_KV_STRIDE: []
  POOL_KV_STRIDE_ADAPTIVE: [1, 8, 8]
  POOL_Q_STRIDE: [[0, 1, 1, 1], [1, 1, 1, 1], [2, 1, 2, 2], [3, 1, 1, 1], [4, 1, 1, 1], [5, 1, 2, 2], [6, 1, 1, 1], [7, 1, 1, 1], [8, 1, 1, 1], [9, 1, 1, 1], [10, 1, 1, 1], [11, 1, 1, 1], [12, 1, 1, 1], [13, 1, 1, 1], [14, 1, 1, 1], [15, 1, 1, 1], [16, 1, 1, 1], [17, 1, 1, 1], [18, 1, 1, 1], [19, 1, 1, 1], [20, 1, 1, 1], [21, 1, 2, 2], [22, 1, 1, 1], [23, 1, 1, 1]]
  QKV_BIAS: True
  REL_POS_SPATIAL: True
  REL_POS_TEMPORAL: True
  REL_POS_ZERO_INIT: False
  RESIDUAL_POOLING: True
  REV:
    BUFFER_LAYERS: []
    ENABLE: False
    PRE_Q_FUSION: avg
    RESPATH_FUSE: concat
    RES_PATH: conv
  SEPARATE_QKV: False
  SEP_POS_EMBED: False
  USE_ABS_POS: False
  USE_FIXED_SINCOS_POS: False
  USE_MEAN_POOLING: False
  ZERO_DECAY_POS_CLS: False
NONLOCAL:
  GROUP: [[1], [1], [1], [1]]
  INSTANTIATION: dot_product
  LOCATION: [[[]], [[]], [[]], [[]]]
  POOL: [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]
NUM_GPUS: 1
NUM_SHARDS: 1
OUTPUT_DIR: .
RESNET:
  DEPTH: 50
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3], [4], [6], [3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1], [1], [1], [1]]
  SPATIAL_STRIDES: [[1], [2], [2], [2]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: False
  ZERO_INIT_FINAL_CONV: False
RNG_SEED: 0
SHARD_ID: 0
SLOWFAST:
  ALPHA: 8
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 5
SOLVER:
  BASE_LR: 0.0002
  BASE_LR_SCALE_NUM_SHARDS: True
  BETAS: (0.9, 0.999)
  CLIP_GRAD_L2NORM: 1.0
  CLIP_GRAD_VAL: None
  COSINE_AFTER_WARMUP: True
  COSINE_END_LR: 2e-05
  DAMPENING: 0.0
  GAMMA: 0.1
  LARS_ON: False
  LAYER_DECAY: 1.0
  LRS: []
  LR_POLICY: cosine
  MAX_EPOCH: 300
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: adamw
  STEPS: []
  STEP_SIZE: 1
  WARMUP_EPOCHS: 30.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 2e-05
  WEIGHT_DECAY: 0.0001
  ZERO_WD_1D_PARAM: True
TASK: 
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: 
  CONFUSION_MATRIX:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: False
  HISTOGRAM:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: 
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: False
    TOPK_PREDS: 1
  PREDICTIONS_PATH: 
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  BATCH_SIZE: 1
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_TYPE: pytorch
  DATASET: kinetics
  ENABLE: True
  NUM_ENSEMBLE_VIEWS: 1
  NUM_SPATIAL_CROPS: 1
  NUM_TEMPORAL_CLIPS: [1]
  SAVE_RESULTS_PATH: 
TRAIN:
  AUTO_RESUME: True
  BATCH_SIZE: 16
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: False
  CHECKPOINT_FILE_PATH: checkpoints/MViTv2_B_32x3_k400_f304025456.pyth
  CHECKPOINT_INFLATE: False
  CHECKPOINT_IN_INIT: False
  CHECKPOINT_PERIOD: 20
  CHECKPOINT_TYPE: pytorch
  DATASET: kinetics
  ENABLE: False
  EVAL_PERIOD: 5
  KILL_LOSS_EXPLOSION_FACTOR: 0.0
  MIXED_PRECISION: False
VIS_MASK:
  ENABLE: False
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[06/12 15:06:05][INFO] misc.py:  185: Model:
MViT(
  (patch_embed): PatchEmbed(
    (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
  )
  (blocks): ModuleList(
    (0): MultiScaleBlock(
      (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=96, out_features=288, bias=True)
        (proj): Linear(in_features=96, out_features=96, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=96, out_features=384, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=384, out_features=96, bias=True)
      )
    )
    (1): MultiScaleBlock(
      (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=96, out_features=288, bias=True)
        (proj): Linear(in_features=96, out_features=96, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=96, out_features=384, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=384, out_features=96, bias=True)
      )
    )
    (2): MultiScaleBlock(
      (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=96, out_features=576, bias=True)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=768, out_features=192, bias=True)
      )
      (proj): Linear(in_features=96, out_features=192, bias=True)
      (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (3): MultiScaleBlock(
      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=192, out_features=576, bias=True)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=768, out_features=192, bias=True)
      )
    )
    (4): MultiScaleBlock(
      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=192, out_features=576, bias=True)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=768, out_features=192, bias=True)
      )
    )
    (5): MultiScaleBlock(
      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=192, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
      (proj): Linear(in_features=192, out_features=384, bias=True)
      (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (6): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (7): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (8): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (9): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (10): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (11): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (12): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (13): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (14): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (15): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (16): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (17): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (18): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (19): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (20): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (21): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=2304, bias=True)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
      )
      (proj): Linear(in_features=384, out_features=768, bias=True)
      (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (22): MultiScaleBlock(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
      )
    )
    (23): MultiScaleBlock(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  (head): TransformerBasicHead(
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=768, out_features=16, bias=True)
    (act): Softmax(dim=1)
  )
)
[06/12 15:06:05][INFO] misc.py:  187: Params: 50,897,968
[06/12 15:06:05][INFO] misc.py:  188: Mem: 0.19084548950195312 MB
[06/12 15:06:09][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 729 time(s)
[06/12 15:06:09][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 102 time(s)
[06/12 15:06:09][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 144 time(s)
[06/12 15:06:09][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 96 time(s)
[06/12 15:06:09][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 120 time(s)
[06/12 15:06:09][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 25 time(s)
[06/12 15:06:09][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 24 time(s)
[06/12 15:06:09][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[06/12 15:06:09][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
blocks.1.drop_path, blocks.10.drop_path, blocks.11.drop_path, blocks.12.drop_path, blocks.13.drop_path, blocks.14.drop_path, blocks.15.drop_path, blocks.16.drop_path, blocks.17.drop_path, blocks.18.drop_path, blocks.19.drop_path, blocks.2.drop_path, blocks.20.drop_path, blocks.21.drop_path, blocks.22.drop_path, blocks.23.drop_path, blocks.3.drop_path, blocks.4.drop_path, blocks.5.drop_path, blocks.6.drop_path, blocks.7.drop_path, blocks.8.drop_path, blocks.9.drop_path
[06/12 15:06:09][INFO] misc.py:  190: Flops: 92.63208983999999 G
[06/12 15:06:11][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 121 time(s)
[06/12 15:06:11][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 729 time(s)
[06/12 15:06:11][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 102 time(s)
[06/12 15:06:11][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 144 time(s)
[06/12 15:06:11][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 96 time(s)
[06/12 15:06:11][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 120 time(s)
[06/12 15:06:11][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 25 time(s)
[06/12 15:06:11][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 24 time(s)
[06/12 15:06:11][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[06/12 15:06:11][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
blocks.1.drop_path, blocks.10.drop_path, blocks.11.drop_path, blocks.12.drop_path, blocks.13.drop_path, blocks.14.drop_path, blocks.15.drop_path, blocks.16.drop_path, blocks.17.drop_path, blocks.18.drop_path, blocks.19.drop_path, blocks.2.drop_path, blocks.20.drop_path, blocks.21.drop_path, blocks.22.drop_path, blocks.23.drop_path, blocks.3.drop_path, blocks.4.drop_path, blocks.5.drop_path, blocks.6.drop_path, blocks.7.drop_path, blocks.8.drop_path, blocks.9.drop_path
[06/12 15:06:11][INFO] misc.py:  191: Activations: 357.084096 M
[06/12 15:06:11][INFO] misc.py:  196: nvidia-smi
[06/12 15:06:11][INFO] misc.py:  185: Model:
MViT(
  (patch_embed): PatchEmbed(
    (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
  )
  (blocks): ModuleList(
    (0): MultiScaleBlock(
      (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=96, out_features=288, bias=True)
        (proj): Linear(in_features=96, out_features=96, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=96, out_features=384, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=384, out_features=96, bias=True)
      )
    )
    (1): MultiScaleBlock(
      (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=96, out_features=288, bias=True)
        (proj): Linear(in_features=96, out_features=96, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=96, out_features=384, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=384, out_features=96, bias=True)
      )
    )
    (2): MultiScaleBlock(
      (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=96, out_features=576, bias=True)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=768, out_features=192, bias=True)
      )
      (proj): Linear(in_features=96, out_features=192, bias=True)
      (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (3): MultiScaleBlock(
      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=192, out_features=576, bias=True)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=768, out_features=192, bias=True)
      )
    )
    (4): MultiScaleBlock(
      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=192, out_features=576, bias=True)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=768, out_features=192, bias=True)
      )
    )
    (5): MultiScaleBlock(
      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=192, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
      (proj): Linear(in_features=192, out_features=384, bias=True)
      (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (6): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (7): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (8): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (9): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (10): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (11): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (12): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (13): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (14): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (15): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (16): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (17): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (18): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (19): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (20): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (21): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=2304, bias=True)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
      )
      (proj): Linear(in_features=384, out_features=768, bias=True)
      (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (22): MultiScaleBlock(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
      )
    )
    (23): MultiScaleBlock(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  (head): TransformerBasicHead(
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=768, out_features=16, bias=True)
    (act): Softmax(dim=1)
  )
)
[06/12 15:06:11][INFO] misc.py:  187: Params: 50,897,968
[06/12 15:06:11][INFO] misc.py:  188: Mem: 2.495626449584961 MB
[06/12 15:06:13][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 729 time(s)
[06/12 15:06:13][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 102 time(s)
[06/12 15:06:13][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 144 time(s)
[06/12 15:06:13][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 96 time(s)
[06/12 15:06:13][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 120 time(s)
[06/12 15:06:13][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 25 time(s)
[06/12 15:06:13][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 24 time(s)
[06/12 15:06:13][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[06/12 15:06:13][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
blocks.1.drop_path, blocks.10.drop_path, blocks.11.drop_path, blocks.12.drop_path, blocks.13.drop_path, blocks.14.drop_path, blocks.15.drop_path, blocks.16.drop_path, blocks.17.drop_path, blocks.18.drop_path, blocks.19.drop_path, blocks.2.drop_path, blocks.20.drop_path, blocks.21.drop_path, blocks.22.drop_path, blocks.23.drop_path, blocks.3.drop_path, blocks.4.drop_path, blocks.5.drop_path, blocks.6.drop_path, blocks.7.drop_path, blocks.8.drop_path, blocks.9.drop_path
[06/12 15:06:13][INFO] misc.py:  190: Flops: 92.63208983999999 G
[06/12 15:06:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 121 time(s)
[06/12 15:06:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 729 time(s)
[06/12 15:06:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 102 time(s)
[06/12 15:06:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 144 time(s)
[06/12 15:06:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 96 time(s)
[06/12 15:06:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 120 time(s)
[06/12 15:06:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 25 time(s)
[06/12 15:06:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 24 time(s)
[06/12 15:06:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[06/12 15:06:15][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
blocks.1.drop_path, blocks.10.drop_path, blocks.11.drop_path, blocks.12.drop_path, blocks.13.drop_path, blocks.14.drop_path, blocks.15.drop_path, blocks.16.drop_path, blocks.17.drop_path, blocks.18.drop_path, blocks.19.drop_path, blocks.2.drop_path, blocks.20.drop_path, blocks.21.drop_path, blocks.22.drop_path, blocks.23.drop_path, blocks.3.drop_path, blocks.4.drop_path, blocks.5.drop_path, blocks.6.drop_path, blocks.7.drop_path, blocks.8.drop_path, blocks.9.drop_path
[06/12 15:06:15][INFO] misc.py:  191: Activations: 357.084096 M
[06/12 15:06:15][INFO] misc.py:  196: nvidia-smi
[06/12 15:06:16][INFO] checkpoint.py:  223: Loading network weights from ./checkpoints/checkpoint_epoch_00240.pyth.
[06/12 15:06:16][INFO] kinetics.py:   93: Constructing Kinetics test...
[06/12 15:06:16][INFO] kinetics.py:  169: Constructing kinetics dataloader (size: 14214 skip_rows 0) from test.csv 
[06/12 15:06:16][INFO] test_net.py:  234: Testing model for 14214 iterations
[06/12 15:06:43][INFO] logging.py:  101: json_stats: {"cur_iter": "500", "eta": "0:10:39", "split": "test_iter", "time_diff": 0.04662}
[06/12 15:07:08][INFO] logging.py:  101: json_stats: {"cur_iter": "1000", "eta": "0:10:50", "split": "test_iter", "time_diff": 0.04925}
[06/12 15:07:34][INFO] logging.py:  101: json_stats: {"cur_iter": "1500", "eta": "0:10:16", "split": "test_iter", "time_diff": 0.04849}
[06/12 15:08:00][INFO] logging.py:  101: json_stats: {"cur_iter": "2000", "eta": "0:10:29", "split": "test_iter", "time_diff": 0.05150}
[06/12 15:08:26][INFO] logging.py:  101: json_stats: {"cur_iter": "2500", "eta": "0:10:37", "split": "test_iter", "time_diff": 0.05439}
[06/12 15:08:52][INFO] logging.py:  101: json_stats: {"cur_iter": "3000", "eta": "0:08:53", "split": "test_iter", "time_diff": 0.04754}
[06/12 15:09:17][INFO] logging.py:  101: json_stats: {"cur_iter": "3500", "eta": "0:08:49", "split": "test_iter", "time_diff": 0.04946}
[06/12 15:09:43][INFO] logging.py:  101: json_stats: {"cur_iter": "4000", "eta": "0:08:16", "split": "test_iter", "time_diff": 0.04858}
[06/12 15:10:08][INFO] logging.py:  101: json_stats: {"cur_iter": "4500", "eta": "0:07:55", "split": "test_iter", "time_diff": 0.04894}
[06/12 15:10:34][INFO] logging.py:  101: json_stats: {"cur_iter": "5000", "eta": "0:07:14", "split": "test_iter", "time_diff": 0.04719}
[06/12 15:11:00][INFO] logging.py:  101: json_stats: {"cur_iter": "5500", "eta": "0:10:36", "split": "test_iter", "time_diff": 0.07300}
[06/12 15:11:26][INFO] logging.py:  101: json_stats: {"cur_iter": "6000", "eta": "0:06:43", "split": "test_iter", "time_diff": 0.04914}
[06/12 15:11:52][INFO] logging.py:  101: json_stats: {"cur_iter": "6500", "eta": "0:06:45", "split": "test_iter", "time_diff": 0.05250}
[06/12 15:12:18][INFO] logging.py:  101: json_stats: {"cur_iter": "7000", "eta": "0:10:34", "split": "test_iter", "time_diff": 0.08798}
[06/12 15:12:44][INFO] logging.py:  101: json_stats: {"cur_iter": "7500", "eta": "0:05:20", "split": "test_iter", "time_diff": 0.04771}
[06/12 15:13:10][INFO] logging.py:  101: json_stats: {"cur_iter": "8000", "eta": "0:05:04", "split": "test_iter", "time_diff": 0.04903}
[06/12 15:13:36][INFO] logging.py:  101: json_stats: {"cur_iter": "8500", "eta": "0:04:55", "split": "test_iter", "time_diff": 0.05175}
[06/12 15:14:01][INFO] logging.py:  101: json_stats: {"cur_iter": "9000", "eta": "0:04:16", "split": "test_iter", "time_diff": 0.04922}
[06/12 15:14:27][INFO] logging.py:  101: json_stats: {"cur_iter": "9500", "eta": "0:03:55", "split": "test_iter", "time_diff": 0.05001}
[06/12 15:14:53][INFO] logging.py:  101: json_stats: {"cur_iter": "10000", "eta": "0:03:22", "split": "test_iter", "time_diff": 0.04815}
[06/12 15:15:19][INFO] logging.py:  101: json_stats: {"cur_iter": "10500", "eta": "0:02:57", "split": "test_iter", "time_diff": 0.04765}
[06/12 15:15:45][INFO] logging.py:  101: json_stats: {"cur_iter": "11000", "eta": "0:02:40", "split": "test_iter", "time_diff": 0.04986}
[06/12 15:16:11][INFO] logging.py:  101: json_stats: {"cur_iter": "11500", "eta": "0:02:10", "split": "test_iter", "time_diff": 0.04810}
[06/12 15:16:37][INFO] logging.py:  101: json_stats: {"cur_iter": "12000", "eta": "0:01:45", "split": "test_iter", "time_diff": 0.04762}
[06/12 15:17:03][INFO] logging.py:  101: json_stats: {"cur_iter": "12500", "eta": "0:01:24", "split": "test_iter", "time_diff": 0.04926}
[06/12 15:17:29][INFO] logging.py:  101: json_stats: {"cur_iter": "13000", "eta": "0:01:00", "split": "test_iter", "time_diff": 0.04947}
[06/12 15:17:55][INFO] logging.py:  101: json_stats: {"cur_iter": "13500", "eta": "0:00:43", "split": "test_iter", "time_diff": 0.06046}
[06/12 15:18:21][INFO] logging.py:  101: json_stats: {"cur_iter": "14000", "eta": "0:00:10", "split": "test_iter", "time_diff": 0.04772}
[06/12 15:18:32][INFO] logging.py:  101: json_stats: {"split": "test_final", "top1_acc": "17.67", "top5_acc": "51.43"}
[06/12 15:18:32][INFO] test_net.py:  276: Finalized testing with 1 temporal clips and 1 spatial crops
[06/12 15:18:32][INFO] test_net.py:  298: _p50.90_f92.63_1a17.67 Top5 Acc: 51.43 MEM: 2.50 f: 92.6321
[06/12 15:18:32][INFO] test_net.py:  299: _p50.90_f92.63_1a17.67
[06/12 17:36:12][INFO] train_net.py:  552: Train with config:
[06/12 17:36:12][INFO] train_net.py:  553: {'AUG': {'AA_TYPE': 'rand-m9-mstd0.5-inc1',
         'COLOR_JITTER': 0.4,
         'ENABLE': False,
         'GEN_MASK_LOADER': False,
         'INTERPOLATION': 'bicubic',
         'MASK_FRAMES': False,
         'MASK_RATIO': 0.0,
         'MASK_TUBE': False,
         'MASK_WINDOW_SIZE': [8, 7, 7],
         'MAX_MASK_PATCHES_PER_BLOCK': None,
         'NUM_SAMPLE': 1,
         'RE_COUNT': 1,
         'RE_MODE': 'pixel',
         'RE_PROB': 0.25,
         'RE_SPLIT': False},
 'AVA': {'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.9,
         'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv',
         'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/',
         'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'],
         'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'],
         'TRAIN_LISTS': ['train.csv'],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': [],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'GLOBAL_SYNC': False,
        'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': True,
        'WEIGHT_DECAY': 0.0},
 'CONTRASTIVE': {'BN_MLP': False,
                 'BN_SYNC_MLP': False,
                 'DELTA_CLIPS_MAX': inf,
                 'DELTA_CLIPS_MIN': -inf,
                 'DIM': 128,
                 'INTERP_MEMORY': False,
                 'KNN_ON': True,
                 'LENGTH': 239975,
                 'LOCAL_SHUFFLE_BN': True,
                 'MEM_TYPE': '1d',
                 'MLP_DIM': 2048,
                 'MOCO_MULTI_VIEW_QUEUE': False,
                 'MOMENTUM': 0.5,
                 'MOMENTUM_ANNEALING': False,
                 'NUM_CLASSES_DOWNSTREAM': 400,
                 'NUM_MLP_LAYERS': 1,
                 'PREDICTOR_DEPTHS': [],
                 'QUEUE_LEN': 65536,
                 'SEQUENTIAL': False,
                 'SIMCLR_DIST_ON': True,
                 'SWAV_QEUE_LEN': 0,
                 'T': 0.07,
                 'TYPE': 'mem'},
 'DATA': {'COLOR_RND_GRAYSCALE': 0.0,
          'DECODING_BACKEND': 'torchvision',
          'DECODING_SHORT_SIZE': 256,
          'DUMMY_LOAD': False,
          'ENSEMBLE_METHOD': 'sum',
          'IN22K_TRAINVAL': False,
          'IN22k_VAL_IN1K': '',
          'INPUT_CHANNEL_NUM': [3, 3],
          'INV_UNIFORM_SAMPLE': False,
          'IN_VAL_CROP_RATIO': 0.875,
          'LOADER_CHUNK_OVERALL_SIZE': 0,
          'LOADER_CHUNK_SIZE': 0,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 16,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '',
          'PATH_TO_PRELOAD_IMDB': '',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 4,
          'SKIP_ROWS': 0,
          'SSL_BLUR_SIGMA_MAX': [0.0, 2.0],
          'SSL_BLUR_SIGMA_MIN': [0.0, 0.1],
          'SSL_COLOR_BRI_CON_SAT': [0.4, 0.4, 0.4],
          'SSL_COLOR_HUE': 0.1,
          'SSL_COLOR_JITTER': False,
          'SSL_MOCOV2_AUG': False,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 30,
          'TEST_CROP_SIZE': 256,
          'TIME_DIFF_PROB': 0.0,
          'TRAIN_CROP_NUM_SPATIAL': 1,
          'TRAIN_CROP_NUM_TEMPORAL': 1,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_ASPECT_RELATIVE': [],
          'TRAIN_JITTER_FPS': 0.0,
          'TRAIN_JITTER_MOTION_SHIFT': False,
          'TRAIN_JITTER_SCALES': [256, 320],
          'TRAIN_JITTER_SCALES_RELATIVE': [],
          'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
          'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                               [-0.5808, -0.0045, -0.814],
                               [-0.5836, -0.6948, 0.4203]],
          'USE_OFFSET_SAMPLING': False},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 4,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': False,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 10,
 'MASK': {'DECODER_DEPTH': 0,
          'DECODER_EMBED_DIM': 512,
          'DECODER_SEP_POS_EMBED': False,
          'DEC_KV_KERNEL': [],
          'DEC_KV_STRIDE': [],
          'ENABLE': False,
          'HEAD_TYPE': 'separate',
          'MAE_ON': False,
          'MAE_RND_MASK': False,
          'NORM_PRED_PIXEL': True,
          'PER_FRAME_MASKING': False,
          'PRED_HOG': False,
          'PRETRAIN_DEPTH': [15],
          'SCALE_INIT_BY_DEPTH': False,
          'TIME_STRIDE_LOSS': True},
 'MIXUP': {'ALPHA': 0.8,
           'CUTMIX_ALPHA': 1.0,
           'ENABLE': False,
           'LABEL_SMOOTH_VALUE': 0.1,
           'PROB': 1.0,
           'SWITCH_PROB': 0.5},
 'MODEL': {'ACT_CHECKPOINT': False,
           'ARCH': 'slowfast',
           'DETACH_FINAL_FC': False,
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'FP16_ALLREDUCE': False,
           'FROZEN_BN': False,
           'HEAD_ACT': 'softmax',
           'LOSS_FUNC': 'cross_entropy',
           'MODEL_NAME': 'SlowFast',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 16,
           'SINGLE_PATHWAY_ARCH': ['2d',
                                   'c2d',
                                   'i3d',
                                   'slow',
                                   'x3d',
                                   'mvit',
                                   'maskmvit']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'MVIT': {'CLS_EMBED_ON': True,
          'DEPTH': 16,
          'DIM_MUL': [],
          'DIM_MUL_IN_ATT': False,
          'DROPOUT_RATE': 0.0,
          'DROPPATH_RATE': 0.1,
          'EMBED_DIM': 96,
          'HEAD_INIT_SCALE': 1.0,
          'HEAD_MUL': [],
          'LAYER_SCALE_INIT_VALUE': 0.0,
          'MLP_RATIO': 4.0,
          'MODE': 'conv',
          'NORM': 'layernorm',
          'NORM_STEM': False,
          'NUM_HEADS': 1,
          'PATCH_2D': False,
          'PATCH_KERNEL': [3, 7, 7],
          'PATCH_PADDING': [2, 4, 4],
          'PATCH_STRIDE': [2, 4, 4],
          'POOL_FIRST': False,
          'POOL_KVQ_KERNEL': None,
          'POOL_KV_STRIDE': [],
          'POOL_KV_STRIDE_ADAPTIVE': None,
          'POOL_Q_STRIDE': [],
          'QKV_BIAS': True,
          'REL_POS_SPATIAL': False,
          'REL_POS_TEMPORAL': False,
          'REL_POS_ZERO_INIT': False,
          'RESIDUAL_POOLING': False,
          'REV': {'BUFFER_LAYERS': [],
                  'ENABLE': False,
                  'PRE_Q_FUSION': 'avg',
                  'RESPATH_FUSE': 'concat',
                  'RES_PATH': 'conv'},
          'SEPARATE_QKV': False,
          'SEP_POS_EMBED': False,
          'USE_ABS_POS': True,
          'USE_FIXED_SINCOS_POS': False,
          'USE_MEAN_POOLING': False,
          'ZERO_DECAY_POS_CLS': True},
 'NONLOCAL': {'GROUP': [[1, 1], [1, 1], [1, 1], [1, 1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[], []], [[], []], [[], []], [[], []]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 2,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3, 3], [4, 4], [6, 6], [3, 3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1, 1], [1, 1], [1, 1], [1, 1]],
            'SPATIAL_STRIDES': [[1, 1], [2, 2], [2, 2], [2, 2]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': True,
            'ZERO_INIT_FINAL_CONV': False},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 4,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 7},
 'SOLVER': {'BASE_LR': 0.002,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'BETAS': (0.9, 0.999),
            'CLIP_GRAD_L2NORM': None,
            'CLIP_GRAD_VAL': None,
            'COSINE_AFTER_WARMUP': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LARS_ON': False,
            'LAYER_DECAY': 1.0,
            'LRS': [],
            'LR_POLICY': 'cosine',
            'MAX_EPOCH': 300,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'sgd',
            'STEPS': [],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 30.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 2e-05,
            'WEIGHT_DECAY': 0.0001,
            'ZERO_WD_1D_PARAM': False},
 'TASK': '',
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': False,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 2,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'kinetics',
          'ENABLE': False,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 3,
          'NUM_TEMPORAL_CLIPS': [],
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 32,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': 'checkpoints/SLOWFAST_8x8_R50.pkl',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_IN_INIT': False,
           'CHECKPOINT_PERIOD': 20,
           'CHECKPOINT_TYPE': 'caffe2',
           'DATASET': 'kinetics',
           'ENABLE': True,
           'EVAL_PERIOD': 5,
           'KILL_LOSS_EXPLOSION_FACTOR': 0.0,
           'MIXED_PRECISION': False},
 'VIS_MASK': CfgNode({'ENABLE': False}),
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[06/12 17:36:14][INFO] misc.py:  185: Model:
DistributedDataParallel(
  (module): SlowFast(
    (s1): VideoModelStem(
      (pathway0_stem): ResNetBasicStem(
        (conv): Conv3d(3, 64, kernel_size=(1, 7, 7), stride=(1, 2, 2), padding=(0, 3, 3), bias=False)
        (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (pathway1_stem): ResNetBasicStem(
        (conv): Conv3d(3, 8, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
        (bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
    )
    (s1_fuse): FuseFastToSlow(
      (conv_f2s): Conv3d(8, 16, kernel_size=(7, 1, 1), stride=(4, 1, 1), padding=(3, 0, 0), bias=False)
      (bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (s2): ResStage(
      (pathway0_res0): ResBlock(
        (branch1): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (branch2): BottleneckTransform(
          (a): Conv3d(80, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway0_res1): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway0_res2): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway1_res0): ResBlock(
        (branch1): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (branch1_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (branch2): BottleneckTransform(
          (a): Conv3d(8, 8, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(8, 8, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway1_res1): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(32, 8, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(8, 8, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway1_res2): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(32, 8, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(8, 8, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
    )
    (s2_fuse): FuseFastToSlow(
      (conv_f2s): Conv3d(32, 64, kernel_size=(7, 1, 1), stride=(4, 1, 1), padding=(3, 0, 0), bias=False)
      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
    (pathway1_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
    (s3): ResStage(
      (pathway0_res0): ResBlock(
        (branch1): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)
        (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (branch2): BottleneckTransform(
          (a): Conv3d(320, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway0_res1): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway0_res2): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway0_res3): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway1_res0): ResBlock(
        (branch1): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)
        (branch1_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (branch2): BottleneckTransform(
          (a): Conv3d(32, 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(16, 16, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(16, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway1_res1): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(64, 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(16, 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(16, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway1_res2): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(64, 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(16, 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(16, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway1_res3): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(64, 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(16, 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(16, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
    )
    (s3_fuse): FuseFastToSlow(
      (conv_f2s): Conv3d(64, 128, kernel_size=(7, 1, 1), stride=(4, 1, 1), padding=(3, 0, 0), bias=False)
      (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (s4): ResStage(
      (pathway0_res0): ResBlock(
        (branch1): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)
        (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (branch2): BottleneckTransform(
          (a): Conv3d(640, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway0_res1): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway0_res2): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway0_res3): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway0_res4): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway0_res5): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway1_res0): ResBlock(
        (branch1): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)
        (branch1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (branch2): BottleneckTransform(
          (a): Conv3d(64, 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(32, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway1_res1): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(128, 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(32, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway1_res2): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(128, 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(32, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway1_res3): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(128, 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(32, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway1_res4): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(128, 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(32, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway1_res5): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(128, 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(32, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
    )
    (s4_fuse): FuseFastToSlow(
      (conv_f2s): Conv3d(128, 256, kernel_size=(7, 1, 1), stride=(4, 1, 1), padding=(3, 0, 0), bias=False)
      (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (s5): ResStage(
      (pathway0_res0): ResBlock(
        (branch1): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)
        (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (branch2): BottleneckTransform(
          (a): Conv3d(1280, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway0_res1): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(2048, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway0_res2): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(2048, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway1_res0): ResBlock(
        (branch1): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)
        (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (branch2): BottleneckTransform(
          (a): Conv3d(128, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway1_res1): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(256, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
      (pathway1_res2): ResBlock(
        (branch2): BottleneckTransform(
          (a): Conv3d(256, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
          (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (a_relu): ReLU(inplace=True)
          (b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
          (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (b_relu): ReLU(inplace=True)
          (c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu): ReLU(inplace=True)
      )
    )
    (head): ResNetBasicHead(
      (predictors): ModuleList()
      (pathway0_avgpool): AvgPool3d(kernel_size=[4, 7, 7], stride=1, padding=0)
      (pathway1_avgpool): AvgPool3d(kernel_size=[16, 7, 7], stride=1, padding=0)
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=2304, out_features=16, bias=True)
      (act): Softmax(dim=4)
    )
  )
)
[06/12 17:36:14][INFO] misc.py:  187: Params: 33,681,368
[06/12 17:36:14][INFO] misc.py:  188: Mem: 0.25213193893432617 MB
[06/12 17:36:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 4 time(s)
[06/12 17:36:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 32 time(s)
[06/12 17:36:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 2 time(s)
[06/12 17:36:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 1 time(s)
[06/12 17:36:15][INFO] misc.py:  190: Flops: 25.290446848 G
[06/12 17:36:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::batch_norm encountered 110 time(s)
[06/12 17:36:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 4 time(s)
[06/12 17:36:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 32 time(s)
[06/12 17:36:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 2 time(s)
[06/12 17:36:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 1 time(s)
[06/12 17:36:15][INFO] misc.py:  191: Activations: 68.289552 M
[06/12 17:36:15][INFO] misc.py:  196: nvidia-smi
[06/12 17:36:16][INFO] train_net.py:  594: Load from given checkpoint file.
[06/12 17:36:16][INFO] checkpoint.py:  223: Loading network weights from checkpoints/SLOWFAST_8x8_R50.pkl.
[06/12 17:36:16][INFO] checkpoint.py:  264: res_conv1_bn_b: (64,) => s1.pathway0_stem.bn.bias: (64,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res5_2_branch2a_bn_riv: (512,) => s5.pathway0_res2.branch2.a_bn.running_var: (512,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_1_branch2c_bn_riv: (128,) => s4.pathway1_res1.branch2.c_bn.running_var: (128,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res3_2_branch2b_bn_rm: (16,) => s3.pathway1_res2.branch2.b_bn.running_mean: (16,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res_conv1_bn_s: (64,) => s1.pathway0_stem.bn.weight: (64,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res3_3_branch2b_bn_riv: (16,) => s3.pathway1_res3.branch2.b_bn.running_var: (16,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res4_4_branch2b_w: (256, 256, 1, 3, 3) => s4.pathway0_res4.branch2.b.weight: (256, 256, 1, 3, 3)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res2_1_branch2b_w: (8, 8, 1, 3, 3) => s2.pathway1_res1.branch2.b.weight: (8, 8, 1, 3, 3)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res5_1_branch2b_bn_riv: (64,) => s5.pathway1_res1.branch2.b_bn.running_var: (64,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_2_branch2a_bn_riv: (32,) => s4.pathway1_res2.branch2.a_bn.running_var: (32,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res3_1_branch2c_bn_s: (512,) => s3.pathway0_res1.branch2.c_bn.weight: (512,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res5_1_branch2b_w: (512, 512, 1, 3, 3) => s5.pathway0_res1.branch2.b.weight: (512, 512, 1, 3, 3)
[06/12 17:36:16][INFO] checkpoint.py:  264: res3_0_branch2a_bn_riv: (128,) => s3.pathway0_res0.branch2.a_bn.running_var: (128,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res2_2_branch2a_bn_rm: (8,) => s2.pathway1_res2.branch2.a_bn.running_mean: (8,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res5_0_branch1_bn_rm: (256,) => s5.pathway1_res0.branch1_bn.running_mean: (256,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res2_1_branch2b_bn_rm: (8,) => s2.pathway1_res1.branch2.b_bn.running_mean: (8,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res3_3_branch2c_bn_riv: (64,) => s3.pathway1_res3.branch2.c_bn.running_var: (64,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res2_2_branch2b_bn_rm: (64,) => s2.pathway0_res2.branch2.b_bn.running_mean: (64,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_3_branch2c_bn_rm: (128,) => s4.pathway1_res3.branch2.c_bn.running_mean: (128,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res3_3_branch2c_bn_riv: (512,) => s3.pathway0_res3.branch2.c_bn.running_var: (512,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res5_0_branch2c_bn_riv: (2048,) => s5.pathway0_res0.branch2.c_bn.running_var: (2048,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res3_2_branch2a_w: (128, 512, 1, 1, 1) => s3.pathway0_res2.branch2.a.weight: (128, 512, 1, 1, 1)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_5_branch2b_w: (32, 32, 1, 3, 3) => s4.pathway1_res5.branch2.b.weight: (32, 32, 1, 3, 3)
[06/12 17:36:16][INFO] checkpoint.py:  264: res3_0_branch1_bn_b: (512,) => s3.pathway0_res0.branch1_bn.bias: (512,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_pool1_subsample_bn_rm: (16,) => s1_fuse.bn.running_mean: (16,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res5_2_branch2c_bn_riv: (256,) => s5.pathway1_res2.branch2.c_bn.running_var: (256,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res3_2_branch2c_w: (512, 128, 1, 1, 1) => s3.pathway0_res2.branch2.c.weight: (512, 128, 1, 1, 1)
[06/12 17:36:16][INFO] checkpoint.py:  264: res2_2_branch2a_bn_riv: (64,) => s2.pathway0_res2.branch2.a_bn.running_var: (64,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res5_2_branch2a_bn_rm: (512,) => s5.pathway0_res2.branch2.a_bn.running_mean: (512,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res3_2_branch2b_bn_b: (16,) => s3.pathway1_res2.branch2.b_bn.bias: (16,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res3_1_branch2a_bn_b: (16,) => s3.pathway1_res1.branch2.a_bn.bias: (16,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res4_5_branch2a_w: (256, 1024, 3, 1, 1) => s4.pathway0_res5.branch2.a.weight: (256, 1024, 3, 1, 1)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res5_0_branch2c_bn_riv: (256,) => s5.pathway1_res0.branch2.c_bn.running_var: (256,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res2_0_branch2a_w: (8, 8, 3, 1, 1) => s2.pathway1_res0.branch2.a.weight: (8, 8, 3, 1, 1)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_2_branch2c_w: (128, 32, 1, 1, 1) => s4.pathway1_res2.branch2.c.weight: (128, 32, 1, 1, 1)
[06/12 17:36:16][INFO] checkpoint.py:  264: res2_2_branch2a_bn_b: (64,) => s2.pathway0_res2.branch2.a_bn.bias: (64,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res5_2_branch2c_bn_rm: (256,) => s5.pathway1_res2.branch2.c_bn.running_mean: (256,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res2_2_branch2a_bn_s: (64,) => s2.pathway0_res2.branch2.a_bn.weight: (64,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_1_branch2b_w: (32, 32, 1, 3, 3) => s4.pathway1_res1.branch2.b.weight: (32, 32, 1, 3, 3)
[06/12 17:36:16][INFO] checkpoint.py:  264: res5_1_branch2c_w: (2048, 512, 1, 1, 1) => s5.pathway0_res1.branch2.c.weight: (2048, 512, 1, 1, 1)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res5_2_branch2a_bn_s: (64,) => s5.pathway1_res2.branch2.a_bn.weight: (64,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_0_branch2c_bn_s: (128,) => s4.pathway1_res0.branch2.c_bn.weight: (128,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res5_1_branch2c_bn_rm: (2048,) => s5.pathway0_res1.branch2.c_bn.running_mean: (2048,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res5_2_branch2a_bn_b: (64,) => s5.pathway1_res2.branch2.a_bn.bias: (64,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res3_0_branch2c_bn_riv: (64,) => s3.pathway1_res0.branch2.c_bn.running_var: (64,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_0_branch2c_bn_b: (128,) => s4.pathway1_res0.branch2.c_bn.bias: (128,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res4_0_branch2b_w: (256, 256, 1, 3, 3) => s4.pathway0_res0.branch2.b.weight: (256, 256, 1, 3, 3)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_2_branch2c_bn_rm: (128,) => s4.pathway1_res2.branch2.c_bn.running_mean: (128,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_1_branch2b_bn_riv: (32,) => s4.pathway1_res1.branch2.b_bn.running_var: (32,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res3_2_branch2a_bn_b: (128,) => s3.pathway0_res2.branch2.a_bn.bias: (128,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res2_1_branch2b_bn_b: (8,) => s2.pathway1_res1.branch2.b_bn.bias: (8,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res4_4_branch2b_bn_b: (256,) => s4.pathway0_res4.branch2.b_bn.bias: (256,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_0_branch1_bn_rm: (128,) => s4.pathway1_res0.branch1_bn.running_mean: (128,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res5_0_branch2b_bn_riv: (64,) => s5.pathway1_res0.branch2.b_bn.running_var: (64,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res3_1_branch2c_bn_b: (512,) => s3.pathway0_res1.branch2.c_bn.bias: (512,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res4_0_branch2c_bn_riv: (1024,) => s4.pathway0_res0.branch2.c_bn.running_var: (1024,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_1_branch2a_bn_s: (32,) => s4.pathway1_res1.branch2.a_bn.weight: (32,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res3_3_branch2b_bn_riv: (128,) => s3.pathway0_res3.branch2.b_bn.running_var: (128,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res5_1_branch2a_bn_riv: (512,) => s5.pathway0_res1.branch2.a_bn.running_var: (512,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res4_4_branch2b_bn_s: (256,) => s4.pathway0_res4.branch2.b_bn.weight: (256,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res5_0_branch1_bn_rm: (2048,) => s5.pathway0_res0.branch1_bn.running_mean: (2048,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_1_branch2a_bn_b: (32,) => s4.pathway1_res1.branch2.a_bn.bias: (32,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res3_3_branch2c_bn_subsample_bn_s: (128,) => s3_fuse.bn.weight: (128,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res4_4_branch2a_bn_rm: (256,) => s4.pathway0_res4.branch2.a_bn.running_mean: (256,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res3_0_branch1_w: (512, 320, 1, 1, 1) => s3.pathway0_res0.branch1.weight: (512, 320, 1, 1, 1)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res3_0_branch2b_bn_rm: (16,) => s3.pathway1_res0.branch2.b_bn.running_mean: (16,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res3_3_branch2c_bn_subsample_bn_b: (128,) => s3_fuse.bn.bias: (128,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res5_0_branch2a_bn_riv: (512,) => s5.pathway0_res0.branch2.a_bn.running_var: (512,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_4_branch2a_bn_riv: (32,) => s4.pathway1_res4.branch2.a_bn.running_var: (32,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res4_5_branch2c_bn_riv: (1024,) => s4.pathway0_res5.branch2.c_bn.running_var: (1024,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res2_0_branch2c_bn_riv: (32,) => s2.pathway1_res0.branch2.c_bn.running_var: (32,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res2_2_branch2c_bn_s: (32,) => s2.pathway1_res2.branch2.c_bn.weight: (32,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_3_branch2a_bn_riv: (32,) => s4.pathway1_res3.branch2.a_bn.running_var: (32,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_5_branch2a_bn_s: (32,) => s4.pathway1_res5.branch2.a_bn.weight: (32,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res2_0_branch2b_bn_b: (8,) => s2.pathway1_res0.branch2.b_bn.bias: (8,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res2_2_branch2c_bn_b: (32,) => s2.pathway1_res2.branch2.c_bn.bias: (32,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_4_branch2b_bn_rm: (32,) => s4.pathway1_res4.branch2.b_bn.running_mean: (32,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res2_2_branch2b_bn_b: (8,) => s2.pathway1_res2.branch2.b_bn.bias: (8,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res3_0_branch1_bn_rm: (512,) => s3.pathway0_res0.branch1_bn.running_mean: (512,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res4_1_branch2c_w: (1024, 256, 1, 1, 1) => s4.pathway0_res1.branch2.c.weight: (1024, 256, 1, 1, 1)
[06/12 17:36:16][INFO] checkpoint.py:  264: res2_1_branch2c_bn_riv: (256,) => s2.pathway0_res1.branch2.c_bn.running_var: (256,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res5_2_branch2b_w: (64, 64, 1, 3, 3) => s5.pathway1_res2.branch2.b.weight: (64, 64, 1, 3, 3)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res2_0_branch2c_w: (32, 8, 1, 1, 1) => s2.pathway1_res0.branch2.c.weight: (32, 8, 1, 1, 1)
[06/12 17:36:16][INFO] checkpoint.py:  264: res4_5_branch2c_w: (1024, 256, 1, 1, 1) => s4.pathway0_res5.branch2.c.weight: (1024, 256, 1, 1, 1)
[06/12 17:36:16][INFO] checkpoint.py:  264: res3_3_branch2c_bn_b: (512,) => s3.pathway0_res3.branch2.c_bn.bias: (512,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res3_2_branch2c_bn_rm: (64,) => s3.pathway1_res2.branch2.c_bn.running_mean: (64,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_0_branch1_bn_riv: (128,) => s4.pathway1_res0.branch1_bn.running_var: (128,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res5_1_branch2b_bn_b: (64,) => s5.pathway1_res1.branch2.b_bn.bias: (64,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res5_1_branch2b_w: (64, 64, 1, 3, 3) => s5.pathway1_res1.branch2.b.weight: (64, 64, 1, 3, 3)
[06/12 17:36:16][INFO] checkpoint.py:  264: res3_3_branch2c_bn_s: (512,) => s3.pathway0_res3.branch2.c_bn.weight: (512,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res3_2_branch2b_w: (128, 128, 1, 3, 3) => s3.pathway0_res2.branch2.b.weight: (128, 128, 1, 3, 3)
[06/12 17:36:16][INFO] checkpoint.py:  264: res5_1_branch2a_w: (512, 2048, 3, 1, 1) => s5.pathway0_res1.branch2.a.weight: (512, 2048, 3, 1, 1)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res3_3_branch2a_bn_riv: (16,) => s3.pathway1_res3.branch2.a_bn.running_var: (16,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res2_2_branch2c_w: (32, 8, 1, 1, 1) => s2.pathway1_res2.branch2.c.weight: (32, 8, 1, 1, 1)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res4_5_branch2c_bn_subsample_bn_b: (256,) => s4_fuse.bn.bias: (256,)
[06/12 17:36:16][INFO] checkpoint.py:  264: res4_5_branch2b_bn_b: (256,) => s4.pathway0_res5.branch2.b_bn.bias: (256,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res3_2_branch2a_bn_riv: (16,) => s3.pathway1_res2.branch2.a_bn.running_var: (16,)
[06/12 17:36:16][INFO] checkpoint.py:  264: t_res2_2_branch2a_w: (8, 32, 3, 1, 1) => s2.pathway1_res2.branch2.a.weight: (8, 32, 3, 1, 1)
[06/12 17:36:16][INFO] checkpoint.py:  264: res2_0_branch1_bn_s: (256,) => s2.pathway0_res0.branch1_bn.weight: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_0_branch2b_bn_s: (8,) => s2.pathway1_res0.branch2.b_bn.weight: (8,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_5_branch2c_bn_subsample_bn_s: (256,) => s4_fuse.bn.weight: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_5_branch2b_bn_s: (256,) => s4.pathway0_res5.branch2.b_bn.weight: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_1_branch2b_bn_rm: (16,) => s3.pathway1_res1.branch2.b_bn.running_mean: (16,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res5_2_branch2b_bn_riv: (64,) => s5.pathway1_res2.branch2.b_bn.running_var: (64,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_4_branch2c_bn_b: (1024,) => s4.pathway0_res4.branch2.c_bn.bias: (1024,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_1_branch2c_bn_b: (32,) => s2.pathway1_res1.branch2.c_bn.bias: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res3_3_branch2b_bn_s: (128,) => s3.pathway0_res3.branch2.b_bn.weight: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_2_branch2c_bn_riv: (64,) => s3.pathway1_res2.branch2.c_bn.running_var: (64,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res2_1_branch2a_bn_rm: (64,) => s2.pathway0_res1.branch2.a_bn.running_mean: (64,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_5_branch2c_bn_subsample_bn_rm: (256,) => s4_fuse.bn.running_mean: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res5_1_branch2b_bn_b: (512,) => s5.pathway0_res1.branch2.b_bn.bias: (512,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res3_1_branch2a_bn_riv: (128,) => s3.pathway0_res1.branch2.a_bn.running_var: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res5_1_branch2b_bn_s: (512,) => s5.pathway0_res1.branch2.b_bn.weight: (512,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_4_branch2c_w: (1024, 256, 1, 1, 1) => s4.pathway0_res4.branch2.c.weight: (1024, 256, 1, 1, 1)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_1_branch2c_w: (32, 8, 1, 1, 1) => s2.pathway1_res1.branch2.c.weight: (32, 8, 1, 1, 1)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res5_0_branch1_w: (256, 128, 1, 1, 1) => s5.pathway1_res0.branch1.weight: (256, 128, 1, 1, 1)
[06/12 17:36:17][INFO] checkpoint.py:  264: res2_2_branch2c_bn_riv: (256,) => s2.pathway0_res2.branch2.c_bn.running_var: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_5_branch2c_bn_subsample_w: (256, 128, 7, 1, 1) => s4_fuse.conv_f2s.weight: (256, 128, 7, 1, 1)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_3_branch2b_bn_rm: (256,) => s4.pathway0_res3.branch2.b_bn.running_mean: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res_conv1_bn_rm: (8,) => s1.pathway1_stem.bn.running_mean: (8,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_2_branch2b_bn_riv: (16,) => s3.pathway1_res2.branch2.b_bn.running_var: (16,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_2_branch2c_bn_b: (1024,) => s4.pathway0_res2.branch2.c_bn.bias: (1024,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res3_3_branch2a_bn_riv: (128,) => s3.pathway0_res3.branch2.a_bn.running_var: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_1_branch2a_w: (16, 64, 3, 1, 1) => s3.pathway1_res1.branch2.a.weight: (16, 64, 3, 1, 1)
[06/12 17:36:17][INFO] checkpoint.py:  264: res2_2_branch2a_w: (64, 256, 1, 1, 1) => s2.pathway0_res2.branch2.a.weight: (64, 256, 1, 1, 1)
[06/12 17:36:17][INFO] checkpoint.py:  264: res2_0_branch2c_bn_riv: (256,) => s2.pathway0_res0.branch2.c_bn.running_var: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res2_0_branch2b_bn_riv: (64,) => s2.pathway0_res0.branch2.b_bn.running_var: (64,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res5_2_branch2b_bn_riv: (512,) => s5.pathway0_res2.branch2.b_bn.running_var: (512,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_4_branch2a_bn_rm: (32,) => s4.pathway1_res4.branch2.a_bn.running_mean: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_0_branch2a_bn_s: (32,) => s4.pathway1_res0.branch2.a_bn.weight: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_4_branch2a_bn_s: (32,) => s4.pathway1_res4.branch2.a_bn.weight: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_1_branch2c_w: (64, 16, 1, 1, 1) => s3.pathway1_res1.branch2.c.weight: (64, 16, 1, 1, 1)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_3_branch2b_bn_rm: (32,) => s4.pathway1_res3.branch2.b_bn.running_mean: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_1_branch2a_bn_s: (256,) => s4.pathway0_res1.branch2.a_bn.weight: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res2_1_branch2c_bn_b: (256,) => s2.pathway0_res1.branch2.c_bn.bias: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res3_2_branch2b_bn_b: (128,) => s3.pathway0_res2.branch2.b_bn.bias: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res3_1_branch2b_bn_s: (128,) => s3.pathway0_res1.branch2.b_bn.weight: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_1_branch2a_bn_b: (256,) => s4.pathway0_res1.branch2.a_bn.bias: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res3_1_branch2a_bn_b: (128,) => s3.pathway0_res1.branch2.a_bn.bias: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_1_branch2a_w: (8, 32, 3, 1, 1) => s2.pathway1_res1.branch2.a.weight: (8, 32, 3, 1, 1)
[06/12 17:36:17][INFO] checkpoint.py:  264: res2_1_branch2c_bn_s: (256,) => s2.pathway0_res1.branch2.c_bn.weight: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_5_branch2b_bn_rm: (32,) => s4.pathway1_res5.branch2.b_bn.running_mean: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res3_2_branch2b_bn_s: (128,) => s3.pathway0_res2.branch2.b_bn.weight: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_2_branch2a_bn_rm: (16,) => s3.pathway1_res2.branch2.a_bn.running_mean: (16,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_1_branch2c_bn_s: (32,) => s2.pathway1_res1.branch2.c_bn.weight: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res5_2_branch2c_bn_riv: (2048,) => s5.pathway0_res2.branch2.c_bn.running_var: (2048,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res5_1_branch2c_bn_s: (2048,) => s5.pathway0_res1.branch2.c_bn.weight: (2048,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_3_branch2a_bn_rm: (32,) => s4.pathway1_res3.branch2.a_bn.running_mean: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res5_1_branch2c_bn_b: (2048,) => s5.pathway0_res1.branch2.c_bn.bias: (2048,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_5_branch2a_bn_riv: (32,) => s4.pathway1_res5.branch2.a_bn.running_var: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res2_1_branch2b_bn_rm: (64,) => s2.pathway0_res1.branch2.b_bn.running_mean: (64,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_3_branch2a_bn_s: (16,) => s3.pathway1_res3.branch2.a_bn.weight: (16,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res5_0_branch2c_bn_b: (2048,) => s5.pathway0_res0.branch2.c_bn.bias: (2048,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_0_branch2c_bn_b: (64,) => s3.pathway1_res0.branch2.c_bn.bias: (64,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_4_branch2b_bn_rm: (256,) => s4.pathway0_res4.branch2.b_bn.running_mean: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res5_1_branch2b_bn_rm: (512,) => s5.pathway0_res1.branch2.b_bn.running_mean: (512,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res5_0_branch2b_w: (512, 512, 1, 3, 3) => s5.pathway0_res0.branch2.b.weight: (512, 512, 1, 3, 3)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_1_branch2b_bn_riv: (8,) => s2.pathway1_res1.branch2.b_bn.running_var: (8,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_0_branch2c_bn_s: (64,) => s3.pathway1_res0.branch2.c_bn.weight: (64,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_1_branch2a_bn_s: (8,) => s2.pathway1_res1.branch2.a_bn.weight: (8,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_4_branch2a_bn_s: (256,) => s4.pathway0_res4.branch2.a_bn.weight: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_2_branch2b_bn_s: (16,) => s3.pathway1_res2.branch2.b_bn.weight: (16,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_0_branch2c_bn_rm: (128,) => s4.pathway1_res0.branch2.c_bn.running_mean: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_2_branch2b_bn_s: (256,) => s4.pathway0_res2.branch2.b_bn.weight: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_1_branch2a_bn_b: (8,) => s2.pathway1_res1.branch2.a_bn.bias: (8,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_4_branch2a_bn_b: (256,) => s4.pathway0_res4.branch2.a_bn.bias: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_5_branch2c_bn_subsample_bn_riv: (256,) => s4_fuse.bn.running_var: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_2_branch2b_bn_b: (256,) => s4.pathway0_res2.branch2.b_bn.bias: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res5_2_branch2c_w: (256, 64, 1, 1, 1) => s5.pathway1_res2.branch2.c.weight: (256, 64, 1, 1, 1)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_3_branch2c_bn_rm: (1024,) => s4.pathway0_res3.branch2.c_bn.running_mean: (1024,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_3_branch2a_bn_b: (32,) => s4.pathway1_res3.branch2.a_bn.bias: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_0_branch2c_w: (64, 16, 1, 1, 1) => s3.pathway1_res0.branch2.c.weight: (64, 16, 1, 1, 1)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_2_branch2a_w: (32, 128, 3, 1, 1) => s4.pathway1_res2.branch2.a.weight: (32, 128, 3, 1, 1)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_5_branch2b_w: (256, 256, 1, 3, 3) => s4.pathway0_res5.branch2.b.weight: (256, 256, 1, 3, 3)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_3_branch2a_bn_s: (32,) => s4.pathway1_res3.branch2.a_bn.weight: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_3_branch2c_bn_riv: (1024,) => s4.pathway0_res3.branch2.c_bn.running_var: (1024,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_2_branch2a_bn_rm: (32,) => s4.pathway1_res2.branch2.a_bn.running_mean: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res3_2_branch2a_bn_rm: (128,) => s3.pathway0_res2.branch2.a_bn.running_mean: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_2_branch2c_bn_rm: (1024,) => s4.pathway0_res2.branch2.c_bn.running_mean: (1024,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_0_branch2c_bn_rm: (1024,) => s4.pathway0_res0.branch2.c_bn.running_mean: (1024,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res5_1_branch2c_bn_riv: (256,) => s5.pathway1_res1.branch2.c_bn.running_var: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_4_branch2c_bn_rm: (128,) => s4.pathway1_res4.branch2.c_bn.running_mean: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res3_0_branch2a_bn_s: (128,) => s3.pathway0_res0.branch2.a_bn.weight: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_0_branch2b_bn_riv: (16,) => s3.pathway1_res0.branch2.b_bn.running_var: (16,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_3_branch2c_bn_subsample_bn_rm: (128,) => s3_fuse.bn.running_mean: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res3_0_branch2a_bn_b: (128,) => s3.pathway0_res0.branch2.a_bn.bias: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_4_branch2a_w: (256, 1024, 3, 1, 1) => s4.pathway0_res4.branch2.a.weight: (256, 1024, 3, 1, 1)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_2_branch2c_bn_riv: (32,) => s2.pathway1_res2.branch2.c_bn.running_var: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_3_branch2a_bn_rm: (16,) => s3.pathway1_res3.branch2.a_bn.running_mean: (16,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_2_branch2b_w: (8, 8, 1, 3, 3) => s2.pathway1_res2.branch2.b.weight: (8, 8, 1, 3, 3)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_0_branch2a_bn_rm: (8,) => s2.pathway1_res0.branch2.a_bn.running_mean: (8,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_0_branch2c_bn_rm: (64,) => s3.pathway1_res0.branch2.c_bn.running_mean: (64,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_5_branch2a_bn_rm: (256,) => s4.pathway0_res5.branch2.a_bn.running_mean: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_4_branch2b_bn_s: (32,) => s4.pathway1_res4.branch2.b_bn.weight: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res5_0_branch2b_bn_riv: (512,) => s5.pathway0_res0.branch2.b_bn.running_var: (512,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_1_branch2b_bn_b: (32,) => s4.pathway1_res1.branch2.b_bn.bias: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res3_1_branch2c_bn_rm: (512,) => s3.pathway0_res1.branch2.c_bn.running_mean: (512,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_4_branch2b_bn_b: (32,) => s4.pathway1_res4.branch2.b_bn.bias: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res3_1_branch2a_bn_s: (128,) => s3.pathway0_res1.branch2.a_bn.weight: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_3_branch2c_bn_b: (64,) => s3.pathway1_res3.branch2.c_bn.bias: (64,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_1_branch2b_bn_s: (32,) => s4.pathway1_res1.branch2.b_bn.weight: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_4_branch2a_bn_b: (32,) => s4.pathway1_res4.branch2.a_bn.bias: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res5_1_branch2a_bn_s: (512,) => s5.pathway0_res1.branch2.a_bn.weight: (512,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_0_branch2a_bn_riv: (256,) => s4.pathway0_res0.branch2.a_bn.running_var: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res5_1_branch2a_bn_b: (512,) => s5.pathway0_res1.branch2.a_bn.bias: (512,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_2_branch2b_bn_riv: (256,) => s4.pathway0_res2.branch2.b_bn.running_var: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_2_branch2b_bn_rm: (8,) => s2.pathway1_res2.branch2.b_bn.running_mean: (8,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res3_0_branch2c_w: (512, 128, 1, 1, 1) => s3.pathway0_res0.branch2.c.weight: (512, 128, 1, 1, 1)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_0_branch2a_bn_s: (16,) => s3.pathway1_res0.branch2.a_bn.weight: (16,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_2_branch2c_bn_riv: (128,) => s4.pathway1_res2.branch2.c_bn.running_var: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_0_branch2a_bn_b: (16,) => s3.pathway1_res0.branch2.a_bn.bias: (16,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_1_branch2a_bn_riv: (16,) => s3.pathway1_res1.branch2.a_bn.running_var: (16,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_0_branch2b_bn_riv: (8,) => s2.pathway1_res0.branch2.b_bn.running_var: (8,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_1_branch2a_bn_s: (16,) => s3.pathway1_res1.branch2.a_bn.weight: (16,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_5_branch2b_bn_riv: (256,) => s4.pathway0_res5.branch2.b_bn.running_var: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res5_2_branch2b_bn_rm: (512,) => s5.pathway0_res2.branch2.b_bn.running_mean: (512,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_3_branch2c_bn_s: (64,) => s3.pathway1_res3.branch2.c_bn.weight: (64,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_0_branch1_bn_riv: (32,) => s2.pathway1_res0.branch1_bn.running_var: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res2_2_branch2b_bn_riv: (64,) => s2.pathway0_res2.branch2.b_bn.running_var: (64,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res2_0_branch1_bn_rm: (256,) => s2.pathway0_res0.branch1_bn.running_mean: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res2_2_branch2b_w: (64, 64, 1, 3, 3) => s2.pathway0_res2.branch2.b.weight: (64, 64, 1, 3, 3)
[06/12 17:36:17][INFO] checkpoint.py:  264: res2_1_branch2a_bn_riv: (64,) => s2.pathway0_res1.branch2.a_bn.running_var: (64,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_2_branch2b_bn_rm: (32,) => s4.pathway1_res2.branch2.b_bn.running_mean: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_2_branch2a_bn_riv: (256,) => s4.pathway0_res2.branch2.a_bn.running_var: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_2_branch2c_bn_s: (1024,) => s4.pathway0_res2.branch2.c_bn.weight: (1024,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res3_3_branch2a_bn_s: (128,) => s3.pathway0_res3.branch2.a_bn.weight: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_0_branch2a_bn_riv: (8,) => s2.pathway1_res0.branch2.a_bn.running_var: (8,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res3_0_branch2b_w: (128, 128, 1, 3, 3) => s3.pathway0_res0.branch2.b.weight: (128, 128, 1, 3, 3)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_5_branch2a_bn_riv: (256,) => s4.pathway0_res5.branch2.a_bn.running_var: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_3_branch2b_bn_rm: (16,) => s3.pathway1_res3.branch2.b_bn.running_mean: (16,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_0_branch1_bn_s: (32,) => s2.pathway1_res0.branch1_bn.weight: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_0_branch2b_bn_riv: (256,) => s4.pathway0_res0.branch2.b_bn.running_var: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_0_branch2b_bn_riv: (32,) => s4.pathway1_res0.branch2.b_bn.running_var: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_0_branch2b_bn_b: (16,) => s3.pathway1_res0.branch2.b_bn.bias: (16,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_0_branch1_bn_b: (32,) => s2.pathway1_res0.branch1_bn.bias: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res5_0_branch1_bn_s: (256,) => s5.pathway1_res0.branch1_bn.weight: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res5_1_branch2b_bn_s: (64,) => s5.pathway1_res1.branch2.b_bn.weight: (64,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res3_0_branch1_bn_riv: (64,) => s3.pathway1_res0.branch1_bn.running_var: (64,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_2_branch2c_bn_subsample_bn_s: (64,) => s2_fuse.bn.weight: (64,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res5_0_branch2c_w: (2048, 512, 1, 1, 1) => s5.pathway0_res0.branch2.c.weight: (2048, 512, 1, 1, 1)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_5_branch2c_bn_s: (128,) => s4.pathway1_res5.branch2.c_bn.weight: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res5_0_branch2b_bn_rm: (64,) => s5.pathway1_res0.branch2.b_bn.running_mean: (64,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_5_branch2b_bn_s: (32,) => s4.pathway1_res5.branch2.b_bn.weight: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_5_branch2b_bn_riv: (32,) => s4.pathway1_res5.branch2.b_bn.running_var: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res5_2_branch2a_w: (512, 2048, 3, 1, 1) => s5.pathway0_res2.branch2.a.weight: (512, 2048, 3, 1, 1)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res5_1_branch2a_w: (64, 256, 3, 1, 1) => s5.pathway1_res1.branch2.a.weight: (64, 256, 3, 1, 1)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_3_branch2b_bn_riv: (32,) => s4.pathway1_res3.branch2.b_bn.running_var: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_2_branch2c_bn_subsample_bn_b: (64,) => s2_fuse.bn.bias: (64,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_5_branch2c_bn_b: (128,) => s4.pathway1_res5.branch2.c_bn.bias: (128,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res4_5_branch2b_bn_b: (32,) => s4.pathway1_res5.branch2.b_bn.bias: (32,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res2_0_branch2c_bn_rm: (256,) => s2.pathway0_res0.branch2.c_bn.running_mean: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res5_0_branch1_w: (2048, 1280, 1, 1, 1) => s5.pathway0_res0.branch1.weight: (2048, 1280, 1, 1, 1)
[06/12 17:36:17][INFO] checkpoint.py:  264: res2_2_branch2c_bn_b: (256,) => s2.pathway0_res2.branch2.c_bn.bias: (256,)
[06/12 17:36:17][INFO] checkpoint.py:  264: res4_5_branch2c_bn_b: (1024,) => s4.pathway0_res5.branch2.c_bn.bias: (1024,)
[06/12 17:36:17][INFO] checkpoint.py:  264: t_res2_2_branch2c_bn_subsample_bn_rm: (64,) => s2_fuse.bn.running_mean: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res2_0_branch2c_bn_b: (32,) => s2.pathway1_res0.branch2.c_bn.bias: (32,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_3_branch2b_bn_s: (256,) => s4.pathway0_res3.branch2.b_bn.weight: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_2_branch2c_bn_riv: (512,) => s3.pathway0_res2.branch2.c_bn.running_var: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res5_0_branch2a_w: (512, 1280, 3, 1, 1) => s5.pathway0_res0.branch2.a.weight: (512, 1280, 3, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res2_0_branch2c_bn_s: (32,) => s2.pathway1_res0.branch2.c_bn.weight: (32,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res2_1_branch2a_bn_rm: (8,) => s2.pathway1_res1.branch2.a_bn.running_mean: (8,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res2_0_branch2b_bn_rm: (64,) => s2.pathway0_res0.branch2.b_bn.running_mean: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res2_2_branch2a_bn_rm: (64,) => s2.pathway0_res2.branch2.a_bn.running_mean: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res3_0_branch2a_bn_riv: (16,) => s3.pathway1_res0.branch2.a_bn.running_var: (16,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res4_5_branch2a_bn_rm: (32,) => s4.pathway1_res5.branch2.a_bn.running_mean: (32,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res3_0_branch2b_bn_s: (16,) => s3.pathway1_res0.branch2.b_bn.weight: (16,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res3_2_branch2a_bn_b: (16,) => s3.pathway1_res2.branch2.a_bn.bias: (16,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res5_2_branch2b_bn_b: (64,) => s5.pathway1_res2.branch2.b_bn.bias: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res5_1_branch2a_bn_rm: (512,) => s5.pathway0_res1.branch2.a_bn.running_mean: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res4_0_branch2a_bn_b: (32,) => s4.pathway1_res0.branch2.a_bn.bias: (32,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res5_2_branch2b_w: (512, 512, 1, 3, 3) => s5.pathway0_res2.branch2.b.weight: (512, 512, 1, 3, 3)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res2_2_branch2a_bn_riv: (8,) => s2.pathway1_res2.branch2.a_bn.running_var: (8,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res2_1_branch2c_bn_riv: (32,) => s2.pathway1_res1.branch2.c_bn.running_var: (32,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res5_2_branch2b_bn_s: (64,) => s5.pathway1_res2.branch2.b_bn.weight: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res5_1_branch2a_bn_rm: (64,) => s5.pathway1_res1.branch2.a_bn.running_mean: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_0_branch2c_bn_b: (1024,) => s4.pathway0_res0.branch2.c_bn.bias: (1024,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_2_branch2a_w: (256, 1024, 3, 1, 1) => s4.pathway0_res2.branch2.a.weight: (256, 1024, 3, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res3_0_branch2a_w: (16, 32, 3, 1, 1) => s3.pathway1_res0.branch2.a.weight: (16, 32, 3, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_0_branch2c_bn_s: (1024,) => s4.pathway0_res0.branch2.c_bn.weight: (1024,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_3_branch2b_bn_b: (128,) => s3.pathway0_res3.branch2.b_bn.bias: (128,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res5_1_branch2c_bn_riv: (2048,) => s5.pathway0_res1.branch2.c_bn.running_var: (2048,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res3_0_branch1_w: (64, 32, 1, 1, 1) => s3.pathway1_res0.branch1.weight: (64, 32, 1, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_1_branch2a_bn_riv: (256,) => s4.pathway0_res1.branch2.a_bn.running_var: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: conv1_w: (64, 3, 1, 7, 7) => s1.pathway0_stem.conv.weight: (64, 3, 1, 7, 7)
[06/12 17:36:18][INFO] checkpoint.py:  264: res2_0_branch1_bn_riv: (256,) => s2.pathway0_res0.branch1_bn.running_var: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_2_branch2c_bn_rm: (512,) => s3.pathway0_res2.branch2.c_bn.running_mean: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_4_branch2c_bn_s: (1024,) => s4.pathway0_res4.branch2.c_bn.weight: (1024,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_1_branch2c_bn_b: (1024,) => s4.pathway0_res1.branch2.c_bn.bias: (1024,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res5_0_branch2b_bn_rm: (512,) => s5.pathway0_res0.branch2.b_bn.running_mean: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res5_1_branch2c_bn_s: (256,) => s5.pathway1_res1.branch2.c_bn.weight: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res2_1_branch2c_bn_rm: (32,) => s2.pathway1_res1.branch2.c_bn.running_mean: (32,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_4_branch2b_bn_riv: (256,) => s4.pathway0_res4.branch2.b_bn.running_var: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_1_branch2c_bn_s: (1024,) => s4.pathway0_res1.branch2.c_bn.weight: (1024,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_1_branch2c_bn_riv: (1024,) => s4.pathway0_res1.branch2.c_bn.running_var: (1024,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res5_1_branch2c_bn_b: (256,) => s5.pathway1_res1.branch2.c_bn.bias: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_5_branch2b_bn_rm: (256,) => s4.pathway0_res5.branch2.b_bn.running_mean: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res4_5_branch2a_w: (32, 128, 3, 1, 1) => s4.pathway1_res5.branch2.a.weight: (32, 128, 3, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res5_0_branch2a_bn_b: (64,) => s5.pathway1_res0.branch2.a_bn.bias: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_1_branch2b_bn_rm: (128,) => s3.pathway0_res1.branch2.b_bn.running_mean: (128,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_pool1_subsample_bn_riv: (16,) => s1_fuse.bn.running_var: (16,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_1_branch2a_bn_rm: (256,) => s4.pathway0_res1.branch2.a_bn.running_mean: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res5_0_branch2a_bn_s: (64,) => s5.pathway1_res0.branch2.a_bn.weight: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res2_1_branch2c_w: (256, 64, 1, 1, 1) => s2.pathway0_res1.branch2.c.weight: (256, 64, 1, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res3_1_branch2b_bn_s: (16,) => s3.pathway1_res1.branch2.b_bn.weight: (16,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res2_0_branch2a_bn_riv: (64,) => s2.pathway0_res0.branch2.a_bn.running_var: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res5_0_branch2a_bn_rm: (512,) => s5.pathway0_res0.branch2.a_bn.running_mean: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_0_branch2c_bn_riv: (512,) => s3.pathway0_res0.branch2.c_bn.running_var: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_2_branch2c_bn_s: (512,) => s3.pathway0_res2.branch2.c_bn.weight: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res3_1_branch2b_bn_b: (16,) => s3.pathway1_res1.branch2.b_bn.bias: (16,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res3_2_branch2a_bn_s: (16,) => s3.pathway1_res2.branch2.a_bn.weight: (16,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res4_4_branch2c_bn_s: (128,) => s4.pathway1_res4.branch2.c_bn.weight: (128,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res2_2_branch2b_bn_riv: (8,) => s2.pathway1_res2.branch2.b_bn.running_var: (8,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res5_0_branch2a_bn_b: (512,) => s5.pathway0_res0.branch2.a_bn.bias: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res4_4_branch2c_bn_b: (128,) => s4.pathway1_res4.branch2.c_bn.bias: (128,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_1_branch2b_bn_b: (128,) => s3.pathway0_res1.branch2.b_bn.bias: (128,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_2_branch2a_bn_s: (128,) => s3.pathway0_res2.branch2.a_bn.weight: (128,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res4_1_branch2a_bn_rm: (32,) => s4.pathway1_res1.branch2.a_bn.running_mean: (32,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res5_0_branch2a_bn_s: (512,) => s5.pathway0_res0.branch2.a_bn.weight: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res5_2_branch2c_bn_b: (256,) => s5.pathway1_res2.branch2.c_bn.bias: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res4_0_branch2b_bn_rm: (32,) => s4.pathway1_res0.branch2.b_bn.running_mean: (32,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res4_0_branch1_w: (128, 64, 1, 1, 1) => s4.pathway1_res0.branch1.weight: (128, 64, 1, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_0_branch2b_bn_s: (256,) => s4.pathway0_res0.branch2.b_bn.weight: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_2_branch2a_bn_b: (256,) => s4.pathway0_res2.branch2.a_bn.bias: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res5_2_branch2b_bn_s: (512,) => s5.pathway0_res2.branch2.b_bn.weight: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_3_branch2c_bn_s: (1024,) => s4.pathway0_res3.branch2.c_bn.weight: (1024,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_2_branch2a_bn_s: (256,) => s4.pathway0_res2.branch2.a_bn.weight: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res5_2_branch2b_bn_b: (512,) => s5.pathway0_res2.branch2.b_bn.bias: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res2_0_branch1_bn_rm: (32,) => s2.pathway1_res0.branch1_bn.running_mean: (32,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_1_branch2a_w: (128, 512, 1, 1, 1) => s3.pathway0_res1.branch2.a.weight: (128, 512, 1, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_3_branch2c_bn_b: (1024,) => s4.pathway0_res3.branch2.c_bn.bias: (1024,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_0_branch2b_bn_rm: (128,) => s3.pathway0_res0.branch2.b_bn.running_mean: (128,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res5_0_branch2b_bn_b: (512,) => s5.pathway0_res0.branch2.b_bn.bias: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res5_2_branch2a_bn_b: (512,) => s5.pathway0_res2.branch2.a_bn.bias: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res5_0_branch1_bn_riv: (256,) => s5.pathway1_res0.branch1_bn.running_var: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res3_0_branch1_bn_b: (64,) => s3.pathway1_res0.branch1_bn.bias: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res4_1_branch2c_bn_b: (128,) => s4.pathway1_res1.branch2.c_bn.bias: (128,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_3_branch2a_bn_b: (128,) => s3.pathway0_res3.branch2.a_bn.bias: (128,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res4_0_branch2c_w: (128, 32, 1, 1, 1) => s4.pathway1_res0.branch2.c.weight: (128, 32, 1, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: res5_2_branch2a_bn_s: (512,) => s5.pathway0_res2.branch2.a_bn.weight: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res3_0_branch1_bn_s: (64,) => s3.pathway1_res0.branch1_bn.weight: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res4_1_branch2c_bn_s: (128,) => s4.pathway1_res1.branch2.c_bn.weight: (128,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res2_0_branch1_bn_b: (256,) => s2.pathway0_res0.branch1_bn.bias: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_1_branch2b_bn_riv: (256,) => s4.pathway0_res1.branch2.b_bn.running_var: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_0_branch2b_bn_rm: (256,) => s4.pathway0_res0.branch2.b_bn.running_mean: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_0_branch1_bn_s: (1024,) => s4.pathway0_res0.branch1_bn.weight: (1024,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res3_2_branch2c_w: (64, 16, 1, 1, 1) => s3.pathway1_res2.branch2.c.weight: (64, 16, 1, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_2_branch2a_bn_rm: (256,) => s4.pathway0_res2.branch2.a_bn.running_mean: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res4_0_branch1_bn_b: (128,) => s4.pathway1_res0.branch1_bn.bias: (128,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res2_0_branch2b_w: (64, 64, 1, 3, 3) => s2.pathway0_res0.branch2.b.weight: (64, 64, 1, 3, 3)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res5_0_branch2c_w: (256, 64, 1, 1, 1) => s5.pathway1_res0.branch2.c.weight: (256, 64, 1, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_0_branch1_bn_b: (1024,) => s4.pathway0_res0.branch1_bn.bias: (1024,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_1_branch2c_bn_rm: (1024,) => s4.pathway0_res1.branch2.c_bn.running_mean: (1024,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res4_2_branch2b_bn_riv: (32,) => s4.pathway1_res2.branch2.b_bn.running_var: (32,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_3_branch2a_bn_rm: (256,) => s4.pathway0_res3.branch2.a_bn.running_mean: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res5_0_branch2b_bn_b: (64,) => s5.pathway1_res0.branch2.b_bn.bias: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res4_1_branch2a_w: (32, 128, 3, 1, 1) => s4.pathway1_res1.branch2.a.weight: (32, 128, 3, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_2_branch2b_w: (256, 256, 1, 3, 3) => s4.pathway0_res2.branch2.b.weight: (256, 256, 1, 3, 3)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_1_branch2c_w: (512, 128, 1, 1, 1) => s3.pathway0_res1.branch2.c.weight: (512, 128, 1, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_0_branch1_bn_s: (512,) => s3.pathway0_res0.branch1_bn.weight: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res3_1_branch2b_w: (16, 16, 1, 3, 3) => s3.pathway1_res1.branch2.b.weight: (16, 16, 1, 3, 3)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res5_0_branch2a_w: (64, 128, 3, 1, 1) => s5.pathway1_res0.branch2.a.weight: (64, 128, 3, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res5_2_branch2a_bn_rm: (64,) => s5.pathway1_res2.branch2.a_bn.running_mean: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res4_1_branch2c_w: (128, 32, 1, 1, 1) => s4.pathway1_res1.branch2.c.weight: (128, 32, 1, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res3_2_branch2c_bn_s: (64,) => s3.pathway1_res2.branch2.c_bn.weight: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_1_branch2b_bn_rm: (256,) => s4.pathway0_res1.branch2.b_bn.running_mean: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_3_branch2b_bn_rm: (128,) => s3.pathway0_res3.branch2.b_bn.running_mean: (128,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_0_branch2b_bn_b: (256,) => s4.pathway0_res0.branch2.b_bn.bias: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res3_2_branch2c_bn_b: (64,) => s3.pathway1_res2.branch2.c_bn.bias: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res5_1_branch2a_bn_riv: (64,) => s5.pathway1_res1.branch2.a_bn.running_var: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_1_branch2c_bn_riv: (512,) => s3.pathway0_res1.branch2.c_bn.running_var: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_0_branch2c_bn_b: (512,) => s3.pathway0_res0.branch2.c_bn.bias: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_0_branch2a_bn_rm: (128,) => s3.pathway0_res0.branch2.a_bn.running_mean: (128,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res5_0_branch2c_bn_s: (2048,) => s5.pathway0_res0.branch2.c_bn.weight: (2048,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res5_1_branch2a_bn_b: (64,) => s5.pathway1_res1.branch2.a_bn.bias: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_2_branch2b_bn_rm: (256,) => s4.pathway0_res2.branch2.b_bn.running_mean: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res5_2_branch2c_w: (2048, 512, 1, 1, 1) => s5.pathway0_res2.branch2.c.weight: (2048, 512, 1, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: res3_0_branch2c_bn_s: (512,) => s3.pathway0_res0.branch2.c_bn.weight: (512,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res2_0_branch2a_w: (64, 80, 1, 1, 1) => s2.pathway0_res0.branch2.a.weight: (64, 80, 1, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res5_1_branch2a_bn_s: (64,) => s5.pathway1_res1.branch2.a_bn.weight: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: res4_3_branch2a_bn_riv: (256,) => s4.pathway0_res3.branch2.a_bn.running_var: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res3_1_branch2c_bn_s: (64,) => s3.pathway1_res1.branch2.c_bn.weight: (64,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res5_2_branch2c_bn_s: (256,) => s5.pathway1_res2.branch2.c_bn.weight: (256,)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res4_4_branch2a_w: (32, 128, 3, 1, 1) => s4.pathway1_res4.branch2.a.weight: (32, 128, 3, 1, 1)
[06/12 17:36:18][INFO] checkpoint.py:  264: t_res3_1_branch2c_bn_b: (64,) => s3.pathway1_res1.branch2.c_bn.bias: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_3_branch2c_w: (128, 32, 1, 1, 1) => s4.pathway1_res3.branch2.c.weight: (128, 32, 1, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_0_branch2b_w: (32, 32, 1, 3, 3) => s4.pathway1_res0.branch2.b.weight: (32, 32, 1, 3, 3)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_2_branch2c_w: (256, 64, 1, 1, 1) => s2.pathway0_res2.branch2.c.weight: (256, 64, 1, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res5_2_branch2a_bn_riv: (64,) => s5.pathway1_res2.branch2.a_bn.running_var: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_0_branch2b_bn_b: (32,) => s4.pathway1_res0.branch2.b_bn.bias: (32,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_0_branch2c_bn_riv: (128,) => s4.pathway1_res0.branch2.c_bn.running_var: (128,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_0_branch2b_bn_s: (32,) => s4.pathway1_res0.branch2.b_bn.weight: (32,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res3_0_branch2b_w: (16, 16, 1, 3, 3) => s3.pathway1_res0.branch2.b.weight: (16, 16, 1, 3, 3)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_3_branch2a_w: (32, 128, 3, 1, 1) => s4.pathway1_res3.branch2.a.weight: (32, 128, 3, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: res3_0_branch2b_bn_riv: (128,) => s3.pathway0_res0.branch2.b_bn.running_var: (128,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res3_0_branch2a_w: (128, 320, 1, 1, 1) => s3.pathway0_res0.branch2.a.weight: (128, 320, 1, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_0_branch2a_bn_s: (64,) => s2.pathway0_res0.branch2.a_bn.weight: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res3_1_branch2c_bn_rm: (64,) => s3.pathway1_res1.branch2.c_bn.running_mean: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res_conv1_bn_b: (8,) => s1.pathway1_stem.bn.bias: (8,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_3_branch2a_bn_b: (256,) => s4.pathway0_res3.branch2.a_bn.bias: (256,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_1_branch2a_bn_s: (64,) => s2.pathway0_res1.branch2.a_bn.weight: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res3_0_branch2c_bn_rm: (512,) => s3.pathway0_res0.branch2.c_bn.running_mean: (512,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res2_1_branch2b_bn_s: (8,) => s2.pathway1_res1.branch2.b_bn.weight: (8,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res3_2_branch2c_bn_b: (512,) => s3.pathway0_res2.branch2.c_bn.bias: (512,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_0_branch2a_bn_b: (64,) => s2.pathway0_res0.branch2.a_bn.bias: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_1_branch2b_bn_s: (256,) => s4.pathway0_res1.branch2.b_bn.weight: (256,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res3_2_branch2b_w: (16, 16, 1, 3, 3) => s3.pathway1_res2.branch2.b.weight: (16, 16, 1, 3, 3)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res_conv1_bn_s: (8,) => s1.pathway1_stem.bn.weight: (8,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res2_0_branch2b_bn_rm: (8,) => s2.pathway1_res0.branch2.b_bn.running_mean: (8,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_1_branch2a_bn_b: (64,) => s2.pathway0_res1.branch2.a_bn.bias: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_2_branch2c_w: (1024, 256, 1, 1, 1) => s4.pathway0_res2.branch2.c.weight: (1024, 256, 1, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: res3_1_branch2b_w: (128, 128, 1, 3, 3) => s3.pathway0_res1.branch2.b.weight: (128, 128, 1, 3, 3)
[06/12 17:36:19][INFO] checkpoint.py:  264: res3_1_branch2a_bn_rm: (128,) => s3.pathway0_res1.branch2.a_bn.running_mean: (128,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res3_3_branch2c_w: (512, 128, 1, 1, 1) => s3.pathway0_res3.branch2.c.weight: (512, 128, 1, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_1_branch2a_bn_riv: (32,) => s4.pathway1_res1.branch2.a_bn.running_var: (32,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_4_branch2b_w: (32, 32, 1, 3, 3) => s4.pathway1_res4.branch2.b.weight: (32, 32, 1, 3, 3)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_0_branch2a_bn_rm: (64,) => s2.pathway0_res0.branch2.a_bn.running_mean: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_0_branch2b_bn_b: (64,) => s2.pathway0_res0.branch2.b_bn.bias: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_0_branch2a_bn_s: (256,) => s4.pathway0_res0.branch2.a_bn.weight: (256,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res3_3_branch2a_w: (128, 512, 1, 1, 1) => s3.pathway0_res3.branch2.a.weight: (128, 512, 1, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_4_branch2c_w: (128, 32, 1, 1, 1) => s4.pathway1_res4.branch2.c.weight: (128, 32, 1, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: res3_1_branch2b_bn_riv: (128,) => s3.pathway0_res1.branch2.b_bn.running_var: (128,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_0_branch2b_bn_s: (64,) => s2.pathway0_res0.branch2.b_bn.weight: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_0_branch2a_bn_b: (256,) => s4.pathway0_res0.branch2.a_bn.bias: (256,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res5_0_branch2c_bn_s: (256,) => s5.pathway1_res0.branch2.c_bn.weight: (256,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_5_branch2c_bn_rm: (128,) => s4.pathway1_res5.branch2.c_bn.running_mean: (128,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res3_3_branch2c_bn_subsample_w: (128, 64, 7, 1, 1) => s3_fuse.conv_f2s.weight: (128, 64, 7, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_0_branch2c_bn_b: (256,) => s2.pathway0_res0.branch2.c_bn.bias: (256,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res2_2_branch2c_bn_rm: (32,) => s2.pathway1_res2.branch2.c_bn.running_mean: (32,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res5_0_branch2b_bn_s: (512,) => s5.pathway0_res0.branch2.b_bn.weight: (512,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res5_0_branch2a_bn_rm: (64,) => s5.pathway1_res0.branch2.a_bn.running_mean: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res5_2_branch2c_bn_rm: (2048,) => s5.pathway0_res2.branch2.c_bn.running_mean: (2048,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_0_branch2c_bn_s: (256,) => s2.pathway0_res0.branch2.c_bn.weight: (256,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_3_branch2b_w: (256, 256, 1, 3, 3) => s4.pathway0_res3.branch2.b.weight: (256, 256, 1, 3, 3)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res5_0_branch2a_bn_riv: (64,) => s5.pathway1_res0.branch2.a_bn.running_var: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res3_0_branch2b_bn_b: (128,) => s3.pathway0_res0.branch2.b_bn.bias: (128,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res3_1_branch2c_bn_riv: (64,) => s3.pathway1_res1.branch2.c_bn.running_var: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_1_branch2b_bn_b: (256,) => s4.pathway0_res1.branch2.b_bn.bias: (256,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_0_branch2a_bn_rm: (256,) => s4.pathway0_res0.branch2.a_bn.running_mean: (256,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_3_branch2c_bn_s: (128,) => s4.pathway1_res3.branch2.c_bn.weight: (128,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_0_branch1_w: (256, 80, 1, 1, 1) => s2.pathway0_res0.branch1.weight: (256, 80, 1, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res5_0_branch2c_bn_b: (256,) => s5.pathway1_res0.branch2.c_bn.bias: (256,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_1_branch2c_bn_rm: (256,) => s2.pathway0_res1.branch2.c_bn.running_mean: (256,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res3_0_branch2b_bn_s: (128,) => s3.pathway0_res0.branch2.b_bn.weight: (128,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res3_3_branch2b_w: (16, 16, 1, 3, 3) => s3.pathway1_res3.branch2.b.weight: (16, 16, 1, 3, 3)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_0_branch2a_bn_rm: (32,) => s4.pathway1_res0.branch2.a_bn.running_mean: (32,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res3_3_branch2c_bn_rm: (64,) => s3.pathway1_res3.branch2.c_bn.running_mean: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_3_branch2c_bn_b: (128,) => s4.pathway1_res3.branch2.c_bn.bias: (128,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_2_branch2a_bn_s: (32,) => s4.pathway1_res2.branch2.a_bn.weight: (32,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_5_branch2c_bn_rm: (1024,) => s4.pathway0_res5.branch2.c_bn.running_mean: (1024,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_2_branch2a_bn_b: (32,) => s4.pathway1_res2.branch2.a_bn.bias: (32,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res_conv1_bn_riv: (64,) => s1.pathway0_stem.bn.running_var: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res5_0_branch1_bn_b: (256,) => s5.pathway1_res0.branch1_bn.bias: (256,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_4_branch2c_bn_riv: (128,) => s4.pathway1_res4.branch2.c_bn.running_var: (128,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_0_branch2a_w: (32, 64, 3, 1, 1) => s4.pathway1_res0.branch2.a.weight: (32, 64, 3, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_5_branch2c_bn_riv: (128,) => s4.pathway1_res5.branch2.c_bn.running_var: (128,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_4_branch2a_bn_riv: (256,) => s4.pathway0_res4.branch2.a_bn.running_var: (256,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res2_1_branch2a_bn_riv: (8,) => s2.pathway1_res1.branch2.a_bn.running_var: (8,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res5_1_branch2c_w: (256, 64, 1, 1, 1) => s5.pathway1_res1.branch2.c.weight: (256, 64, 1, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: res5_1_branch2b_bn_riv: (512,) => s5.pathway0_res1.branch2.b_bn.running_var: (512,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res2_0_branch2c_bn_rm: (32,) => s2.pathway1_res0.branch2.c_bn.running_mean: (32,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res3_3_branch2c_bn_subsample_bn_riv: (128,) => s3_fuse.bn.running_var: (128,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res5_2_branch2c_bn_s: (2048,) => s5.pathway0_res2.branch2.c_bn.weight: (2048,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res3_3_branch2a_bn_b: (16,) => s3.pathway1_res3.branch2.a_bn.bias: (16,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_0_branch2c_w: (256, 64, 1, 1, 1) => s2.pathway0_res0.branch2.c.weight: (256, 64, 1, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: res5_2_branch2c_bn_b: (2048,) => s5.pathway0_res2.branch2.c_bn.bias: (2048,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_5_branch2a_bn_b: (32,) => s4.pathway1_res5.branch2.a_bn.bias: (32,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res5_0_branch2b_w: (64, 64, 1, 3, 3) => s5.pathway1_res0.branch2.b.weight: (64, 64, 1, 3, 3)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_5_branch2c_w: (128, 32, 1, 1, 1) => s4.pathway1_res5.branch2.c.weight: (128, 32, 1, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res2_2_branch2a_bn_s: (8,) => s2.pathway1_res2.branch2.a_bn.weight: (8,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_3_branch2a_bn_s: (256,) => s4.pathway0_res3.branch2.a_bn.weight: (256,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_3_branch2b_bn_riv: (256,) => s4.pathway0_res3.branch2.b_bn.running_var: (256,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_2_branch2c_bn_riv: (1024,) => s4.pathway0_res2.branch2.c_bn.running_var: (1024,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_1_branch2b_w: (256, 256, 1, 3, 3) => s4.pathway0_res1.branch2.b.weight: (256, 256, 1, 3, 3)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res5_2_branch2b_bn_rm: (64,) => s5.pathway1_res2.branch2.b_bn.running_mean: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_1_branch2a_w: (64, 256, 1, 1, 1) => s2.pathway0_res1.branch2.a.weight: (64, 256, 1, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_0_branch1_w: (1024, 640, 1, 1, 1) => s4.pathway0_res0.branch1.weight: (1024, 640, 1, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_2_branch2b_bn_b: (32,) => s4.pathway1_res2.branch2.b_bn.bias: (32,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_2_branch2b_w: (32, 32, 1, 3, 3) => s4.pathway1_res2.branch2.b.weight: (32, 32, 1, 3, 3)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res_conv1_bn_riv: (8,) => s1.pathway1_stem.bn.running_var: (8,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res3_3_branch2b_bn_s: (16,) => s3.pathway1_res3.branch2.b_bn.weight: (16,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_2_branch2b_bn_s: (32,) => s4.pathway1_res2.branch2.b_bn.weight: (32,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res3_3_branch2c_bn_rm: (512,) => s3.pathway0_res3.branch2.c_bn.running_mean: (512,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_0_branch2a_bn_riv: (32,) => s4.pathway1_res0.branch2.a_bn.running_var: (32,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res3_2_branch2b_bn_riv: (128,) => s3.pathway0_res2.branch2.b_bn.running_var: (128,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res3_3_branch2b_bn_b: (16,) => s3.pathway1_res3.branch2.b_bn.bias: (16,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res2_0_branch2b_w: (8, 8, 1, 3, 3) => s2.pathway1_res0.branch2.b.weight: (8, 8, 1, 3, 3)
[06/12 17:36:19][INFO] checkpoint.py:  264: res3_3_branch2a_bn_rm: (128,) => s3.pathway0_res3.branch2.a_bn.running_mean: (128,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res5_0_branch1_bn_riv: (2048,) => s5.pathway0_res0.branch1_bn.running_var: (2048,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_4_branch2c_bn_riv: (1024,) => s4.pathway0_res4.branch2.c_bn.running_var: (1024,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_1_branch2b_bn_rm: (32,) => s4.pathway1_res1.branch2.b_bn.running_mean: (32,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_2_branch2b_bn_s: (64,) => s2.pathway0_res2.branch2.b_bn.weight: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res_conv1_bn_rm: (64,) => s1.pathway0_stem.bn.running_mean: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res3_2_branch2b_bn_rm: (128,) => s3.pathway0_res2.branch2.b_bn.running_mean: (128,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_2_branch2b_bn_b: (64,) => s2.pathway0_res2.branch2.b_bn.bias: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_2_branch2c_bn_s: (256,) => s2.pathway0_res2.branch2.c_bn.weight: (256,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_1_branch2c_bn_rm: (128,) => s4.pathway1_res1.branch2.c_bn.running_mean: (128,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_conv1_w: (8, 3, 5, 7, 7) => s1.pathway1_stem.conv.weight: (8, 3, 5, 7, 7)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_0_branch1_bn_rm: (1024,) => s4.pathway0_res0.branch1_bn.running_mean: (1024,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_0_branch1_bn_riv: (1024,) => s4.pathway0_res0.branch1_bn.running_var: (1024,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res5_0_branch1_bn_s: (2048,) => s5.pathway0_res0.branch1_bn.weight: (2048,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_0_branch2c_w: (1024, 256, 1, 1, 1) => s4.pathway0_res0.branch2.c.weight: (1024, 256, 1, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_1_branch2b_bn_b: (64,) => s2.pathway0_res1.branch2.b_bn.bias: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res5_0_branch2c_bn_rm: (2048,) => s5.pathway0_res0.branch2.c_bn.running_mean: (2048,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res5_0_branch1_bn_b: (2048,) => s5.pathway0_res0.branch1_bn.bias: (2048,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_0_branch2a_w: (256, 640, 3, 1, 1) => s4.pathway0_res0.branch2.a.weight: (256, 640, 3, 1, 1)
[06/12 17:36:19][INFO] checkpoint.py:  264: res4_4_branch2c_bn_rm: (1024,) => s4.pathway0_res4.branch2.c_bn.running_mean: (1024,)
[06/12 17:36:19][INFO] checkpoint.py:  264: res2_1_branch2b_bn_s: (64,) => s2.pathway0_res1.branch2.b_bn.weight: (64,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res5_0_branch2c_bn_rm: (256,) => s5.pathway1_res0.branch2.c_bn.running_mean: (256,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res3_1_branch2a_bn_rm: (16,) => s3.pathway1_res1.branch2.a_bn.running_mean: (16,)
[06/12 17:36:19][INFO] checkpoint.py:  264: t_res4_3_branch2b_w: (32, 32, 1, 3, 3) => s4.pathway1_res3.branch2.b.weight: (32, 32, 1, 3, 3)
[06/12 17:36:19][INFO] checkpoint.py:  264: res3_0_branch1_bn_riv: (512,) => s3.pathway0_res0.branch1_bn.running_var: (512,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res2_2_branch2a_bn_b: (8,) => s2.pathway1_res2.branch2.a_bn.bias: (8,)
[06/12 17:36:20][INFO] checkpoint.py:  264: res4_3_branch2c_w: (1024, 256, 1, 1, 1) => s4.pathway0_res3.branch2.c.weight: (1024, 256, 1, 1, 1)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res5_0_branch2b_bn_s: (64,) => s5.pathway1_res0.branch2.b_bn.weight: (64,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res5_1_branch2b_bn_rm: (64,) => s5.pathway1_res1.branch2.b_bn.running_mean: (64,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res4_3_branch2b_bn_s: (32,) => s4.pathway1_res3.branch2.b_bn.weight: (32,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_pool1_subsample_bn_s: (16,) => s1_fuse.bn.weight: (16,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res2_2_branch2b_bn_s: (8,) => s2.pathway1_res2.branch2.b_bn.weight: (8,)
[06/12 17:36:20][INFO] checkpoint.py:  264: res2_1_branch2b_w: (64, 64, 1, 3, 3) => s2.pathway0_res1.branch2.b.weight: (64, 64, 1, 3, 3)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res5_1_branch2c_bn_rm: (256,) => s5.pathway1_res1.branch2.c_bn.running_mean: (256,)
[06/12 17:36:20][INFO] checkpoint.py:  264: res3_2_branch2a_bn_riv: (128,) => s3.pathway0_res2.branch2.a_bn.running_var: (128,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res4_3_branch2b_bn_b: (32,) => s4.pathway1_res3.branch2.b_bn.bias: (32,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_pool1_subsample_bn_b: (16,) => s1_fuse.bn.bias: (16,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res4_0_branch1_bn_s: (128,) => s4.pathway1_res0.branch1_bn.weight: (128,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res4_4_branch2b_bn_riv: (32,) => s4.pathway1_res4.branch2.b_bn.running_var: (32,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res3_0_branch1_bn_rm: (64,) => s3.pathway1_res0.branch1_bn.running_mean: (64,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res3_0_branch2a_bn_rm: (16,) => s3.pathway1_res0.branch2.a_bn.running_mean: (16,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res4_3_branch2c_bn_riv: (128,) => s4.pathway1_res3.branch2.c_bn.running_var: (128,)
[06/12 17:36:20][INFO] checkpoint.py:  264: res2_2_branch2c_bn_rm: (256,) => s2.pathway0_res2.branch2.c_bn.running_mean: (256,)
[06/12 17:36:20][WARNING] checkpoint.py:  273: !! pred_b: (400,) does not match head.projection.bias: (16,)
[06/12 17:36:20][INFO] checkpoint.py:  264: res3_3_branch2b_w: (128, 128, 1, 3, 3) => s3.pathway0_res3.branch2.b.weight: (128, 128, 1, 3, 3)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res3_2_branch2a_w: (16, 64, 3, 1, 1) => s3.pathway1_res2.branch2.a.weight: (16, 64, 3, 1, 1)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res4_2_branch2c_bn_s: (128,) => s4.pathway1_res2.branch2.c_bn.weight: (128,)
[06/12 17:36:20][INFO] checkpoint.py:  264: res2_1_branch2b_bn_riv: (64,) => s2.pathway0_res1.branch2.b_bn.running_var: (64,)
[06/12 17:36:20][WARNING] checkpoint.py:  273: !! pred_w: (400, 2304) does not match head.projection.weight: (16, 2304)
[06/12 17:36:20][INFO] checkpoint.py:  264: res4_3_branch2a_w: (256, 1024, 3, 1, 1) => s4.pathway0_res3.branch2.a.weight: (256, 1024, 3, 1, 1)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res2_2_branch2c_bn_subsample_bn_riv: (64,) => s2_fuse.bn.running_var: (64,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res3_3_branch2a_w: (16, 64, 3, 1, 1) => s3.pathway1_res3.branch2.a.weight: (16, 64, 3, 1, 1)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res3_1_branch2b_bn_riv: (16,) => s3.pathway1_res1.branch2.b_bn.running_var: (16,)
[06/12 17:36:20][INFO] checkpoint.py:  264: res4_1_branch2a_w: (256, 1024, 3, 1, 1) => s4.pathway0_res1.branch2.a.weight: (256, 1024, 3, 1, 1)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res2_0_branch1_w: (32, 8, 1, 1, 1) => s2.pathway1_res0.branch1.weight: (32, 8, 1, 1, 1)
[06/12 17:36:20][INFO] checkpoint.py:  264: res4_5_branch2c_bn_s: (1024,) => s4.pathway0_res5.branch2.c_bn.weight: (1024,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res4_2_branch2c_bn_b: (128,) => s4.pathway1_res2.branch2.c_bn.bias: (128,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res2_0_branch2a_bn_s: (8,) => s2.pathway1_res0.branch2.a_bn.weight: (8,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res2_2_branch2c_bn_subsample_w: (64, 32, 7, 1, 1) => s2_fuse.conv_f2s.weight: (64, 32, 7, 1, 1)
[06/12 17:36:20][INFO] checkpoint.py:  264: res4_5_branch2a_bn_s: (256,) => s4.pathway0_res5.branch2.a_bn.weight: (256,)
[06/12 17:36:20][INFO] checkpoint.py:  264: res4_3_branch2b_bn_b: (256,) => s4.pathway0_res3.branch2.b_bn.bias: (256,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res5_2_branch2a_w: (64, 256, 3, 1, 1) => s5.pathway1_res2.branch2.a.weight: (64, 256, 3, 1, 1)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_pool1_subsample_w: (16, 8, 7, 1, 1) => s1_fuse.conv_f2s.weight: (16, 8, 7, 1, 1)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res2_0_branch2a_bn_b: (8,) => s2.pathway1_res0.branch2.a_bn.bias: (8,)
[06/12 17:36:20][INFO] checkpoint.py:  264: res4_5_branch2a_bn_b: (256,) => s4.pathway0_res5.branch2.a_bn.bias: (256,)
[06/12 17:36:20][INFO] checkpoint.py:  264: t_res3_3_branch2c_w: (64, 16, 1, 1, 1) => s3.pathway1_res3.branch2.c.weight: (64, 16, 1, 1, 1)
[06/12 17:36:20][WARNING] checkpoint.py:  293: Not loaded {'head.projection.weight', 'head.projection.bias'}
[06/12 17:36:20][INFO] kinetics.py:   93: Constructing Kinetics train...
[06/12 17:36:20][INFO] kinetics.py:  169: Constructing kinetics dataloader (size: 1927 skip_rows 0) from train.csv 
[06/12 17:36:20][INFO] kinetics.py:   93: Constructing Kinetics val...
[06/12 17:36:20][INFO] kinetics.py:  169: Constructing kinetics dataloader (size: 482 skip_rows 0) from val.csv 
[06/12 17:36:20][INFO] kinetics.py:   93: Constructing Kinetics train...
[06/12 17:36:20][INFO] kinetics.py:  169: Constructing kinetics dataloader (size: 1927 skip_rows 0) from train.csv 
[06/12 17:36:20][INFO] train_net.py:  647: Start epoch: 1
[06/12 17:36:34][INFO] distributed.py: 1027: Reducer buckets have been rebuilt in this iteration.
[06/12 17:36:39][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.45639, "dt_data": 0.00051, "dt_net": 0.45587, "epoch": "1/300", "eta": "2:16:50", "gpu_mem": "10.06G", "grad_norm": 4.12284, "iter": "10/60", "loss": 2.78378, "lr": 0.0000296553, "top1_acc": 0.00000, "top1_err": 95.31250, "top5_acc": 25.00000, "top5_err": 68.75000}
[06/12 17:36:44][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47410, "dt_data": 0.00097, "dt_net": 0.47313, "epoch": "1/300", "eta": "2:22:04", "gpu_mem": "10.06G", "grad_norm": 4.31403, "iter": "20/60", "loss": 2.78490, "lr": 0.0000403834, "top1_acc": 3.12500, "top1_err": 96.87500, "top5_acc": 28.12500, "top5_err": 75.00000}
[06/12 17:36:51][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.24170, "dt_data": 0.78708, "dt_net": 0.45461, "epoch": "1/300", "eta": "6:11:53", "gpu_mem": "10.06G", "grad_norm": 4.09940, "iter": "30/60", "loss": 2.77739, "lr": 0.0000511115, "top1_acc": 6.25000, "top1_err": 93.75000, "top5_acc": 25.00000, "top5_err": 71.87500}
[06/12 17:36:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.70641, "dt_data": 0.25449, "dt_net": 0.45192, "epoch": "1/300", "eta": "3:31:27", "gpu_mem": "10.06G", "grad_norm": 4.16123, "iter": "40/60", "loss": 2.80939, "lr": 0.0000618396, "top1_acc": 3.12500, "top1_err": 95.31250, "top5_acc": 25.00000, "top5_err": 75.00000}
[06/12 17:37:03][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.45969, "dt_data": 0.00036, "dt_net": 0.45933, "epoch": "1/300", "eta": "2:17:31", "gpu_mem": "10.06G", "grad_norm": 4.43483, "iter": "50/60", "loss": 2.79011, "lr": 0.0000725676, "top1_acc": 6.25000, "top1_err": 93.75000, "top5_acc": 31.25000, "top5_err": 70.31250}
[06/12 17:37:09][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46214, "dt_data": 0.00966, "dt_net": 0.45248, "epoch": "1/300", "eta": "2:18:10", "gpu_mem": "10.06G", "grad_norm": 3.99545, "iter": "60/60", "loss": 2.79089, "lr": 0.0000832957, "top1_acc": 6.25000, "top1_err": 93.75000, "top5_acc": 31.25000, "top5_err": 68.75000}
[06/12 17:37:09][INFO] logging.py:  101: json_stats: {"RAM": "13.62/31.07G", "_type": "train_epoch", "dt": 0.72225, "dt_data": 0.72225, "dt_net": 0.45248, "epoch": "1/300", "eta": "3:35:56", "gpu_mem": "10.06G", "grad_norm": 3.99545, "loss": 2.79020, "lr": 0.0000832957, "top1_acc": 5.41667, "top1_err": 94.63542, "top5_acc": 28.33333, "top5_err": 71.82292}
[06/12 17:37:09][INFO] train_net.py:  708: Epoch 0 takes 49.42s. Epochs from 0 to 0 take 49.42s in average and 49.42s in median.
[06/12 17:37:09][INFO] train_net.py:  714: For epoch 0, each iteraction takes 0.82s in average. From epoch 0 to 0, each iteraction takes 0.82s in average.
[06/12 17:37:27][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.45771, "dt_data": 0.00086, "dt_net": 0.45684, "epoch": "2/300", "eta": "2:16:46", "gpu_mem": "10.06G", "grad_norm": 3.95223, "iter": "10/60", "loss": 2.79238, "lr": 0.0000940238, "top1_acc": 12.50000, "top1_err": 92.18750, "top5_acc": 31.25000, "top5_err": 65.62500}
[06/12 17:37:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46307, "dt_data": 0.00072, "dt_net": 0.46236, "epoch": "2/300", "eta": "2:18:18", "gpu_mem": "10.06G", "grad_norm": 4.20276, "iter": "20/60", "loss": 2.76313, "lr": 0.0001047519, "top1_acc": 12.50000, "top1_err": 90.62500, "top5_acc": 37.50000, "top5_err": 62.50000}
[06/12 17:37:39][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46157, "dt_data": 0.00043, "dt_net": 0.46114, "epoch": "2/300", "eta": "2:17:46", "gpu_mem": "10.06G", "grad_norm": 4.02394, "iter": "30/60", "loss": 2.77126, "lr": 0.0001154800, "top1_acc": 12.50000, "top1_err": 92.18750, "top5_acc": 37.50000, "top5_err": 67.18750}
[06/12 17:37:45][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46460, "dt_data": 0.00049, "dt_net": 0.46411, "epoch": "2/300", "eta": "2:18:36", "gpu_mem": "10.06G", "grad_norm": 4.08904, "iter": "40/60", "loss": 2.76371, "lr": 0.0001262081, "top1_acc": 6.25000, "top1_err": 93.75000, "top5_acc": 37.50000, "top5_err": 65.62500}
[06/12 17:37:51][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46341, "dt_data": 0.00043, "dt_net": 0.46298, "epoch": "2/300", "eta": "2:18:10", "gpu_mem": "10.06G", "grad_norm": 4.01286, "iter": "50/60", "loss": 2.78046, "lr": 0.0001369362, "top1_acc": 9.37500, "top1_err": 90.62500, "top5_acc": 28.12500, "top5_err": 70.31250}
[06/12 17:37:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46158, "dt_data": 0.00017, "dt_net": 0.46141, "epoch": "2/300", "eta": "2:17:33", "gpu_mem": "10.06G", "grad_norm": 4.04497, "iter": "60/60", "loss": 2.75056, "lr": 0.0001476643, "top1_acc": 6.25000, "top1_err": 93.75000, "top5_acc": 40.62500, "top5_err": 60.93750}
[06/12 17:37:57][INFO] logging.py:  101: json_stats: {"RAM": "13.63/31.07G", "_type": "train_epoch", "dt": 0.69301, "dt_data": 0.69301, "dt_net": 0.46141, "epoch": "2/300", "eta": "3:26:30", "gpu_mem": "10.06G", "grad_norm": 4.04497, "loss": 2.76828, "lr": 0.0001476643, "top1_acc": 9.16667, "top1_err": 92.34375, "top5_acc": 35.52083, "top5_err": 65.67708}
[06/12 17:37:57][INFO] train_net.py:  708: Epoch 1 takes 48.03s. Epochs from 0 to 1 take 48.72s in average and 48.72s in median.
[06/12 17:37:57][INFO] train_net.py:  714: For epoch 1, each iteraction takes 0.80s in average. From epoch 0 to 1, each iteraction takes 0.81s in average.
[06/12 17:38:15][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46371, "dt_data": 0.00050, "dt_net": 0.46321, "epoch": "3/300", "eta": "2:18:06", "gpu_mem": "10.06G", "grad_norm": 3.97290, "iter": "10/60", "loss": 2.74186, "lr": 0.0001583924, "top1_acc": 15.62500, "top1_err": 92.18750, "top5_acc": 40.62500, "top5_err": 60.93750}
[06/12 17:38:20][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47421, "dt_data": 0.00055, "dt_net": 0.47366, "epoch": "3/300", "eta": "2:21:09", "gpu_mem": "10.06G", "grad_norm": 4.17168, "iter": "20/60", "loss": 2.75374, "lr": 0.0001691205, "top1_acc": 6.25000, "top1_err": 93.75000, "top5_acc": 34.37500, "top5_err": 60.93750}
[06/12 17:38:27][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46584, "dt_data": 0.00032, "dt_net": 0.46552, "epoch": "3/300", "eta": "2:18:35", "gpu_mem": "10.06G", "grad_norm": 3.96912, "iter": "30/60", "loss": 2.74696, "lr": 0.0001798486, "top1_acc": 6.25000, "top1_err": 90.62500, "top5_acc": 43.75000, "top5_err": 59.37500}
[06/12 17:38:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46777, "dt_data": 0.00044, "dt_net": 0.46733, "epoch": "3/300", "eta": "2:19:04", "gpu_mem": "10.06G", "grad_norm": 3.98427, "iter": "40/60", "loss": 2.75525, "lr": 0.0001905767, "top1_acc": 6.25000, "top1_err": 93.75000, "top5_acc": 40.62500, "top5_err": 64.06250}
[06/12 17:38:39][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47354, "dt_data": 0.00047, "dt_net": 0.47307, "epoch": "3/300", "eta": "2:20:43", "gpu_mem": "10.06G", "grad_norm": 4.05722, "iter": "50/60", "loss": 2.74171, "lr": 0.0002013048, "top1_acc": 12.50000, "top1_err": 90.62500, "top5_acc": 43.75000, "top5_err": 60.93750}
[06/12 17:38:45][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46262, "dt_data": 0.00019, "dt_net": 0.46242, "epoch": "3/300", "eta": "2:17:23", "gpu_mem": "10.06G", "grad_norm": 4.29163, "iter": "60/60", "loss": 2.73560, "lr": 0.0002120328, "top1_acc": 12.50000, "top1_err": 87.50000, "top5_acc": 43.75000, "top5_err": 57.81250}
[06/12 17:38:46][INFO] logging.py:  101: json_stats: {"RAM": "13.63/31.07G", "_type": "train_epoch", "dt": 0.71249, "dt_data": 0.71249, "dt_net": 0.46242, "epoch": "3/300", "eta": "3:31:36", "gpu_mem": "10.06G", "grad_norm": 4.29163, "loss": 2.75039, "lr": 0.0002120328, "top1_acc": 9.58333, "top1_err": 90.57292, "top5_acc": 39.89583, "top5_err": 61.19792}
[06/12 17:38:46][INFO] train_net.py:  708: Epoch 2 takes 48.83s. Epochs from 0 to 2 take 48.76s in average and 48.83s in median.
[06/12 17:38:46][INFO] train_net.py:  714: For epoch 2, each iteraction takes 0.81s in average. From epoch 0 to 2, each iteraction takes 0.81s in average.
[06/12 17:39:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46977, "dt_data": 0.00073, "dt_net": 0.46903, "epoch": "4/300", "eta": "2:19:26", "gpu_mem": "10.06G", "grad_norm": 3.87860, "iter": "10/60", "loss": 2.70494, "lr": 0.0002227609, "top1_acc": 12.50000, "top1_err": 87.50000, "top5_acc": 46.87500, "top5_err": 48.43750}
[06/12 17:39:10][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47526, "dt_data": 0.00478, "dt_net": 0.47048, "epoch": "4/300", "eta": "2:20:59", "gpu_mem": "10.06G", "grad_norm": 4.01322, "iter": "20/60", "loss": 2.73062, "lr": 0.0002334890, "top1_acc": 12.50000, "top1_err": 89.06250, "top5_acc": 43.75000, "top5_err": 57.81250}
[06/12 17:39:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47231, "dt_data": 0.00054, "dt_net": 0.47177, "epoch": "4/300", "eta": "2:20:02", "gpu_mem": "10.06G", "grad_norm": 4.03024, "iter": "30/60", "loss": 2.70269, "lr": 0.0002442171, "top1_acc": 12.50000, "top1_err": 85.93750, "top5_acc": 43.75000, "top5_err": 54.68750}
[06/12 17:39:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47578, "dt_data": 0.00080, "dt_net": 0.47498, "epoch": "4/300", "eta": "2:20:59", "gpu_mem": "10.06G", "grad_norm": 4.06779, "iter": "40/60", "loss": 2.71247, "lr": 0.0002549452, "top1_acc": 15.62500, "top1_err": 82.81250, "top5_acc": 46.87500, "top5_err": 54.68750}
[06/12 17:39:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47035, "dt_data": 0.00065, "dt_net": 0.46970, "epoch": "4/300", "eta": "2:19:18", "gpu_mem": "10.06G", "grad_norm": 4.36242, "iter": "50/60", "loss": 2.71390, "lr": 0.0002656733, "top1_acc": 18.75000, "top1_err": 87.50000, "top5_acc": 50.00000, "top5_err": 59.37500}
[06/12 17:39:34][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46608, "dt_data": 0.00020, "dt_net": 0.46589, "epoch": "4/300", "eta": "2:17:57", "gpu_mem": "10.06G", "grad_norm": 4.32140, "iter": "60/60", "loss": 2.70710, "lr": 0.0002764014, "top1_acc": 9.37500, "top1_err": 85.93750, "top5_acc": 43.75000, "top5_err": 53.12500}
[06/12 17:39:35][INFO] logging.py:  101: json_stats: {"RAM": "13.64/31.07G", "_type": "train_epoch", "dt": 0.71073, "dt_data": 0.71073, "dt_net": 0.46589, "epoch": "4/300", "eta": "3:30:21", "gpu_mem": "10.06G", "grad_norm": 4.32140, "loss": 2.70801, "lr": 0.0002764014, "top1_acc": 13.22917, "top1_err": 86.04167, "top5_acc": 46.87500, "top5_err": 52.81250}
[06/12 17:39:35][INFO] train_net.py:  708: Epoch 3 takes 48.53s. Epochs from 0 to 3 take 48.70s in average and 48.68s in median.
[06/12 17:39:35][INFO] train_net.py:  714: For epoch 3, each iteraction takes 0.81s in average. From epoch 0 to 3, each iteraction takes 0.81s in average.
[06/12 17:39:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.57704, "dt_data": 0.00041, "dt_net": 0.57663, "epoch": "5/300", "eta": "2:50:42", "gpu_mem": "10.06G", "grad_norm": 4.19166, "iter": "10/60", "loss": 2.69528, "lr": 0.0002871295, "top1_acc": 12.50000, "top1_err": 84.37500, "top5_acc": 50.00000, "top5_err": 45.31250}
[06/12 17:39:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47238, "dt_data": 0.00086, "dt_net": 0.47151, "epoch": "5/300", "eta": "2:19:39", "gpu_mem": "10.06G", "grad_norm": 4.16792, "iter": "20/60", "loss": 2.68844, "lr": 0.0002978576, "top1_acc": 18.75000, "top1_err": 85.93750, "top5_acc": 53.12500, "top5_err": 48.43750}
[06/12 17:40:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.23411, "dt_data": 0.00039, "dt_net": 1.23372, "epoch": "5/300", "eta": "6:04:40", "gpu_mem": "10.06G", "grad_norm": 4.41587, "iter": "30/60", "loss": 2.67326, "lr": 0.0003085857, "top1_acc": 21.87500, "top1_err": 79.68750, "top5_acc": 59.37500, "top5_err": 45.31250}
[06/12 17:40:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47335, "dt_data": 0.00044, "dt_net": 0.47291, "epoch": "5/300", "eta": "2:19:47", "gpu_mem": "10.06G", "grad_norm": 4.23051, "iter": "40/60", "loss": 2.63860, "lr": 0.0003193138, "top1_acc": 18.75000, "top1_err": 78.12500, "top5_acc": 59.37500, "top5_err": 45.31250}
[06/12 17:40:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47090, "dt_data": 0.00070, "dt_net": 0.47020, "epoch": "5/300", "eta": "2:18:59", "gpu_mem": "10.06G", "grad_norm": 4.19429, "iter": "50/60", "loss": 2.62242, "lr": 0.0003300419, "top1_acc": 21.87500, "top1_err": 82.81250, "top5_acc": 56.25000, "top5_err": 43.75000}
[06/12 17:40:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46770, "dt_data": 0.00017, "dt_net": 0.46753, "epoch": "5/300", "eta": "2:17:58", "gpu_mem": "10.06G", "grad_norm": 4.45399, "iter": "60/60", "loss": 2.63888, "lr": 0.0003407699, "top1_acc": 25.00000, "top1_err": 81.25000, "top5_acc": 50.00000, "top5_err": 46.87500}
[06/12 17:40:23][INFO] logging.py:  101: json_stats: {"RAM": "13.64/31.07G", "_type": "train_epoch", "dt": 0.70455, "dt_data": 0.70455, "dt_net": 0.46753, "epoch": "5/300", "eta": "3:27:49", "gpu_mem": "10.06G", "grad_norm": 4.45399, "loss": 2.65622, "lr": 0.0003407699, "top1_acc": 19.37500, "top1_err": 81.40625, "top5_acc": 54.16667, "top5_err": 46.30208}
[06/12 17:40:23][INFO] train_net.py:  708: Epoch 4 takes 48.55s. Epochs from 0 to 4 take 48.67s in average and 48.55s in median.
[06/12 17:40:23][INFO] train_net.py:  714: For epoch 4, each iteraction takes 0.81s in average. From epoch 0 to 4, each iteraction takes 0.81s in average.
[06/12 17:40:23][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 17:41:26][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "5/300", "eta": "0:00:00", "gpu_mem": "10.06G", "iter": "10/16", "time_diff": 0.13002, "top1_acc": 23.43750, "top1_err": 76.56250, "top5_acc": 64.06250, "top5_err": 35.93750}
[06/12 17:41:29][INFO] logging.py:  101: json_stats: {"RAM": "13.81/31.07G", "_type": "val_epoch", "epoch": "5/300", "gpu_mem": "10.06G", "min_top1_err": 74.89627, "min_top5_err": 36.51452, "time_diff": 0.61318, "top1_acc": 25.10373, "top1_err": 74.89627, "top5_acc": 63.48548, "top5_err": 36.51452}
[06/12 17:41:47][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46125, "dt_data": 0.00036, "dt_net": 0.46088, "epoch": "6/300", "eta": "2:15:59", "gpu_mem": "10.07G", "grad_norm": 4.52382, "iter": "10/60", "loss": 2.60584, "lr": 0.0003514980, "top1_acc": 28.12500, "top1_err": 78.12500, "top5_acc": 62.50000, "top5_err": 40.62500}
[06/12 17:41:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46738, "dt_data": 0.00057, "dt_net": 0.46681, "epoch": "6/300", "eta": "2:17:43", "gpu_mem": "10.07G", "grad_norm": 4.52295, "iter": "20/60", "loss": 2.58732, "lr": 0.0003622261, "top1_acc": 15.62500, "top1_err": 81.25000, "top5_acc": 56.25000, "top5_err": 42.18750}
[06/12 17:41:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46900, "dt_data": 0.00059, "dt_net": 0.46840, "epoch": "6/300", "eta": "2:18:07", "gpu_mem": "10.07G", "grad_norm": 4.14952, "iter": "30/60", "loss": 2.57775, "lr": 0.0003729542, "top1_acc": 18.75000, "top1_err": 78.12500, "top5_acc": 56.25000, "top5_err": 43.75000}
[06/12 17:42:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46461, "dt_data": 0.00068, "dt_net": 0.46393, "epoch": "6/300", "eta": "2:16:45", "gpu_mem": "10.07G", "grad_norm": 4.19577, "iter": "40/60", "loss": 2.53862, "lr": 0.0003836823, "top1_acc": 25.00000, "top1_err": 71.87500, "top5_acc": 53.12500, "top5_err": 39.06250}
[06/12 17:42:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47466, "dt_data": 0.00066, "dt_net": 0.47400, "epoch": "6/300", "eta": "2:19:37", "gpu_mem": "10.07G", "grad_norm": 4.62729, "iter": "50/60", "loss": 2.53543, "lr": 0.0003944104, "top1_acc": 25.00000, "top1_err": 75.00000, "top5_acc": 68.75000, "top5_err": 35.93750}
[06/12 17:42:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46499, "dt_data": 0.00017, "dt_net": 0.46481, "epoch": "6/300", "eta": "2:16:42", "gpu_mem": "10.07G", "grad_norm": 4.98415, "iter": "60/60", "loss": 2.49090, "lr": 0.0004051385, "top1_acc": 28.12500, "top1_err": 73.43750, "top5_acc": 62.50000, "top5_err": 37.50000}
[06/12 17:42:17][INFO] logging.py:  101: json_stats: {"RAM": "13.63/31.07G", "_type": "train_epoch", "dt": 0.68921, "dt_data": 0.68921, "dt_net": 0.46481, "epoch": "6/300", "eta": "3:22:37", "gpu_mem": "10.07G", "grad_norm": 4.98415, "loss": 2.55808, "lr": 0.0004051385, "top1_acc": 23.64583, "top1_err": 76.40625, "top5_acc": 60.10417, "top5_err": 39.53125}
[06/12 17:42:17][INFO] train_net.py:  708: Epoch 5 takes 48.55s. Epochs from 0 to 5 take 48.65s in average and 48.55s in median.
[06/12 17:42:17][INFO] train_net.py:  714: For epoch 5, each iteraction takes 0.81s in average. From epoch 0 to 5, each iteraction takes 0.81s in average.
[06/12 17:42:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.84780, "dt_data": 0.00048, "dt_net": 0.84732, "epoch": "7/300", "eta": "4:09:06", "gpu_mem": "10.07G", "grad_norm": 4.72869, "iter": "10/60", "loss": 2.53460, "lr": 0.0004158666, "top1_acc": 25.00000, "top1_err": 78.12500, "top5_acc": 59.37500, "top5_err": 39.06250}
[06/12 17:42:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47400, "dt_data": 0.00054, "dt_net": 0.47346, "epoch": "7/300", "eta": "2:19:11", "gpu_mem": "10.07G", "grad_norm": 4.32962, "iter": "20/60", "loss": 2.41805, "lr": 0.0004265947, "top1_acc": 28.12500, "top1_err": 68.75000, "top5_acc": 68.75000, "top5_err": 31.25000}
[06/12 17:42:47][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.87793, "dt_data": 0.00047, "dt_net": 0.87746, "epoch": "7/300", "eta": "4:17:40", "gpu_mem": "10.07G", "grad_norm": 4.76018, "iter": "30/60", "loss": 2.38837, "lr": 0.0004373228, "top1_acc": 31.25000, "top1_err": 68.75000, "top5_acc": 68.75000, "top5_err": 31.25000}
[06/12 17:42:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48536, "dt_data": 0.00037, "dt_net": 0.48499, "epoch": "7/300", "eta": "2:22:22", "gpu_mem": "10.07G", "grad_norm": 4.56071, "iter": "40/60", "loss": 2.40491, "lr": 0.0004480509, "top1_acc": 31.25000, "top1_err": 70.31250, "top5_acc": 65.62500, "top5_err": 34.37500}
[06/12 17:42:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.84751, "dt_data": 0.00031, "dt_net": 0.84720, "epoch": "7/300", "eta": "4:08:27", "gpu_mem": "10.07G", "grad_norm": 4.54466, "iter": "50/60", "loss": 2.22899, "lr": 0.0004587790, "top1_acc": 34.37500, "top1_err": 67.18750, "top5_acc": 78.12500, "top5_err": 21.87500}
[06/12 17:43:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46855, "dt_data": 0.00021, "dt_net": 0.46834, "epoch": "7/300", "eta": "2:17:17", "gpu_mem": "10.07G", "grad_norm": 5.18365, "iter": "60/60", "loss": 2.37168, "lr": 0.0004695070, "top1_acc": 28.12500, "top1_err": 73.43750, "top5_acc": 71.87500, "top5_err": 28.12500}
[06/12 17:43:06][INFO] logging.py:  101: json_stats: {"RAM": "13.63/31.07G", "_type": "train_epoch", "dt": 0.70850, "dt_data": 0.70850, "dt_net": 0.46834, "epoch": "7/300", "eta": "3:27:34", "gpu_mem": "10.07G", "grad_norm": 5.18365, "loss": 2.39805, "lr": 0.0004695070, "top1_acc": 30.20833, "top1_err": 71.04167, "top5_acc": 67.70833, "top5_err": 31.45833}
[06/12 17:43:06][INFO] train_net.py:  708: Epoch 6 takes 48.59s. Epochs from 0 to 6 take 48.64s in average and 48.55s in median.
[06/12 17:43:06][INFO] train_net.py:  714: For epoch 6, each iteraction takes 0.81s in average. From epoch 0 to 6, each iteraction takes 0.81s in average.
[06/12 17:43:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47448, "dt_data": 0.00049, "dt_net": 0.47399, "epoch": "8/300", "eta": "2:18:56", "gpu_mem": "10.07G", "grad_norm": 4.73937, "iter": "10/60", "loss": 2.34351, "lr": 0.0004802351, "top1_acc": 28.12500, "top1_err": 76.56250, "top5_acc": 71.87500, "top5_err": 26.56250}
[06/12 17:43:29][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47033, "dt_data": 0.00052, "dt_net": 0.46981, "epoch": "8/300", "eta": "2:17:39", "gpu_mem": "10.07G", "grad_norm": 4.32174, "iter": "20/60", "loss": 2.19643, "lr": 0.0004909632, "top1_acc": 34.37500, "top1_err": 62.50000, "top5_acc": 75.00000, "top5_err": 25.00000}
[06/12 17:43:36][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.66720, "dt_data": 0.19654, "dt_net": 0.47065, "epoch": "8/300", "eta": "3:15:09", "gpu_mem": "10.07G", "grad_norm": 4.77123, "iter": "30/60", "loss": 2.24609, "lr": 0.0005016913, "top1_acc": 31.25000, "top1_err": 67.18750, "top5_acc": 78.12500, "top5_err": 25.00000}
[06/12 17:43:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47245, "dt_data": 0.00046, "dt_net": 0.47198, "epoch": "8/300", "eta": "2:18:06", "gpu_mem": "10.07G", "grad_norm": 4.77870, "iter": "40/60", "loss": 2.19645, "lr": 0.0005124194, "top1_acc": 31.25000, "top1_err": 68.75000, "top5_acc": 81.25000, "top5_err": 21.87500}
[06/12 17:43:48][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.98840, "dt_data": 0.51618, "dt_net": 0.47221, "epoch": "8/300", "eta": "4:48:46", "gpu_mem": "10.07G", "grad_norm": 4.36400, "iter": "50/60", "loss": 2.14163, "lr": 0.0005231475, "top1_acc": 34.37500, "top1_err": 59.37500, "top5_acc": 78.12500, "top5_err": 18.75000}
[06/12 17:43:54][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46856, "dt_data": 0.00018, "dt_net": 0.46838, "epoch": "8/300", "eta": "2:16:49", "gpu_mem": "10.07G", "grad_norm": 4.47812, "iter": "60/60", "loss": 2.13242, "lr": 0.0005338756, "top1_acc": 34.37500, "top1_err": 67.18750, "top5_acc": 81.25000, "top5_err": 21.87500}
[06/12 17:43:54][INFO] logging.py:  101: json_stats: {"RAM": "13.64/31.07G", "_type": "train_epoch", "dt": 0.71555, "dt_data": 0.71555, "dt_net": 0.46838, "epoch": "8/300", "eta": "3:28:55", "gpu_mem": "10.07G", "grad_norm": 4.47812, "loss": 2.22011, "lr": 0.0005338756, "top1_acc": 34.47917, "top1_err": 66.25000, "top5_acc": 75.72917, "top5_err": 24.11458}
[06/12 17:43:54][INFO] train_net.py:  708: Epoch 7 takes 48.64s. Epochs from 0 to 7 take 48.64s in average and 48.57s in median.
[06/12 17:43:54][INFO] train_net.py:  714: For epoch 7, each iteraction takes 0.81s in average. From epoch 0 to 7, each iteraction takes 0.81s in average.
[06/12 17:44:12][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.73015, "dt_data": 0.00042, "dt_net": 0.72973, "epoch": "9/300", "eta": "3:33:04", "gpu_mem": "10.07G", "grad_norm": 4.96290, "iter": "10/60", "loss": 2.10088, "lr": 0.0005446037, "top1_acc": 31.25000, "top1_err": 64.06250, "top5_acc": 75.00000, "top5_err": 20.31250}
[06/12 17:44:18][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47844, "dt_data": 0.00043, "dt_net": 0.47800, "epoch": "9/300", "eta": "2:19:32", "gpu_mem": "10.07G", "grad_norm": 4.81587, "iter": "20/60", "loss": 2.11028, "lr": 0.0005553318, "top1_acc": 34.37500, "top1_err": 62.50000, "top5_acc": 81.25000, "top5_err": 17.18750}
[06/12 17:44:24][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.06684, "dt_data": 0.00042, "dt_net": 1.06642, "epoch": "9/300", "eta": "5:10:58", "gpu_mem": "10.07G", "grad_norm": 4.79441, "iter": "30/60", "loss": 2.00627, "lr": 0.0005660599, "top1_acc": 40.62500, "top1_err": 59.37500, "top5_acc": 87.50000, "top5_err": 17.18750}
[06/12 17:44:30][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47335, "dt_data": 0.00038, "dt_net": 0.47297, "epoch": "9/300", "eta": "2:17:54", "gpu_mem": "10.07G", "grad_norm": 5.80420, "iter": "40/60", "loss": 2.04583, "lr": 0.0005767880, "top1_acc": 43.75000, "top1_err": 62.50000, "top5_acc": 81.25000, "top5_err": 21.87500}
[06/12 17:44:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.00090, "dt_data": 0.00056, "dt_net": 1.00034, "epoch": "9/300", "eta": "4:51:25", "gpu_mem": "10.07G", "grad_norm": 5.41226, "iter": "50/60", "loss": 2.01209, "lr": 0.0005875161, "top1_acc": 37.50000, "top1_err": 62.50000, "top5_acc": 81.25000, "top5_err": 23.43750}
[06/12 17:44:42][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47112, "dt_data": 0.00030, "dt_net": 0.47082, "epoch": "9/300", "eta": "2:17:05", "gpu_mem": "10.07G", "grad_norm": 5.30998, "iter": "60/60", "loss": 2.06951, "lr": 0.0005982441, "top1_acc": 34.37500, "top1_err": 62.50000, "top5_acc": 81.25000, "top5_err": 15.62500}
[06/12 17:44:43][INFO] logging.py:  101: json_stats: {"RAM": "13.63/31.07G", "_type": "train_epoch", "dt": 0.70926, "dt_data": 0.70926, "dt_net": 0.47082, "epoch": "9/300", "eta": "3:26:22", "gpu_mem": "10.07G", "grad_norm": 5.30998, "loss": 2.04545, "lr": 0.0005982441, "top1_acc": 38.22917, "top1_err": 61.87500, "top5_acc": 80.62500, "top5_err": 19.89583}
[06/12 17:44:43][INFO] train_net.py:  708: Epoch 8 takes 48.62s. Epochs from 0 to 8 take 48.64s in average and 48.59s in median.
[06/12 17:44:43][INFO] train_net.py:  714: For epoch 8, each iteraction takes 0.81s in average. From epoch 0 to 8, each iteraction takes 0.81s in average.
[06/12 17:45:00][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47084, "dt_data": 0.00061, "dt_net": 0.47023, "epoch": "10/300", "eta": "2:16:56", "gpu_mem": "10.07G", "grad_norm": 6.58038, "iter": "10/60", "loss": 1.89881, "lr": 0.0006089722, "top1_acc": 43.75000, "top1_err": 56.25000, "top5_acc": 81.25000, "top5_err": 15.62500}
[06/12 17:45:06][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48264, "dt_data": 0.00056, "dt_net": 0.48208, "epoch": "10/300", "eta": "2:20:17", "gpu_mem": "10.07G", "grad_norm": 5.16328, "iter": "20/60", "loss": 1.89636, "lr": 0.0006197003, "top1_acc": 43.75000, "top1_err": 57.81250, "top5_acc": 81.25000, "top5_err": 18.75000}
[06/12 17:45:12][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46953, "dt_data": 0.00065, "dt_net": 0.46887, "epoch": "10/300", "eta": "2:16:23", "gpu_mem": "10.07G", "grad_norm": 5.28567, "iter": "30/60", "loss": 1.87652, "lr": 0.0006304284, "top1_acc": 43.75000, "top1_err": 59.37500, "top5_acc": 81.25000, "top5_err": 18.75000}
[06/12 17:45:18][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48498, "dt_data": 0.00049, "dt_net": 0.48449, "epoch": "10/300", "eta": "2:20:48", "gpu_mem": "10.07G", "grad_norm": 5.94654, "iter": "40/60", "loss": 1.95806, "lr": 0.0006411565, "top1_acc": 40.62500, "top1_err": 60.93750, "top5_acc": 84.37500, "top5_err": 15.62500}
[06/12 17:45:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47693, "dt_data": 0.00044, "dt_net": 0.47649, "epoch": "10/300", "eta": "2:18:23", "gpu_mem": "10.07G", "grad_norm": 7.03382, "iter": "50/60", "loss": 1.71391, "lr": 0.0006518846, "top1_acc": 46.87500, "top1_err": 54.68750, "top5_acc": 93.75000, "top5_err": 12.50000}
[06/12 17:45:30][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46896, "dt_data": 0.00018, "dt_net": 0.46879, "epoch": "10/300", "eta": "2:15:59", "gpu_mem": "10.07G", "grad_norm": 6.35604, "iter": "60/60", "loss": 1.72857, "lr": 0.0006626127, "top1_acc": 43.75000, "top1_err": 57.81250, "top5_acc": 93.75000, "top5_err": 14.06250}
[06/12 17:45:31][INFO] logging.py:  101: json_stats: {"RAM": "13.64/31.07G", "_type": "train_epoch", "dt": 0.70700, "dt_data": 0.70700, "dt_net": 0.46879, "epoch": "10/300", "eta": "3:25:00", "gpu_mem": "10.07G", "grad_norm": 6.35604, "loss": 1.86093, "lr": 0.0006626127, "top1_acc": 43.02083, "top1_err": 56.82292, "top5_acc": 84.68750, "top5_err": 15.31250}
[06/12 17:45:31][INFO] train_net.py:  708: Epoch 9 takes 48.04s. Epochs from 0 to 9 take 48.58s in average and 48.57s in median.
[06/12 17:45:31][INFO] train_net.py:  714: For epoch 9, each iteraction takes 0.80s in average. From epoch 0 to 9, each iteraction takes 0.81s in average.
[06/12 17:45:31][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 17:46:33][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "10/300", "eta": "0:00:03", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.59230, "top1_acc": 50.00000, "top1_err": 50.00000, "top5_acc": 90.62500, "top5_err": 9.37500}
[06/12 17:46:36][INFO] logging.py:  101: json_stats: {"RAM": "13.64/31.07G", "_type": "val_epoch", "epoch": "10/300", "gpu_mem": "10.07G", "min_top1_err": 49.37759, "min_top5_err": 10.58091, "time_diff": 0.61637, "top1_acc": 50.62241, "top1_err": 49.37759, "top5_acc": 89.41909, "top5_err": 10.58091}
[06/12 17:46:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46665, "dt_data": 0.00106, "dt_net": 0.46558, "epoch": "11/300", "eta": "2:15:15", "gpu_mem": "10.07G", "grad_norm": 7.63064, "iter": "10/60", "loss": 1.65159, "lr": 0.0006733408, "top1_acc": 50.00000, "top1_err": 50.00000, "top5_acc": 90.62500, "top5_err": 10.93750}
[06/12 17:46:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47090, "dt_data": 0.00043, "dt_net": 0.47047, "epoch": "11/300", "eta": "2:16:24", "gpu_mem": "10.07G", "grad_norm": 5.03657, "iter": "20/60", "loss": 1.70211, "lr": 0.0006840689, "top1_acc": 43.75000, "top1_err": 51.56250, "top5_acc": 87.50000, "top5_err": 14.06250}
[06/12 17:47:06][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46747, "dt_data": 0.00047, "dt_net": 0.46700, "epoch": "11/300", "eta": "2:15:19", "gpu_mem": "10.07G", "grad_norm": 9.16701, "iter": "30/60", "loss": 1.69276, "lr": 0.0006947970, "top1_acc": 50.00000, "top1_err": 53.12500, "top5_acc": 90.62500, "top5_err": 9.37500}
[06/12 17:47:12][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47334, "dt_data": 0.00079, "dt_net": 0.47254, "epoch": "11/300", "eta": "2:16:57", "gpu_mem": "10.07G", "grad_norm": 6.42410, "iter": "40/60", "loss": 1.66435, "lr": 0.0007055251, "top1_acc": 46.87500, "top1_err": 56.25000, "top5_acc": 90.62500, "top5_err": 9.37500}
[06/12 17:47:18][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46938, "dt_data": 0.00045, "dt_net": 0.46893, "epoch": "11/300", "eta": "2:15:43", "gpu_mem": "10.07G", "grad_norm": 6.76773, "iter": "50/60", "loss": 1.65043, "lr": 0.0007162532, "top1_acc": 34.37500, "top1_err": 53.12500, "top5_acc": 81.25000, "top5_err": 15.62500}
[06/12 17:47:24][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46386, "dt_data": 0.00016, "dt_net": 0.46369, "epoch": "11/300", "eta": "2:14:03", "gpu_mem": "10.07G", "grad_norm": 6.84101, "iter": "60/60", "loss": 1.74174, "lr": 0.0007269812, "top1_acc": 50.00000, "top1_err": 54.68750, "top5_acc": 84.37500, "top5_err": 20.31250}
[06/12 17:47:25][INFO] logging.py:  101: json_stats: {"RAM": "13.63/31.07G", "_type": "train_epoch", "dt": 0.70025, "dt_data": 0.70025, "dt_net": 0.46369, "epoch": "11/300", "eta": "3:22:21", "gpu_mem": "10.07G", "grad_norm": 6.84101, "loss": 1.70229, "lr": 0.0007269812, "top1_acc": 45.31250, "top1_err": 52.96875, "top5_acc": 86.14583, "top5_err": 13.59375}
[06/12 17:47:25][INFO] train_net.py:  708: Epoch 10 takes 48.29s. Epochs from 0 to 10 take 48.55s in average and 48.55s in median.
[06/12 17:47:25][INFO] train_net.py:  714: For epoch 10, each iteraction takes 0.80s in average. From epoch 0 to 10, each iteraction takes 0.81s in average.
[06/12 17:47:42][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47143, "dt_data": 0.00055, "dt_net": 0.47087, "epoch": "12/300", "eta": "2:16:09", "gpu_mem": "10.07G", "grad_norm": 7.13793, "iter": "10/60", "loss": 1.61822, "lr": 0.0007377093, "top1_acc": 46.87500, "top1_err": 51.56250, "top5_acc": 81.25000, "top5_err": 12.50000}
[06/12 17:47:48][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46901, "dt_data": 0.00038, "dt_net": 0.46863, "epoch": "12/300", "eta": "2:15:23", "gpu_mem": "10.07G", "grad_norm": 7.73632, "iter": "20/60", "loss": 1.51435, "lr": 0.0007484374, "top1_acc": 46.87500, "top1_err": 46.87500, "top5_acc": 90.62500, "top5_err": 7.81250}
[06/12 17:47:54][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48116, "dt_data": 0.00047, "dt_net": 0.48069, "epoch": "12/300", "eta": "2:18:48", "gpu_mem": "10.07G", "grad_norm": 8.32239, "iter": "30/60", "loss": 1.63596, "lr": 0.0007591655, "top1_acc": 43.75000, "top1_err": 54.68750, "top5_acc": 87.50000, "top5_err": 14.06250}
[06/12 17:48:00][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47559, "dt_data": 0.00042, "dt_net": 0.47517, "epoch": "12/300", "eta": "2:17:07", "gpu_mem": "10.07G", "grad_norm": 6.28674, "iter": "40/60", "loss": 1.41680, "lr": 0.0007698936, "top1_acc": 53.12500, "top1_err": 45.31250, "top5_acc": 93.75000, "top5_err": 10.93750}
[06/12 17:48:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47081, "dt_data": 0.00060, "dt_net": 0.47021, "epoch": "12/300", "eta": "2:15:40", "gpu_mem": "10.07G", "grad_norm": 8.24506, "iter": "50/60", "loss": 1.57543, "lr": 0.0007806217, "top1_acc": 53.12500, "top1_err": 48.43750, "top5_acc": 87.50000, "top5_err": 14.06250}
[06/12 17:48:12][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47636, "dt_data": 0.00916, "dt_net": 0.46720, "epoch": "12/300", "eta": "2:17:11", "gpu_mem": "10.07G", "grad_norm": 7.64555, "iter": "60/60", "loss": 1.48035, "lr": 0.0007913498, "top1_acc": 56.25000, "top1_err": 48.43750, "top5_acc": 90.62500, "top5_err": 7.81250}
[06/12 17:48:13][INFO] logging.py:  101: json_stats: {"RAM": "13.63/31.07G", "_type": "train_epoch", "dt": 0.71784, "dt_data": 0.71784, "dt_net": 0.46720, "epoch": "12/300", "eta": "3:26:43", "gpu_mem": "10.07G", "grad_norm": 7.64555, "loss": 1.54578, "lr": 0.0007913498, "top1_acc": 50.00000, "top1_err": 48.85417, "top5_acc": 88.43750, "top5_err": 11.45833}
[06/12 17:48:13][INFO] train_net.py:  708: Epoch 11 takes 48.64s. Epochs from 0 to 11 take 48.56s in average and 48.57s in median.
[06/12 17:48:13][INFO] train_net.py:  714: For epoch 11, each iteraction takes 0.81s in average. From epoch 0 to 11, each iteraction takes 0.81s in average.
[06/12 17:48:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47019, "dt_data": 0.00040, "dt_net": 0.46978, "epoch": "13/300", "eta": "2:15:20", "gpu_mem": "10.07G", "grad_norm": 7.07189, "iter": "10/60", "loss": 1.41278, "lr": 0.0008020779, "top1_acc": 68.75000, "top1_err": 45.31250, "top5_acc": 93.75000, "top5_err": 7.81250}
[06/12 17:48:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47871, "dt_data": 0.00083, "dt_net": 0.47787, "epoch": "13/300", "eta": "2:17:42", "gpu_mem": "10.07G", "grad_norm": 6.56466, "iter": "20/60", "loss": 1.48310, "lr": 0.0008128060, "top1_acc": 46.87500, "top1_err": 45.31250, "top5_acc": 93.75000, "top5_err": 10.93750}
[06/12 17:48:44][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.78466, "dt_data": 0.31382, "dt_net": 0.47084, "epoch": "13/300", "eta": "3:45:35", "gpu_mem": "10.07G", "grad_norm": 6.92091, "iter": "30/60", "loss": 1.44178, "lr": 0.0008235341, "top1_acc": 53.12500, "top1_err": 46.87500, "top5_acc": 87.50000, "top5_err": 12.50000}
[06/12 17:48:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47213, "dt_data": 0.00059, "dt_net": 0.47154, "epoch": "13/300", "eta": "2:15:39", "gpu_mem": "10.07G", "grad_norm": 7.38242, "iter": "40/60", "loss": 1.42828, "lr": 0.0008342622, "top1_acc": 50.00000, "top1_err": 48.43750, "top5_acc": 87.50000, "top5_err": 7.81250}
[06/12 17:48:56][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.66090, "dt_data": 0.18960, "dt_net": 0.47129, "epoch": "13/300", "eta": "3:09:47", "gpu_mem": "10.07G", "grad_norm": 6.92045, "iter": "50/60", "loss": 1.43357, "lr": 0.0008449903, "top1_acc": 50.00000, "top1_err": 43.75000, "top5_acc": 90.62500, "top5_err": 12.50000}
[06/12 17:49:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46812, "dt_data": 0.00017, "dt_net": 0.46795, "epoch": "13/300", "eta": "2:14:21", "gpu_mem": "10.07G", "grad_norm": 6.66878, "iter": "60/60", "loss": 1.32294, "lr": 0.0008557183, "top1_acc": 62.50000, "top1_err": 50.00000, "top5_acc": 93.75000, "top5_err": 12.50000}
[06/12 17:49:02][INFO] logging.py:  101: json_stats: {"RAM": "13.63/31.07G", "_type": "train_epoch", "dt": 0.70345, "dt_data": 0.70345, "dt_net": 0.46795, "epoch": "13/300", "eta": "3:21:52", "gpu_mem": "10.07G", "grad_norm": 6.66878, "loss": 1.42556, "lr": 0.0008557183, "top1_acc": 53.64583, "top1_err": 45.93750, "top5_acc": 90.00000, "top5_err": 10.57292}
[06/12 17:49:02][INFO] train_net.py:  708: Epoch 12 takes 48.90s. Epochs from 0 to 12 take 48.59s in average and 48.59s in median.
[06/12 17:49:02][INFO] train_net.py:  714: For epoch 12, each iteraction takes 0.81s in average. From epoch 0 to 12, each iteraction takes 0.81s in average.
[06/12 17:49:20][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48311, "dt_data": 0.00074, "dt_net": 0.48237, "epoch": "14/300", "eta": "2:18:34", "gpu_mem": "10.07G", "grad_norm": 7.28355, "iter": "10/60", "loss": 1.29875, "lr": 0.0008664464, "top1_acc": 56.25000, "top1_err": 40.62500, "top5_acc": 87.50000, "top5_err": 9.37500}
[06/12 17:49:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47147, "dt_data": 0.00176, "dt_net": 0.46969, "epoch": "14/300", "eta": "2:15:09", "gpu_mem": "10.07G", "grad_norm": 8.93958, "iter": "20/60", "loss": 1.31376, "lr": 0.0008771745, "top1_acc": 59.37500, "top1_err": 43.75000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/12 17:49:32][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47233, "dt_data": 0.00057, "dt_net": 0.47175, "epoch": "14/300", "eta": "2:15:19", "gpu_mem": "10.07G", "grad_norm": 7.07121, "iter": "30/60", "loss": 1.38226, "lr": 0.0008879026, "top1_acc": 56.25000, "top1_err": 45.31250, "top5_acc": 90.62500, "top5_err": 7.81250}
[06/12 17:49:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47637, "dt_data": 0.00045, "dt_net": 0.47593, "epoch": "14/300", "eta": "2:16:24", "gpu_mem": "10.07G", "grad_norm": 8.47579, "iter": "40/60", "loss": 1.40231, "lr": 0.0008986307, "top1_acc": 56.25000, "top1_err": 43.75000, "top5_acc": 87.50000, "top5_err": 9.37500}
[06/12 17:49:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47447, "dt_data": 0.00049, "dt_net": 0.47398, "epoch": "14/300", "eta": "2:15:46", "gpu_mem": "10.07G", "grad_norm": 8.45681, "iter": "50/60", "loss": 1.32523, "lr": 0.0009093588, "top1_acc": 53.12500, "top1_err": 45.31250, "top5_acc": 90.62500, "top5_err": 6.25000}
[06/12 17:49:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46888, "dt_data": 0.00018, "dt_net": 0.46870, "epoch": "14/300", "eta": "2:14:06", "gpu_mem": "10.07G", "grad_norm": 8.38097, "iter": "60/60", "loss": 1.22489, "lr": 0.0009200869, "top1_acc": 62.50000, "top1_err": 37.50000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/12 17:49:50][INFO] logging.py:  101: json_stats: {"RAM": "13.63/31.07G", "_type": "train_epoch", "dt": 0.72192, "dt_data": 0.72192, "dt_net": 0.46870, "epoch": "14/300", "eta": "3:26:27", "gpu_mem": "10.07G", "grad_norm": 8.38097, "loss": 1.32368, "lr": 0.0009200869, "top1_acc": 57.50000, "top1_err": 42.55208, "top5_acc": 90.20833, "top5_err": 8.38542}
[06/12 17:49:50][INFO] train_net.py:  708: Epoch 13 takes 47.76s. Epochs from 0 to 13 take 48.53s in average and 48.57s in median.
[06/12 17:49:50][INFO] train_net.py:  714: For epoch 13, each iteraction takes 0.80s in average. From epoch 0 to 13, each iteraction takes 0.81s in average.
[06/12 17:50:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46801, "dt_data": 0.00051, "dt_net": 0.46749, "epoch": "15/300", "eta": "2:13:46", "gpu_mem": "10.07G", "grad_norm": 9.14690, "iter": "10/60", "loss": 1.33072, "lr": 0.0009308150, "top1_acc": 65.62500, "top1_err": 40.62500, "top5_acc": 93.75000, "top5_err": 10.93750}
[06/12 17:50:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47553, "dt_data": 0.00086, "dt_net": 0.47466, "epoch": "15/300", "eta": "2:15:50", "gpu_mem": "10.07G", "grad_norm": 7.72686, "iter": "20/60", "loss": 1.25385, "lr": 0.0009415431, "top1_acc": 56.25000, "top1_err": 42.18750, "top5_acc": 93.75000, "top5_err": 7.81250}
[06/12 17:50:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.91618, "dt_data": 0.44509, "dt_net": 0.47108, "epoch": "15/300", "eta": "4:21:34", "gpu_mem": "10.07G", "grad_norm": 8.61062, "iter": "30/60", "loss": 1.26721, "lr": 0.0009522712, "top1_acc": 59.37500, "top1_err": 43.75000, "top5_acc": 90.62500, "top5_err": 9.37500}
[06/12 17:50:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.73047, "dt_data": 0.25869, "dt_net": 0.47177, "epoch": "15/300", "eta": "3:28:25", "gpu_mem": "10.07G", "grad_norm": 8.61641, "iter": "40/60", "loss": 1.28277, "lr": 0.0009629993, "top1_acc": 62.50000, "top1_err": 37.50000, "top5_acc": 96.87500, "top5_err": 7.81250}
[06/12 17:50:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.00968, "dt_data": 0.53222, "dt_net": 0.47745, "epoch": "15/300", "eta": "4:47:55", "gpu_mem": "10.07G", "grad_norm": 6.76604, "iter": "50/60", "loss": 1.20679, "lr": 0.0009737274, "top1_acc": 68.75000, "top1_err": 39.06250, "top5_acc": 93.75000, "top5_err": 7.81250}
[06/12 17:50:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.02241, "dt_data": 0.54502, "dt_net": 0.47738, "epoch": "15/300", "eta": "4:51:23", "gpu_mem": "10.07G", "grad_norm": 8.24127, "iter": "60/60", "loss": 1.23119, "lr": 0.0009844554, "top1_acc": 65.62500, "top1_err": 40.62500, "top5_acc": 90.62500, "top5_err": 12.50000}
[06/12 17:50:37][INFO] logging.py:  101: json_stats: {"RAM": "13.63/31.07G", "_type": "train_epoch", "dt": 0.70061, "dt_data": 0.70061, "dt_net": 0.47738, "epoch": "15/300", "eta": "3:19:39", "gpu_mem": "10.07G", "grad_norm": 8.24127, "loss": 1.25320, "lr": 0.0009844554, "top1_acc": 59.16667, "top1_err": 40.88542, "top5_acc": 92.70833, "top5_err": 9.01042}
[06/12 17:50:37][INFO] train_net.py:  708: Epoch 14 takes 47.69s. Epochs from 0 to 14 take 48.47s in average and 48.55s in median.
[06/12 17:50:37][INFO] train_net.py:  714: For epoch 14, each iteraction takes 0.79s in average. From epoch 0 to 14, each iteraction takes 0.81s in average.
[06/12 17:50:37][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 17:51:39][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "15/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.12991, "top1_acc": 62.50000, "top1_err": 37.50000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/12 17:51:42][INFO] logging.py:  101: json_stats: {"RAM": "13.64/31.07G", "_type": "val_epoch", "epoch": "15/300", "gpu_mem": "10.07G", "min_top1_err": 38.38174, "min_top5_err": 8.09129, "time_diff": 0.60650, "top1_acc": 61.61826, "top1_err": 38.38174, "top5_acc": 91.90871, "top5_err": 8.09129}
[06/12 17:52:00][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46797, "dt_data": 0.00053, "dt_net": 0.46744, "epoch": "16/300", "eta": "2:13:17", "gpu_mem": "10.07G", "grad_norm": 7.89507, "iter": "10/60", "loss": 1.09460, "lr": 0.0009951835, "top1_acc": 62.50000, "top1_err": 40.62500, "top5_acc": 96.87500, "top5_err": 4.68750}
[06/12 17:52:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46587, "dt_data": 0.00049, "dt_net": 0.46538, "epoch": "16/300", "eta": "2:12:37", "gpu_mem": "10.07G", "grad_norm": 7.93588, "iter": "20/60", "loss": 1.17115, "lr": 0.0010059116, "top1_acc": 65.62500, "top1_err": 32.81250, "top5_acc": 90.62500, "top5_err": 7.81250}
[06/12 17:52:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46763, "dt_data": 0.00035, "dt_net": 0.46728, "epoch": "16/300", "eta": "2:13:02", "gpu_mem": "10.07G", "grad_norm": 9.67300, "iter": "30/60", "loss": 1.03092, "lr": 0.0010166397, "top1_acc": 62.50000, "top1_err": 35.93750, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/12 17:52:17][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46719, "dt_data": 0.00042, "dt_net": 0.46677, "epoch": "16/300", "eta": "2:12:50", "gpu_mem": "10.07G", "grad_norm": 9.21311, "iter": "40/60", "loss": 1.04759, "lr": 0.0010273678, "top1_acc": 68.75000, "top1_err": 31.25000, "top5_acc": 93.75000, "top5_err": 4.68750}
[06/12 17:52:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47196, "dt_data": 0.00080, "dt_net": 0.47116, "epoch": "16/300", "eta": "2:14:06", "gpu_mem": "10.07G", "grad_norm": 9.06393, "iter": "50/60", "loss": 1.36840, "lr": 0.0010380959, "top1_acc": 62.50000, "top1_err": 42.18750, "top5_acc": 93.75000, "top5_err": 9.37500}
[06/12 17:52:30][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.60997, "dt_data": 0.14448, "dt_net": 0.46548, "epoch": "16/300", "eta": "2:53:13", "gpu_mem": "10.07G", "grad_norm": 8.51580, "iter": "60/60", "loss": 1.13989, "lr": 0.0010488240, "top1_acc": 59.37500, "top1_err": 37.50000, "top5_acc": 90.62500, "top5_err": 7.81250}
[06/12 17:52:30][INFO] logging.py:  101: json_stats: {"RAM": "13.64/31.07G", "_type": "train_epoch", "dt": 0.70946, "dt_data": 0.70946, "dt_net": 0.46548, "epoch": "16/300", "eta": "3:21:28", "gpu_mem": "10.07G", "grad_norm": 8.51580, "loss": 1.14638, "lr": 0.0010488240, "top1_acc": 61.45833, "top1_err": 37.29167, "top5_acc": 92.08333, "top5_err": 7.60417}
[06/12 17:52:30][INFO] train_net.py:  708: Epoch 15 takes 47.90s. Epochs from 0 to 15 take 48.43s in average and 48.55s in median.
[06/12 17:52:30][INFO] train_net.py:  714: For epoch 15, each iteraction takes 0.80s in average. From epoch 0 to 15, each iteraction takes 0.81s in average.
[06/12 17:52:48][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.81780, "dt_data": 0.34527, "dt_net": 0.47252, "epoch": "17/300", "eta": "3:52:07", "gpu_mem": "10.07G", "grad_norm": 8.31843, "iter": "10/60", "loss": 1.13324, "lr": 0.0010595521, "top1_acc": 65.62500, "top1_err": 34.37500, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/12 17:52:54][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47277, "dt_data": 0.00042, "dt_net": 0.47235, "epoch": "17/300", "eta": "2:14:06", "gpu_mem": "10.07G", "grad_norm": 6.33024, "iter": "20/60", "loss": 1.01695, "lr": 0.0010702802, "top1_acc": 71.87500, "top1_err": 31.25000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/12 17:53:00][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.78132, "dt_data": 1.31186, "dt_net": 0.46946, "epoch": "17/300", "eta": "8:25:00", "gpu_mem": "10.07G", "grad_norm": 10.56907, "iter": "30/60", "loss": 1.04556, "lr": 0.0010810083, "top1_acc": 62.50000, "top1_err": 34.37500, "top5_acc": 87.50000, "top5_err": 7.81250}
[06/12 17:53:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47105, "dt_data": 0.00033, "dt_net": 0.47072, "epoch": "17/300", "eta": "2:13:27", "gpu_mem": "10.07G", "grad_norm": 8.82924, "iter": "40/60", "loss": 1.10860, "lr": 0.0010917364, "top1_acc": 62.50000, "top1_err": 35.93750, "top5_acc": 87.50000, "top5_err": 7.81250}
[06/12 17:53:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.09606, "dt_data": 0.62742, "dt_net": 0.46864, "epoch": "17/300", "eta": "5:10:22", "gpu_mem": "10.07G", "grad_norm": 8.70800, "iter": "50/60", "loss": 0.98671, "lr": 0.0011024645, "top1_acc": 68.75000, "top1_err": 31.25000, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 17:53:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46687, "dt_data": 0.00016, "dt_net": 0.46672, "epoch": "17/300", "eta": "2:12:07", "gpu_mem": "10.07G", "grad_norm": 7.63535, "iter": "60/60", "loss": 1.09550, "lr": 0.0011131926, "top1_acc": 68.75000, "top1_err": 35.93750, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/12 17:53:19][INFO] logging.py:  101: json_stats: {"RAM": "13.62/31.07G", "_type": "train_epoch", "dt": 0.69424, "dt_data": 0.69424, "dt_net": 0.46672, "epoch": "17/300", "eta": "3:16:27", "gpu_mem": "10.07G", "grad_norm": 7.63535, "loss": 1.07627, "lr": 0.0011131926, "top1_acc": 64.68750, "top1_err": 34.32292, "top5_acc": 92.81250, "top5_err": 6.97917}
[06/12 17:53:19][INFO] train_net.py:  708: Epoch 16 takes 48.93s. Epochs from 0 to 16 take 48.46s in average and 48.55s in median.
[06/12 17:53:19][INFO] train_net.py:  714: For epoch 16, each iteraction takes 0.82s in average. From epoch 0 to 16, each iteraction takes 0.81s in average.
[06/12 17:53:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46753, "dt_data": 0.00038, "dt_net": 0.46715, "epoch": "18/300", "eta": "2:12:13", "gpu_mem": "10.07G", "grad_norm": 7.90969, "iter": "10/60", "loss": 1.08736, "lr": 0.0011239206, "top1_acc": 62.50000, "top1_err": 37.50000, "top5_acc": 93.75000, "top5_err": 4.68750}
[06/12 17:53:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47949, "dt_data": 0.00091, "dt_net": 0.47856, "epoch": "18/300", "eta": "2:15:32", "gpu_mem": "10.07G", "grad_norm": 8.34762, "iter": "20/60", "loss": 1.08922, "lr": 0.0011346487, "top1_acc": 68.75000, "top1_err": 34.37500, "top5_acc": 90.62500, "top5_err": 7.81250}
[06/12 17:53:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47410, "dt_data": 0.00033, "dt_net": 0.47377, "epoch": "18/300", "eta": "2:13:55", "gpu_mem": "10.07G", "grad_norm": 6.58775, "iter": "30/60", "loss": 1.07534, "lr": 0.0011453768, "top1_acc": 62.50000, "top1_err": 35.93750, "top5_acc": 93.75000, "top5_err": 4.68750}
[06/12 17:53:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47416, "dt_data": 0.00083, "dt_net": 0.47332, "epoch": "18/300", "eta": "2:13:52", "gpu_mem": "10.07G", "grad_norm": 9.40672, "iter": "40/60", "loss": 1.03373, "lr": 0.0011561049, "top1_acc": 62.50000, "top1_err": 34.37500, "top5_acc": 90.62500, "top5_err": 7.81250}
[06/12 17:54:03][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.76337, "dt_data": 0.00035, "dt_net": 0.76302, "epoch": "18/300", "eta": "3:35:23", "gpu_mem": "10.07G", "grad_norm": 8.87609, "iter": "50/60", "loss": 1.04379, "lr": 0.0011668330, "top1_acc": 68.75000, "top1_err": 37.50000, "top5_acc": 100.00000, "top5_err": 6.25000}
[06/12 17:54:09][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46796, "dt_data": 0.00020, "dt_net": 0.46776, "epoch": "18/300", "eta": "2:11:57", "gpu_mem": "10.07G", "grad_norm": 9.31788, "iter": "60/60", "loss": 0.97073, "lr": 0.0011775611, "top1_acc": 65.62500, "top1_err": 34.37500, "top5_acc": 93.75000, "top5_err": 4.68750}
[06/12 17:54:09][INFO] logging.py:  101: json_stats: {"RAM": "13.64/31.07G", "_type": "train_epoch", "dt": 0.71159, "dt_data": 0.71159, "dt_net": 0.46776, "epoch": "18/300", "eta": "3:20:39", "gpu_mem": "10.07G", "grad_norm": 9.31788, "loss": 1.05324, "lr": 0.0011775611, "top1_acc": 64.47917, "top1_err": 35.26042, "top5_acc": 93.95833, "top5_err": 6.45833}
[06/12 17:54:09][INFO] train_net.py:  708: Epoch 17 takes 50.12s. Epochs from 0 to 17 take 48.56s in average and 48.57s in median.
[06/12 17:54:09][INFO] train_net.py:  714: For epoch 17, each iteraction takes 0.84s in average. From epoch 0 to 17, each iteraction takes 0.81s in average.
[06/12 17:54:27][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47181, "dt_data": 0.00039, "dt_net": 0.47141, "epoch": "19/300", "eta": "2:12:58", "gpu_mem": "10.07G", "grad_norm": 7.58936, "iter": "10/60", "loss": 0.87633, "lr": 0.0011882892, "top1_acc": 68.75000, "top1_err": 31.25000, "top5_acc": 96.87500, "top5_err": 4.68750}
[06/12 17:54:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47203, "dt_data": 0.00037, "dt_net": 0.47165, "epoch": "19/300", "eta": "2:12:57", "gpu_mem": "10.07G", "grad_norm": 7.82180, "iter": "20/60", "loss": 1.06508, "lr": 0.0011990173, "top1_acc": 68.75000, "top1_err": 32.81250, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/12 17:54:39][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47169, "dt_data": 0.00047, "dt_net": 0.47122, "epoch": "19/300", "eta": "2:12:46", "gpu_mem": "10.07G", "grad_norm": 6.40778, "iter": "30/60", "loss": 0.87365, "lr": 0.0012097454, "top1_acc": 68.75000, "top1_err": 31.25000, "top5_acc": 96.87500, "top5_err": 4.68750}
[06/12 17:54:45][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47136, "dt_data": 0.00065, "dt_net": 0.47070, "epoch": "19/300", "eta": "2:12:36", "gpu_mem": "10.07G", "grad_norm": 7.94536, "iter": "40/60", "loss": 0.84046, "lr": 0.0012204735, "top1_acc": 71.87500, "top1_err": 26.56250, "top5_acc": 93.75000, "top5_err": 3.12500}
[06/12 17:54:51][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.87239, "dt_data": 0.40069, "dt_net": 0.47170, "epoch": "19/300", "eta": "4:05:17", "gpu_mem": "10.07G", "grad_norm": 7.96157, "iter": "50/60", "loss": 0.99393, "lr": 0.0012312016, "top1_acc": 65.62500, "top1_err": 34.37500, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/12 17:54:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46998, "dt_data": 0.00020, "dt_net": 0.46978, "epoch": "19/300", "eta": "2:12:03", "gpu_mem": "10.07G", "grad_norm": 6.42639, "iter": "60/60", "loss": 0.98804, "lr": 0.0012419297, "top1_acc": 71.87500, "top1_err": 31.25000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/12 17:54:57][INFO] logging.py:  101: json_stats: {"RAM": "13.64/31.07G", "_type": "train_epoch", "dt": 0.70922, "dt_data": 0.70922, "dt_net": 0.46978, "epoch": "19/300", "eta": "3:19:17", "gpu_mem": "10.07G", "grad_norm": 6.42639, "loss": 0.96079, "lr": 0.0012419297, "top1_acc": 66.97917, "top1_err": 31.77083, "top5_acc": 93.64583, "top5_err": 5.78125}
[06/12 17:54:57][INFO] train_net.py:  708: Epoch 18 takes 47.96s. Epochs from 0 to 18 take 48.52s in average and 48.55s in median.
[06/12 17:54:57][INFO] train_net.py:  714: For epoch 18, each iteraction takes 0.80s in average. From epoch 0 to 18, each iteraction takes 0.81s in average.
[06/12 17:55:15][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47189, "dt_data": 0.00055, "dt_net": 0.47134, "epoch": "20/300", "eta": "2:12:31", "gpu_mem": "10.07G", "grad_norm": 11.55861, "iter": "10/60", "loss": 0.78100, "lr": 0.0012526577, "top1_acc": 75.00000, "top1_err": 26.56250, "top5_acc": 96.87500, "top5_err": 4.68750}
[06/12 17:55:20][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47145, "dt_data": 0.00035, "dt_net": 0.47110, "epoch": "20/300", "eta": "2:12:19", "gpu_mem": "10.07G", "grad_norm": 9.26146, "iter": "20/60", "loss": 0.95610, "lr": 0.0012633858, "top1_acc": 65.62500, "top1_err": 31.25000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/12 17:55:27][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.98868, "dt_data": 0.51963, "dt_net": 0.46904, "epoch": "20/300", "eta": "4:37:19", "gpu_mem": "10.07G", "grad_norm": 7.96225, "iter": "30/60", "loss": 0.92878, "lr": 0.0012741139, "top1_acc": 68.75000, "top1_err": 34.37500, "top5_acc": 93.75000, "top5_err": 4.68750}
[06/12 17:55:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47273, "dt_data": 0.00069, "dt_net": 0.47203, "epoch": "20/300", "eta": "2:12:31", "gpu_mem": "10.07G", "grad_norm": 9.70287, "iter": "40/60", "loss": 0.94397, "lr": 0.0012848420, "top1_acc": 68.75000, "top1_err": 32.81250, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/12 17:55:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.15018, "dt_data": 0.67371, "dt_net": 0.47647, "epoch": "20/300", "eta": "5:22:14", "gpu_mem": "10.07G", "grad_norm": 10.74718, "iter": "50/60", "loss": 0.96982, "lr": 0.0012955701, "top1_acc": 68.75000, "top1_err": 29.68750, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/12 17:55:45][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46905, "dt_data": 0.00017, "dt_net": 0.46888, "epoch": "20/300", "eta": "2:11:20", "gpu_mem": "10.07G", "grad_norm": 10.83249, "iter": "60/60", "loss": 0.91595, "lr": 0.0013062982, "top1_acc": 68.75000, "top1_err": 28.12500, "top5_acc": 93.75000, "top5_err": 7.81250}
[06/12 17:55:46][INFO] logging.py:  101: json_stats: {"RAM": "13.65/31.07G", "_type": "train_epoch", "dt": 0.75043, "dt_data": 0.75043, "dt_net": 0.46888, "epoch": "20/300", "eta": "3:30:05", "gpu_mem": "10.07G", "grad_norm": 10.83249, "loss": 0.92666, "lr": 0.0013062982, "top1_acc": 69.47917, "top1_err": 30.62500, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/12 17:55:46][INFO] train_net.py:  708: Epoch 19 takes 48.45s. Epochs from 0 to 19 take 48.52s in average and 48.55s in median.
[06/12 17:55:46][INFO] train_net.py:  714: For epoch 19, each iteraction takes 0.81s in average. From epoch 0 to 19, each iteraction takes 0.81s in average.
[06/12 17:55:46][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 17:56:47][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "20/300", "eta": "0:00:01", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.20867, "top1_acc": 67.18750, "top1_err": 32.81250, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/12 17:56:50][INFO] logging.py:  101: json_stats: {"RAM": "13.66/31.07G", "_type": "val_epoch", "epoch": "20/300", "gpu_mem": "10.07G", "min_top1_err": 35.68465, "min_top5_err": 7.88382, "time_diff": 0.60854, "top1_acc": 64.31535, "top1_err": 35.68465, "top5_acc": 92.11618, "top5_err": 7.88382}
[06/12 17:57:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46570, "dt_data": 0.00048, "dt_net": 0.46522, "epoch": "21/300", "eta": "2:10:19", "gpu_mem": "10.07G", "grad_norm": 6.11147, "iter": "10/60", "loss": 0.80134, "lr": 0.0013170263, "top1_acc": 75.00000, "top1_err": 28.12500, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 17:57:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46646, "dt_data": 0.00034, "dt_net": 0.46611, "epoch": "21/300", "eta": "2:10:27", "gpu_mem": "10.07G", "grad_norm": 8.09131, "iter": "20/60", "loss": 0.79429, "lr": 0.0013277544, "top1_acc": 75.00000, "top1_err": 23.43750, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/12 17:57:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.09503, "dt_data": 0.00037, "dt_net": 1.09466, "epoch": "21/300", "eta": "5:06:03", "gpu_mem": "10.07G", "grad_norm": 9.21249, "iter": "30/60", "loss": 0.97988, "lr": 0.0013384825, "top1_acc": 68.75000, "top1_err": 31.25000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/12 17:57:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46981, "dt_data": 0.00043, "dt_net": 0.46937, "epoch": "21/300", "eta": "2:11:13", "gpu_mem": "10.07G", "grad_norm": 12.25697, "iter": "40/60", "loss": 0.84211, "lr": 0.0013492106, "top1_acc": 68.75000, "top1_err": 28.12500, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 17:57:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.68488, "dt_data": 0.00065, "dt_net": 0.68422, "epoch": "21/300", "eta": "3:11:11", "gpu_mem": "10.07G", "grad_norm": 8.81979, "iter": "50/60", "loss": 0.79975, "lr": 0.0013599387, "top1_acc": 71.87500, "top1_err": 29.68750, "top5_acc": 100.00000, "top5_err": 4.68750}
[06/12 17:57:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46597, "dt_data": 0.00016, "dt_net": 0.46581, "epoch": "21/300", "eta": "2:10:00", "gpu_mem": "10.07G", "grad_norm": 8.91678, "iter": "60/60", "loss": 0.78210, "lr": 0.0013706668, "top1_acc": 71.87500, "top1_err": 23.43750, "top5_acc": 93.75000, "top5_err": 3.12500}
[06/12 17:57:38][INFO] logging.py:  101: json_stats: {"RAM": "13.65/31.07G", "_type": "train_epoch", "dt": 0.72673, "dt_data": 0.72673, "dt_net": 0.46581, "epoch": "21/300", "eta": "3:22:44", "gpu_mem": "10.07G", "grad_norm": 8.91678, "loss": 0.85777, "lr": 0.0013706668, "top1_acc": 70.83333, "top1_err": 27.13542, "top5_acc": 95.31250, "top5_err": 4.94792}
[06/12 17:57:38][INFO] train_net.py:  708: Epoch 20 takes 47.93s. Epochs from 0 to 20 take 48.49s in average and 48.55s in median.
[06/12 17:57:38][INFO] train_net.py:  714: For epoch 20, each iteraction takes 0.80s in average. From epoch 0 to 20, each iteraction takes 0.81s in average.
[06/12 17:57:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.75194, "dt_data": 0.28317, "dt_net": 0.46877, "epoch": "22/300", "eta": "3:29:39", "gpu_mem": "10.07G", "grad_norm": 13.68778, "iter": "10/60", "loss": 0.90101, "lr": 0.0013813948, "top1_acc": 71.87500, "top1_err": 21.87500, "top5_acc": 96.87500, "top5_err": 4.68750}
[06/12 17:58:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47070, "dt_data": 0.00069, "dt_net": 0.46999, "epoch": "22/300", "eta": "2:11:10", "gpu_mem": "10.07G", "grad_norm": 9.49411, "iter": "20/60", "loss": 0.97471, "lr": 0.0013921229, "top1_acc": 68.75000, "top1_err": 34.37500, "top5_acc": 90.62500, "top5_err": 9.37500}
[06/12 17:58:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.79993, "dt_data": 0.00038, "dt_net": 0.79955, "epoch": "22/300", "eta": "3:42:46", "gpu_mem": "10.07G", "grad_norm": 9.79283, "iter": "30/60", "loss": 0.84612, "lr": 0.0014028510, "top1_acc": 75.00000, "top1_err": 29.68750, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 17:58:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47788, "dt_data": 0.00066, "dt_net": 0.47722, "epoch": "22/300", "eta": "2:13:00", "gpu_mem": "10.07G", "grad_norm": 6.99908, "iter": "40/60", "loss": 0.85439, "lr": 0.0014135791, "top1_acc": 75.00000, "top1_err": 28.12500, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 17:58:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.92689, "dt_data": 0.00036, "dt_net": 0.92653, "epoch": "22/300", "eta": "4:17:49", "gpu_mem": "10.07G", "grad_norm": 9.27677, "iter": "50/60", "loss": 0.72384, "lr": 0.0014243072, "top1_acc": 78.12500, "top1_err": 25.00000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 17:58:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46780, "dt_data": 0.00017, "dt_net": 0.46763, "epoch": "22/300", "eta": "2:10:02", "gpu_mem": "10.07G", "grad_norm": 10.35827, "iter": "60/60", "loss": 0.86623, "lr": 0.0014350353, "top1_acc": 81.25000, "top1_err": 25.00000, "top5_acc": 96.87500, "top5_err": 6.25000}
[06/12 17:58:25][INFO] logging.py:  101: json_stats: {"RAM": "13.66/31.07G", "_type": "train_epoch", "dt": 0.69854, "dt_data": 0.69854, "dt_net": 0.46763, "epoch": "22/300", "eta": "3:14:11", "gpu_mem": "10.07G", "grad_norm": 10.35827, "loss": 0.84459, "lr": 0.0014350353, "top1_acc": 73.54167, "top1_err": 26.66667, "top5_acc": 95.20833, "top5_err": 4.84375}
[06/12 17:58:25][INFO] train_net.py:  708: Epoch 21 takes 47.53s. Epochs from 0 to 21 take 48.45s in average and 48.54s in median.
[06/12 17:58:25][INFO] train_net.py:  714: For epoch 21, each iteraction takes 0.79s in average. From epoch 0 to 21, each iteraction takes 0.81s in average.
[06/12 17:58:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47575, "dt_data": 0.00041, "dt_net": 0.47534, "epoch": "23/300", "eta": "2:12:10", "gpu_mem": "10.07G", "grad_norm": 10.14167, "iter": "10/60", "loss": 0.73430, "lr": 0.0014457634, "top1_acc": 87.50000, "top1_err": 18.75000, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 17:58:48][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47401, "dt_data": 0.00052, "dt_net": 0.47348, "epoch": "23/300", "eta": "2:11:36", "gpu_mem": "10.07G", "grad_norm": 10.57835, "iter": "20/60", "loss": 0.79285, "lr": 0.0014564915, "top1_acc": 68.75000, "top1_err": 21.87500, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/12 17:58:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47063, "dt_data": 0.00058, "dt_net": 0.47005, "epoch": "23/300", "eta": "2:10:35", "gpu_mem": "10.07G", "grad_norm": 9.56612, "iter": "30/60", "loss": 0.77150, "lr": 0.0014672196, "top1_acc": 75.00000, "top1_err": 23.43750, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/12 17:59:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47296, "dt_data": 0.00051, "dt_net": 0.47245, "epoch": "23/300", "eta": "2:11:10", "gpu_mem": "10.07G", "grad_norm": 9.50127, "iter": "40/60", "loss": 0.81055, "lr": 0.0014779477, "top1_acc": 75.00000, "top1_err": 28.12500, "top5_acc": 96.87500, "top5_err": 6.25000}
[06/12 17:59:08][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47405, "dt_data": 0.00054, "dt_net": 0.47351, "epoch": "23/300", "eta": "2:11:23", "gpu_mem": "10.07G", "grad_norm": 8.57950, "iter": "50/60", "loss": 0.78624, "lr": 0.0014886758, "top1_acc": 71.87500, "top1_err": 26.56250, "top5_acc": 93.75000, "top5_err": 3.12500}
[06/12 17:59:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47370, "dt_data": 0.00026, "dt_net": 0.47343, "epoch": "23/300", "eta": "2:11:12", "gpu_mem": "10.07G", "grad_norm": 11.74834, "iter": "60/60", "loss": 0.80814, "lr": 0.0014994039, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/12 17:59:14][INFO] logging.py:  101: json_stats: {"RAM": "13.66/31.07G", "_type": "train_epoch", "dt": 0.72687, "dt_data": 0.72687, "dt_net": 0.47343, "epoch": "23/300", "eta": "3:21:19", "gpu_mem": "10.07G", "grad_norm": 11.74834, "loss": 0.78288, "lr": 0.0014994039, "top1_acc": 76.66667, "top1_err": 23.90625, "top5_acc": 95.10417, "top5_err": 5.00000}
[06/12 17:59:14][INFO] train_net.py:  708: Epoch 22 takes 48.37s. Epochs from 0 to 22 take 48.45s in average and 48.53s in median.
[06/12 17:59:14][INFO] train_net.py:  714: For epoch 22, each iteraction takes 0.81s in average. From epoch 0 to 22, each iteraction takes 0.81s in average.
[06/12 17:59:32][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47199, "dt_data": 0.00035, "dt_net": 0.47163, "epoch": "24/300", "eta": "2:10:39", "gpu_mem": "10.07G", "grad_norm": 6.09342, "iter": "10/60", "loss": 0.64509, "lr": 0.0015101319, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 17:59:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47295, "dt_data": 0.00057, "dt_net": 0.47238, "epoch": "24/300", "eta": "2:10:51", "gpu_mem": "10.07G", "grad_norm": 7.49832, "iter": "20/60", "loss": 0.74918, "lr": 0.0015208600, "top1_acc": 75.00000, "top1_err": 21.87500, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/12 17:59:44][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47148, "dt_data": 0.00036, "dt_net": 0.47112, "epoch": "24/300", "eta": "2:10:21", "gpu_mem": "10.07G", "grad_norm": 8.18724, "iter": "30/60", "loss": 0.69994, "lr": 0.0015315881, "top1_acc": 75.00000, "top1_err": 21.87500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 17:59:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48368, "dt_data": 0.00066, "dt_net": 0.48302, "epoch": "24/300", "eta": "2:13:39", "gpu_mem": "10.07G", "grad_norm": 9.39146, "iter": "40/60", "loss": 0.84395, "lr": 0.0015423162, "top1_acc": 68.75000, "top1_err": 29.68750, "top5_acc": 93.75000, "top5_err": 4.68750}
[06/12 17:59:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.91783, "dt_data": 0.44552, "dt_net": 0.47231, "epoch": "24/300", "eta": "4:13:28", "gpu_mem": "10.07G", "grad_norm": 7.95200, "iter": "50/60", "loss": 0.79535, "lr": 0.0015530443, "top1_acc": 81.25000, "top1_err": 25.00000, "top5_acc": 93.75000, "top5_err": 4.68750}
[06/12 18:00:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46868, "dt_data": 0.00017, "dt_net": 0.46850, "epoch": "24/300", "eta": "2:09:21", "gpu_mem": "10.07G", "grad_norm": 10.26131, "iter": "60/60", "loss": 0.77307, "lr": 0.0015637724, "top1_acc": 81.25000, "top1_err": 21.87500, "top5_acc": 96.87500, "top5_err": 6.25000}
[06/12 18:00:02][INFO] logging.py:  101: json_stats: {"RAM": "13.66/31.07G", "_type": "train_epoch", "dt": 0.73954, "dt_data": 0.73954, "dt_net": 0.46850, "epoch": "24/300", "eta": "3:24:04", "gpu_mem": "10.07G", "grad_norm": 10.26131, "loss": 0.76049, "lr": 0.0015637724, "top1_acc": 76.77083, "top1_err": 24.21875, "top5_acc": 95.62500, "top5_err": 4.68750}
[06/12 18:00:02][INFO] train_net.py:  708: Epoch 23 takes 47.79s. Epochs from 0 to 23 take 48.42s in average and 48.49s in median.
[06/12 18:00:02][INFO] train_net.py:  714: For epoch 23, each iteraction takes 0.80s in average. From epoch 0 to 23, each iteraction takes 0.81s in average.
[06/12 18:00:18][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47387, "dt_data": 0.00055, "dt_net": 0.47332, "epoch": "25/300", "eta": "2:10:42", "gpu_mem": "10.07G", "grad_norm": 11.35526, "iter": "10/60", "loss": 0.67775, "lr": 0.0015745005, "top1_acc": 71.87500, "top1_err": 23.43750, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:00:24][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47006, "dt_data": 0.00043, "dt_net": 0.46964, "epoch": "25/300", "eta": "2:09:34", "gpu_mem": "10.07G", "grad_norm": 5.99595, "iter": "20/60", "loss": 0.73111, "lr": 0.0015852286, "top1_acc": 81.25000, "top1_err": 20.31250, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/12 18:00:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.91925, "dt_data": 0.00086, "dt_net": 0.91838, "epoch": "25/300", "eta": "4:13:15", "gpu_mem": "10.07G", "grad_norm": 9.30217, "iter": "30/60", "loss": 0.67777, "lr": 0.0015959567, "top1_acc": 75.00000, "top1_err": 23.43750, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:00:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47563, "dt_data": 0.00042, "dt_net": 0.47521, "epoch": "25/300", "eta": "2:10:57", "gpu_mem": "10.07G", "grad_norm": 6.90771, "iter": "40/60", "loss": 0.62554, "lr": 0.0016066848, "top1_acc": 78.12500, "top1_err": 20.31250, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:00:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47672, "dt_data": 0.00059, "dt_net": 0.47613, "epoch": "25/300", "eta": "2:11:10", "gpu_mem": "10.07G", "grad_norm": 9.53868, "iter": "50/60", "loss": 0.74153, "lr": 0.0016174129, "top1_acc": 75.00000, "top1_err": 23.43750, "top5_acc": 93.75000, "top5_err": 4.68750}
[06/12 18:00:48][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46902, "dt_data": 0.00017, "dt_net": 0.46885, "epoch": "25/300", "eta": "2:08:58", "gpu_mem": "10.07G", "grad_norm": 10.81350, "iter": "60/60", "loss": 0.74951, "lr": 0.0016281410, "top1_acc": 75.00000, "top1_err": 26.56250, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 18:00:49][INFO] logging.py:  101: json_stats: {"RAM": "13.66/31.07G", "_type": "train_epoch", "dt": 0.68676, "dt_data": 0.68676, "dt_net": 0.46885, "epoch": "25/300", "eta": "3:08:50", "gpu_mem": "10.07G", "grad_norm": 10.81350, "loss": 0.72071, "lr": 0.0016281410, "top1_acc": 76.45833, "top1_err": 23.07292, "top5_acc": 95.31250, "top5_err": 4.37500}
[06/12 18:00:49][INFO] train_net.py:  708: Epoch 24 takes 47.43s. Epochs from 0 to 24 take 48.38s in average and 48.45s in median.
[06/12 18:00:49][INFO] train_net.py:  714: For epoch 24, each iteraction takes 0.79s in average. From epoch 0 to 24, each iteraction takes 0.81s in average.
[06/12 18:00:49][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 18:01:50][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "25/300", "eta": "0:00:01", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.31455, "top1_acc": 70.31250, "top1_err": 29.68750, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/12 18:01:53][INFO] logging.py:  101: json_stats: {"RAM": "13.65/31.07G", "_type": "val_epoch", "epoch": "25/300", "gpu_mem": "10.07G", "min_top1_err": 35.68465, "min_top5_err": 7.46888, "time_diff": 0.62424, "top1_acc": 63.69295, "top1_err": 36.30705, "top5_acc": 92.53112, "top5_err": 7.46888}
[06/12 18:02:10][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.77817, "dt_data": 0.00031, "dt_net": 0.77786, "epoch": "26/300", "eta": "3:33:52", "gpu_mem": "10.07G", "grad_norm": 6.83377, "iter": "10/60", "loss": 0.74164, "lr": 0.0016388690, "top1_acc": 84.37500, "top1_err": 20.31250, "top5_acc": 100.00000, "top5_err": 4.68750}
[06/12 18:02:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47133, "dt_data": 0.00050, "dt_net": 0.47083, "epoch": "26/300", "eta": "2:09:27", "gpu_mem": "10.07G", "grad_norm": 9.91472, "iter": "20/60", "loss": 0.63664, "lr": 0.0016495971, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:02:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.54278, "dt_data": 0.00046, "dt_net": 0.54232, "epoch": "26/300", "eta": "2:28:59", "gpu_mem": "10.07G", "grad_norm": 8.53715, "iter": "30/60", "loss": 0.59745, "lr": 0.0016603252, "top1_acc": 81.25000, "top1_err": 15.62500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 18:02:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46763, "dt_data": 0.00044, "dt_net": 0.46719, "epoch": "26/300", "eta": "2:08:17", "gpu_mem": "10.07G", "grad_norm": 12.75389, "iter": "40/60", "loss": 0.69515, "lr": 0.0016710533, "top1_acc": 75.00000, "top1_err": 21.87500, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:02:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.28084, "dt_data": 0.00074, "dt_net": 1.28009, "epoch": "26/300", "eta": "5:51:09", "gpu_mem": "10.07G", "grad_norm": 6.42796, "iter": "50/60", "loss": 0.66551, "lr": 0.0016817814, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:02:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46513, "dt_data": 0.00020, "dt_net": 0.46493, "epoch": "26/300", "eta": "2:07:26", "gpu_mem": "10.07G", "grad_norm": 8.59867, "iter": "60/60", "loss": 0.83026, "lr": 0.0016925095, "top1_acc": 75.00000, "top1_err": 21.87500, "top5_acc": 93.75000, "top5_err": 7.81250}
[06/12 18:02:41][INFO] logging.py:  101: json_stats: {"RAM": "13.65/31.07G", "_type": "train_epoch", "dt": 0.71318, "dt_data": 0.71318, "dt_net": 0.46493, "epoch": "26/300", "eta": "3:15:24", "gpu_mem": "10.07G", "grad_norm": 8.59867, "loss": 0.69042, "lr": 0.0016925095, "top1_acc": 78.75000, "top1_err": 21.40625, "top5_acc": 96.45833, "top5_err": 3.75000}
[06/12 18:02:41][INFO] train_net.py:  708: Epoch 25 takes 48.23s. Epochs from 0 to 25 take 48.37s in average and 48.41s in median.
[06/12 18:02:41][INFO] train_net.py:  714: For epoch 25, each iteraction takes 0.80s in average. From epoch 0 to 25, each iteraction takes 0.81s in average.
[06/12 18:02:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47873, "dt_data": 0.00053, "dt_net": 0.47821, "epoch": "27/300", "eta": "2:11:05", "gpu_mem": "10.07G", "grad_norm": 11.60035, "iter": "10/60", "loss": 0.73544, "lr": 0.0017032376, "top1_acc": 81.25000, "top1_err": 21.87500, "top5_acc": 93.75000, "top5_err": 4.68750}
[06/12 18:03:03][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47641, "dt_data": 0.00053, "dt_net": 0.47588, "epoch": "27/300", "eta": "2:10:22", "gpu_mem": "10.07G", "grad_norm": 9.08481, "iter": "20/60", "loss": 0.67211, "lr": 0.0017139657, "top1_acc": 81.25000, "top1_err": 20.31250, "top5_acc": 93.75000, "top5_err": 3.12500}
[06/12 18:03:10][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.70457, "dt_data": 0.00037, "dt_net": 0.70420, "epoch": "27/300", "eta": "3:12:42", "gpu_mem": "10.07G", "grad_norm": 6.96337, "iter": "30/60", "loss": 0.58665, "lr": 0.0017246938, "top1_acc": 84.37500, "top1_err": 18.75000, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:03:15][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47913, "dt_data": 0.00089, "dt_net": 0.47822, "epoch": "27/300", "eta": "2:10:57", "gpu_mem": "10.07G", "grad_norm": 10.09737, "iter": "40/60", "loss": 0.52633, "lr": 0.0017354219, "top1_acc": 81.25000, "top1_err": 15.62500, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:03:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.11087, "dt_data": 0.00054, "dt_net": 1.11033, "epoch": "27/300", "eta": "5:03:27", "gpu_mem": "10.07G", "grad_norm": 8.99764, "iter": "50/60", "loss": 0.69989, "lr": 0.0017461500, "top1_acc": 81.25000, "top1_err": 25.00000, "top5_acc": 96.87500, "top5_err": 4.68750}
[06/12 18:03:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47027, "dt_data": 0.00020, "dt_net": 0.47007, "epoch": "27/300", "eta": "2:08:23", "gpu_mem": "10.07G", "grad_norm": 9.86110, "iter": "60/60", "loss": 0.65597, "lr": 0.0017568781, "top1_acc": 87.50000, "top1_err": 20.31250, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:03:28][INFO] logging.py:  101: json_stats: {"RAM": "13.65/31.07G", "_type": "train_epoch", "dt": 0.72684, "dt_data": 0.72684, "dt_net": 0.47007, "epoch": "27/300", "eta": "3:18:24", "gpu_mem": "10.07G", "grad_norm": 9.86110, "loss": 0.65682, "lr": 0.0017568781, "top1_acc": 80.20833, "top1_err": 20.52083, "top5_acc": 96.87500, "top5_err": 3.38542}
[06/12 18:03:28][INFO] train_net.py:  708: Epoch 26 takes 47.24s. Epochs from 0 to 26 take 48.33s in average and 48.37s in median.
[06/12 18:03:28][INFO] train_net.py:  714: For epoch 26, each iteraction takes 0.79s in average. From epoch 0 to 26, each iteraction takes 0.81s in average.
[06/12 18:03:45][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46860, "dt_data": 0.00046, "dt_net": 0.46814, "epoch": "28/300", "eta": "2:07:50", "gpu_mem": "10.07G", "grad_norm": 15.04588, "iter": "10/60", "loss": 0.57575, "lr": 0.0017676061, "top1_acc": 84.37500, "top1_err": 15.62500, "top5_acc": 93.75000, "top5_err": 3.12500}
[06/12 18:03:51][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46898, "dt_data": 0.00055, "dt_net": 0.46842, "epoch": "28/300", "eta": "2:07:52", "gpu_mem": "10.07G", "grad_norm": 9.89166, "iter": "20/60", "loss": 0.59132, "lr": 0.0017783342, "top1_acc": 87.50000, "top1_err": 18.75000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:03:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47820, "dt_data": 0.00062, "dt_net": 0.47758, "epoch": "28/300", "eta": "2:10:18", "gpu_mem": "10.07G", "grad_norm": 8.56294, "iter": "30/60", "loss": 0.65792, "lr": 0.0017890623, "top1_acc": 81.25000, "top1_err": 20.31250, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:04:03][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48796, "dt_data": 0.00059, "dt_net": 0.48737, "epoch": "28/300", "eta": "2:12:53", "gpu_mem": "10.07G", "grad_norm": 13.27676, "iter": "40/60", "loss": 0.66423, "lr": 0.0017997904, "top1_acc": 81.25000, "top1_err": 20.31250, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:04:10][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.15039, "dt_data": 0.00065, "dt_net": 1.14973, "epoch": "28/300", "eta": "5:13:05", "gpu_mem": "10.07G", "grad_norm": 4.95263, "iter": "50/60", "loss": 0.60614, "lr": 0.0018105185, "top1_acc": 84.37500, "top1_err": 18.75000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 18:04:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46927, "dt_data": 0.00018, "dt_net": 0.46910, "epoch": "28/300", "eta": "2:07:38", "gpu_mem": "10.07G", "grad_norm": 6.93839, "iter": "60/60", "loss": 0.64365, "lr": 0.0018212466, "top1_acc": 81.25000, "top1_err": 21.87500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 18:04:17][INFO] logging.py:  101: json_stats: {"RAM": "13.66/31.07G", "_type": "train_epoch", "dt": 0.72360, "dt_data": 0.72360, "dt_net": 0.46910, "epoch": "28/300", "eta": "3:16:48", "gpu_mem": "10.07G", "grad_norm": 6.93839, "loss": 0.63166, "lr": 0.0018212466, "top1_acc": 81.45833, "top1_err": 18.85417, "top5_acc": 96.66667, "top5_err": 3.43750}
[06/12 18:04:17][INFO] train_net.py:  708: Epoch 27 takes 48.25s. Epochs from 0 to 27 take 48.33s in average and 48.33s in median.
[06/12 18:04:17][INFO] train_net.py:  714: For epoch 27, each iteraction takes 0.80s in average. From epoch 0 to 27, each iteraction takes 0.81s in average.
[06/12 18:04:34][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46899, "dt_data": 0.00074, "dt_net": 0.46824, "epoch": "29/300", "eta": "2:07:29", "gpu_mem": "10.07G", "grad_norm": 9.28261, "iter": "10/60", "loss": 0.60016, "lr": 0.0018319747, "top1_acc": 87.50000, "top1_err": 18.75000, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:04:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48177, "dt_data": 0.00038, "dt_net": 0.48139, "epoch": "29/300", "eta": "2:10:52", "gpu_mem": "10.07G", "grad_norm": 7.53970, "iter": "20/60", "loss": 0.63305, "lr": 0.0018427028, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:04:47][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47421, "dt_data": 0.00032, "dt_net": 0.47389, "epoch": "29/300", "eta": "2:08:44", "gpu_mem": "10.07G", "grad_norm": 12.14184, "iter": "30/60", "loss": 0.63593, "lr": 0.0018534309, "top1_acc": 81.25000, "top1_err": 21.87500, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:04:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47501, "dt_data": 0.00059, "dt_net": 0.47442, "epoch": "29/300", "eta": "2:08:53", "gpu_mem": "10.07G", "grad_norm": 6.71726, "iter": "40/60", "loss": 0.70595, "lr": 0.0018641590, "top1_acc": 78.12500, "top1_err": 18.75000, "top5_acc": 93.75000, "top5_err": 3.12500}
[06/12 18:04:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47884, "dt_data": 0.00049, "dt_net": 0.47835, "epoch": "29/300", "eta": "2:09:50", "gpu_mem": "10.07G", "grad_norm": 7.81195, "iter": "50/60", "loss": 0.69675, "lr": 0.0018748871, "top1_acc": 78.12500, "top1_err": 23.43750, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:05:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47092, "dt_data": 0.00020, "dt_net": 0.47072, "epoch": "29/300", "eta": "2:07:37", "gpu_mem": "10.07G", "grad_norm": 7.93432, "iter": "60/60", "loss": 0.70073, "lr": 0.0018856152, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:05:06][INFO] logging.py:  101: json_stats: {"RAM": "13.65/31.07G", "_type": "train_epoch", "dt": 0.69883, "dt_data": 0.69883, "dt_net": 0.47072, "epoch": "29/300", "eta": "3:09:22", "gpu_mem": "10.07G", "grad_norm": 7.93432, "loss": 0.65231, "lr": 0.0018856152, "top1_acc": 79.16667, "top1_err": 21.04167, "top5_acc": 96.97917, "top5_err": 3.07292}
[06/12 18:05:06][INFO] train_net.py:  708: Epoch 28 takes 48.95s. Epochs from 0 to 28 take 48.35s in average and 48.37s in median.
[06/12 18:05:06][INFO] train_net.py:  714: For epoch 28, each iteraction takes 0.82s in average. From epoch 0 to 28, each iteraction takes 0.81s in average.
[06/12 18:05:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46845, "dt_data": 0.00035, "dt_net": 0.46810, "epoch": "30/300", "eta": "2:06:52", "gpu_mem": "10.07G", "grad_norm": 9.07828, "iter": "10/60", "loss": 0.59965, "lr": 0.0018963432, "top1_acc": 78.12500, "top1_err": 20.31250, "top5_acc": 93.75000, "top5_err": 4.68750}
[06/12 18:05:29][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47631, "dt_data": 0.00042, "dt_net": 0.47588, "epoch": "30/300", "eta": "2:08:55", "gpu_mem": "10.07G", "grad_norm": 6.25320, "iter": "20/60", "loss": 0.61123, "lr": 0.0019070713, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 18:05:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47432, "dt_data": 0.00046, "dt_net": 0.47386, "epoch": "30/300", "eta": "2:08:18", "gpu_mem": "10.07G", "grad_norm": 8.67173, "iter": "30/60", "loss": 0.54641, "lr": 0.0019177994, "top1_acc": 84.37500, "top1_err": 15.62500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:05:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47165, "dt_data": 0.00056, "dt_net": 0.47108, "epoch": "30/300", "eta": "2:07:30", "gpu_mem": "10.07G", "grad_norm": 6.62447, "iter": "40/60", "loss": 0.55075, "lr": 0.0019285275, "top1_acc": 84.37500, "top1_err": 17.18750, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:05:47][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48341, "dt_data": 0.00052, "dt_net": 0.48289, "epoch": "30/300", "eta": "2:10:36", "gpu_mem": "10.07G", "grad_norm": 12.45083, "iter": "50/60", "loss": 0.62985, "lr": 0.0019392556, "top1_acc": 75.00000, "top1_err": 18.75000, "top5_acc": 93.75000, "top5_err": 3.12500}
[06/12 18:05:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46836, "dt_data": 0.00019, "dt_net": 0.46816, "epoch": "30/300", "eta": "2:06:27", "gpu_mem": "10.07G", "grad_norm": 15.93893, "iter": "60/60", "loss": 0.64185, "lr": 0.0019499837, "top1_acc": 75.00000, "top1_err": 20.31250, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:05:54][INFO] logging.py:  101: json_stats: {"RAM": "13.65/31.07G", "_type": "train_epoch", "dt": 0.71860, "dt_data": 0.71858, "dt_net": 0.46816, "epoch": "30/300", "eta": "3:14:00", "gpu_mem": "10.07G", "grad_norm": 15.93893, "loss": 0.58212, "lr": 0.0019499837, "top1_acc": 79.89583, "top1_err": 18.95833, "top5_acc": 96.25000, "top5_err": 3.02083}
[06/12 18:05:54][INFO] train_net.py:  708: Epoch 29 takes 48.01s. Epochs from 0 to 29 take 48.34s in average and 48.33s in median.
[06/12 18:05:54][INFO] train_net.py:  714: For epoch 29, each iteraction takes 0.80s in average. From epoch 0 to 29, each iteraction takes 0.81s in average.
[06/12 18:05:54][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 18:06:55][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "30/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.13101, "top1_acc": 71.87500, "top1_err": 28.12500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 18:06:58][INFO] logging.py:  101: json_stats: {"RAM": "13.66/31.07G", "_type": "val_epoch", "epoch": "30/300", "gpu_mem": "10.07G", "min_top1_err": 27.38589, "min_top5_err": 3.52697, "time_diff": 0.62264, "top1_acc": 72.61411, "top1_err": 27.38589, "top5_acc": 96.47303, "top5_err": 3.52697}
[06/12 18:07:15][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.80189, "dt_data": 0.34195, "dt_net": 0.45994, "epoch": "31/300", "eta": "3:36:22", "gpu_mem": "10.07G", "grad_norm": 6.30709, "iter": "10/60", "loss": 0.60529, "lr": 0.0019505699, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:07:21][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46859, "dt_data": 0.00055, "dt_net": 0.46804, "epoch": "31/300", "eta": "2:06:21", "gpu_mem": "10.07G", "grad_norm": 10.29987, "iter": "20/60", "loss": 0.51451, "lr": 0.0019500265, "top1_acc": 87.50000, "top1_err": 14.06250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:07:27][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.96847, "dt_data": 0.50466, "dt_net": 0.46381, "epoch": "31/300", "eta": "4:21:00", "gpu_mem": "10.07G", "grad_norm": 6.66143, "iter": "30/60", "loss": 0.63563, "lr": 0.0019494803, "top1_acc": 81.25000, "top1_err": 20.31250, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:07:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47002, "dt_data": 0.00052, "dt_net": 0.46950, "epoch": "31/300", "eta": "2:06:35", "gpu_mem": "10.07G", "grad_norm": 7.40182, "iter": "40/60", "loss": 0.47938, "lr": 0.0019489311, "top1_acc": 87.50000, "top1_err": 15.62500, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:07:39][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.59971, "dt_data": 0.13239, "dt_net": 0.46732, "epoch": "31/300", "eta": "2:41:25", "gpu_mem": "10.07G", "grad_norm": 10.07989, "iter": "50/60", "loss": 0.60928, "lr": 0.0019483790, "top1_acc": 81.25000, "top1_err": 17.18750, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 18:07:44][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46916, "dt_data": 0.00016, "dt_net": 0.46899, "epoch": "31/300", "eta": "2:06:12", "gpu_mem": "10.07G", "grad_norm": 8.72116, "iter": "60/60", "loss": 0.71134, "lr": 0.0019478241, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 18:07:45][INFO] logging.py:  101: json_stats: {"RAM": "13.65/31.07G", "_type": "train_epoch", "dt": 0.69202, "dt_data": 0.69202, "dt_net": 0.46899, "epoch": "31/300", "eta": "3:06:08", "gpu_mem": "10.07G", "grad_norm": 8.72116, "loss": 0.59324, "lr": 0.0019478241, "top1_acc": 80.10417, "top1_err": 19.11458, "top5_acc": 96.97917, "top5_err": 3.12500}
[06/12 18:07:45][INFO] train_net.py:  708: Epoch 30 takes 47.42s. Epochs from 0 to 30 take 48.31s in average and 48.29s in median.
[06/12 18:07:45][INFO] train_net.py:  714: For epoch 30, each iteraction takes 0.79s in average. From epoch 0 to 30, each iteraction takes 0.81s in average.
[06/12 18:08:03][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46712, "dt_data": 0.00029, "dt_net": 0.46683, "epoch": "32/300", "eta": "2:05:34", "gpu_mem": "10.07G", "grad_norm": 9.13752, "iter": "10/60", "loss": 0.53360, "lr": 0.0019472662, "top1_acc": 81.25000, "top1_err": 20.31250, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:08:09][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46795, "dt_data": 0.00051, "dt_net": 0.46743, "epoch": "32/300", "eta": "2:05:43", "gpu_mem": "10.07G", "grad_norm": 11.57883, "iter": "20/60", "loss": 0.47679, "lr": 0.0019467055, "top1_acc": 81.25000, "top1_err": 17.18750, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:08:15][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46898, "dt_data": 0.00054, "dt_net": 0.46843, "epoch": "32/300", "eta": "2:05:55", "gpu_mem": "10.07G", "grad_norm": 6.31439, "iter": "30/60", "loss": 0.48139, "lr": 0.0019461419, "top1_acc": 84.37500, "top1_err": 15.62500, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:08:21][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47206, "dt_data": 0.00038, "dt_net": 0.47168, "epoch": "32/300", "eta": "2:06:40", "gpu_mem": "10.07G", "grad_norm": 12.99129, "iter": "40/60", "loss": 0.50983, "lr": 0.0019455754, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:08:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47935, "dt_data": 0.00042, "dt_net": 0.47893, "epoch": "32/300", "eta": "2:08:32", "gpu_mem": "10.07G", "grad_norm": 7.35101, "iter": "50/60", "loss": 0.51054, "lr": 0.0019450060, "top1_acc": 84.37500, "top1_err": 17.18750, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:08:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46816, "dt_data": 0.00019, "dt_net": 0.46797, "epoch": "32/300", "eta": "2:05:27", "gpu_mem": "10.07G", "grad_norm": 7.35363, "iter": "60/60", "loss": 0.57456, "lr": 0.0019444338, "top1_acc": 81.25000, "top1_err": 17.18750, "top5_acc": 96.87500, "top5_err": 1.56250}
[06/12 18:08:33][INFO] logging.py:  101: json_stats: {"RAM": "13.66/31.07G", "_type": "train_epoch", "dt": 0.71096, "dt_data": 0.71096, "dt_net": 0.46797, "epoch": "32/300", "eta": "3:10:31", "gpu_mem": "10.07G", "grad_norm": 7.35363, "loss": 0.53434, "lr": 0.0019444338, "top1_acc": 80.83333, "top1_err": 17.91667, "top5_acc": 97.81250, "top5_err": 2.34375}
[06/12 18:08:33][INFO] train_net.py:  708: Epoch 31 takes 48.43s. Epochs from 0 to 31 take 48.31s in average and 48.33s in median.
[06/12 18:08:33][INFO] train_net.py:  714: For epoch 31, each iteraction takes 0.81s in average. From epoch 0 to 31, each iteraction takes 0.81s in average.
[06/12 18:08:51][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47165, "dt_data": 0.00055, "dt_net": 0.47109, "epoch": "33/300", "eta": "2:06:19", "gpu_mem": "10.07G", "grad_norm": 8.64332, "iter": "10/60", "loss": 0.53666, "lr": 0.0019438586, "top1_acc": 84.37500, "top1_err": 17.18750, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 18:08:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48836, "dt_data": 0.00050, "dt_net": 0.48787, "epoch": "33/300", "eta": "2:10:43", "gpu_mem": "10.07G", "grad_norm": 9.88629, "iter": "20/60", "loss": 0.53903, "lr": 0.0019432806, "top1_acc": 81.25000, "top1_err": 15.62500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 18:09:03][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47726, "dt_data": 0.00033, "dt_net": 0.47694, "epoch": "33/300", "eta": "2:07:40", "gpu_mem": "10.07G", "grad_norm": 7.98574, "iter": "30/60", "loss": 0.44672, "lr": 0.0019426997, "top1_acc": 81.25000, "top1_err": 15.62500, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:09:09][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47428, "dt_data": 0.00049, "dt_net": 0.47380, "epoch": "33/300", "eta": "2:06:47", "gpu_mem": "10.07G", "grad_norm": 11.12145, "iter": "40/60", "loss": 0.52628, "lr": 0.0019421160, "top1_acc": 78.12500, "top1_err": 15.62500, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:09:15][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47103, "dt_data": 0.00061, "dt_net": 0.47041, "epoch": "33/300", "eta": "2:05:50", "gpu_mem": "10.07G", "grad_norm": 8.81426, "iter": "50/60", "loss": 0.50484, "lr": 0.0019415294, "top1_acc": 84.37500, "top1_err": 18.75000, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:09:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46914, "dt_data": 0.00016, "dt_net": 0.46899, "epoch": "33/300", "eta": "2:05:15", "gpu_mem": "10.07G", "grad_norm": 8.77834, "iter": "60/60", "loss": 0.55689, "lr": 0.0019409399, "top1_acc": 81.25000, "top1_err": 17.18750, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:09:22][INFO] logging.py:  101: json_stats: {"RAM": "13.66/31.07G", "_type": "train_epoch", "dt": 0.71420, "dt_data": 0.71420, "dt_net": 0.46899, "epoch": "33/300", "eta": "3:10:40", "gpu_mem": "10.07G", "grad_norm": 8.77834, "loss": 0.54358, "lr": 0.0019409399, "top1_acc": 81.35417, "top1_err": 17.29167, "top5_acc": 97.60417, "top5_err": 2.60417}
[06/12 18:09:22][INFO] train_net.py:  708: Epoch 32 takes 48.95s. Epochs from 0 to 32 take 48.33s in average and 48.37s in median.
[06/12 18:09:22][INFO] train_net.py:  714: For epoch 32, each iteraction takes 0.82s in average. From epoch 0 to 32, each iteraction takes 0.81s in average.
[06/12 18:09:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47097, "dt_data": 0.00044, "dt_net": 0.47053, "epoch": "34/300", "eta": "2:05:40", "gpu_mem": "10.07G", "grad_norm": 7.35901, "iter": "10/60", "loss": 0.41302, "lr": 0.0019403475, "top1_acc": 87.50000, "top1_err": 15.62500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:09:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47089, "dt_data": 0.00032, "dt_net": 0.47056, "epoch": "34/300", "eta": "2:05:34", "gpu_mem": "10.07G", "grad_norm": 6.90130, "iter": "20/60", "loss": 0.42074, "lr": 0.0019397523, "top1_acc": 87.50000, "top1_err": 14.06250, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 18:09:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.59798, "dt_data": 0.13052, "dt_net": 0.46745, "epoch": "34/300", "eta": "2:39:21", "gpu_mem": "10.07G", "grad_norm": 12.43415, "iter": "30/60", "loss": 0.55463, "lr": 0.0019391542, "top1_acc": 87.50000, "top1_err": 15.62500, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:09:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47168, "dt_data": 0.00049, "dt_net": 0.47119, "epoch": "34/300", "eta": "2:05:37", "gpu_mem": "10.07G", "grad_norm": 10.63016, "iter": "40/60", "loss": 0.69303, "lr": 0.0019385533, "top1_acc": 81.25000, "top1_err": 21.87500, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/12 18:10:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.56351, "dt_data": 0.09420, "dt_net": 0.46931, "epoch": "34/300", "eta": "2:29:59", "gpu_mem": "10.07G", "grad_norm": 7.99104, "iter": "50/60", "loss": 0.46724, "lr": 0.0019379495, "top1_acc": 84.37500, "top1_err": 15.62500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:10:10][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46892, "dt_data": 0.00016, "dt_net": 0.46876, "epoch": "34/300", "eta": "2:04:44", "gpu_mem": "10.07G", "grad_norm": 9.05587, "iter": "60/60", "loss": 0.44873, "lr": 0.0019373428, "top1_acc": 81.25000, "top1_err": 14.06250, "top5_acc": 96.87500, "top5_err": 1.56250}
[06/12 18:10:11][INFO] logging.py:  101: json_stats: {"RAM": "13.66/31.07G", "_type": "train_epoch", "dt": 0.71652, "dt_data": 0.71652, "dt_net": 0.46876, "epoch": "34/300", "eta": "3:10:34", "gpu_mem": "10.07G", "grad_norm": 9.05587, "loss": 0.49692, "lr": 0.0019373428, "top1_acc": 84.37500, "top1_err": 15.88542, "top5_acc": 96.87500, "top5_err": 2.65625}
[06/12 18:10:11][INFO] train_net.py:  708: Epoch 33 takes 48.62s. Epochs from 0 to 33 take 48.34s in average and 48.40s in median.
[06/12 18:10:11][INFO] train_net.py:  714: For epoch 33, each iteraction takes 0.81s in average. From epoch 0 to 33, each iteraction takes 0.81s in average.
[06/12 18:10:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.77003, "dt_data": 0.30299, "dt_net": 0.46703, "epoch": "35/300", "eta": "3:24:41", "gpu_mem": "10.07G", "grad_norm": 6.71969, "iter": "10/60", "loss": 0.45760, "lr": 0.0019367333, "top1_acc": 78.12500, "top1_err": 15.62500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:10:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47444, "dt_data": 0.00046, "dt_net": 0.47398, "epoch": "35/300", "eta": "2:06:02", "gpu_mem": "10.07G", "grad_norm": 7.83822, "iter": "20/60", "loss": 0.51822, "lr": 0.0019361209, "top1_acc": 87.50000, "top1_err": 17.18750, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:10:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.98615, "dt_data": 0.51371, "dt_net": 0.47244, "epoch": "35/300", "eta": "4:21:49", "gpu_mem": "10.07G", "grad_norm": 5.24016, "iter": "30/60", "loss": 0.46616, "lr": 0.0019355057, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:10:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47196, "dt_data": 0.00043, "dt_net": 0.47153, "epoch": "35/300", "eta": "2:05:13", "gpu_mem": "10.07G", "grad_norm": 12.29246, "iter": "40/60", "loss": 0.40213, "lr": 0.0019348876, "top1_acc": 87.50000, "top1_err": 15.62500, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:10:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.28709, "dt_data": 0.79936, "dt_net": 0.48773, "epoch": "35/300", "eta": "5:41:17", "gpu_mem": "10.07G", "grad_norm": 8.02376, "iter": "50/60", "loss": 0.43402, "lr": 0.0019342667, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:10:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46931, "dt_data": 0.00016, "dt_net": 0.46915, "epoch": "35/300", "eta": "2:04:21", "gpu_mem": "10.07G", "grad_norm": 11.22516, "iter": "60/60", "loss": 0.46248, "lr": 0.0019336430, "top1_acc": 87.50000, "top1_err": 14.06250, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:10:59][INFO] logging.py:  101: json_stats: {"RAM": "13.66/31.07G", "_type": "train_epoch", "dt": 0.69993, "dt_data": 0.69993, "dt_net": 0.46915, "epoch": "35/300", "eta": "3:05:28", "gpu_mem": "10.07G", "grad_norm": 11.22516, "loss": 0.46316, "lr": 0.0019336430, "top1_acc": 85.62500, "top1_err": 14.16667, "top5_acc": 98.43750, "top5_err": 2.08333}
[06/12 18:10:59][INFO] train_net.py:  708: Epoch 34 takes 48.04s. Epochs from 0 to 34 take 48.33s in average and 48.37s in median.
[06/12 18:10:59][INFO] train_net.py:  714: For epoch 34, each iteraction takes 0.80s in average. From epoch 0 to 34, each iteraction takes 0.81s in average.
[06/12 18:10:59][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 18:12:01][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "35/300", "eta": "0:00:04", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.70324, "top1_acc": 73.43750, "top1_err": 26.56250, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 18:12:04][INFO] logging.py:  101: json_stats: {"RAM": "13.90/31.07G", "_type": "val_epoch", "epoch": "35/300", "gpu_mem": "10.07G", "min_top1_err": 26.76349, "min_top5_err": 3.52697, "time_diff": 0.62720, "top1_acc": 73.23651, "top1_err": 26.76349, "top5_acc": 96.47303, "top5_err": 3.52697}
[06/12 18:12:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46593, "dt_data": 0.00033, "dt_net": 0.46560, "epoch": "36/300", "eta": "2:03:23", "gpu_mem": "10.07G", "grad_norm": 8.06730, "iter": "10/60", "loss": 0.34005, "lr": 0.0019330164, "top1_acc": 84.37500, "top1_err": 10.93750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:12:27][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46627, "dt_data": 0.00035, "dt_net": 0.46592, "epoch": "36/300", "eta": "2:03:24", "gpu_mem": "10.07G", "grad_norm": 9.99503, "iter": "20/60", "loss": 0.47343, "lr": 0.0019323869, "top1_acc": 87.50000, "top1_err": 15.62500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:12:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.57373, "dt_data": 0.10451, "dt_net": 0.46921, "epoch": "36/300", "eta": "2:31:45", "gpu_mem": "10.07G", "grad_norm": 8.01282, "iter": "30/60", "loss": 0.38354, "lr": 0.0019317546, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:12:39][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.64203, "dt_data": 0.00045, "dt_net": 0.64158, "epoch": "36/300", "eta": "2:49:42", "gpu_mem": "10.07G", "grad_norm": 6.64115, "iter": "40/60", "loss": 0.48721, "lr": 0.0019311195, "top1_acc": 84.37500, "top1_err": 14.06250, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:12:45][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.08451, "dt_data": 0.60704, "dt_net": 0.47746, "epoch": "36/300", "eta": "4:46:29", "gpu_mem": "10.07G", "grad_norm": 9.19759, "iter": "50/60", "loss": 0.48128, "lr": 0.0019304815, "top1_acc": 84.37500, "top1_err": 15.62500, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:12:51][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46694, "dt_data": 0.00015, "dt_net": 0.46679, "epoch": "36/300", "eta": "2:03:16", "gpu_mem": "10.07G", "grad_norm": 11.24284, "iter": "60/60", "loss": 0.51724, "lr": 0.0019298407, "top1_acc": 87.50000, "top1_err": 15.62500, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:12:51][INFO] logging.py:  101: json_stats: {"RAM": "13.89/31.07G", "_type": "train_epoch", "dt": 0.69269, "dt_data": 0.69269, "dt_net": 0.46679, "epoch": "36/300", "eta": "3:02:51", "gpu_mem": "10.07G", "grad_norm": 11.24284, "loss": 0.44961, "lr": 0.0019298407, "top1_acc": 86.45833, "top1_err": 14.42708, "top5_acc": 98.43750, "top5_err": 2.23958}
[06/12 18:12:51][INFO] train_net.py:  708: Epoch 35 takes 47.01s. Epochs from 0 to 35 take 48.29s in average and 48.33s in median.
[06/12 18:12:51][INFO] train_net.py:  714: For epoch 35, each iteraction takes 0.78s in average. From epoch 0 to 35, each iteraction takes 0.80s in average.
[06/12 18:13:08][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47140, "dt_data": 0.00059, "dt_net": 0.47081, "epoch": "37/300", "eta": "2:04:22", "gpu_mem": "10.07G", "grad_norm": 13.23674, "iter": "10/60", "loss": 0.41039, "lr": 0.0019291971, "top1_acc": 87.50000, "top1_err": 14.06250, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:13:14][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47697, "dt_data": 0.00033, "dt_net": 0.47665, "epoch": "37/300", "eta": "2:05:45", "gpu_mem": "10.07G", "grad_norm": 9.69129, "iter": "20/60", "loss": 0.37907, "lr": 0.0019285506, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:13:20][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47371, "dt_data": 0.00041, "dt_net": 0.47329, "epoch": "37/300", "eta": "2:04:49", "gpu_mem": "10.07G", "grad_norm": 7.07127, "iter": "30/60", "loss": 0.37449, "lr": 0.0019279013, "top1_acc": 87.50000, "top1_err": 10.93750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:13:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47103, "dt_data": 0.00051, "dt_net": 0.47052, "epoch": "37/300", "eta": "2:04:02", "gpu_mem": "10.07G", "grad_norm": 9.08524, "iter": "40/60", "loss": 0.42266, "lr": 0.0019272492, "top1_acc": 84.37500, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:13:32][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.91822, "dt_data": 0.00036, "dt_net": 0.91786, "epoch": "37/300", "eta": "4:01:38", "gpu_mem": "10.07G", "grad_norm": 11.08603, "iter": "50/60", "loss": 0.48422, "lr": 0.0019265943, "top1_acc": 81.25000, "top1_err": 14.06250, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:13:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46891, "dt_data": 0.00017, "dt_net": 0.46874, "epoch": "37/300", "eta": "2:03:19", "gpu_mem": "10.07G", "grad_norm": 6.17475, "iter": "60/60", "loss": 0.49428, "lr": 0.0019259365, "top1_acc": 84.37500, "top1_err": 15.62500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 18:13:38][INFO] logging.py:  101: json_stats: {"RAM": "13.86/31.07G", "_type": "train_epoch", "dt": 0.69010, "dt_data": 0.69010, "dt_net": 0.46874, "epoch": "37/300", "eta": "3:01:29", "gpu_mem": "10.07G", "grad_norm": 6.17475, "loss": 0.44941, "lr": 0.0019259365, "top1_acc": 84.68750, "top1_err": 13.85417, "top5_acc": 97.08333, "top5_err": 2.50000}
[06/12 18:13:38][INFO] train_net.py:  708: Epoch 36 takes 46.78s. Epochs from 0 to 36 take 48.25s in average and 48.29s in median.
[06/12 18:13:38][INFO] train_net.py:  714: For epoch 36, each iteraction takes 0.78s in average. From epoch 0 to 36, each iteraction takes 0.80s in average.
[06/12 18:13:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47124, "dt_data": 0.00087, "dt_net": 0.47036, "epoch": "38/300", "eta": "2:03:51", "gpu_mem": "10.07G", "grad_norm": 7.28544, "iter": "10/60", "loss": 0.42039, "lr": 0.0019252759, "top1_acc": 84.37500, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:14:00][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48149, "dt_data": 0.00039, "dt_net": 0.48110, "epoch": "38/300", "eta": "2:06:28", "gpu_mem": "10.07G", "grad_norm": 7.84224, "iter": "20/60", "loss": 0.38099, "lr": 0.0019246125, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:14:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.51474, "dt_data": 0.00043, "dt_net": 0.51431, "epoch": "38/300", "eta": "2:15:07", "gpu_mem": "10.07G", "grad_norm": 7.94051, "iter": "30/60", "loss": 0.57390, "lr": 0.0019239463, "top1_acc": 87.50000, "top1_err": 17.18750, "top5_acc": 100.00000, "top5_err": 4.68750}
[06/12 18:14:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47457, "dt_data": 0.00031, "dt_net": 0.47426, "epoch": "38/300", "eta": "2:04:29", "gpu_mem": "10.07G", "grad_norm": 4.47445, "iter": "40/60", "loss": 0.42062, "lr": 0.0019232773, "top1_acc": 90.62500, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:14:20][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.91956, "dt_data": 0.43960, "dt_net": 0.47995, "epoch": "38/300", "eta": "4:01:04", "gpu_mem": "10.07G", "grad_norm": 6.14162, "iter": "50/60", "loss": 0.40115, "lr": 0.0019226054, "top1_acc": 87.50000, "top1_err": 15.62500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:14:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46900, "dt_data": 0.00016, "dt_net": 0.46883, "epoch": "38/300", "eta": "2:02:52", "gpu_mem": "10.07G", "grad_norm": 6.49375, "iter": "60/60", "loss": 0.40734, "lr": 0.0019219308, "top1_acc": 87.50000, "top1_err": 14.06250, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:14:26][INFO] logging.py:  101: json_stats: {"RAM": "13.86/31.07G", "_type": "train_epoch", "dt": 0.71274, "dt_data": 0.71274, "dt_net": 0.46883, "epoch": "38/300", "eta": "3:06:43", "gpu_mem": "10.07G", "grad_norm": 6.49375, "loss": 0.45546, "lr": 0.0019219308, "top1_acc": 86.35417, "top1_err": 14.27083, "top5_acc": 98.12500, "top5_err": 2.13542}
[06/12 18:14:26][INFO] train_net.py:  708: Epoch 37 takes 47.93s. Epochs from 0 to 37 take 48.24s in average and 48.27s in median.
[06/12 18:14:26][INFO] train_net.py:  714: For epoch 37, each iteraction takes 0.80s in average. From epoch 0 to 37, each iteraction takes 0.80s in average.
[06/12 18:14:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47636, "dt_data": 0.00056, "dt_net": 0.47580, "epoch": "39/300", "eta": "2:04:43", "gpu_mem": "10.07G", "grad_norm": 7.29431, "iter": "10/60", "loss": 0.48800, "lr": 0.0019212533, "top1_acc": 87.50000, "top1_err": 14.06250, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:14:48][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47052, "dt_data": 0.00051, "dt_net": 0.47000, "epoch": "39/300", "eta": "2:03:07", "gpu_mem": "10.07G", "grad_norm": 4.62960, "iter": "20/60", "loss": 0.35955, "lr": 0.0019205730, "top1_acc": 87.50000, "top1_err": 14.06250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:14:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.77775, "dt_data": 0.30921, "dt_net": 0.46854, "epoch": "39/300", "eta": "3:23:22", "gpu_mem": "10.07G", "grad_norm": 8.34715, "iter": "30/60", "loss": 0.41989, "lr": 0.0019198900, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:15:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.51788, "dt_data": 0.00055, "dt_net": 0.51733, "epoch": "39/300", "eta": "2:15:20", "gpu_mem": "10.07G", "grad_norm": 8.23018, "iter": "40/60", "loss": 0.48878, "lr": 0.0019192041, "top1_acc": 87.50000, "top1_err": 15.62500, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:15:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47374, "dt_data": 0.00044, "dt_net": 0.47329, "epoch": "39/300", "eta": "2:03:43", "gpu_mem": "10.07G", "grad_norm": 11.62211, "iter": "50/60", "loss": 0.51807, "lr": 0.0019185154, "top1_acc": 84.37500, "top1_err": 15.62500, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:15:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.79171, "dt_data": 0.00021, "dt_net": 0.79150, "epoch": "39/300", "eta": "3:26:38", "gpu_mem": "10.07G", "grad_norm": 9.85653, "iter": "60/60", "loss": 0.38858, "lr": 0.0019178239, "top1_acc": 87.50000, "top1_err": 10.93750, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:15:13][INFO] logging.py:  101: json_stats: {"RAM": "13.86/31.07G", "_type": "train_epoch", "dt": 0.69953, "dt_data": 0.69953, "dt_net": 0.79150, "epoch": "39/300", "eta": "3:02:33", "gpu_mem": "10.07G", "grad_norm": 9.85653, "loss": 0.46108, "lr": 0.0019178239, "top1_acc": 86.66667, "top1_err": 14.06250, "top5_acc": 98.12500, "top5_err": 2.65625}
[06/12 18:15:13][INFO] train_net.py:  708: Epoch 38 takes 47.38s. Epochs from 0 to 38 take 48.22s in average and 48.25s in median.
[06/12 18:15:13][INFO] train_net.py:  714: For epoch 38, each iteraction takes 0.79s in average. From epoch 0 to 38, each iteraction takes 0.80s in average.
[06/12 18:15:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47158, "dt_data": 0.00033, "dt_net": 0.47125, "epoch": "40/300", "eta": "2:03:00", "gpu_mem": "10.07G", "grad_norm": 9.29201, "iter": "10/60", "loss": 0.33311, "lr": 0.0019171297, "top1_acc": 90.62500, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:15:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47646, "dt_data": 0.00068, "dt_net": 0.47576, "epoch": "40/300", "eta": "2:04:11", "gpu_mem": "10.07G", "grad_norm": 9.96070, "iter": "20/60", "loss": 0.38210, "lr": 0.0019164326, "top1_acc": 87.50000, "top1_err": 10.93750, "top5_acc": 96.87500, "top5_err": 1.56250}
[06/12 18:15:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.68123, "dt_data": 0.00043, "dt_net": 0.68080, "epoch": "40/300", "eta": "2:57:27", "gpu_mem": "10.07G", "grad_norm": 9.91837, "iter": "30/60", "loss": 0.36862, "lr": 0.0019157327, "top1_acc": 93.75000, "top1_err": 10.93750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:15:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48015, "dt_data": 0.00084, "dt_net": 0.47931, "epoch": "40/300", "eta": "2:04:59", "gpu_mem": "10.07G", "grad_norm": 6.87415, "iter": "40/60", "loss": 0.40662, "lr": 0.0019150301, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:15:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.51621, "dt_data": 0.00109, "dt_net": 0.51511, "epoch": "40/300", "eta": "2:14:18", "gpu_mem": "10.07G", "grad_norm": 9.07932, "iter": "50/60", "loss": 0.40324, "lr": 0.0019143247, "top1_acc": 87.50000, "top1_err": 14.06250, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:16:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46972, "dt_data": 0.00017, "dt_net": 0.46955, "epoch": "40/300", "eta": "2:02:07", "gpu_mem": "10.07G", "grad_norm": 15.93286, "iter": "60/60", "loss": 0.42220, "lr": 0.0019136164, "top1_acc": 84.37500, "top1_err": 17.18750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:16:02][INFO] logging.py:  101: json_stats: {"RAM": "13.85/31.07G", "_type": "train_epoch", "dt": 0.69661, "dt_data": 0.69661, "dt_net": 0.46955, "epoch": "40/300", "eta": "3:01:06", "gpu_mem": "10.07G", "grad_norm": 15.93286, "loss": 0.40237, "lr": 0.0019136164, "top1_acc": 87.60417, "top1_err": 12.76042, "top5_acc": 98.02083, "top5_err": 1.56250}
[06/12 18:16:02][INFO] train_net.py:  708: Epoch 39 takes 48.09s. Epochs from 0 to 39 take 48.22s in average and 48.24s in median.
[06/12 18:16:02][INFO] train_net.py:  714: For epoch 39, each iteraction takes 0.80s in average. From epoch 0 to 39, each iteraction takes 0.80s in average.
[06/12 18:16:02][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 18:17:05][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "40/300", "eta": "0:00:06", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 1.07100, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 93.75000, "top5_err": 6.25000}
[06/12 18:17:08][INFO] logging.py:  101: json_stats: {"RAM": "13.16/31.07G", "_type": "val_epoch", "epoch": "40/300", "gpu_mem": "10.07G", "min_top1_err": 26.76349, "min_top5_err": 3.52697, "time_diff": 0.61121, "top1_acc": 73.23651, "top1_err": 26.76349, "top5_acc": 94.19087, "top5_err": 5.80913}
[06/12 18:17:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.54207, "dt_data": 0.07884, "dt_net": 0.46323, "epoch": "41/300", "eta": "2:20:50", "gpu_mem": "10.07G", "grad_norm": 9.02403, "iter": "10/60", "loss": 0.54684, "lr": 0.0019129054, "top1_acc": 90.62500, "top1_err": 15.62500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:17:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46667, "dt_data": 0.00035, "dt_net": 0.46632, "epoch": "41/300", "eta": "2:01:10", "gpu_mem": "10.07G", "grad_norm": 5.94769, "iter": "20/60", "loss": 0.40928, "lr": 0.0019121916, "top1_acc": 87.50000, "top1_err": 14.06250, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:17:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46729, "dt_data": 0.00044, "dt_net": 0.46684, "epoch": "41/300", "eta": "2:01:15", "gpu_mem": "10.07G", "grad_norm": 6.45816, "iter": "30/60", "loss": 0.41610, "lr": 0.0019114751, "top1_acc": 84.37500, "top1_err": 14.06250, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:17:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46923, "dt_data": 0.00041, "dt_net": 0.46882, "epoch": "41/300", "eta": "2:01:41", "gpu_mem": "10.07G", "grad_norm": 5.87426, "iter": "40/60", "loss": 0.32654, "lr": 0.0019107557, "top1_acc": 87.50000, "top1_err": 9.37500, "top5_acc": 96.87500, "top5_err": 1.56250}
[06/12 18:17:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47712, "dt_data": 0.00071, "dt_net": 0.47641, "epoch": "41/300", "eta": "2:03:39", "gpu_mem": "10.07G", "grad_norm": 6.57800, "iter": "50/60", "loss": 0.49178, "lr": 0.0019100336, "top1_acc": 84.37500, "top1_err": 17.18750, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:17:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46563, "dt_data": 0.00015, "dt_net": 0.46548, "epoch": "41/300", "eta": "2:00:35", "gpu_mem": "10.07G", "grad_norm": 10.28839, "iter": "60/60", "loss": 0.55120, "lr": 0.0019093087, "top1_acc": 84.37500, "top1_err": 17.18750, "top5_acc": 93.75000, "top5_err": 3.12500}
[06/12 18:17:55][INFO] logging.py:  101: json_stats: {"RAM": "13.13/31.07G", "_type": "train_epoch", "dt": 0.72053, "dt_data": 0.72053, "dt_net": 0.46548, "epoch": "41/300", "eta": "3:06:36", "gpu_mem": "10.07G", "grad_norm": 10.28839, "loss": 0.46332, "lr": 0.0019093087, "top1_acc": 85.93750, "top1_err": 14.21875, "top5_acc": 97.39583, "top5_err": 2.23958}
[06/12 18:17:55][INFO] train_net.py:  708: Epoch 40 takes 47.52s. Epochs from 0 to 40 take 48.20s in average and 48.23s in median.
[06/12 18:17:55][INFO] train_net.py:  714: For epoch 40, each iteraction takes 0.79s in average. From epoch 0 to 40, each iteraction takes 0.80s in average.
[06/12 18:18:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46986, "dt_data": 0.00049, "dt_net": 0.46937, "epoch": "42/300", "eta": "2:01:36", "gpu_mem": "10.07G", "grad_norm": 6.55074, "iter": "10/60", "loss": 0.33820, "lr": 0.0019085811, "top1_acc": 87.50000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:18:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47204, "dt_data": 0.00067, "dt_net": 0.47136, "epoch": "42/300", "eta": "2:02:06", "gpu_mem": "10.07G", "grad_norm": 4.13649, "iter": "20/60", "loss": 0.33890, "lr": 0.0019078507, "top1_acc": 87.50000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:18:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46905, "dt_data": 0.00030, "dt_net": 0.46875, "epoch": "42/300", "eta": "2:01:14", "gpu_mem": "10.07G", "grad_norm": 5.79624, "iter": "30/60", "loss": 0.37211, "lr": 0.0019071175, "top1_acc": 90.62500, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:18:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48557, "dt_data": 0.01522, "dt_net": 0.47034, "epoch": "42/300", "eta": "2:05:26", "gpu_mem": "10.07G", "grad_norm": 7.47890, "iter": "40/60", "loss": 0.29631, "lr": 0.0019063815, "top1_acc": 93.75000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:18:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47493, "dt_data": 0.00037, "dt_net": 0.47455, "epoch": "42/300", "eta": "2:02:36", "gpu_mem": "10.07G", "grad_norm": 10.44569, "iter": "50/60", "loss": 0.42999, "lr": 0.0019056428, "top1_acc": 81.25000, "top1_err": 14.06250, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:18:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46778, "dt_data": 0.00015, "dt_net": 0.46762, "epoch": "42/300", "eta": "2:00:41", "gpu_mem": "10.07G", "grad_norm": 7.06615, "iter": "60/60", "loss": 0.33115, "lr": 0.0019049014, "top1_acc": 87.50000, "top1_err": 10.93750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:18:43][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.69981, "dt_data": 0.69981, "dt_net": 0.46762, "epoch": "42/300", "eta": "3:00:32", "gpu_mem": "10.07G", "grad_norm": 7.06615, "loss": 0.36726, "lr": 0.0019049014, "top1_acc": 89.16667, "top1_err": 11.77083, "top5_acc": 98.12500, "top5_err": 1.51042}
[06/12 18:18:43][INFO] train_net.py:  708: Epoch 41 takes 48.08s. Epochs from 0 to 41 take 48.20s in average and 48.16s in median.
[06/12 18:18:43][INFO] train_net.py:  714: For epoch 41, each iteraction takes 0.80s in average. From epoch 0 to 41, each iteraction takes 0.80s in average.
[06/12 18:19:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47581, "dt_data": 0.00048, "dt_net": 0.47533, "epoch": "43/300", "eta": "2:02:40", "gpu_mem": "10.07G", "grad_norm": 4.96303, "iter": "10/60", "loss": 0.33083, "lr": 0.0019041571, "top1_acc": 93.75000, "top1_err": 10.93750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:19:06][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47855, "dt_data": 0.00075, "dt_net": 0.47779, "epoch": "43/300", "eta": "2:03:18", "gpu_mem": "10.07G", "grad_norm": 6.63507, "iter": "20/60", "loss": 0.29969, "lr": 0.0019034101, "top1_acc": 87.50000, "top1_err": 10.93750, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:19:12][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47316, "dt_data": 0.00033, "dt_net": 0.47283, "epoch": "43/300", "eta": "2:01:50", "gpu_mem": "10.07G", "grad_norm": 6.45187, "iter": "30/60", "loss": 0.32014, "lr": 0.0019026604, "top1_acc": 90.62500, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:19:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47367, "dt_data": 0.00074, "dt_net": 0.47293, "epoch": "43/300", "eta": "2:01:53", "gpu_mem": "10.07G", "grad_norm": 8.53197, "iter": "40/60", "loss": 0.40506, "lr": 0.0019019079, "top1_acc": 93.75000, "top1_err": 10.93750, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:19:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47227, "dt_data": 0.00034, "dt_net": 0.47192, "epoch": "43/300", "eta": "2:01:27", "gpu_mem": "10.07G", "grad_norm": 7.55397, "iter": "50/60", "loss": 0.39548, "lr": 0.0019011527, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:19:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46860, "dt_data": 0.00022, "dt_net": 0.46837, "epoch": "43/300", "eta": "2:00:25", "gpu_mem": "10.07G", "grad_norm": 8.40516, "iter": "60/60", "loss": 0.25442, "lr": 0.0019003947, "top1_acc": 90.62500, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:19:32][INFO] logging.py:  101: json_stats: {"RAM": "13.13/31.07G", "_type": "train_epoch", "dt": 0.70955, "dt_data": 0.70955, "dt_net": 0.46837, "epoch": "43/300", "eta": "3:02:20", "gpu_mem": "10.07G", "grad_norm": 8.40516, "loss": 0.35646, "lr": 0.0019003947, "top1_acc": 89.16667, "top1_err": 10.72917, "top5_acc": 98.75000, "top5_err": 1.66667}
[06/12 18:19:32][INFO] train_net.py:  708: Epoch 42 takes 48.58s. Epochs from 0 to 42 take 48.21s in average and 48.23s in median.
[06/12 18:19:32][INFO] train_net.py:  714: For epoch 42, each iteraction takes 0.81s in average. From epoch 0 to 42, each iteraction takes 0.80s in average.
[06/12 18:19:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47167, "dt_data": 0.00039, "dt_net": 0.47128, "epoch": "44/300", "eta": "2:01:08", "gpu_mem": "10.07G", "grad_norm": 16.60753, "iter": "10/60", "loss": 0.33518, "lr": 0.0018996340, "top1_acc": 81.25000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:19:56][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47310, "dt_data": 0.00039, "dt_net": 0.47271, "epoch": "44/300", "eta": "2:01:25", "gpu_mem": "10.07G", "grad_norm": 10.05906, "iter": "20/60", "loss": 0.49291, "lr": 0.0018988705, "top1_acc": 90.62500, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:20:02][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47243, "dt_data": 0.00054, "dt_net": 0.47189, "epoch": "44/300", "eta": "2:01:10", "gpu_mem": "10.07G", "grad_norm": 7.64103, "iter": "30/60", "loss": 0.43056, "lr": 0.0018981043, "top1_acc": 84.37500, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:20:08][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47858, "dt_data": 0.00054, "dt_net": 0.47804, "epoch": "44/300", "eta": "2:02:40", "gpu_mem": "10.07G", "grad_norm": 10.63889, "iter": "40/60", "loss": 0.40258, "lr": 0.0018973354, "top1_acc": 90.62500, "top1_err": 10.93750, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:20:14][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47381, "dt_data": 0.00045, "dt_net": 0.47335, "epoch": "44/300", "eta": "2:01:22", "gpu_mem": "10.07G", "grad_norm": 6.02741, "iter": "50/60", "loss": 0.31618, "lr": 0.0018965637, "top1_acc": 87.50000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:20:20][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47040, "dt_data": 0.00017, "dt_net": 0.47023, "epoch": "44/300", "eta": "2:00:25", "gpu_mem": "10.07G", "grad_norm": 13.49035, "iter": "60/60", "loss": 0.42353, "lr": 0.0018957894, "top1_acc": 87.50000, "top1_err": 14.06250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:20:20][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.74082, "dt_data": 0.74082, "dt_net": 0.47023, "epoch": "44/300", "eta": "3:09:38", "gpu_mem": "10.07G", "grad_norm": 13.49035, "loss": 0.40129, "lr": 0.0018957894, "top1_acc": 86.25000, "top1_err": 12.34375, "top5_acc": 98.75000, "top5_err": 1.35417}
[06/12 18:20:20][INFO] train_net.py:  708: Epoch 43 takes 48.28s. Epochs from 0 to 43 take 48.21s in average and 48.24s in median.
[06/12 18:20:20][INFO] train_net.py:  714: For epoch 43, each iteraction takes 0.80s in average. From epoch 0 to 43, each iteraction takes 0.80s in average.
[06/12 18:20:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47462, "dt_data": 0.00043, "dt_net": 0.47419, "epoch": "45/300", "eta": "2:01:25", "gpu_mem": "10.07G", "grad_norm": 7.37339, "iter": "10/60", "loss": 0.27743, "lr": 0.0018950122, "top1_acc": 93.75000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:20:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47178, "dt_data": 0.00049, "dt_net": 0.47128, "epoch": "45/300", "eta": "2:00:37", "gpu_mem": "10.07G", "grad_norm": 8.52851, "iter": "20/60", "loss": 0.44095, "lr": 0.0018942324, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:20:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47699, "dt_data": 0.00080, "dt_net": 0.47618, "epoch": "45/300", "eta": "2:01:52", "gpu_mem": "10.07G", "grad_norm": 11.85045, "iter": "30/60", "loss": 0.37134, "lr": 0.0018934498, "top1_acc": 93.75000, "top1_err": 10.93750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:20:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47824, "dt_data": 0.00056, "dt_net": 0.47768, "epoch": "45/300", "eta": "2:02:06", "gpu_mem": "10.07G", "grad_norm": 9.85800, "iter": "40/60", "loss": 0.41841, "lr": 0.0018926645, "top1_acc": 87.50000, "top1_err": 14.06250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:21:02][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.66041, "dt_data": 0.00033, "dt_net": 0.66008, "epoch": "45/300", "eta": "2:48:30", "gpu_mem": "10.07G", "grad_norm": 12.86026, "iter": "50/60", "loss": 0.41159, "lr": 0.0018918765, "top1_acc": 93.75000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:21:08][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46963, "dt_data": 0.00019, "dt_net": 0.46944, "epoch": "45/300", "eta": "1:59:45", "gpu_mem": "10.07G", "grad_norm": 6.23639, "iter": "60/60", "loss": 0.34054, "lr": 0.0018910857, "top1_acc": 84.37500, "top1_err": 14.06250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:21:08][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.69632, "dt_data": 0.69632, "dt_net": 0.46944, "epoch": "45/300", "eta": "2:57:33", "gpu_mem": "10.07G", "grad_norm": 6.23639, "loss": 0.40159, "lr": 0.0018910857, "top1_acc": 88.22917, "top1_err": 12.91667, "top5_acc": 98.22917, "top5_err": 1.92708}
[06/12 18:21:08][INFO] train_net.py:  708: Epoch 44 takes 47.98s. Epochs from 0 to 44 take 48.20s in average and 48.23s in median.
[06/12 18:21:08][INFO] train_net.py:  714: For epoch 44, each iteraction takes 0.80s in average. From epoch 0 to 44, each iteraction takes 0.80s in average.
[06/12 18:21:08][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 18:22:11][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "45/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.13039, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 95.31250, "top5_err": 4.68750}
[06/12 18:22:14][INFO] logging.py:  101: json_stats: {"RAM": "13.16/31.07G", "_type": "val_epoch", "epoch": "45/300", "gpu_mem": "10.07G", "min_top1_err": 26.55602, "min_top5_err": 3.52697, "time_diff": 0.60905, "top1_acc": 73.44398, "top1_err": 26.55602, "top5_acc": 95.85062, "top5_err": 4.14938}
[06/12 18:22:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46798, "dt_data": 0.00051, "dt_net": 0.46747, "epoch": "46/300", "eta": "1:59:15", "gpu_mem": "10.07G", "grad_norm": 8.42295, "iter": "10/60", "loss": 0.32839, "lr": 0.0018902923, "top1_acc": 87.50000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:22:38][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47083, "dt_data": 0.00040, "dt_net": 0.47043, "epoch": "46/300", "eta": "1:59:54", "gpu_mem": "10.07G", "grad_norm": 8.91682, "iter": "20/60", "loss": 0.47476, "lr": 0.0018894961, "top1_acc": 87.50000, "top1_err": 17.18750, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:22:44][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.88125, "dt_data": 0.41126, "dt_net": 0.46999, "epoch": "46/300", "eta": "3:44:16", "gpu_mem": "10.07G", "grad_norm": 5.32272, "iter": "30/60", "loss": 0.35612, "lr": 0.0018886973, "top1_acc": 93.75000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:22:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47058, "dt_data": 0.00042, "dt_net": 0.47016, "epoch": "46/300", "eta": "1:59:41", "gpu_mem": "10.07G", "grad_norm": 5.54718, "iter": "40/60", "loss": 0.30649, "lr": 0.0018878957, "top1_acc": 84.37500, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:22:56][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.98308, "dt_data": 0.51191, "dt_net": 0.47116, "epoch": "46/300", "eta": "4:09:51", "gpu_mem": "10.07G", "grad_norm": 9.85617, "iter": "50/60", "loss": 0.37380, "lr": 0.0018870914, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:23:02][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46712, "dt_data": 0.00016, "dt_net": 0.46695, "epoch": "46/300", "eta": "1:58:38", "gpu_mem": "10.07G", "grad_norm": 7.65983, "iter": "60/60", "loss": 0.38107, "lr": 0.0018862844, "top1_acc": 84.37500, "top1_err": 10.93750, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:23:02][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.70875, "dt_data": 0.70875, "dt_net": 0.46695, "epoch": "46/300", "eta": "3:00:00", "gpu_mem": "10.07G", "grad_norm": 7.65983, "loss": 0.38649, "lr": 0.0018862844, "top1_acc": 88.12500, "top1_err": 12.29167, "top5_acc": 98.95833, "top5_err": 1.45833}
[06/12 18:23:02][INFO] train_net.py:  708: Epoch 45 takes 48.22s. Epochs from 0 to 45 take 48.21s in average and 48.22s in median.
[06/12 18:23:02][INFO] train_net.py:  714: For epoch 45, each iteraction takes 0.80s in average. From epoch 0 to 45, each iteraction takes 0.80s in average.
[06/12 18:23:20][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48239, "dt_data": 0.00056, "dt_net": 0.48183, "epoch": "47/300", "eta": "2:02:26", "gpu_mem": "10.07G", "grad_norm": 7.47170, "iter": "10/60", "loss": 0.36198, "lr": 0.0018854747, "top1_acc": 90.62500, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:23:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47338, "dt_data": 0.00051, "dt_net": 0.47286, "epoch": "47/300", "eta": "2:00:04", "gpu_mem": "10.07G", "grad_norm": 9.95338, "iter": "20/60", "loss": 0.27422, "lr": 0.0018846624, "top1_acc": 87.50000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:23:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47353, "dt_data": 0.00078, "dt_net": 0.47274, "epoch": "47/300", "eta": "2:00:02", "gpu_mem": "10.07G", "grad_norm": 7.58607, "iter": "30/60", "loss": 0.31090, "lr": 0.0018838473, "top1_acc": 96.87500, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:23:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47389, "dt_data": 0.00066, "dt_net": 0.47322, "epoch": "47/300", "eta": "2:00:03", "gpu_mem": "10.07G", "grad_norm": 4.41309, "iter": "40/60", "loss": 0.33861, "lr": 0.0018830295, "top1_acc": 93.75000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:23:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47769, "dt_data": 0.00064, "dt_net": 0.47705, "epoch": "47/300", "eta": "2:00:56", "gpu_mem": "10.07G", "grad_norm": 9.31212, "iter": "50/60", "loss": 0.28448, "lr": 0.0018822091, "top1_acc": 87.50000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:23:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46818, "dt_data": 0.00019, "dt_net": 0.46799, "epoch": "47/300", "eta": "1:58:26", "gpu_mem": "10.07G", "grad_norm": 9.39584, "iter": "60/60", "loss": 0.28526, "lr": 0.0018813859, "top1_acc": 93.75000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:23:49][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.69505, "dt_data": 0.69505, "dt_net": 0.46799, "epoch": "47/300", "eta": "2:55:50", "gpu_mem": "10.07G", "grad_norm": 9.39584, "loss": 0.33485, "lr": 0.0018813859, "top1_acc": 90.62500, "top1_err": 10.00000, "top5_acc": 98.54167, "top5_err": 1.19792}
[06/12 18:23:49][INFO] train_net.py:  708: Epoch 46 takes 47.05s. Epochs from 0 to 46 take 48.18s in average and 48.22s in median.
[06/12 18:23:49][INFO] train_net.py:  714: For epoch 46, each iteraction takes 0.78s in average. From epoch 0 to 46, each iteraction takes 0.80s in average.
[06/12 18:24:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46889, "dt_data": 0.00040, "dt_net": 0.46849, "epoch": "48/300", "eta": "1:58:33", "gpu_mem": "10.07G", "grad_norm": 13.21141, "iter": "10/60", "loss": 0.24080, "lr": 0.0018805601, "top1_acc": 93.75000, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:24:12][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47083, "dt_data": 0.00031, "dt_net": 0.47052, "epoch": "48/300", "eta": "1:58:57", "gpu_mem": "10.07G", "grad_norm": 5.70853, "iter": "20/60", "loss": 0.26006, "lr": 0.0018797316, "top1_acc": 93.75000, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:24:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47919, "dt_data": 0.00073, "dt_net": 0.47846, "epoch": "48/300", "eta": "2:00:59", "gpu_mem": "10.07G", "grad_norm": 6.75043, "iter": "30/60", "loss": 0.37082, "lr": 0.0018789004, "top1_acc": 90.62500, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:24:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48958, "dt_data": 0.00031, "dt_net": 0.48927, "epoch": "48/300", "eta": "2:03:32", "gpu_mem": "10.07G", "grad_norm": 5.73610, "iter": "40/60", "loss": 0.24895, "lr": 0.0018780665, "top1_acc": 93.75000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:24:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47407, "dt_data": 0.00034, "dt_net": 0.47373, "epoch": "48/300", "eta": "1:59:32", "gpu_mem": "10.07G", "grad_norm": 6.85943, "iter": "50/60", "loss": 0.35227, "lr": 0.0018772300, "top1_acc": 90.62500, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:24:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46750, "dt_data": 0.00021, "dt_net": 0.46728, "epoch": "48/300", "eta": "1:57:48", "gpu_mem": "10.07G", "grad_norm": 6.65681, "iter": "60/60", "loss": 0.23352, "lr": 0.0018763907, "top1_acc": 90.62500, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:24:38][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.72568, "dt_data": 0.72568, "dt_net": 0.46728, "epoch": "48/300", "eta": "3:02:51", "gpu_mem": "10.07G", "grad_norm": 6.65681, "loss": 0.30793, "lr": 0.0018763907, "top1_acc": 90.41667, "top1_err": 9.53125, "top5_acc": 98.75000, "top5_err": 1.09375}
[06/12 18:24:38][INFO] train_net.py:  708: Epoch 47 takes 48.13s. Epochs from 0 to 47 take 48.18s in average and 48.17s in median.
[06/12 18:24:38][INFO] train_net.py:  714: For epoch 47, each iteraction takes 0.80s in average. From epoch 0 to 47, each iteraction takes 0.80s in average.
[06/12 18:24:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.91692, "dt_data": 0.00053, "dt_net": 0.91639, "epoch": "49/300", "eta": "3:50:54", "gpu_mem": "10.07G", "grad_norm": 8.23887, "iter": "10/60", "loss": 0.34971, "lr": 0.0018755489, "top1_acc": 87.50000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:25:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48005, "dt_data": 0.00072, "dt_net": 0.47933, "epoch": "49/300", "eta": "2:00:48", "gpu_mem": "10.07G", "grad_norm": 8.71566, "iter": "20/60", "loss": 0.25023, "lr": 0.0018747043, "top1_acc": 87.50000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:25:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.67898, "dt_data": 0.00037, "dt_net": 0.67861, "epoch": "49/300", "eta": "2:50:45", "gpu_mem": "10.07G", "grad_norm": 6.15347, "iter": "30/60", "loss": 0.25392, "lr": 0.0018738571, "top1_acc": 90.62500, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:25:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47590, "dt_data": 0.00057, "dt_net": 0.47533, "epoch": "49/300", "eta": "1:59:36", "gpu_mem": "10.07G", "grad_norm": 3.63544, "iter": "40/60", "loss": 0.33607, "lr": 0.0018730072, "top1_acc": 90.62500, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:25:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.82701, "dt_data": 0.00072, "dt_net": 0.82628, "epoch": "49/300", "eta": "3:27:43", "gpu_mem": "10.07G", "grad_norm": 11.35801, "iter": "50/60", "loss": 0.32602, "lr": 0.0018721547, "top1_acc": 84.37500, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:25:24][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46994, "dt_data": 0.00020, "dt_net": 0.46974, "epoch": "49/300", "eta": "1:57:57", "gpu_mem": "10.07G", "grad_norm": 7.05434, "iter": "60/60", "loss": 0.30040, "lr": 0.0018712995, "top1_acc": 87.50000, "top1_err": 10.93750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:25:25][INFO] logging.py:  101: json_stats: {"RAM": "13.13/31.07G", "_type": "train_epoch", "dt": 0.72049, "dt_data": 0.72049, "dt_net": 0.46974, "epoch": "49/300", "eta": "3:00:49", "gpu_mem": "10.07G", "grad_norm": 7.05434, "loss": 0.31942, "lr": 0.0018712995, "top1_acc": 89.47917, "top1_err": 9.42708, "top5_acc": 97.81250, "top5_err": 1.87500}
[06/12 18:25:25][INFO] train_net.py:  708: Epoch 48 takes 47.47s. Epochs from 0 to 48 take 48.17s in average and 48.13s in median.
[06/12 18:25:25][INFO] train_net.py:  714: For epoch 48, each iteraction takes 0.79s in average. From epoch 0 to 48, each iteraction takes 0.80s in average.
[06/12 18:25:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47079, "dt_data": 0.00036, "dt_net": 0.47043, "epoch": "50/300", "eta": "1:58:05", "gpu_mem": "10.07G", "grad_norm": 13.29682, "iter": "10/60", "loss": 0.26941, "lr": 0.0018704416, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:25:48][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47885, "dt_data": 0.00045, "dt_net": 0.47840, "epoch": "50/300", "eta": "2:00:01", "gpu_mem": "10.07G", "grad_norm": 10.59843, "iter": "20/60", "loss": 0.33972, "lr": 0.0018695811, "top1_acc": 90.62500, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:25:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.66780, "dt_data": 0.00054, "dt_net": 0.66725, "epoch": "50/300", "eta": "2:47:17", "gpu_mem": "10.07G", "grad_norm": 11.94261, "iter": "30/60", "loss": 0.35669, "lr": 0.0018687180, "top1_acc": 93.75000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:26:00][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48383, "dt_data": 0.00055, "dt_net": 0.48328, "epoch": "50/300", "eta": "2:01:07", "gpu_mem": "10.07G", "grad_norm": 8.75147, "iter": "40/60", "loss": 0.31336, "lr": 0.0018678522, "top1_acc": 87.50000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:26:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48611, "dt_data": 0.00080, "dt_net": 0.48531, "epoch": "50/300", "eta": "2:01:36", "gpu_mem": "10.07G", "grad_norm": 5.32147, "iter": "50/60", "loss": 0.27847, "lr": 0.0018669837, "top1_acc": 93.75000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:26:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46975, "dt_data": 0.00014, "dt_net": 0.46961, "epoch": "50/300", "eta": "1:57:26", "gpu_mem": "10.07G", "grad_norm": 11.60040, "iter": "60/60", "loss": 0.35589, "lr": 0.0018661127, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:26:13][INFO] logging.py:  101: json_stats: {"RAM": "13.13/31.07G", "_type": "train_epoch", "dt": 0.69941, "dt_data": 0.69941, "dt_net": 0.46961, "epoch": "50/300", "eta": "2:54:50", "gpu_mem": "10.07G", "grad_norm": 11.60040, "loss": 0.33751, "lr": 0.0018661127, "top1_acc": 88.64583, "top1_err": 10.26042, "top5_acc": 98.85417, "top5_err": 1.35417}
[06/12 18:26:13][INFO] train_net.py:  708: Epoch 49 takes 48.15s. Epochs from 0 to 49 take 48.16s in average and 48.14s in median.
[06/12 18:26:13][INFO] train_net.py:  714: For epoch 49, each iteraction takes 0.80s in average. From epoch 0 to 49, each iteraction takes 0.80s in average.
[06/12 18:26:13][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 18:27:15][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "50/300", "eta": "0:00:01", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.25871, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 18:27:18][INFO] logging.py:  101: json_stats: {"RAM": "13.26/31.07G", "_type": "val_epoch", "epoch": "50/300", "gpu_mem": "10.07G", "min_top1_err": 26.55602, "min_top5_err": 3.52697, "time_diff": 0.61811, "top1_acc": 71.57676, "top1_err": 28.42324, "top5_acc": 96.26556, "top5_err": 3.73444}
[06/12 18:27:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.95496, "dt_data": 0.00066, "dt_net": 0.95430, "epoch": "51/300", "eta": "3:58:34", "gpu_mem": "10.07G", "grad_norm": 9.88886, "iter": "10/60", "loss": 0.22035, "lr": 0.0018652389, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:27:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46767, "dt_data": 0.00055, "dt_net": 0.46711, "epoch": "51/300", "eta": "1:56:45", "gpu_mem": "10.07G", "grad_norm": 10.57105, "iter": "20/60", "loss": 0.40007, "lr": 0.0018643626, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:27:48][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.58812, "dt_data": 0.00040, "dt_net": 0.58772, "epoch": "51/300", "eta": "2:26:44", "gpu_mem": "10.07G", "grad_norm": 6.52620, "iter": "30/60", "loss": 0.30606, "lr": 0.0018634836, "top1_acc": 90.62500, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:27:54][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47071, "dt_data": 0.00053, "dt_net": 0.47018, "epoch": "51/300", "eta": "1:57:21", "gpu_mem": "10.07G", "grad_norm": 6.87044, "iter": "40/60", "loss": 0.33536, "lr": 0.0018626020, "top1_acc": 93.75000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:28:00][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.61352, "dt_data": 0.00040, "dt_net": 0.61312, "epoch": "51/300", "eta": "2:32:52", "gpu_mem": "10.07G", "grad_norm": 9.17235, "iter": "50/60", "loss": 0.26685, "lr": 0.0018617177, "top1_acc": 93.75000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:28:06][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46686, "dt_data": 0.00017, "dt_net": 0.46669, "epoch": "51/300", "eta": "1:56:14", "gpu_mem": "10.07G", "grad_norm": 16.09247, "iter": "60/60", "loss": 0.34910, "lr": 0.0018608309, "top1_acc": 93.75000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:28:06][INFO] logging.py:  101: json_stats: {"RAM": "13.12/31.07G", "_type": "train_epoch", "dt": 0.70435, "dt_data": 0.70435, "dt_net": 0.46669, "epoch": "51/300", "eta": "2:55:22", "gpu_mem": "10.07G", "grad_norm": 16.09247, "loss": 0.31735, "lr": 0.0018608309, "top1_acc": 91.14583, "top1_err": 9.63542, "top5_acc": 98.95833, "top5_err": 1.14583}
[06/12 18:28:06][INFO] train_net.py:  708: Epoch 50 takes 48.78s. Epochs from 0 to 50 take 48.18s in average and 48.15s in median.
[06/12 18:28:06][INFO] train_net.py:  714: For epoch 50, each iteraction takes 0.81s in average. From epoch 0 to 50, each iteraction takes 0.80s in average.
[06/12 18:28:24][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46709, "dt_data": 0.00049, "dt_net": 0.46660, "epoch": "52/300", "eta": "1:56:13", "gpu_mem": "10.07G", "grad_norm": 7.18553, "iter": "10/60", "loss": 0.28839, "lr": 0.0018599414, "top1_acc": 93.75000, "top1_err": 10.93750, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:28:30][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47103, "dt_data": 0.00053, "dt_net": 0.47050, "epoch": "52/300", "eta": "1:57:07", "gpu_mem": "10.07G", "grad_norm": 5.11599, "iter": "20/60", "loss": 0.26714, "lr": 0.0018590493, "top1_acc": 93.75000, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:28:36][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47116, "dt_data": 0.00043, "dt_net": 0.47073, "epoch": "52/300", "eta": "1:57:05", "gpu_mem": "10.07G", "grad_norm": 6.85678, "iter": "30/60", "loss": 0.22746, "lr": 0.0018581545, "top1_acc": 93.75000, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:28:42][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47746, "dt_data": 0.00049, "dt_net": 0.47696, "epoch": "52/300", "eta": "1:58:34", "gpu_mem": "10.07G", "grad_norm": 5.64056, "iter": "40/60", "loss": 0.26188, "lr": 0.0018572572, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:28:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47708, "dt_data": 0.00066, "dt_net": 0.47642, "epoch": "52/300", "eta": "1:58:23", "gpu_mem": "10.07G", "grad_norm": 8.13058, "iter": "50/60", "loss": 0.27727, "lr": 0.0018563572, "top1_acc": 87.50000, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:28:54][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46833, "dt_data": 0.00014, "dt_net": 0.46819, "epoch": "52/300", "eta": "1:56:08", "gpu_mem": "10.07G", "grad_norm": 8.44772, "iter": "60/60", "loss": 0.28233, "lr": 0.0018554547, "top1_acc": 87.50000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:28:55][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.70608, "dt_data": 0.70608, "dt_net": 0.46819, "epoch": "52/300", "eta": "2:55:05", "gpu_mem": "10.07G", "grad_norm": 8.44772, "loss": 0.29588, "lr": 0.0018554547, "top1_acc": 91.14583, "top1_err": 9.21875, "top5_acc": 99.06250, "top5_err": 1.19792}
[06/12 18:28:55][INFO] train_net.py:  708: Epoch 51 takes 48.37s. Epochs from 0 to 51 take 48.18s in average and 48.19s in median.
[06/12 18:28:55][INFO] train_net.py:  714: For epoch 51, each iteraction takes 0.81s in average. From epoch 0 to 51, each iteraction takes 0.80s in average.
[06/12 18:29:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46892, "dt_data": 0.00041, "dt_net": 0.46851, "epoch": "53/300", "eta": "1:56:12", "gpu_mem": "10.07G", "grad_norm": 6.04886, "iter": "10/60", "loss": 0.27770, "lr": 0.0018545495, "top1_acc": 93.75000, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:29:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47575, "dt_data": 0.00071, "dt_net": 0.47503, "epoch": "53/300", "eta": "1:57:49", "gpu_mem": "10.07G", "grad_norm": 9.28729, "iter": "20/60", "loss": 0.31240, "lr": 0.0018536417, "top1_acc": 87.50000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:29:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47355, "dt_data": 0.00061, "dt_net": 0.47293, "epoch": "53/300", "eta": "1:57:12", "gpu_mem": "10.07G", "grad_norm": 10.76348, "iter": "30/60", "loss": 0.31858, "lr": 0.0018527313, "top1_acc": 87.50000, "top1_err": 10.93750, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:29:30][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47657, "dt_data": 0.00053, "dt_net": 0.47603, "epoch": "53/300", "eta": "1:57:52", "gpu_mem": "10.07G", "grad_norm": 5.42736, "iter": "40/60", "loss": 0.21063, "lr": 0.0018518184, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:29:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47336, "dt_data": 0.00056, "dt_net": 0.47280, "epoch": "53/300", "eta": "1:56:59", "gpu_mem": "10.07G", "grad_norm": 9.49394, "iter": "50/60", "loss": 0.28109, "lr": 0.0018509028, "top1_acc": 87.50000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:29:42][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47098, "dt_data": 0.00019, "dt_net": 0.47079, "epoch": "53/300", "eta": "1:56:19", "gpu_mem": "10.07G", "grad_norm": 10.28912, "iter": "60/60", "loss": 0.21165, "lr": 0.0018499847, "top1_acc": 93.75000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:29:43][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.72765, "dt_data": 0.72765, "dt_net": 0.47079, "epoch": "53/300", "eta": "2:59:43", "gpu_mem": "10.07G", "grad_norm": 10.28912, "loss": 0.30060, "lr": 0.0018499847, "top1_acc": 90.62500, "top1_err": 9.06250, "top5_acc": 98.75000, "top5_err": 1.40625}
[06/12 18:29:43][INFO] train_net.py:  708: Epoch 52 takes 48.04s. Epochs from 0 to 52 take 48.18s in average and 48.15s in median.
[06/12 18:29:43][INFO] train_net.py:  714: For epoch 52, each iteraction takes 0.80s in average. From epoch 0 to 52, each iteraction takes 0.80s in average.
[06/12 18:30:00][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47123, "dt_data": 0.00046, "dt_net": 0.47076, "epoch": "54/300", "eta": "1:56:18", "gpu_mem": "10.07G", "grad_norm": 6.99149, "iter": "10/60", "loss": 0.29616, "lr": 0.0018490639, "top1_acc": 100.00000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:30:06][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47913, "dt_data": 0.00039, "dt_net": 0.47874, "epoch": "54/300", "eta": "1:58:11", "gpu_mem": "10.07G", "grad_norm": 5.95659, "iter": "20/60", "loss": 0.20090, "lr": 0.0018481406, "top1_acc": 90.62500, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:30:12][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.09998, "dt_data": 0.62684, "dt_net": 0.47314, "epoch": "54/300", "eta": "4:31:08", "gpu_mem": "10.07G", "grad_norm": 7.90280, "iter": "30/60", "loss": 0.31808, "lr": 0.0018472147, "top1_acc": 93.75000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:30:18][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47692, "dt_data": 0.00041, "dt_net": 0.47651, "epoch": "54/300", "eta": "1:57:28", "gpu_mem": "10.07G", "grad_norm": 6.46877, "iter": "40/60", "loss": 0.35519, "lr": 0.0018462862, "top1_acc": 87.50000, "top1_err": 10.93750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:30:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.71360, "dt_data": 0.24265, "dt_net": 0.47094, "epoch": "54/300", "eta": "2:55:39", "gpu_mem": "10.07G", "grad_norm": 8.86752, "iter": "50/60", "loss": 0.30407, "lr": 0.0018453551, "top1_acc": 87.50000, "top1_err": 9.37500, "top5_acc": 93.75000, "top5_err": 3.12500}
[06/12 18:30:30][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47164, "dt_data": 0.00016, "dt_net": 0.47148, "epoch": "54/300", "eta": "1:56:01", "gpu_mem": "10.07G", "grad_norm": 7.64432, "iter": "60/60", "loss": 0.27761, "lr": 0.0018444214, "top1_acc": 87.50000, "top1_err": 10.93750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:30:31][INFO] logging.py:  101: json_stats: {"RAM": "13.13/31.07G", "_type": "train_epoch", "dt": 0.70643, "dt_data": 0.70643, "dt_net": 0.47148, "epoch": "54/300", "eta": "2:53:46", "gpu_mem": "10.07G", "grad_norm": 7.64432, "loss": 0.30600, "lr": 0.0018444214, "top1_acc": 90.83333, "top1_err": 8.95833, "top5_acc": 98.64583, "top5_err": 1.25000}
[06/12 18:30:31][INFO] train_net.py:  708: Epoch 53 takes 48.12s. Epochs from 0 to 53 take 48.18s in average and 48.14s in median.
[06/12 18:30:31][INFO] train_net.py:  714: For epoch 53, each iteraction takes 0.80s in average. From epoch 0 to 53, each iteraction takes 0.80s in average.
[06/12 18:30:48][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47555, "dt_data": 0.00084, "dt_net": 0.47470, "epoch": "55/300", "eta": "1:56:54", "gpu_mem": "10.07G", "grad_norm": 6.47692, "iter": "10/60", "loss": 0.25618, "lr": 0.0018434852, "top1_acc": 93.75000, "top1_err": 9.37500, "top5_acc": 96.87500, "top5_err": 1.56250}
[06/12 18:30:54][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48180, "dt_data": 0.00037, "dt_net": 0.48143, "epoch": "55/300", "eta": "1:58:21", "gpu_mem": "10.07G", "grad_norm": 8.31519, "iter": "20/60", "loss": 0.30837, "lr": 0.0018425464, "top1_acc": 87.50000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:31:00][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48071, "dt_data": 0.00071, "dt_net": 0.48000, "epoch": "55/300", "eta": "1:58:00", "gpu_mem": "10.07G", "grad_norm": 6.62277, "iter": "30/60", "loss": 0.27033, "lr": 0.0018416051, "top1_acc": 90.62500, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:31:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47510, "dt_data": 0.00042, "dt_net": 0.47469, "epoch": "55/300", "eta": "1:56:33", "gpu_mem": "10.07G", "grad_norm": 9.83327, "iter": "40/60", "loss": 0.35230, "lr": 0.0018406611, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:31:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.49078, "dt_data": 0.00089, "dt_net": 0.48988, "epoch": "55/300", "eta": "2:00:19", "gpu_mem": "10.07G", "grad_norm": 2.69427, "iter": "50/60", "loss": 0.26192, "lr": 0.0018397147, "top1_acc": 87.50000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:31:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47119, "dt_data": 0.00017, "dt_net": 0.47102, "epoch": "55/300", "eta": "1:55:26", "gpu_mem": "10.07G", "grad_norm": 6.15336, "iter": "60/60", "loss": 0.32630, "lr": 0.0018387656, "top1_acc": 90.62500, "top1_err": 10.93750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:31:20][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.71537, "dt_data": 0.71537, "dt_net": 0.47102, "epoch": "55/300", "eta": "2:55:15", "gpu_mem": "10.07G", "grad_norm": 6.15336, "loss": 0.31673, "lr": 0.0018387656, "top1_acc": 89.27083, "top1_err": 10.05208, "top5_acc": 98.12500, "top5_err": 1.45833}
[06/12 18:31:20][INFO] train_net.py:  708: Epoch 54 takes 48.90s. Epochs from 0 to 54 take 48.19s in average and 48.15s in median.
[06/12 18:31:20][INFO] train_net.py:  714: For epoch 54, each iteraction takes 0.81s in average. From epoch 0 to 54, each iteraction takes 0.80s in average.
[06/12 18:31:20][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 18:32:23][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "55/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.13023, "top1_acc": 76.56250, "top1_err": 23.43750, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 18:32:26][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "val_epoch", "epoch": "55/300", "gpu_mem": "10.07G", "min_top1_err": 24.68880, "min_top5_err": 3.52697, "time_diff": 0.63852, "top1_acc": 75.31120, "top1_err": 24.68880, "top5_acc": 96.26556, "top5_err": 3.73444}
[06/12 18:32:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46680, "dt_data": 0.00047, "dt_net": 0.46633, "epoch": "56/300", "eta": "1:54:17", "gpu_mem": "10.07G", "grad_norm": 6.33153, "iter": "10/60", "loss": 0.26057, "lr": 0.0018378140, "top1_acc": 87.50000, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:32:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47195, "dt_data": 0.00065, "dt_net": 0.47129, "epoch": "56/300", "eta": "1:55:28", "gpu_mem": "10.07G", "grad_norm": 8.95259, "iter": "20/60", "loss": 0.23504, "lr": 0.0018368599, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:32:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.50604, "dt_data": 0.00056, "dt_net": 1.50547, "epoch": "56/300", "eta": "6:08:13", "gpu_mem": "10.07G", "grad_norm": 5.24982, "iter": "30/60", "loss": 0.35980, "lr": 0.0018359032, "top1_acc": 93.75000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:33:02][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46713, "dt_data": 0.00041, "dt_net": 0.46672, "epoch": "56/300", "eta": "1:54:08", "gpu_mem": "10.07G", "grad_norm": 4.13279, "iter": "40/60", "loss": 0.31153, "lr": 0.0018349439, "top1_acc": 90.62500, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:33:09][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.32265, "dt_data": 0.00035, "dt_net": 1.32230, "epoch": "56/300", "eta": "5:22:56", "gpu_mem": "10.07G", "grad_norm": 9.86455, "iter": "50/60", "loss": 0.28819, "lr": 0.0018339821, "top1_acc": 93.75000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:33:14][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46757, "dt_data": 0.00016, "dt_net": 0.46741, "epoch": "56/300", "eta": "1:54:05", "gpu_mem": "10.07G", "grad_norm": 6.79228, "iter": "60/60", "loss": 0.28153, "lr": 0.0018330178, "top1_acc": 90.62500, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:33:15][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.70565, "dt_data": 0.70565, "dt_net": 0.46741, "epoch": "56/300", "eta": "2:52:10", "gpu_mem": "10.07G", "grad_norm": 6.79228, "loss": 0.30868, "lr": 0.0018330178, "top1_acc": 90.41667, "top1_err": 9.47917, "top5_acc": 98.12500, "top5_err": 1.40625}
[06/12 18:33:15][INFO] train_net.py:  708: Epoch 55 takes 48.57s. Epochs from 0 to 55 take 48.20s in average and 48.19s in median.
[06/12 18:33:15][INFO] train_net.py:  714: For epoch 55, each iteraction takes 0.81s in average. From epoch 0 to 55, each iteraction takes 0.80s in average.
[06/12 18:33:32][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46732, "dt_data": 0.00042, "dt_net": 0.46690, "epoch": "57/300", "eta": "1:53:56", "gpu_mem": "10.07G", "grad_norm": 4.79169, "iter": "10/60", "loss": 0.20880, "lr": 0.0018320509, "top1_acc": 90.62500, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:33:39][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46890, "dt_data": 0.00042, "dt_net": 0.46847, "epoch": "57/300", "eta": "1:54:15", "gpu_mem": "10.07G", "grad_norm": 8.63640, "iter": "20/60", "loss": 0.29289, "lr": 0.0018310815, "top1_acc": 93.75000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:33:45][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47395, "dt_data": 0.00097, "dt_net": 0.47296, "epoch": "57/300", "eta": "1:55:24", "gpu_mem": "10.07G", "grad_norm": 6.65239, "iter": "30/60", "loss": 0.28260, "lr": 0.0018301096, "top1_acc": 93.75000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:33:51][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47422, "dt_data": 0.00042, "dt_net": 0.47380, "epoch": "57/300", "eta": "1:55:23", "gpu_mem": "10.07G", "grad_norm": 5.66106, "iter": "40/60", "loss": 0.25884, "lr": 0.0018291352, "top1_acc": 93.75000, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:33:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47086, "dt_data": 0.00035, "dt_net": 0.47051, "epoch": "57/300", "eta": "1:54:29", "gpu_mem": "10.07G", "grad_norm": 5.25255, "iter": "50/60", "loss": 0.25289, "lr": 0.0018281582, "top1_acc": 87.50000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:34:03][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46878, "dt_data": 0.00015, "dt_net": 0.46864, "epoch": "57/300", "eta": "1:53:54", "gpu_mem": "10.07G", "grad_norm": 4.95130, "iter": "60/60", "loss": 0.22684, "lr": 0.0018271787, "top1_acc": 93.75000, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:34:03][INFO] logging.py:  101: json_stats: {"RAM": "13.16/31.07G", "_type": "train_epoch", "dt": 0.70447, "dt_data": 0.70447, "dt_net": 0.46864, "epoch": "57/300", "eta": "2:51:10", "gpu_mem": "10.07G", "grad_norm": 4.95130, "loss": 0.27130, "lr": 0.0018271787, "top1_acc": 92.29167, "top1_err": 8.43750, "top5_acc": 99.37500, "top5_err": 0.67708}
[06/12 18:34:03][INFO] train_net.py:  708: Epoch 56 takes 48.59s. Epochs from 0 to 56 take 48.20s in average and 48.22s in median.
[06/12 18:34:03][INFO] train_net.py:  714: For epoch 56, each iteraction takes 0.81s in average. From epoch 0 to 56, each iteraction takes 0.80s in average.
[06/12 18:34:20][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47348, "dt_data": 0.00045, "dt_net": 0.47303, "epoch": "58/300", "eta": "1:54:58", "gpu_mem": "10.07G", "grad_norm": 11.56527, "iter": "10/60", "loss": 0.26379, "lr": 0.0018261966, "top1_acc": 87.50000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:34:27][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48122, "dt_data": 0.00046, "dt_net": 0.48077, "epoch": "58/300", "eta": "1:56:46", "gpu_mem": "10.07G", "grad_norm": 2.89311, "iter": "20/60", "loss": 0.21519, "lr": 0.0018252121, "top1_acc": 96.87500, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:34:32][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47056, "dt_data": 0.00033, "dt_net": 0.47023, "epoch": "58/300", "eta": "1:54:06", "gpu_mem": "10.07G", "grad_norm": 5.54684, "iter": "30/60", "loss": 0.25508, "lr": 0.0018242250, "top1_acc": 87.50000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:34:39][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47426, "dt_data": 0.00067, "dt_net": 0.47358, "epoch": "58/300", "eta": "1:54:55", "gpu_mem": "10.07G", "grad_norm": 9.35919, "iter": "40/60", "loss": 0.28764, "lr": 0.0018232355, "top1_acc": 90.62500, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:34:45][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47444, "dt_data": 0.00064, "dt_net": 0.47380, "epoch": "58/300", "eta": "1:54:53", "gpu_mem": "10.07G", "grad_norm": 10.68334, "iter": "50/60", "loss": 0.26374, "lr": 0.0018222434, "top1_acc": 93.75000, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:34:51][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46783, "dt_data": 0.00016, "dt_net": 0.46768, "epoch": "58/300", "eta": "1:53:12", "gpu_mem": "10.07G", "grad_norm": 4.68433, "iter": "60/60", "loss": 0.28502, "lr": 0.0018212488, "top1_acc": 90.62500, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:34:52][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.70117, "dt_data": 0.70117, "dt_net": 0.46768, "epoch": "58/300", "eta": "2:49:40", "gpu_mem": "10.07G", "grad_norm": 4.68433, "loss": 0.28088, "lr": 0.0018212488, "top1_acc": 91.56250, "top1_err": 8.33333, "top5_acc": 98.85417, "top5_err": 1.19792}
[06/12 18:34:52][INFO] train_net.py:  708: Epoch 57 takes 48.40s. Epochs from 0 to 57 take 48.21s in average and 48.22s in median.
[06/12 18:34:52][INFO] train_net.py:  714: For epoch 57, each iteraction takes 0.81s in average. From epoch 0 to 57, each iteraction takes 0.80s in average.
[06/12 18:35:09][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47212, "dt_data": 0.00034, "dt_net": 0.47179, "epoch": "59/300", "eta": "1:54:10", "gpu_mem": "10.07G", "grad_norm": 7.00364, "iter": "10/60", "loss": 0.24539, "lr": 0.0018202517, "top1_acc": 93.75000, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:35:15][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47445, "dt_data": 0.00071, "dt_net": 0.47373, "epoch": "59/300", "eta": "1:54:39", "gpu_mem": "10.07G", "grad_norm": 7.88512, "iter": "20/60", "loss": 0.26050, "lr": 0.0018192521, "top1_acc": 87.50000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:35:21][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48130, "dt_data": 0.00155, "dt_net": 0.47973, "epoch": "59/300", "eta": "1:56:14", "gpu_mem": "10.07G", "grad_norm": 4.57173, "iter": "30/60", "loss": 0.18655, "lr": 0.0018182501, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:35:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47609, "dt_data": 0.00058, "dt_net": 0.47551, "epoch": "59/300", "eta": "1:54:53", "gpu_mem": "10.07G", "grad_norm": 11.80422, "iter": "40/60", "loss": 0.28861, "lr": 0.0018172455, "top1_acc": 87.50000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:35:34][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.55082, "dt_data": 0.07495, "dt_net": 0.47587, "epoch": "59/300", "eta": "2:12:50", "gpu_mem": "10.07G", "grad_norm": 5.39537, "iter": "50/60", "loss": 0.22808, "lr": 0.0018162384, "top1_acc": 93.75000, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:35:39][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46875, "dt_data": 0.00016, "dt_net": 0.46858, "epoch": "59/300", "eta": "1:52:58", "gpu_mem": "10.07G", "grad_norm": 5.86881, "iter": "60/60", "loss": 0.29563, "lr": 0.0018152289, "top1_acc": 93.75000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:35:40][INFO] logging.py:  101: json_stats: {"RAM": "13.13/31.07G", "_type": "train_epoch", "dt": 0.71403, "dt_data": 0.71403, "dt_net": 0.46858, "epoch": "59/300", "eta": "2:52:04", "gpu_mem": "10.07G", "grad_norm": 5.86881, "loss": 0.27487, "lr": 0.0018152289, "top1_acc": 91.14583, "top1_err": 8.75000, "top5_acc": 99.06250, "top5_err": 0.98958}
[06/12 18:35:40][INFO] train_net.py:  708: Epoch 58 takes 48.03s. Epochs from 0 to 58 take 48.20s in average and 48.22s in median.
[06/12 18:35:40][INFO] train_net.py:  714: For epoch 58, each iteraction takes 0.80s in average. From epoch 0 to 58, each iteraction takes 0.80s in average.
[06/12 18:35:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48199, "dt_data": 0.00066, "dt_net": 0.48133, "epoch": "60/300", "eta": "1:56:04", "gpu_mem": "10.07G", "grad_norm": 6.05953, "iter": "10/60", "loss": 0.27456, "lr": 0.0018142169, "top1_acc": 93.75000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:36:03][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47048, "dt_data": 0.00041, "dt_net": 0.47006, "epoch": "60/300", "eta": "1:53:13", "gpu_mem": "10.07G", "grad_norm": 3.17938, "iter": "20/60", "loss": 0.27895, "lr": 0.0018132023, "top1_acc": 87.50000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:36:09][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47292, "dt_data": 0.00034, "dt_net": 0.47257, "epoch": "60/300", "eta": "1:53:44", "gpu_mem": "10.07G", "grad_norm": 6.63043, "iter": "30/60", "loss": 0.27134, "lr": 0.0018121854, "top1_acc": 96.87500, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:36:15][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48194, "dt_data": 0.00048, "dt_net": 0.48146, "epoch": "60/300", "eta": "1:55:49", "gpu_mem": "10.07G", "grad_norm": 9.03544, "iter": "40/60", "loss": 0.33158, "lr": 0.0018111659, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 18:36:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47128, "dt_data": 0.00047, "dt_net": 0.47081, "epoch": "60/300", "eta": "1:53:11", "gpu_mem": "10.07G", "grad_norm": 9.08240, "iter": "50/60", "loss": 0.26669, "lr": 0.0018101440, "top1_acc": 90.62500, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:36:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46907, "dt_data": 0.00016, "dt_net": 0.46890, "epoch": "60/300", "eta": "1:52:34", "gpu_mem": "10.07G", "grad_norm": 5.64948, "iter": "60/60", "loss": 0.24209, "lr": 0.0018091196, "top1_acc": 93.75000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:36:29][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.72244, "dt_data": 0.72244, "dt_net": 0.46890, "epoch": "60/300", "eta": "2:53:22", "gpu_mem": "10.07G", "grad_norm": 5.64948, "loss": 0.28270, "lr": 0.0018091196, "top1_acc": 91.87500, "top1_err": 9.32292, "top5_acc": 99.06250, "top5_err": 0.93750}
[06/12 18:36:29][INFO] train_net.py:  708: Epoch 59 takes 48.73s. Epochs from 0 to 59 take 48.21s in average and 48.22s in median.
[06/12 18:36:29][INFO] train_net.py:  714: For epoch 59, each iteraction takes 0.81s in average. From epoch 0 to 59, each iteraction takes 0.80s in average.
[06/12 18:36:29][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 18:37:30][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "60/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.12905, "top1_acc": 71.87500, "top1_err": 28.12500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 18:37:33][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "val_epoch", "epoch": "60/300", "gpu_mem": "10.07G", "min_top1_err": 24.68880, "min_top5_err": 3.31950, "time_diff": 0.60705, "top1_acc": 72.61411, "top1_err": 27.38589, "top5_acc": 96.68050, "top5_err": 3.31950}
[06/12 18:37:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46642, "dt_data": 0.00039, "dt_net": 0.46603, "epoch": "61/300", "eta": "1:51:51", "gpu_mem": "10.07G", "grad_norm": 7.17033, "iter": "10/60", "loss": 0.22501, "lr": 0.0018080927, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:37:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46990, "dt_data": 0.00047, "dt_net": 0.46943, "epoch": "61/300", "eta": "1:52:37", "gpu_mem": "10.07G", "grad_norm": 6.73479, "iter": "20/60", "loss": 0.17598, "lr": 0.0018070634, "top1_acc": 96.87500, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:38:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47015, "dt_data": 0.00036, "dt_net": 0.46978, "epoch": "61/300", "eta": "1:52:36", "gpu_mem": "10.07G", "grad_norm": 12.01861, "iter": "30/60", "loss": 0.26112, "lr": 0.0018060316, "top1_acc": 90.62500, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:38:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46936, "dt_data": 0.00031, "dt_net": 0.46905, "epoch": "61/300", "eta": "1:52:19", "gpu_mem": "10.07G", "grad_norm": 9.52428, "iter": "40/60", "loss": 0.16584, "lr": 0.0018049974, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:38:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46986, "dt_data": 0.00060, "dt_net": 0.46926, "epoch": "61/300", "eta": "1:52:22", "gpu_mem": "10.07G", "grad_norm": 6.22169, "iter": "50/60", "loss": 0.29690, "lr": 0.0018039607, "top1_acc": 93.75000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:38:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46646, "dt_data": 0.00016, "dt_net": 0.46630, "epoch": "61/300", "eta": "1:51:29", "gpu_mem": "10.07G", "grad_norm": 4.81616, "iter": "60/60", "loss": 0.23784, "lr": 0.0018029215, "top1_acc": 96.87500, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:38:23][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.74519, "dt_data": 0.74519, "dt_net": 0.46630, "epoch": "61/300", "eta": "2:58:05", "gpu_mem": "10.07G", "grad_norm": 4.81616, "loss": 0.24132, "lr": 0.0018029215, "top1_acc": 93.33333, "top1_err": 7.34375, "top5_acc": 99.06250, "top5_err": 0.88542}
[06/12 18:38:23][INFO] train_net.py:  708: Epoch 60 takes 49.68s. Epochs from 0 to 60 take 48.24s in average and 48.23s in median.
[06/12 18:38:23][INFO] train_net.py:  714: For epoch 60, each iteraction takes 0.83s in average. From epoch 0 to 60, each iteraction takes 0.80s in average.
[06/12 18:38:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.03543, "dt_data": 0.56559, "dt_net": 0.46983, "epoch": "62/300", "eta": "4:07:17", "gpu_mem": "10.07G", "grad_norm": 5.29716, "iter": "10/60", "loss": 0.19472, "lr": 0.0018018799, "top1_acc": 96.87500, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:38:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47116, "dt_data": 0.00052, "dt_net": 0.47064, "epoch": "62/300", "eta": "1:52:26", "gpu_mem": "10.07G", "grad_norm": 8.20509, "iter": "20/60", "loss": 0.21666, "lr": 0.0018008359, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:38:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46991, "dt_data": 0.00035, "dt_net": 0.46955, "epoch": "62/300", "eta": "1:52:04", "gpu_mem": "10.07G", "grad_norm": 4.61741, "iter": "30/60", "loss": 0.17196, "lr": 0.0017997894, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:38:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47350, "dt_data": 0.00072, "dt_net": 0.47277, "epoch": "62/300", "eta": "1:52:51", "gpu_mem": "10.07G", "grad_norm": 5.20430, "iter": "40/60", "loss": 0.20692, "lr": 0.0017987405, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:39:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47822, "dt_data": 0.00100, "dt_net": 0.47721, "epoch": "62/300", "eta": "1:53:53", "gpu_mem": "10.07G", "grad_norm": 8.25864, "iter": "50/60", "loss": 0.19214, "lr": 0.0017976892, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:39:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46906, "dt_data": 0.00019, "dt_net": 0.46887, "epoch": "62/300", "eta": "1:51:38", "gpu_mem": "10.07G", "grad_norm": 10.60764, "iter": "60/60", "loss": 0.31413, "lr": 0.0017966354, "top1_acc": 90.62500, "top1_err": 9.37500, "top5_acc": 96.87500, "top5_err": 1.56250}
[06/12 18:39:12][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.72459, "dt_data": 0.72459, "dt_net": 0.46887, "epoch": "62/300", "eta": "2:52:26", "gpu_mem": "10.07G", "grad_norm": 10.60764, "loss": 0.22575, "lr": 0.0017966354, "top1_acc": 92.91667, "top1_err": 6.25000, "top5_acc": 98.54167, "top5_err": 1.04167}
[06/12 18:39:12][INFO] train_net.py:  708: Epoch 61 takes 48.71s. Epochs from 0 to 61 take 48.24s in average and 48.24s in median.
[06/12 18:39:12][INFO] train_net.py:  714: For epoch 61, each iteraction takes 0.81s in average. From epoch 0 to 61, each iteraction takes 0.80s in average.
[06/12 18:39:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46972, "dt_data": 0.00032, "dt_net": 0.46940, "epoch": "63/300", "eta": "1:51:42", "gpu_mem": "10.07G", "grad_norm": 3.02936, "iter": "10/60", "loss": 0.25471, "lr": 0.0017955792, "top1_acc": 96.87500, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:39:34][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47799, "dt_data": 0.00039, "dt_net": 0.47760, "epoch": "63/300", "eta": "1:53:36", "gpu_mem": "10.07G", "grad_norm": 5.97321, "iter": "20/60", "loss": 0.18851, "lr": 0.0017945206, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:39:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.77315, "dt_data": 0.30102, "dt_net": 0.47212, "epoch": "63/300", "eta": "3:03:37", "gpu_mem": "10.07G", "grad_norm": 6.20857, "iter": "30/60", "loss": 0.14727, "lr": 0.0017934596, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:39:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47359, "dt_data": 0.00049, "dt_net": 0.47310, "epoch": "63/300", "eta": "1:52:23", "gpu_mem": "10.07G", "grad_norm": 7.75098, "iter": "40/60", "loss": 0.25534, "lr": 0.0017923961, "top1_acc": 87.50000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:39:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.91081, "dt_data": 0.44086, "dt_net": 0.46994, "epoch": "63/300", "eta": "3:36:00", "gpu_mem": "10.07G", "grad_norm": 5.43620, "iter": "50/60", "loss": 0.21159, "lr": 0.0017913303, "top1_acc": 93.75000, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:39:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.74524, "dt_data": 0.27855, "dt_net": 0.46669, "epoch": "63/300", "eta": "2:56:37", "gpu_mem": "10.07G", "grad_norm": 7.86292, "iter": "60/60", "loss": 0.21665, "lr": 0.0017902620, "top1_acc": 90.62500, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 3.12500}
[06/12 18:39:59][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.71754, "dt_data": 0.71754, "dt_net": 0.46669, "epoch": "63/300", "eta": "2:50:02", "gpu_mem": "10.07G", "grad_norm": 7.86292, "loss": 0.22476, "lr": 0.0017902620, "top1_acc": 94.06250, "top1_err": 6.45833, "top5_acc": 99.16667, "top5_err": 0.93750}
[06/12 18:39:59][INFO] train_net.py:  708: Epoch 62 takes 47.65s. Epochs from 0 to 62 take 48.24s in average and 48.23s in median.
[06/12 18:39:59][INFO] train_net.py:  714: For epoch 62, each iteraction takes 0.79s in average. From epoch 0 to 62, each iteraction takes 0.80s in average.
[06/12 18:40:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47008, "dt_data": 0.00041, "dt_net": 0.46966, "epoch": "64/300", "eta": "1:51:19", "gpu_mem": "10.07G", "grad_norm": 6.59773, "iter": "10/60", "loss": 0.26317, "lr": 0.0017891913, "top1_acc": 93.75000, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:40:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47531, "dt_data": 0.00039, "dt_net": 0.47491, "epoch": "64/300", "eta": "1:52:29", "gpu_mem": "10.07G", "grad_norm": 5.99674, "iter": "20/60", "loss": 0.26280, "lr": 0.0017881182, "top1_acc": 90.62500, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:40:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47989, "dt_data": 0.00085, "dt_net": 0.47904, "epoch": "64/300", "eta": "1:53:29", "gpu_mem": "10.07G", "grad_norm": 5.06762, "iter": "30/60", "loss": 0.22475, "lr": 0.0017870427, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:40:34][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47266, "dt_data": 0.00062, "dt_net": 0.47203, "epoch": "64/300", "eta": "1:51:42", "gpu_mem": "10.07G", "grad_norm": 4.68468, "iter": "40/60", "loss": 0.18968, "lr": 0.0017859648, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:40:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47388, "dt_data": 0.00107, "dt_net": 0.47280, "epoch": "64/300", "eta": "1:51:54", "gpu_mem": "10.07G", "grad_norm": 8.48724, "iter": "50/60", "loss": 0.19184, "lr": 0.0017848845, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:40:47][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46847, "dt_data": 0.00017, "dt_net": 0.46830, "epoch": "64/300", "eta": "1:50:33", "gpu_mem": "10.07G", "grad_norm": 6.92689, "iter": "60/60", "loss": 0.25657, "lr": 0.0017838019, "top1_acc": 93.75000, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:40:47][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.69755, "dt_data": 0.69755, "dt_net": 0.46830, "epoch": "64/300", "eta": "2:44:35", "gpu_mem": "10.07G", "grad_norm": 6.92689, "loss": 0.25150, "lr": 0.0017838019, "top1_acc": 92.50000, "top1_err": 8.12500, "top5_acc": 99.27083, "top5_err": 0.83333}
[06/12 18:40:47][INFO] train_net.py:  708: Epoch 63 takes 48.19s. Epochs from 0 to 63 take 48.23s in average and 48.22s in median.
[06/12 18:40:47][INFO] train_net.py:  714: For epoch 63, each iteraction takes 0.80s in average. From epoch 0 to 63, each iteraction takes 0.80s in average.
[06/12 18:41:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47007, "dt_data": 0.00034, "dt_net": 0.46972, "epoch": "65/300", "eta": "1:50:51", "gpu_mem": "10.07G", "grad_norm": 13.09846, "iter": "10/60", "loss": 0.17878, "lr": 0.0017827168, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:41:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46836, "dt_data": 0.00037, "dt_net": 0.46799, "epoch": "65/300", "eta": "1:50:22", "gpu_mem": "10.07G", "grad_norm": 6.69907, "iter": "20/60", "loss": 0.20702, "lr": 0.0017816293, "top1_acc": 93.75000, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:41:17][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47315, "dt_data": 0.00042, "dt_net": 0.47272, "epoch": "65/300", "eta": "1:51:25", "gpu_mem": "10.07G", "grad_norm": 6.44541, "iter": "30/60", "loss": 0.17879, "lr": 0.0017805395, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:41:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48420, "dt_data": 0.00051, "dt_net": 0.48369, "epoch": "65/300", "eta": "1:53:56", "gpu_mem": "10.07G", "grad_norm": 8.47939, "iter": "40/60", "loss": 0.26242, "lr": 0.0017794473, "top1_acc": 87.50000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:41:30][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47849, "dt_data": 0.00080, "dt_net": 0.47768, "epoch": "65/300", "eta": "1:52:31", "gpu_mem": "10.07G", "grad_norm": 10.09180, "iter": "50/60", "loss": 0.28269, "lr": 0.0017783527, "top1_acc": 93.75000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:41:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46929, "dt_data": 0.00021, "dt_net": 0.46908, "epoch": "65/300", "eta": "1:50:16", "gpu_mem": "10.07G", "grad_norm": 4.96177, "iter": "60/60", "loss": 0.23474, "lr": 0.0017772558, "top1_acc": 93.75000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:41:36][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.73367, "dt_data": 0.73367, "dt_net": 0.46908, "epoch": "65/300", "eta": "2:52:23", "gpu_mem": "10.07G", "grad_norm": 4.96177, "loss": 0.25264, "lr": 0.0017772558, "top1_acc": 92.08333, "top1_err": 8.22917, "top5_acc": 99.16667, "top5_err": 0.72917}
[06/12 18:41:36][INFO] train_net.py:  708: Epoch 64 takes 48.49s. Epochs from 0 to 64 take 48.24s in average and 48.23s in median.
[06/12 18:41:36][INFO] train_net.py:  714: For epoch 64, each iteraction takes 0.81s in average. From epoch 0 to 64, each iteraction takes 0.80s in average.
[06/12 18:41:36][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 18:42:37][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "65/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.12966, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 18:42:41][INFO] logging.py:  101: json_stats: {"RAM": "13.17/31.07G", "_type": "val_epoch", "epoch": "65/300", "gpu_mem": "10.07G", "min_top1_err": 24.27386, "min_top5_err": 3.31950, "time_diff": 0.60170, "top1_acc": 75.72614, "top1_err": 24.27386, "top5_acc": 95.64315, "top5_err": 4.35685}
[06/12 18:42:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46645, "dt_data": 0.00060, "dt_net": 0.46585, "epoch": "66/300", "eta": "1:49:32", "gpu_mem": "10.07G", "grad_norm": 5.10705, "iter": "10/60", "loss": 0.25830, "lr": 0.0017761565, "top1_acc": 87.50000, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:43:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46724, "dt_data": 0.00042, "dt_net": 0.46681, "epoch": "66/300", "eta": "1:49:38", "gpu_mem": "10.07G", "grad_norm": 11.44712, "iter": "20/60", "loss": 0.22709, "lr": 0.0017750548, "top1_acc": 96.87500, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 1.56250}
[06/12 18:43:10][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.53339, "dt_data": 0.06614, "dt_net": 0.46725, "epoch": "66/300", "eta": "2:05:04", "gpu_mem": "10.07G", "grad_norm": 7.67568, "iter": "30/60", "loss": 0.31833, "lr": 0.0017739507, "top1_acc": 96.87500, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:43:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.52252, "dt_data": 0.05588, "dt_net": 0.46663, "epoch": "66/300", "eta": "2:02:26", "gpu_mem": "10.07G", "grad_norm": 5.81588, "iter": "40/60", "loss": 0.23463, "lr": 0.0017728443, "top1_acc": 100.00000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:43:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47010, "dt_data": 0.00038, "dt_net": 0.46972, "epoch": "66/300", "eta": "1:50:04", "gpu_mem": "10.07G", "grad_norm": 5.53973, "iter": "50/60", "loss": 0.25140, "lr": 0.0017717356, "top1_acc": 90.62500, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:43:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47142, "dt_data": 0.00022, "dt_net": 0.47120, "epoch": "66/300", "eta": "1:50:18", "gpu_mem": "10.07G", "grad_norm": 9.99010, "iter": "60/60", "loss": 0.26288, "lr": 0.0017706245, "top1_acc": 90.62500, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:43:28][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.72728, "dt_data": 0.72728, "dt_net": 0.47120, "epoch": "66/300", "eta": "2:50:10", "gpu_mem": "10.07G", "grad_norm": 9.99010, "loss": 0.25382, "lr": 0.0017706245, "top1_acc": 93.02083, "top1_err": 7.50000, "top5_acc": 99.47917, "top5_err": 0.78125}
[06/12 18:43:28][INFO] train_net.py:  708: Epoch 65 takes 47.61s. Epochs from 0 to 65 take 48.23s in average and 48.22s in median.
[06/12 18:43:28][INFO] train_net.py:  714: For epoch 65, each iteraction takes 0.79s in average. From epoch 0 to 65, each iteraction takes 0.80s in average.
[06/12 18:43:45][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46915, "dt_data": 0.00044, "dt_net": 0.46871, "epoch": "67/300", "eta": "1:49:42", "gpu_mem": "10.07G", "grad_norm": 1.56989, "iter": "10/60", "loss": 0.17182, "lr": 0.0017695110, "top1_acc": 93.75000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:43:51][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46998, "dt_data": 0.00075, "dt_net": 0.46922, "epoch": "67/300", "eta": "1:49:49", "gpu_mem": "10.07G", "grad_norm": 5.77254, "iter": "20/60", "loss": 0.34039, "lr": 0.0017683952, "top1_acc": 87.50000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:43:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46804, "dt_data": 0.00080, "dt_net": 0.46723, "epoch": "67/300", "eta": "1:49:17", "gpu_mem": "10.07G", "grad_norm": 11.33758, "iter": "30/60", "loss": 0.25455, "lr": 0.0017672771, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:44:03][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48378, "dt_data": 0.00055, "dt_net": 0.48322, "epoch": "67/300", "eta": "1:52:52", "gpu_mem": "10.07G", "grad_norm": 7.71504, "iter": "40/60", "loss": 0.20627, "lr": 0.0017661566, "top1_acc": 90.62500, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:44:10][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48768, "dt_data": 0.00050, "dt_net": 0.48717, "epoch": "67/300", "eta": "1:53:42", "gpu_mem": "10.07G", "grad_norm": 3.75418, "iter": "50/60", "loss": 0.15702, "lr": 0.0017650338, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:44:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46941, "dt_data": 0.00016, "dt_net": 0.46924, "epoch": "67/300", "eta": "1:49:22", "gpu_mem": "10.07G", "grad_norm": 9.77548, "iter": "60/60", "loss": 0.17684, "lr": 0.0017639087, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:44:17][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.69881, "dt_data": 0.69881, "dt_net": 0.46924, "epoch": "67/300", "eta": "2:42:48", "gpu_mem": "10.07G", "grad_norm": 9.77548, "loss": 0.23903, "lr": 0.0017639087, "top1_acc": 91.87500, "top1_err": 7.50000, "top5_acc": 99.06250, "top5_err": 0.78125}
[06/12 18:44:17][INFO] train_net.py:  708: Epoch 66 takes 48.40s. Epochs from 0 to 66 take 48.23s in average and 48.23s in median.
[06/12 18:44:17][INFO] train_net.py:  714: For epoch 66, each iteraction takes 0.81s in average. From epoch 0 to 66, each iteraction takes 0.80s in average.
[06/12 18:44:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47000, "dt_data": 0.00057, "dt_net": 0.46943, "epoch": "68/300", "eta": "1:49:25", "gpu_mem": "10.07G", "grad_norm": 4.34171, "iter": "10/60", "loss": 0.25598, "lr": 0.0017627812, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:44:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47018, "dt_data": 0.00039, "dt_net": 0.46978, "epoch": "68/300", "eta": "1:49:23", "gpu_mem": "10.07G", "grad_norm": 5.07694, "iter": "20/60", "loss": 0.16032, "lr": 0.0017616514, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:44:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47525, "dt_data": 0.00046, "dt_net": 0.47479, "epoch": "68/300", "eta": "1:50:29", "gpu_mem": "10.07G", "grad_norm": 10.92859, "iter": "30/60", "loss": 0.27539, "lr": 0.0017605193, "top1_acc": 100.00000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:44:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47356, "dt_data": 0.00033, "dt_net": 0.47323, "epoch": "68/300", "eta": "1:50:01", "gpu_mem": "10.07G", "grad_norm": 12.16721, "iter": "40/60", "loss": 0.27946, "lr": 0.0017593849, "top1_acc": 93.75000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:44:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47589, "dt_data": 0.00073, "dt_net": 0.47515, "epoch": "68/300", "eta": "1:50:29", "gpu_mem": "10.07G", "grad_norm": 8.55879, "iter": "50/60", "loss": 0.26487, "lr": 0.0017582481, "top1_acc": 87.50000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:45:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46968, "dt_data": 0.00017, "dt_net": 0.46951, "epoch": "68/300", "eta": "1:48:58", "gpu_mem": "10.07G", "grad_norm": 7.85014, "iter": "60/60", "loss": 0.23063, "lr": 0.0017571091, "top1_acc": 93.75000, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:45:05][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.70171, "dt_data": 0.70171, "dt_net": 0.46951, "epoch": "68/300", "eta": "2:42:47", "gpu_mem": "10.07G", "grad_norm": 7.85014, "loss": 0.25976, "lr": 0.0017571091, "top1_acc": 91.56250, "top1_err": 8.75000, "top5_acc": 99.16667, "top5_err": 0.98958}
[06/12 18:45:05][INFO] train_net.py:  708: Epoch 67 takes 48.14s. Epochs from 0 to 67 take 48.23s in average and 48.22s in median.
[06/12 18:45:05][INFO] train_net.py:  714: For epoch 67, each iteraction takes 0.80s in average. From epoch 0 to 67, each iteraction takes 0.80s in average.
[06/12 18:45:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46739, "dt_data": 0.00067, "dt_net": 0.46671, "epoch": "69/300", "eta": "1:48:21", "gpu_mem": "10.07G", "grad_norm": 11.15201, "iter": "10/60", "loss": 0.20851, "lr": 0.0017559677, "top1_acc": 87.50000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:45:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47637, "dt_data": 0.00079, "dt_net": 0.47557, "epoch": "69/300", "eta": "1:50:21", "gpu_mem": "10.07G", "grad_norm": 7.00790, "iter": "20/60", "loss": 0.17510, "lr": 0.0017548241, "top1_acc": 93.75000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:45:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47735, "dt_data": 0.00076, "dt_net": 0.47659, "epoch": "69/300", "eta": "1:50:30", "gpu_mem": "10.07G", "grad_norm": 2.79077, "iter": "30/60", "loss": 0.23465, "lr": 0.0017536781, "top1_acc": 90.62500, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:45:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47543, "dt_data": 0.00079, "dt_net": 0.47464, "epoch": "69/300", "eta": "1:49:58", "gpu_mem": "10.07G", "grad_norm": 8.61457, "iter": "40/60", "loss": 0.20795, "lr": 0.0017525299, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:45:48][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47624, "dt_data": 0.00055, "dt_net": 0.47568, "epoch": "69/300", "eta": "1:50:05", "gpu_mem": "10.07G", "grad_norm": 4.21693, "iter": "50/60", "loss": 0.22493, "lr": 0.0017513793, "top1_acc": 90.62500, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:45:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46931, "dt_data": 0.00016, "dt_net": 0.46914, "epoch": "69/300", "eta": "1:48:24", "gpu_mem": "10.07G", "grad_norm": 3.26484, "iter": "60/60", "loss": 0.20181, "lr": 0.0017502265, "top1_acc": 93.75000, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:45:54][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.69944, "dt_data": 0.69944, "dt_net": 0.46914, "epoch": "69/300", "eta": "2:41:33", "gpu_mem": "10.07G", "grad_norm": 3.26484, "loss": 0.24323, "lr": 0.0017502265, "top1_acc": 91.56250, "top1_err": 7.91667, "top5_acc": 98.95833, "top5_err": 0.67708}
[06/12 18:45:54][INFO] train_net.py:  708: Epoch 68 takes 48.78s. Epochs from 0 to 68 take 48.24s in average and 48.23s in median.
[06/12 18:45:54][INFO] train_net.py:  714: For epoch 68, each iteraction takes 0.81s in average. From epoch 0 to 68, each iteraction takes 0.80s in average.
[06/12 18:46:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46985, "dt_data": 0.00052, "dt_net": 0.46933, "epoch": "70/300", "eta": "1:48:27", "gpu_mem": "10.07G", "grad_norm": 9.16585, "iter": "10/60", "loss": 0.19869, "lr": 0.0017490714, "top1_acc": 84.37500, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:46:17][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47864, "dt_data": 0.00061, "dt_net": 0.47803, "epoch": "70/300", "eta": "1:50:24", "gpu_mem": "10.07G", "grad_norm": 6.73866, "iter": "20/60", "loss": 0.27239, "lr": 0.0017479140, "top1_acc": 93.75000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:46:24][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47337, "dt_data": 0.00069, "dt_net": 0.47267, "epoch": "70/300", "eta": "1:49:06", "gpu_mem": "10.07G", "grad_norm": 9.21610, "iter": "30/60", "loss": 0.26376, "lr": 0.0017467543, "top1_acc": 87.50000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:46:29][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47649, "dt_data": 0.00103, "dt_net": 0.47546, "epoch": "70/300", "eta": "1:49:45", "gpu_mem": "10.07G", "grad_norm": 6.68513, "iter": "40/60", "loss": 0.18640, "lr": 0.0017455923, "top1_acc": 90.62500, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:46:36][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.51691, "dt_data": 0.00085, "dt_net": 0.51605, "epoch": "70/300", "eta": "1:58:58", "gpu_mem": "10.07G", "grad_norm": 2.96494, "iter": "50/60", "loss": 0.23002, "lr": 0.0017444281, "top1_acc": 93.75000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:46:42][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46886, "dt_data": 0.00017, "dt_net": 0.46870, "epoch": "70/300", "eta": "1:47:50", "gpu_mem": "10.07G", "grad_norm": 3.03003, "iter": "60/60", "loss": 0.17068, "lr": 0.0017432616, "top1_acc": 93.75000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:46:43][INFO] logging.py:  101: json_stats: {"RAM": "13.13/31.07G", "_type": "train_epoch", "dt": 0.70238, "dt_data": 0.70238, "dt_net": 0.46870, "epoch": "70/300", "eta": "2:41:32", "gpu_mem": "10.07G", "grad_norm": 3.03003, "loss": 0.24245, "lr": 0.0017432616, "top1_acc": 90.83333, "top1_err": 7.91667, "top5_acc": 98.54167, "top5_err": 1.09375}
[06/12 18:46:43][INFO] train_net.py:  708: Epoch 69 takes 49.08s. Epochs from 0 to 69 take 48.25s in average and 48.24s in median.
[06/12 18:46:43][INFO] train_net.py:  714: For epoch 69, each iteraction takes 0.82s in average. From epoch 0 to 69, each iteraction takes 0.80s in average.
[06/12 18:46:43][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 18:47:44][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "70/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.12906, "top1_acc": 79.68750, "top1_err": 20.31250, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 18:47:47][INFO] logging.py:  101: json_stats: {"RAM": "13.13/31.07G", "_type": "val_epoch", "epoch": "70/300", "gpu_mem": "10.07G", "min_top1_err": 24.27386, "min_top5_err": 3.31950, "time_diff": 0.61861, "top1_acc": 73.65145, "top1_err": 26.34855, "top5_acc": 96.05809, "top5_err": 3.94191}
[06/12 18:48:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46799, "dt_data": 0.00040, "dt_net": 0.46758, "epoch": "71/300", "eta": "1:47:33", "gpu_mem": "10.07G", "grad_norm": 5.77756, "iter": "10/60", "loss": 0.14443, "lr": 0.0017420928, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:48:10][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47097, "dt_data": 0.00080, "dt_net": 0.47016, "epoch": "71/300", "eta": "1:48:10", "gpu_mem": "10.07G", "grad_norm": 3.22776, "iter": "20/60", "loss": 0.20791, "lr": 0.0017409218, "top1_acc": 96.87500, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:48:17][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46536, "dt_data": 0.00039, "dt_net": 0.46497, "epoch": "71/300", "eta": "1:46:48", "gpu_mem": "10.07G", "grad_norm": 8.62353, "iter": "30/60", "loss": 0.28616, "lr": 0.0017397485, "top1_acc": 87.50000, "top1_err": 12.50000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:48:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47576, "dt_data": 0.00116, "dt_net": 0.47460, "epoch": "71/300", "eta": "1:49:06", "gpu_mem": "10.07G", "grad_norm": 4.18259, "iter": "40/60", "loss": 0.12473, "lr": 0.0017385730, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:48:29][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.92432, "dt_data": 0.10972, "dt_net": 0.81460, "epoch": "71/300", "eta": "3:31:49", "gpu_mem": "10.07G", "grad_norm": 4.66085, "iter": "50/60", "loss": 0.16961, "lr": 0.0017373952, "top1_acc": 93.75000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:48:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46550, "dt_data": 0.00014, "dt_net": 0.46536, "epoch": "71/300", "eta": "1:46:36", "gpu_mem": "10.07G", "grad_norm": 11.35003, "iter": "60/60", "loss": 0.21791, "lr": 0.0017362152, "top1_acc": 93.75000, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:48:35][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.71956, "dt_data": 0.71956, "dt_net": 0.46536, "epoch": "71/300", "eta": "2:44:46", "gpu_mem": "10.07G", "grad_norm": 11.35003, "loss": 0.23333, "lr": 0.0017362152, "top1_acc": 93.02083, "top1_err": 7.39583, "top5_acc": 98.64583, "top5_err": 1.14583}
[06/12 18:48:35][INFO] train_net.py:  708: Epoch 70 takes 47.90s. Epochs from 0 to 70 take 48.25s in average and 48.23s in median.
[06/12 18:48:35][INFO] train_net.py:  714: For epoch 70, each iteraction takes 0.80s in average. From epoch 0 to 70, each iteraction takes 0.80s in average.
[06/12 18:48:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47038, "dt_data": 0.00043, "dt_net": 0.46995, "epoch": "72/300", "eta": "1:47:38", "gpu_mem": "10.07G", "grad_norm": 9.85125, "iter": "10/60", "loss": 0.21753, "lr": 0.0017350329, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:48:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48263, "dt_data": 0.00046, "dt_net": 0.48217, "epoch": "72/300", "eta": "1:50:21", "gpu_mem": "10.07G", "grad_norm": 8.86911, "iter": "20/60", "loss": 0.25831, "lr": 0.0017338484, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:49:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47137, "dt_data": 0.00062, "dt_net": 0.47074, "epoch": "72/300", "eta": "1:47:42", "gpu_mem": "10.07G", "grad_norm": 8.66572, "iter": "30/60", "loss": 0.19422, "lr": 0.0017326617, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:49:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47184, "dt_data": 0.00034, "dt_net": 0.47150, "epoch": "72/300", "eta": "1:47:44", "gpu_mem": "10.07G", "grad_norm": 5.34994, "iter": "40/60", "loss": 0.19760, "lr": 0.0017314727, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:49:17][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47631, "dt_data": 0.00095, "dt_net": 0.47535, "epoch": "72/300", "eta": "1:48:40", "gpu_mem": "10.07G", "grad_norm": 10.18417, "iter": "50/60", "loss": 0.18623, "lr": 0.0017302815, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:49:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46845, "dt_data": 0.00019, "dt_net": 0.46827, "epoch": "72/300", "eta": "1:46:48", "gpu_mem": "10.07G", "grad_norm": 7.87940, "iter": "60/60", "loss": 0.22322, "lr": 0.0017290881, "top1_acc": 93.75000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:49:24][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.68951, "dt_data": 0.68951, "dt_net": 0.46827, "epoch": "72/300", "eta": "2:37:11", "gpu_mem": "10.07G", "grad_norm": 7.87940, "loss": 0.21743, "lr": 0.0017290881, "top1_acc": 93.64583, "top1_err": 6.92708, "top5_acc": 99.16667, "top5_err": 0.78125}
[06/12 18:49:24][INFO] train_net.py:  708: Epoch 71 takes 48.31s. Epochs from 0 to 71 take 48.25s in average and 48.24s in median.
[06/12 18:49:24][INFO] train_net.py:  714: For epoch 71, each iteraction takes 0.81s in average. From epoch 0 to 71, each iteraction takes 0.80s in average.
[06/12 18:49:42][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.07952, "dt_data": 0.00044, "dt_net": 1.07907, "epoch": "73/300", "eta": "4:05:56", "gpu_mem": "10.07G", "grad_norm": 10.50798, "iter": "10/60", "loss": 0.19623, "lr": 0.0017278924, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:49:47][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46943, "dt_data": 0.00037, "dt_net": 0.46906, "epoch": "73/300", "eta": "1:46:52", "gpu_mem": "10.07G", "grad_norm": 6.50144, "iter": "20/60", "loss": 0.20824, "lr": 0.0017266946, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:49:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46907, "dt_data": 0.00046, "dt_net": 0.46861, "epoch": "73/300", "eta": "1:46:42", "gpu_mem": "10.07G", "grad_norm": 7.32340, "iter": "30/60", "loss": 0.11616, "lr": 0.0017254945, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:49:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48922, "dt_data": 0.00098, "dt_net": 0.48823, "epoch": "73/300", "eta": "1:51:12", "gpu_mem": "10.07G", "grad_norm": 10.02422, "iter": "40/60", "loss": 0.26641, "lr": 0.0017242922, "top1_acc": 87.50000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:50:06][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47772, "dt_data": 0.00120, "dt_net": 0.47651, "epoch": "73/300", "eta": "1:48:31", "gpu_mem": "10.07G", "grad_norm": 8.19676, "iter": "50/60", "loss": 0.16974, "lr": 0.0017230877, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:50:12][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46998, "dt_data": 0.00019, "dt_net": 0.46978, "epoch": "73/300", "eta": "1:46:41", "gpu_mem": "10.07G", "grad_norm": 8.13131, "iter": "60/60", "loss": 0.26011, "lr": 0.0017218810, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:50:12][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.71977, "dt_data": 0.71978, "dt_net": 0.46978, "epoch": "73/300", "eta": "2:43:22", "gpu_mem": "10.07G", "grad_norm": 8.13131, "loss": 0.22034, "lr": 0.0017218810, "top1_acc": 93.12500, "top1_err": 6.77083, "top5_acc": 99.27083, "top5_err": 0.62500}
[06/12 18:50:12][INFO] train_net.py:  708: Epoch 72 takes 48.70s. Epochs from 0 to 72 take 48.25s in average and 48.25s in median.
[06/12 18:50:12][INFO] train_net.py:  714: For epoch 72, each iteraction takes 0.81s in average. From epoch 0 to 72, each iteraction takes 0.80s in average.
[06/12 18:50:29][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46955, "dt_data": 0.00050, "dt_net": 0.46905, "epoch": "74/300", "eta": "1:46:30", "gpu_mem": "10.07G", "grad_norm": 1.33980, "iter": "10/60", "loss": 0.26059, "lr": 0.0017206721, "top1_acc": 93.75000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:50:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47077, "dt_data": 0.00033, "dt_net": 0.47043, "epoch": "74/300", "eta": "1:46:42", "gpu_mem": "10.07G", "grad_norm": 8.02593, "iter": "20/60", "loss": 0.25002, "lr": 0.0017194610, "top1_acc": 90.62500, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:50:42][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47236, "dt_data": 0.00035, "dt_net": 0.47200, "epoch": "74/300", "eta": "1:46:59", "gpu_mem": "10.07G", "grad_norm": 13.12698, "iter": "30/60", "loss": 0.19693, "lr": 0.0017182477, "top1_acc": 93.75000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:50:48][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47493, "dt_data": 0.00045, "dt_net": 0.47448, "epoch": "74/300", "eta": "1:47:29", "gpu_mem": "10.07G", "grad_norm": 5.82086, "iter": "40/60", "loss": 0.15476, "lr": 0.0017170323, "top1_acc": 100.00000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:50:54][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47681, "dt_data": 0.00055, "dt_net": 0.47627, "epoch": "74/300", "eta": "1:47:50", "gpu_mem": "10.07G", "grad_norm": 7.71663, "iter": "50/60", "loss": 0.15627, "lr": 0.0017158146, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:51:00][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46887, "dt_data": 0.00016, "dt_net": 0.46871, "epoch": "74/300", "eta": "1:45:57", "gpu_mem": "10.07G", "grad_norm": 5.39221, "iter": "60/60", "loss": 0.15305, "lr": 0.0017145948, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:51:01][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.71118, "dt_data": 0.71118, "dt_net": 0.46871, "epoch": "74/300", "eta": "2:40:43", "gpu_mem": "10.07G", "grad_norm": 5.39221, "loss": 0.20688, "lr": 0.0017145948, "top1_acc": 92.91667, "top1_err": 7.29167, "top5_acc": 99.37500, "top5_err": 0.72917}
[06/12 18:51:01][INFO] train_net.py:  708: Epoch 73 takes 48.44s. Epochs from 0 to 73 take 48.25s in average and 48.26s in median.
[06/12 18:51:01][INFO] train_net.py:  714: For epoch 73, each iteraction takes 0.81s in average. From epoch 0 to 73, each iteraction takes 0.80s in average.
[06/12 18:51:17][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47545, "dt_data": 0.00071, "dt_net": 0.47474, "epoch": "75/300", "eta": "1:47:22", "gpu_mem": "10.07G", "grad_norm": 6.26590, "iter": "10/60", "loss": 0.14285, "lr": 0.0017133728, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:51:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47129, "dt_data": 0.00064, "dt_net": 0.47064, "epoch": "75/300", "eta": "1:46:21", "gpu_mem": "10.07G", "grad_norm": 9.32151, "iter": "20/60", "loss": 0.08189, "lr": 0.0017121486, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:51:30][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47098, "dt_data": 0.00060, "dt_net": 0.47037, "epoch": "75/300", "eta": "1:46:12", "gpu_mem": "10.07G", "grad_norm": 8.95551, "iter": "30/60", "loss": 0.15937, "lr": 0.0017109222, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:51:36][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47309, "dt_data": 0.00048, "dt_net": 0.47261, "epoch": "75/300", "eta": "1:46:36", "gpu_mem": "10.07G", "grad_norm": 4.43974, "iter": "40/60", "loss": 0.15019, "lr": 0.0017096937, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:51:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47998, "dt_data": 0.00075, "dt_net": 0.47922, "epoch": "75/300", "eta": "1:48:04", "gpu_mem": "10.07G", "grad_norm": 5.92219, "iter": "50/60", "loss": 0.14494, "lr": 0.0017084630, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:51:48][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46868, "dt_data": 0.00017, "dt_net": 0.46850, "epoch": "75/300", "eta": "1:45:27", "gpu_mem": "10.07G", "grad_norm": 5.73383, "iter": "60/60", "loss": 0.15959, "lr": 0.0017072302, "top1_acc": 93.75000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:51:49][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.68681, "dt_data": 0.68681, "dt_net": 0.46850, "epoch": "75/300", "eta": "2:34:31", "gpu_mem": "10.07G", "grad_norm": 5.73383, "loss": 0.17230, "lr": 0.0017072302, "top1_acc": 94.06250, "top1_err": 5.62500, "top5_acc": 99.47917, "top5_err": 0.31250}
[06/12 18:51:49][INFO] train_net.py:  708: Epoch 74 takes 48.02s. Epochs from 0 to 74 take 48.25s in average and 48.25s in median.
[06/12 18:51:49][INFO] train_net.py:  714: For epoch 74, each iteraction takes 0.80s in average. From epoch 0 to 74, each iteraction takes 0.80s in average.
[06/12 18:51:49][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 18:52:51][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "75/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.12916, "top1_acc": 70.31250, "top1_err": 29.68750, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 18:52:54][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "val_epoch", "epoch": "75/300", "gpu_mem": "10.07G", "min_top1_err": 24.27386, "min_top5_err": 3.31950, "time_diff": 0.62485, "top1_acc": 72.40664, "top1_err": 27.59336, "top5_acc": 96.26556, "top5_err": 3.73444}
[06/12 18:53:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46538, "dt_data": 0.00046, "dt_net": 0.46492, "epoch": "76/300", "eta": "1:44:37", "gpu_mem": "10.07G", "grad_norm": 7.13222, "iter": "10/60", "loss": 0.14211, "lr": 0.0017059952, "top1_acc": 96.87500, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:53:17][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46796, "dt_data": 0.00038, "dt_net": 0.46758, "epoch": "76/300", "eta": "1:45:08", "gpu_mem": "10.07G", "grad_norm": 6.45503, "iter": "20/60", "loss": 0.20814, "lr": 0.0017047580, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:53:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47257, "dt_data": 0.00053, "dt_net": 0.47204, "epoch": "76/300", "eta": "1:46:05", "gpu_mem": "10.07G", "grad_norm": 4.00404, "iter": "30/60", "loss": 0.18229, "lr": 0.0017035188, "top1_acc": 90.62500, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:53:29][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.69570, "dt_data": 0.22625, "dt_net": 0.46944, "epoch": "76/300", "eta": "2:36:04", "gpu_mem": "10.07G", "grad_norm": 9.91652, "iter": "40/60", "loss": 0.16457, "lr": 0.0017022773, "top1_acc": 100.00000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:53:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47218, "dt_data": 0.00041, "dt_net": 0.47177, "epoch": "76/300", "eta": "1:45:50", "gpu_mem": "10.07G", "grad_norm": 5.61347, "iter": "50/60", "loss": 0.16692, "lr": 0.0017010337, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:53:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46595, "dt_data": 0.00019, "dt_net": 0.46575, "epoch": "76/300", "eta": "1:44:22", "gpu_mem": "10.07G", "grad_norm": 9.52601, "iter": "60/60", "loss": 0.19651, "lr": 0.0016997880, "top1_acc": 87.50000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:53:42][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.71751, "dt_data": 0.71751, "dt_net": 0.46575, "epoch": "76/300", "eta": "2:40:42", "gpu_mem": "10.07G", "grad_norm": 9.52601, "loss": 0.19190, "lr": 0.0016997880, "top1_acc": 93.75000, "top1_err": 6.09375, "top5_acc": 99.68750, "top5_err": 0.36458}
[06/12 18:53:42][INFO] train_net.py:  708: Epoch 75 takes 48.27s. Epochs from 0 to 75 take 48.25s in average and 48.26s in median.
[06/12 18:53:42][INFO] train_net.py:  714: For epoch 75, each iteraction takes 0.80s in average. From epoch 0 to 75, each iteraction takes 0.80s in average.
[06/12 18:53:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46982, "dt_data": 0.00050, "dt_net": 0.46931, "epoch": "77/300", "eta": "1:45:09", "gpu_mem": "10.07G", "grad_norm": 9.47088, "iter": "10/60", "loss": 0.18026, "lr": 0.0016985402, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:54:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47780, "dt_data": 0.00039, "dt_net": 0.47740, "epoch": "77/300", "eta": "1:46:52", "gpu_mem": "10.07G", "grad_norm": 10.99432, "iter": "20/60", "loss": 0.16725, "lr": 0.0016972902, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:54:12][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.67658, "dt_data": 0.00062, "dt_net": 0.67596, "epoch": "77/300", "eta": "2:31:12", "gpu_mem": "10.07G", "grad_norm": 5.37699, "iter": "30/60", "loss": 0.16517, "lr": 0.0016960381, "top1_acc": 87.50000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:54:18][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47481, "dt_data": 0.00060, "dt_net": 0.47420, "epoch": "77/300", "eta": "1:46:02", "gpu_mem": "10.07G", "grad_norm": 5.18047, "iter": "40/60", "loss": 0.34652, "lr": 0.0016947839, "top1_acc": 90.62500, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:54:24][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.28993, "dt_data": 0.00039, "dt_net": 1.28954, "epoch": "77/300", "eta": "4:47:52", "gpu_mem": "10.07G", "grad_norm": 10.01087, "iter": "50/60", "loss": 0.16238, "lr": 0.0016935276, "top1_acc": 96.87500, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:54:30][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46832, "dt_data": 0.00020, "dt_net": 0.46812, "epoch": "77/300", "eta": "1:44:26", "gpu_mem": "10.07G", "grad_norm": 6.46689, "iter": "60/60", "loss": 0.16545, "lr": 0.0016922691, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:54:31][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.70250, "dt_data": 0.70250, "dt_net": 0.46812, "epoch": "77/300", "eta": "2:36:39", "gpu_mem": "10.07G", "grad_norm": 6.46689, "loss": 0.20271, "lr": 0.0016922691, "top1_acc": 93.12500, "top1_err": 6.82292, "top5_acc": 99.27083, "top5_err": 0.57292}
[06/12 18:54:31][INFO] train_net.py:  708: Epoch 76 takes 48.73s. Epochs from 0 to 76 take 48.26s in average and 48.27s in median.
[06/12 18:54:31][INFO] train_net.py:  714: For epoch 76, each iteraction takes 0.81s in average. From epoch 0 to 76, each iteraction takes 0.80s in average.
[06/12 18:54:48][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.96494, "dt_data": 0.49595, "dt_net": 0.46898, "epoch": "78/300", "eta": "3:35:01", "gpu_mem": "10.07G", "grad_norm": 9.07478, "iter": "10/60", "loss": 0.20333, "lr": 0.0016910086, "top1_acc": 90.62500, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:54:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47884, "dt_data": 0.00047, "dt_net": 0.47837, "epoch": "78/300", "eta": "1:46:37", "gpu_mem": "10.07G", "grad_norm": 6.20835, "iter": "20/60", "loss": 0.18098, "lr": 0.0016897459, "top1_acc": 90.62500, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:55:00][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.23542, "dt_data": 0.76510, "dt_net": 0.47031, "epoch": "78/300", "eta": "4:34:52", "gpu_mem": "10.07G", "grad_norm": 10.38728, "iter": "30/60", "loss": 0.21708, "lr": 0.0016884812, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:55:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47585, "dt_data": 0.00062, "dt_net": 0.47523, "epoch": "78/300", "eta": "1:45:47", "gpu_mem": "10.07G", "grad_norm": 6.34369, "iter": "40/60", "loss": 0.16824, "lr": 0.0016872143, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:55:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.03145, "dt_data": 0.56022, "dt_net": 0.47123, "epoch": "78/300", "eta": "3:49:09", "gpu_mem": "10.07G", "grad_norm": 10.97508, "iter": "50/60", "loss": 0.20200, "lr": 0.0016859454, "top1_acc": 90.62500, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:55:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46922, "dt_data": 0.00016, "dt_net": 0.46905, "epoch": "78/300", "eta": "1:44:09", "gpu_mem": "10.07G", "grad_norm": 5.97708, "iter": "60/60", "loss": 0.28485, "lr": 0.0016846743, "top1_acc": 93.75000, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:55:19][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.71469, "dt_data": 0.71469, "dt_net": 0.46905, "epoch": "78/300", "eta": "2:38:38", "gpu_mem": "10.07G", "grad_norm": 5.97708, "loss": 0.21932, "lr": 0.0016846743, "top1_acc": 91.97917, "top1_err": 7.29167, "top5_acc": 99.27083, "top5_err": 0.72917}
[06/12 18:55:19][INFO] train_net.py:  708: Epoch 77 takes 48.83s. Epochs from 0 to 77 take 48.27s in average and 48.28s in median.
[06/12 18:55:19][INFO] train_net.py:  714: For epoch 77, each iteraction takes 0.81s in average. From epoch 0 to 77, each iteraction takes 0.80s in average.
[06/12 18:55:38][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.49400, "dt_data": 0.00142, "dt_net": 0.49256, "epoch": "79/300", "eta": "1:49:35", "gpu_mem": "10.07G", "grad_norm": 6.38478, "iter": "10/60", "loss": 0.16720, "lr": 0.0016834012, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:55:44][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47564, "dt_data": 0.00039, "dt_net": 0.47525, "epoch": "79/300", "eta": "1:45:26", "gpu_mem": "10.07G", "grad_norm": 3.10025, "iter": "20/60", "loss": 0.15713, "lr": 0.0016821260, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:55:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47421, "dt_data": 0.00061, "dt_net": 0.47360, "epoch": "79/300", "eta": "1:45:02", "gpu_mem": "10.07G", "grad_norm": 7.73703, "iter": "30/60", "loss": 0.20648, "lr": 0.0016808487, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:55:56][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47259, "dt_data": 0.00056, "dt_net": 0.47203, "epoch": "79/300", "eta": "1:44:35", "gpu_mem": "10.07G", "grad_norm": 7.64446, "iter": "40/60", "loss": 0.20999, "lr": 0.0016795694, "top1_acc": 100.00000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:56:02][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47242, "dt_data": 0.00041, "dt_net": 0.47201, "epoch": "79/300", "eta": "1:44:29", "gpu_mem": "10.07G", "grad_norm": 4.03050, "iter": "50/60", "loss": 0.20557, "lr": 0.0016782879, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:56:08][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47131, "dt_data": 0.00035, "dt_net": 0.47096, "epoch": "79/300", "eta": "1:44:09", "gpu_mem": "10.07G", "grad_norm": 7.15671, "iter": "60/60", "loss": 0.18176, "lr": 0.0016770044, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:56:09][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.72383, "dt_data": 0.72383, "dt_net": 0.47096, "epoch": "79/300", "eta": "2:39:57", "gpu_mem": "10.07G", "grad_norm": 7.15671, "loss": 0.21671, "lr": 0.0016770044, "top1_acc": 94.16667, "top1_err": 7.18750, "top5_acc": 99.37500, "top5_err": 0.62500}
[06/12 18:56:09][INFO] train_net.py:  708: Epoch 78 takes 49.27s. Epochs from 0 to 78 take 48.28s in average and 48.28s in median.
[06/12 18:56:09][INFO] train_net.py:  714: For epoch 78, each iteraction takes 0.82s in average. From epoch 0 to 78, each iteraction takes 0.80s in average.
[06/12 18:56:27][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47423, "dt_data": 0.00046, "dt_net": 0.47377, "epoch": "80/300", "eta": "1:44:43", "gpu_mem": "10.07G", "grad_norm": 5.88240, "iter": "10/60", "loss": 0.18398, "lr": 0.0016757189, "top1_acc": 90.62500, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:56:32][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47107, "dt_data": 0.00051, "dt_net": 0.47056, "epoch": "80/300", "eta": "1:43:56", "gpu_mem": "10.07G", "grad_norm": 2.95506, "iter": "20/60", "loss": 0.17029, "lr": 0.0016744313, "top1_acc": 93.75000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:56:38][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.56369, "dt_data": 0.08934, "dt_net": 0.47434, "epoch": "80/300", "eta": "2:04:17", "gpu_mem": "10.07G", "grad_norm": 4.64117, "iter": "30/60", "loss": 0.21202, "lr": 0.0016731416, "top1_acc": 93.75000, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:56:44][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47830, "dt_data": 0.00051, "dt_net": 0.47779, "epoch": "80/300", "eta": "1:45:23", "gpu_mem": "10.07G", "grad_norm": 6.63950, "iter": "40/60", "loss": 0.19414, "lr": 0.0016718499, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:56:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.75712, "dt_data": 0.28005, "dt_net": 0.47706, "epoch": "80/300", "eta": "2:46:41", "gpu_mem": "10.07G", "grad_norm": 8.12245, "iter": "50/60", "loss": 0.14117, "lr": 0.0016705561, "top1_acc": 93.75000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:56:56][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46965, "dt_data": 0.00015, "dt_net": 0.46951, "epoch": "80/300", "eta": "1:43:19", "gpu_mem": "10.07G", "grad_norm": 9.15179, "iter": "60/60", "loss": 0.16343, "lr": 0.0016692603, "top1_acc": 96.87500, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:56:57][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.72026, "dt_data": 0.72026, "dt_net": 0.46951, "epoch": "80/300", "eta": "2:38:26", "gpu_mem": "10.07G", "grad_norm": 9.15179, "loss": 0.20021, "lr": 0.0016692603, "top1_acc": 93.33333, "top1_err": 6.30208, "top5_acc": 99.37500, "top5_err": 0.62500}
[06/12 18:56:57][INFO] train_net.py:  708: Epoch 79 takes 48.14s. Epochs from 0 to 79 take 48.28s in average and 48.28s in median.
[06/12 18:56:57][INFO] train_net.py:  714: For epoch 79, each iteraction takes 0.80s in average. From epoch 0 to 79, each iteraction takes 0.80s in average.
[06/12 18:56:57][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 18:57:58][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "80/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.12983, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 18:58:01][INFO] logging.py:  101: json_stats: {"RAM": "13.21/31.07G", "_type": "val_epoch", "epoch": "80/300", "gpu_mem": "10.07G", "min_top1_err": 24.27386, "min_top5_err": 2.90456, "time_diff": 0.59660, "top1_acc": 75.51867, "top1_err": 24.48133, "top5_acc": 97.09544, "top5_err": 2.90456}
[06/12 18:58:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46891, "dt_data": 0.00039, "dt_net": 0.46852, "epoch": "81/300", "eta": "1:43:04", "gpu_mem": "10.07G", "grad_norm": 7.43820, "iter": "10/60", "loss": 0.16688, "lr": 0.0016679625, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:58:24][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46737, "dt_data": 0.00072, "dt_net": 0.46664, "epoch": "81/300", "eta": "1:42:39", "gpu_mem": "10.07G", "grad_norm": 7.82728, "iter": "20/60", "loss": 0.18634, "lr": 0.0016666626, "top1_acc": 93.75000, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:58:30][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46865, "dt_data": 0.00046, "dt_net": 0.46818, "epoch": "81/300", "eta": "1:42:52", "gpu_mem": "10.07G", "grad_norm": 9.62793, "iter": "30/60", "loss": 0.21365, "lr": 0.0016653607, "top1_acc": 93.75000, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:58:36][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47196, "dt_data": 0.00034, "dt_net": 0.47162, "epoch": "81/300", "eta": "1:43:30", "gpu_mem": "10.07G", "grad_norm": 6.32884, "iter": "40/60", "loss": 0.14974, "lr": 0.0016640567, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:58:42][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47203, "dt_data": 0.00044, "dt_net": 0.47159, "epoch": "81/300", "eta": "1:43:27", "gpu_mem": "10.07G", "grad_norm": 8.34828, "iter": "50/60", "loss": 0.20088, "lr": 0.0016627508, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:58:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46881, "dt_data": 0.00021, "dt_net": 0.46860, "epoch": "81/300", "eta": "1:42:40", "gpu_mem": "10.07G", "grad_norm": 10.59838, "iter": "60/60", "loss": 0.18428, "lr": 0.0016614428, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:58:49][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.68772, "dt_data": 0.68772, "dt_net": 0.46860, "epoch": "81/300", "eta": "2:30:36", "gpu_mem": "10.07G", "grad_norm": 10.59838, "loss": 0.20750, "lr": 0.0016614428, "top1_acc": 93.43750, "top1_err": 6.92708, "top5_acc": 99.37500, "top5_err": 0.62500}
[06/12 18:58:49][INFO] train_net.py:  708: Epoch 80 takes 47.85s. Epochs from 0 to 80 take 48.27s in average and 48.27s in median.
[06/12 18:58:49][INFO] train_net.py:  714: For epoch 80, each iteraction takes 0.80s in average. From epoch 0 to 80, each iteraction takes 0.80s in average.
[06/12 18:59:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47123, "dt_data": 0.00033, "dt_net": 0.47090, "epoch": "82/300", "eta": "1:43:07", "gpu_mem": "10.07G", "grad_norm": 7.26118, "iter": "10/60", "loss": 0.20842, "lr": 0.0016601328, "top1_acc": 93.75000, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:59:12][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47340, "dt_data": 0.00047, "dt_net": 0.47293, "epoch": "82/300", "eta": "1:43:31", "gpu_mem": "10.07G", "grad_norm": 5.96253, "iter": "20/60", "loss": 0.18900, "lr": 0.0016588208, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:59:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47768, "dt_data": 0.00079, "dt_net": 0.47689, "epoch": "82/300", "eta": "1:44:22", "gpu_mem": "10.07G", "grad_norm": 5.74146, "iter": "30/60", "loss": 0.28885, "lr": 0.0016575068, "top1_acc": 93.75000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:59:24][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47119, "dt_data": 0.00051, "dt_net": 0.47067, "epoch": "82/300", "eta": "1:42:52", "gpu_mem": "10.07G", "grad_norm": 2.16200, "iter": "40/60", "loss": 0.21770, "lr": 0.0016561907, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:59:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.31380, "dt_data": 0.00055, "dt_net": 1.31325, "epoch": "82/300", "eta": "4:46:37", "gpu_mem": "10.07G", "grad_norm": 7.42656, "iter": "50/60", "loss": 0.14878, "lr": 0.0016548727, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:59:36][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.67023, "dt_data": 0.00018, "dt_net": 0.67005, "epoch": "82/300", "eta": "2:26:06", "gpu_mem": "10.07G", "grad_norm": 9.66222, "iter": "60/60", "loss": 0.26611, "lr": 0.0016535527, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 18:59:37][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.68052, "dt_data": 0.68052, "dt_net": 0.67005, "epoch": "82/300", "eta": "2:28:20", "gpu_mem": "10.07G", "grad_norm": 9.66222, "loss": 0.21730, "lr": 0.0016535527, "top1_acc": 93.33333, "top1_err": 6.82292, "top5_acc": 99.68750, "top5_err": 0.41667}
[06/12 18:59:37][INFO] train_net.py:  708: Epoch 81 takes 47.64s. Epochs from 0 to 81 take 48.26s in average and 48.26s in median.
[06/12 18:59:37][INFO] train_net.py:  714: For epoch 81, each iteraction takes 0.79s in average. From epoch 0 to 81, each iteraction takes 0.80s in average.
[06/12 18:59:54][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.78297, "dt_data": 0.00052, "dt_net": 0.78245, "epoch": "83/300", "eta": "2:50:33", "gpu_mem": "10.07G", "grad_norm": 3.37075, "iter": "10/60", "loss": 0.16239, "lr": 0.0016522307, "top1_acc": 96.87500, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:00:00][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47833, "dt_data": 0.00044, "dt_net": 0.47788, "epoch": "83/300", "eta": "1:44:06", "gpu_mem": "10.07G", "grad_norm": 2.50070, "iter": "20/60", "loss": 0.09386, "lr": 0.0016509067, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:00:06][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47266, "dt_data": 0.00034, "dt_net": 0.47232, "epoch": "83/300", "eta": "1:42:48", "gpu_mem": "10.07G", "grad_norm": 4.77814, "iter": "30/60", "loss": 0.16630, "lr": 0.0016495808, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:00:12][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47605, "dt_data": 0.00047, "dt_net": 0.47558, "epoch": "83/300", "eta": "1:43:27", "gpu_mem": "10.07G", "grad_norm": 3.11959, "iter": "40/60", "loss": 0.16269, "lr": 0.0016482528, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:00:18][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.81842, "dt_data": 0.00041, "dt_net": 0.81801, "epoch": "83/300", "eta": "2:57:43", "gpu_mem": "10.07G", "grad_norm": 10.64911, "iter": "50/60", "loss": 0.19451, "lr": 0.0016469229, "top1_acc": 93.75000, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:00:24][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46982, "dt_data": 0.00019, "dt_net": 0.46963, "epoch": "83/300", "eta": "1:41:57", "gpu_mem": "10.07G", "grad_norm": 6.13431, "iter": "60/60", "loss": 0.14893, "lr": 0.0016455910, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:00:25][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.69898, "dt_data": 0.69898, "dt_net": 0.46963, "epoch": "83/300", "eta": "2:31:40", "gpu_mem": "10.07G", "grad_norm": 6.13431, "loss": 0.16696, "lr": 0.0016455910, "top1_acc": 94.68750, "top1_err": 5.41667, "top5_acc": 99.58333, "top5_err": 0.31250}
[06/12 19:00:25][INFO] train_net.py:  708: Epoch 82 takes 47.75s. Epochs from 0 to 82 take 48.26s in average and 48.25s in median.
[06/12 19:00:25][INFO] train_net.py:  714: For epoch 82, each iteraction takes 0.80s in average. From epoch 0 to 82, each iteraction takes 0.80s in average.
[06/12 19:00:42][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47534, "dt_data": 0.00059, "dt_net": 0.47474, "epoch": "84/300", "eta": "1:43:04", "gpu_mem": "10.07G", "grad_norm": 0.29320, "iter": "10/60", "loss": 0.18145, "lr": 0.0016442571, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:00:48][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47475, "dt_data": 0.00090, "dt_net": 0.47385, "epoch": "84/300", "eta": "1:42:51", "gpu_mem": "10.07G", "grad_norm": 4.20660, "iter": "20/60", "loss": 0.17202, "lr": 0.0016429213, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:00:54][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47252, "dt_data": 0.00048, "dt_net": 0.47203, "epoch": "84/300", "eta": "1:42:18", "gpu_mem": "10.07G", "grad_norm": 4.69451, "iter": "30/60", "loss": 0.11809, "lr": 0.0016415835, "top1_acc": 93.75000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:01:00][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47376, "dt_data": 0.00070, "dt_net": 0.47305, "epoch": "84/300", "eta": "1:42:29", "gpu_mem": "10.07G", "grad_norm": 7.02770, "iter": "40/60", "loss": 0.21171, "lr": 0.0016402438, "top1_acc": 93.75000, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:01:06][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47665, "dt_data": 0.00046, "dt_net": 0.47619, "epoch": "84/300", "eta": "1:43:02", "gpu_mem": "10.07G", "grad_norm": 6.05900, "iter": "50/60", "loss": 0.10887, "lr": 0.0016389021, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:01:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47017, "dt_data": 0.00015, "dt_net": 0.47001, "epoch": "84/300", "eta": "1:41:33", "gpu_mem": "10.07G", "grad_norm": 6.36155, "iter": "60/60", "loss": 0.18269, "lr": 0.0016375585, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:01:13][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.69578, "dt_data": 0.69578, "dt_net": 0.47001, "epoch": "84/300", "eta": "2:30:16", "gpu_mem": "10.07G", "grad_norm": 6.36155, "loss": 0.18258, "lr": 0.0016375585, "top1_acc": 94.68750, "top1_err": 5.98958, "top5_acc": 99.68750, "top5_err": 0.31250}
[06/12 19:01:13][INFO] train_net.py:  708: Epoch 83 takes 48.85s. Epochs from 0 to 83 take 48.26s in average and 48.26s in median.
[06/12 19:01:13][INFO] train_net.py:  714: For epoch 83, each iteraction takes 0.81s in average. From epoch 0 to 83, each iteraction takes 0.80s in average.
[06/12 19:01:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47017, "dt_data": 0.00030, "dt_net": 0.46987, "epoch": "85/300", "eta": "1:41:28", "gpu_mem": "10.07G", "grad_norm": 7.48121, "iter": "10/60", "loss": 0.11646, "lr": 0.0016362129, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:01:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47843, "dt_data": 0.00034, "dt_net": 0.47810, "epoch": "85/300", "eta": "1:43:10", "gpu_mem": "10.07G", "grad_norm": 7.84309, "iter": "20/60", "loss": 0.20318, "lr": 0.0016348654, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:01:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47110, "dt_data": 0.00039, "dt_net": 0.47071, "epoch": "85/300", "eta": "1:41:31", "gpu_mem": "10.07G", "grad_norm": 6.26279, "iter": "30/60", "loss": 0.13932, "lr": 0.0016335159, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:01:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48529, "dt_data": 0.00034, "dt_net": 0.48495, "epoch": "85/300", "eta": "1:44:29", "gpu_mem": "10.07G", "grad_norm": 2.50562, "iter": "40/60", "loss": 0.09998, "lr": 0.0016321645, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:01:56][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47630, "dt_data": 0.00073, "dt_net": 0.47557, "epoch": "85/300", "eta": "1:42:29", "gpu_mem": "10.07G", "grad_norm": 3.33652, "iter": "50/60", "loss": 0.18054, "lr": 0.0016308112, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:02:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46997, "dt_data": 0.00016, "dt_net": 0.46980, "epoch": "85/300", "eta": "1:41:02", "gpu_mem": "10.07G", "grad_norm": 6.77296, "iter": "60/60", "loss": 0.09776, "lr": 0.0016294560, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:02:01][INFO] logging.py:  101: json_stats: {"RAM": "13.17/31.07G", "_type": "train_epoch", "dt": 0.69911, "dt_data": 0.69911, "dt_net": 0.46980, "epoch": "85/300", "eta": "2:30:18", "gpu_mem": "10.07G", "grad_norm": 6.77296, "loss": 0.15535, "lr": 0.0016294560, "top1_acc": 94.37500, "top1_err": 4.79167, "top5_acc": 99.37500, "top5_err": 0.46875}
[06/12 19:02:01][INFO] train_net.py:  708: Epoch 84 takes 47.83s. Epochs from 0 to 84 take 48.26s in average and 48.25s in median.
[06/12 19:02:01][INFO] train_net.py:  714: For epoch 84, each iteraction takes 0.80s in average. From epoch 0 to 84, each iteraction takes 0.80s in average.
[06/12 19:02:01][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 19:03:03][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "85/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.13002, "top1_acc": 76.56250, "top1_err": 23.43750, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 19:03:06][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "val_epoch", "epoch": "85/300", "gpu_mem": "10.07G", "min_top1_err": 23.44398, "min_top5_err": 2.90456, "time_diff": 0.60345, "top1_acc": 76.55602, "top1_err": 23.44398, "top5_acc": 95.02075, "top5_err": 4.97925}
[06/12 19:03:24][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46458, "dt_data": 0.00054, "dt_net": 0.46403, "epoch": "86/300", "eta": "1:39:48", "gpu_mem": "10.07G", "grad_norm": 10.82812, "iter": "10/60", "loss": 0.17079, "lr": 0.0016280989, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:03:30][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46769, "dt_data": 0.00077, "dt_net": 0.46691, "epoch": "86/300", "eta": "1:40:23", "gpu_mem": "10.07G", "grad_norm": 5.81501, "iter": "20/60", "loss": 0.12273, "lr": 0.0016267398, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:03:36][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46705, "dt_data": 0.00080, "dt_net": 0.46625, "epoch": "86/300", "eta": "1:40:10", "gpu_mem": "10.07G", "grad_norm": 4.75869, "iter": "30/60", "loss": 0.18327, "lr": 0.0016253789, "top1_acc": 93.75000, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:03:42][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47044, "dt_data": 0.00054, "dt_net": 0.46991, "epoch": "86/300", "eta": "1:40:49", "gpu_mem": "10.07G", "grad_norm": 2.29012, "iter": "40/60", "loss": 0.07772, "lr": 0.0016240160, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:03:48][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48739, "dt_data": 0.00061, "dt_net": 0.48678, "epoch": "86/300", "eta": "1:44:23", "gpu_mem": "10.07G", "grad_norm": 7.56234, "iter": "50/60", "loss": 0.14276, "lr": 0.0016226512, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:03:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46569, "dt_data": 0.00021, "dt_net": 0.46548, "epoch": "86/300", "eta": "1:39:39", "gpu_mem": "10.07G", "grad_norm": 4.82976, "iter": "60/60", "loss": 0.14453, "lr": 0.0016212846, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:03:54][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.70837, "dt_data": 0.70837, "dt_net": 0.46548, "epoch": "86/300", "eta": "2:31:34", "gpu_mem": "10.07G", "grad_norm": 4.82976, "loss": 0.15571, "lr": 0.0016212846, "top1_acc": 95.10417, "top1_err": 5.10417, "top5_acc": 99.47917, "top5_err": 0.46875}
[06/12 19:03:54][INFO] train_net.py:  708: Epoch 85 takes 47.89s. Epochs from 0 to 85 take 48.25s in average and 48.24s in median.
[06/12 19:03:54][INFO] train_net.py:  714: For epoch 85, each iteraction takes 0.80s in average. From epoch 0 to 85, each iteraction takes 0.80s in average.
[06/12 19:04:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46891, "dt_data": 0.00047, "dt_net": 0.46844, "epoch": "87/300", "eta": "1:40:16", "gpu_mem": "10.07G", "grad_norm": 6.31257, "iter": "10/60", "loss": 0.15741, "lr": 0.0016199160, "top1_acc": 93.75000, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:04:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47673, "dt_data": 0.00044, "dt_net": 0.47628, "epoch": "87/300", "eta": "1:41:51", "gpu_mem": "10.07G", "grad_norm": 13.13002, "iter": "20/60", "loss": 0.28427, "lr": 0.0016185455, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:04:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47132, "dt_data": 0.00041, "dt_net": 0.47091, "epoch": "87/300", "eta": "1:40:37", "gpu_mem": "10.07G", "grad_norm": 7.27084, "iter": "30/60", "loss": 0.20025, "lr": 0.0016171732, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:04:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47256, "dt_data": 0.00035, "dt_net": 0.47221, "epoch": "87/300", "eta": "1:40:48", "gpu_mem": "10.07G", "grad_norm": 6.61813, "iter": "40/60", "loss": 0.16840, "lr": 0.0016157990, "top1_acc": 96.87500, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:04:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47160, "dt_data": 0.00061, "dt_net": 0.47098, "epoch": "87/300", "eta": "1:40:31", "gpu_mem": "10.07G", "grad_norm": 12.71201, "iter": "50/60", "loss": 0.19942, "lr": 0.0016144229, "top1_acc": 93.75000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:04:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47826, "dt_data": 0.00016, "dt_net": 0.47810, "epoch": "87/300", "eta": "1:41:52", "gpu_mem": "10.07G", "grad_norm": 6.80205, "iter": "60/60", "loss": 0.16504, "lr": 0.0016130450, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:04:41][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.68704, "dt_data": 0.68704, "dt_net": 0.47810, "epoch": "87/300", "eta": "2:26:19", "gpu_mem": "10.07G", "grad_norm": 6.80205, "loss": 0.20672, "lr": 0.0016130450, "top1_acc": 93.75000, "top1_err": 6.14583, "top5_acc": 99.37500, "top5_err": 0.57292}
[06/12 19:04:41][INFO] train_net.py:  708: Epoch 86 takes 47.59s. Epochs from 0 to 86 take 48.25s in average and 48.23s in median.
[06/12 19:04:41][INFO] train_net.py:  714: For epoch 86, each iteraction takes 0.79s in average. From epoch 0 to 86, each iteraction takes 0.80s in average.
[06/12 19:04:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47634, "dt_data": 0.00061, "dt_net": 0.47572, "epoch": "88/300", "eta": "1:41:22", "gpu_mem": "10.07G", "grad_norm": 4.79469, "iter": "10/60", "loss": 0.19819, "lr": 0.0016116651, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:05:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47266, "dt_data": 0.00053, "dt_net": 0.47213, "epoch": "88/300", "eta": "1:40:31", "gpu_mem": "10.07G", "grad_norm": 7.71473, "iter": "20/60", "loss": 0.09139, "lr": 0.0016102834, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:05:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47193, "dt_data": 0.00037, "dt_net": 0.47156, "epoch": "88/300", "eta": "1:40:17", "gpu_mem": "10.07G", "grad_norm": 4.85144, "iter": "30/60", "loss": 0.13060, "lr": 0.0016088999, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:05:17][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47707, "dt_data": 0.00043, "dt_net": 0.47664, "epoch": "88/300", "eta": "1:41:17", "gpu_mem": "10.07G", "grad_norm": 8.09128, "iter": "40/60", "loss": 0.14238, "lr": 0.0016075145, "top1_acc": 90.62500, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:05:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47951, "dt_data": 0.00053, "dt_net": 0.47898, "epoch": "88/300", "eta": "1:41:44", "gpu_mem": "10.07G", "grad_norm": 8.41943, "iter": "50/60", "loss": 0.18896, "lr": 0.0016061272, "top1_acc": 100.00000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:05:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46964, "dt_data": 0.00017, "dt_net": 0.46947, "epoch": "88/300", "eta": "1:39:33", "gpu_mem": "10.07G", "grad_norm": 5.37442, "iter": "60/60", "loss": 0.22459, "lr": 0.0016047381, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:05:29][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.70677, "dt_data": 0.70677, "dt_net": 0.46947, "epoch": "88/300", "eta": "2:29:48", "gpu_mem": "10.07G", "grad_norm": 5.37442, "loss": 0.18571, "lr": 0.0016047381, "top1_acc": 94.16667, "top1_err": 5.98958, "top5_acc": 99.68750, "top5_err": 0.57292}
[06/12 19:05:29][INFO] train_net.py:  708: Epoch 87 takes 47.73s. Epochs from 0 to 87 take 48.24s in average and 48.22s in median.
[06/12 19:05:29][INFO] train_net.py:  714: For epoch 87, each iteraction takes 0.80s in average. From epoch 0 to 87, each iteraction takes 0.80s in average.
[06/12 19:05:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47347, "dt_data": 0.00037, "dt_net": 0.47309, "epoch": "89/300", "eta": "1:40:17", "gpu_mem": "10.07G", "grad_norm": 3.76263, "iter": "10/60", "loss": 0.28789, "lr": 0.0016033472, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:05:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48213, "dt_data": 0.00048, "dt_net": 0.48166, "epoch": "89/300", "eta": "1:42:03", "gpu_mem": "10.07G", "grad_norm": 1.85041, "iter": "20/60", "loss": 0.14530, "lr": 0.0016019544, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:05:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47278, "dt_data": 0.00053, "dt_net": 0.47224, "epoch": "89/300", "eta": "1:39:59", "gpu_mem": "10.07G", "grad_norm": 8.28823, "iter": "30/60", "loss": 0.13237, "lr": 0.0016005598, "top1_acc": 96.87500, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:06:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.93683, "dt_data": 0.46513, "dt_net": 0.47169, "epoch": "89/300", "eta": "3:17:58", "gpu_mem": "10.07G", "grad_norm": 5.97546, "iter": "40/60", "loss": 0.16605, "lr": 0.0015991633, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:06:10][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47855, "dt_data": 0.00050, "dt_net": 0.47804, "epoch": "89/300", "eta": "1:41:03", "gpu_mem": "10.07G", "grad_norm": 2.47031, "iter": "50/60", "loss": 0.23615, "lr": 0.0015977651, "top1_acc": 93.75000, "top1_err": 7.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:06:15][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.55194, "dt_data": 0.08355, "dt_net": 0.46839, "epoch": "89/300", "eta": "1:56:27", "gpu_mem": "10.07G", "grad_norm": 6.71405, "iter": "60/60", "loss": 0.11473, "lr": 0.0015963650, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:06:16][INFO] logging.py:  101: json_stats: {"RAM": "13.13/31.07G", "_type": "train_epoch", "dt": 0.69081, "dt_data": 0.69081, "dt_net": 0.46839, "epoch": "89/300", "eta": "2:25:45", "gpu_mem": "10.07G", "grad_norm": 6.71405, "loss": 0.17682, "lr": 0.0015963650, "top1_acc": 94.16667, "top1_err": 5.36458, "top5_acc": 99.16667, "top5_err": 0.52083}
[06/12 19:06:16][INFO] train_net.py:  708: Epoch 88 takes 46.71s. Epochs from 0 to 88 take 48.22s in average and 48.22s in median.
[06/12 19:06:16][INFO] train_net.py:  714: For epoch 88, each iteraction takes 0.78s in average. From epoch 0 to 88, each iteraction takes 0.80s in average.
[06/12 19:06:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47235, "dt_data": 0.00046, "dt_net": 0.47189, "epoch": "90/300", "eta": "1:39:35", "gpu_mem": "10.07G", "grad_norm": 10.68217, "iter": "10/60", "loss": 0.14798, "lr": 0.0015949631, "top1_acc": 96.87500, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:06:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47366, "dt_data": 0.00034, "dt_net": 0.47333, "epoch": "90/300", "eta": "1:39:47", "gpu_mem": "10.07G", "grad_norm": 5.31285, "iter": "20/60", "loss": 0.12148, "lr": 0.0015935594, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:06:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47360, "dt_data": 0.00047, "dt_net": 0.47313, "epoch": "90/300", "eta": "1:39:41", "gpu_mem": "10.07G", "grad_norm": 4.55097, "iter": "30/60", "loss": 0.10301, "lr": 0.0015921538, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:06:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47749, "dt_data": 0.00072, "dt_net": 0.47676, "epoch": "90/300", "eta": "1:40:25", "gpu_mem": "10.07G", "grad_norm": 7.15488, "iter": "40/60", "loss": 0.19133, "lr": 0.0015907465, "top1_acc": 100.00000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:06:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47145, "dt_data": 0.00051, "dt_net": 0.47093, "epoch": "90/300", "eta": "1:39:04", "gpu_mem": "10.07G", "grad_norm": 3.64282, "iter": "50/60", "loss": 0.08252, "lr": 0.0015893374, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:07:03][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46953, "dt_data": 0.00021, "dt_net": 0.46932, "epoch": "90/300", "eta": "1:38:36", "gpu_mem": "10.07G", "grad_norm": 10.33561, "iter": "60/60", "loss": 0.10438, "lr": 0.0015879264, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:07:04][INFO] logging.py:  101: json_stats: {"RAM": "13.13/31.07G", "_type": "train_epoch", "dt": 0.68541, "dt_data": 0.68541, "dt_net": 0.46932, "epoch": "90/300", "eta": "2:23:55", "gpu_mem": "10.07G", "grad_norm": 10.33561, "loss": 0.14840, "lr": 0.0015879264, "top1_acc": 95.83333, "top1_err": 5.31250, "top5_acc": 99.79167, "top5_err": 0.36458}
[06/12 19:07:04][INFO] train_net.py:  708: Epoch 89 takes 47.79s. Epochs from 0 to 89 take 48.22s in average and 48.21s in median.
[06/12 19:07:04][INFO] train_net.py:  714: For epoch 89, each iteraction takes 0.80s in average. From epoch 0 to 89, each iteraction takes 0.80s in average.
[06/12 19:07:04][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 19:08:04][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "90/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.13290, "top1_acc": 73.43750, "top1_err": 26.56250, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 19:08:07][INFO] logging.py:  101: json_stats: {"RAM": "13.18/31.07G", "_type": "val_epoch", "epoch": "90/300", "gpu_mem": "10.07G", "min_top1_err": 23.44398, "min_top5_err": 2.90456, "time_diff": 0.60358, "top1_acc": 73.02905, "top1_err": 26.97095, "top5_acc": 95.85062, "top5_err": 4.14938}
[06/12 19:08:24][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46705, "dt_data": 0.00038, "dt_net": 0.46666, "epoch": "91/300", "eta": "1:38:00", "gpu_mem": "10.07G", "grad_norm": 11.05995, "iter": "10/60", "loss": 0.12471, "lr": 0.0015865137, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:08:30][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46918, "dt_data": 0.00048, "dt_net": 0.46869, "epoch": "91/300", "eta": "1:38:22", "gpu_mem": "10.07G", "grad_norm": 5.72668, "iter": "20/60", "loss": 0.16056, "lr": 0.0015850992, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:08:36][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47076, "dt_data": 0.00036, "dt_net": 0.47040, "epoch": "91/300", "eta": "1:38:37", "gpu_mem": "10.07G", "grad_norm": 3.94863, "iter": "30/60", "loss": 0.16637, "lr": 0.0015836829, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:08:42][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47278, "dt_data": 0.00057, "dt_net": 0.47220, "epoch": "91/300", "eta": "1:38:58", "gpu_mem": "10.07G", "grad_norm": 4.37151, "iter": "40/60", "loss": 0.10165, "lr": 0.0015822649, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:08:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47422, "dt_data": 0.00041, "dt_net": 0.47381, "epoch": "91/300", "eta": "1:39:11", "gpu_mem": "10.07G", "grad_norm": 6.29107, "iter": "50/60", "loss": 0.10274, "lr": 0.0015808450, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:08:54][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46572, "dt_data": 0.00014, "dt_net": 0.46558, "epoch": "91/300", "eta": "1:37:20", "gpu_mem": "10.07G", "grad_norm": 3.28476, "iter": "60/60", "loss": 0.12350, "lr": 0.0015794234, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:08:55][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.74378, "dt_data": 0.74378, "dt_net": 0.46558, "epoch": "91/300", "eta": "2:35:26", "gpu_mem": "10.07G", "grad_norm": 3.28476, "loss": 0.15605, "lr": 0.0015794234, "top1_acc": 94.79167, "top1_err": 4.73958, "top5_acc": 99.79167, "top5_err": 0.31250}
[06/12 19:08:55][INFO] train_net.py:  708: Epoch 90 takes 47.34s. Epochs from 0 to 90 take 48.21s in average and 48.19s in median.
[06/12 19:08:55][INFO] train_net.py:  714: For epoch 90, each iteraction takes 0.79s in average. From epoch 0 to 90, each iteraction takes 0.80s in average.
[06/12 19:09:12][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46857, "dt_data": 0.00035, "dt_net": 0.46822, "epoch": "92/300", "eta": "1:37:51", "gpu_mem": "10.07G", "grad_norm": 2.88624, "iter": "10/60", "loss": 0.08541, "lr": 0.0015780001, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:09:17][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47911, "dt_data": 0.00058, "dt_net": 0.47852, "epoch": "92/300", "eta": "1:39:58", "gpu_mem": "10.07G", "grad_norm": 2.24363, "iter": "20/60", "loss": 0.20310, "lr": 0.0015765749, "top1_acc": 100.00000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:09:24][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47250, "dt_data": 0.00043, "dt_net": 0.47207, "epoch": "92/300", "eta": "1:38:31", "gpu_mem": "10.07G", "grad_norm": 3.87678, "iter": "30/60", "loss": 0.20185, "lr": 0.0015751480, "top1_acc": 93.75000, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:09:30][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48890, "dt_data": 0.00052, "dt_net": 0.48838, "epoch": "92/300", "eta": "1:41:51", "gpu_mem": "10.07G", "grad_norm": 7.18636, "iter": "40/60", "loss": 0.13268, "lr": 0.0015737194, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:09:36][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47803, "dt_data": 0.00034, "dt_net": 0.47769, "epoch": "92/300", "eta": "1:39:30", "gpu_mem": "10.07G", "grad_norm": 10.04336, "iter": "50/60", "loss": 0.11579, "lr": 0.0015722890, "top1_acc": 96.87500, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:09:42][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46973, "dt_data": 0.00015, "dt_net": 0.46957, "epoch": "92/300", "eta": "1:37:42", "gpu_mem": "10.07G", "grad_norm": 5.33838, "iter": "60/60", "loss": 0.15136, "lr": 0.0015708569, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:09:43][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.69348, "dt_data": 0.69348, "dt_net": 0.46957, "epoch": "92/300", "eta": "2:24:14", "gpu_mem": "10.07G", "grad_norm": 5.33838, "loss": 0.15456, "lr": 0.0015708569, "top1_acc": 95.72917, "top1_err": 4.73958, "top5_acc": 99.79167, "top5_err": 0.20833}
[06/12 19:09:43][INFO] train_net.py:  708: Epoch 91 takes 48.25s. Epochs from 0 to 91 take 48.21s in average and 48.21s in median.
[06/12 19:09:43][INFO] train_net.py:  714: For epoch 91, each iteraction takes 0.80s in average. From epoch 0 to 91, each iteraction takes 0.80s in average.
[06/12 19:10:00][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47313, "dt_data": 0.00071, "dt_net": 0.47241, "epoch": "93/300", "eta": "1:38:19", "gpu_mem": "10.07G", "grad_norm": 13.54267, "iter": "10/60", "loss": 0.24627, "lr": 0.0015694230, "top1_acc": 90.62500, "top1_err": 9.37500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:10:06][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47642, "dt_data": 0.00052, "dt_net": 0.47590, "epoch": "93/300", "eta": "1:38:56", "gpu_mem": "10.07G", "grad_norm": 8.14363, "iter": "20/60", "loss": 0.14453, "lr": 0.0015679874, "top1_acc": 96.87500, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:10:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.00396, "dt_data": 0.53256, "dt_net": 0.47140, "epoch": "93/300", "eta": "3:28:19", "gpu_mem": "10.07G", "grad_norm": 4.04533, "iter": "30/60", "loss": 0.11121, "lr": 0.0015665501, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:10:18][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47154, "dt_data": 0.00044, "dt_net": 0.47110, "epoch": "93/300", "eta": "1:37:45", "gpu_mem": "10.07G", "grad_norm": 5.45015, "iter": "40/60", "loss": 0.16355, "lr": 0.0015651110, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:10:24][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.35655, "dt_data": 0.87439, "dt_net": 0.48215, "epoch": "93/300", "eta": "4:41:01", "gpu_mem": "10.07G", "grad_norm": 1.28355, "iter": "50/60", "loss": 0.15738, "lr": 0.0015636702, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:10:30][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46980, "dt_data": 0.00016, "dt_net": 0.46964, "epoch": "93/300", "eta": "1:37:14", "gpu_mem": "10.07G", "grad_norm": 5.52628, "iter": "60/60", "loss": 0.11067, "lr": 0.0015622277, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:10:30][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.70333, "dt_data": 0.70333, "dt_net": 0.46964, "epoch": "93/300", "eta": "2:25:34", "gpu_mem": "10.07G", "grad_norm": 5.52628, "loss": 0.17088, "lr": 0.0015622277, "top1_acc": 94.58333, "top1_err": 5.41667, "top5_acc": 99.79167, "top5_err": 0.41667}
[06/12 19:10:30][INFO] train_net.py:  708: Epoch 92 takes 47.36s. Epochs from 0 to 92 take 48.20s in average and 48.19s in median.
[06/12 19:10:30][INFO] train_net.py:  714: For epoch 92, each iteraction takes 0.79s in average. From epoch 0 to 92, each iteraction takes 0.80s in average.
[06/12 19:10:48][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47531, "dt_data": 0.00033, "dt_net": 0.47498, "epoch": "94/300", "eta": "1:38:18", "gpu_mem": "10.07G", "grad_norm": 6.44363, "iter": "10/60", "loss": 0.10273, "lr": 0.0015607835, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:10:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47520, "dt_data": 0.00032, "dt_net": 0.47488, "epoch": "94/300", "eta": "1:38:12", "gpu_mem": "10.07G", "grad_norm": 9.10876, "iter": "20/60", "loss": 0.17245, "lr": 0.0015593376, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:10:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47202, "dt_data": 0.00034, "dt_net": 0.47168, "epoch": "94/300", "eta": "1:37:28", "gpu_mem": "10.07G", "grad_norm": 7.77441, "iter": "30/60", "loss": 0.10598, "lr": 0.0015578900, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:11:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47618, "dt_data": 0.00051, "dt_net": 0.47567, "epoch": "94/300", "eta": "1:38:15", "gpu_mem": "10.07G", "grad_norm": 8.92070, "iter": "40/60", "loss": 0.16748, "lr": 0.0015564406, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:11:12][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48045, "dt_data": 0.00044, "dt_net": 0.48001, "epoch": "94/300", "eta": "1:39:03", "gpu_mem": "10.07G", "grad_norm": 6.69015, "iter": "50/60", "loss": 0.12381, "lr": 0.0015549896, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:11:17][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46976, "dt_data": 0.00018, "dt_net": 0.46958, "epoch": "94/300", "eta": "1:36:46", "gpu_mem": "10.07G", "grad_norm": 2.87637, "iter": "60/60", "loss": 0.18109, "lr": 0.0015535369, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:11:18][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.69953, "dt_data": 0.69953, "dt_net": 0.46958, "epoch": "94/300", "eta": "2:24:05", "gpu_mem": "10.07G", "grad_norm": 2.87637, "loss": 0.16290, "lr": 0.0015535369, "top1_acc": 95.52083, "top1_err": 4.58333, "top5_acc": 99.37500, "top5_err": 0.57292}
[06/12 19:11:18][INFO] train_net.py:  708: Epoch 93 takes 47.65s. Epochs from 0 to 93 take 48.20s in average and 48.17s in median.
[06/12 19:11:18][INFO] train_net.py:  714: For epoch 93, each iteraction takes 0.79s in average. From epoch 0 to 93, each iteraction takes 0.80s in average.
[06/12 19:11:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.58436, "dt_data": 0.00046, "dt_net": 0.58390, "epoch": "95/300", "eta": "2:00:16", "gpu_mem": "10.07G", "grad_norm": 2.78430, "iter": "10/60", "loss": 0.12181, "lr": 0.0015520825, "top1_acc": 93.75000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:11:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48343, "dt_data": 0.00057, "dt_net": 0.48285, "epoch": "95/300", "eta": "1:39:25", "gpu_mem": "10.07G", "grad_norm": 6.81841, "iter": "20/60", "loss": 0.16365, "lr": 0.0015506264, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:11:47][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.54373, "dt_data": 0.00044, "dt_net": 0.54329, "epoch": "95/300", "eta": "1:51:44", "gpu_mem": "10.07G", "grad_norm": 5.37787, "iter": "30/60", "loss": 0.10113, "lr": 0.0015491687, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:11:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47860, "dt_data": 0.00035, "dt_net": 0.47825, "epoch": "95/300", "eta": "1:38:16", "gpu_mem": "10.07G", "grad_norm": 4.87423, "iter": "40/60", "loss": 0.13465, "lr": 0.0015477093, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:11:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.89782, "dt_data": 0.00036, "dt_net": 0.89746, "epoch": "95/300", "eta": "3:04:12", "gpu_mem": "10.07G", "grad_norm": 3.30232, "iter": "50/60", "loss": 0.11247, "lr": 0.0015462482, "top1_acc": 100.00000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:12:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46958, "dt_data": 0.00018, "dt_net": 0.46941, "epoch": "95/300", "eta": "1:36:15", "gpu_mem": "10.07G", "grad_norm": 2.99785, "iter": "60/60", "loss": 0.11886, "lr": 0.0015447854, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:12:06][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.69206, "dt_data": 0.69206, "dt_net": 0.46941, "epoch": "95/300", "eta": "2:21:52", "gpu_mem": "10.07G", "grad_norm": 2.99785, "loss": 0.14666, "lr": 0.0015447854, "top1_acc": 95.31250, "top1_err": 4.58333, "top5_acc": 99.58333, "top5_err": 0.36458}
[06/12 19:12:06][INFO] train_net.py:  708: Epoch 94 takes 47.72s. Epochs from 0 to 94 take 48.19s in average and 48.15s in median.
[06/12 19:12:06][INFO] train_net.py:  714: For epoch 94, each iteraction takes 0.80s in average. From epoch 0 to 94, each iteraction takes 0.80s in average.
[06/12 19:12:06][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 19:13:07][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "95/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.13078, "top1_acc": 76.56250, "top1_err": 23.43750, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 19:13:10][INFO] logging.py:  101: json_stats: {"RAM": "13.23/31.07G", "_type": "val_epoch", "epoch": "95/300", "gpu_mem": "10.07G", "min_top1_err": 22.82158, "min_top5_err": 2.90456, "time_diff": 0.61219, "top1_acc": 77.17842, "top1_err": 22.82158, "top5_acc": 95.43568, "top5_err": 4.56432}
[06/12 19:13:27][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46733, "dt_data": 0.00081, "dt_net": 0.46652, "epoch": "96/300", "eta": "1:35:43", "gpu_mem": "10.07G", "grad_norm": 7.69413, "iter": "10/60", "loss": 0.11490, "lr": 0.0015433210, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:13:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46750, "dt_data": 0.00037, "dt_net": 0.46712, "epoch": "96/300", "eta": "1:35:40", "gpu_mem": "10.07G", "grad_norm": 5.47594, "iter": "20/60", "loss": 0.16011, "lr": 0.0015418549, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:13:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47929, "dt_data": 0.00072, "dt_net": 0.47857, "epoch": "96/300", "eta": "1:38:00", "gpu_mem": "10.07G", "grad_norm": 4.85291, "iter": "30/60", "loss": 0.14443, "lr": 0.0015403872, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:13:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47394, "dt_data": 0.00058, "dt_net": 0.47336, "epoch": "96/300", "eta": "1:36:50", "gpu_mem": "10.07G", "grad_norm": 3.06785, "iter": "40/60", "loss": 0.09134, "lr": 0.0015389178, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:13:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47317, "dt_data": 0.00054, "dt_net": 0.47263, "epoch": "96/300", "eta": "1:36:36", "gpu_mem": "10.07G", "grad_norm": 6.24097, "iter": "50/60", "loss": 0.19220, "lr": 0.0015374468, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:13:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46761, "dt_data": 0.00019, "dt_net": 0.46743, "epoch": "96/300", "eta": "1:35:23", "gpu_mem": "10.07G", "grad_norm": 6.69956, "iter": "60/60", "loss": 0.13888, "lr": 0.0015359741, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:13:59][INFO] logging.py:  101: json_stats: {"RAM": "13.16/31.07G", "_type": "train_epoch", "dt": 0.69241, "dt_data": 0.69241, "dt_net": 0.46743, "epoch": "96/300", "eta": "2:21:14", "gpu_mem": "10.07G", "grad_norm": 6.69956, "loss": 0.15675, "lr": 0.0015359741, "top1_acc": 95.52083, "top1_err": 4.89583, "top5_acc": 99.58333, "top5_err": 0.41667}
[06/12 19:13:59][INFO] train_net.py:  708: Epoch 95 takes 48.89s. Epochs from 0 to 95 take 48.20s in average and 48.17s in median.
[06/12 19:13:59][INFO] train_net.py:  714: For epoch 95, each iteraction takes 0.81s in average. From epoch 0 to 95, each iteraction takes 0.80s in average.
[06/12 19:14:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46839, "dt_data": 0.00059, "dt_net": 0.46779, "epoch": "97/300", "eta": "1:35:28", "gpu_mem": "10.07G", "grad_norm": 4.75520, "iter": "10/60", "loss": 0.07166, "lr": 0.0015344999, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:14:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47518, "dt_data": 0.00038, "dt_net": 0.47479, "epoch": "97/300", "eta": "1:36:46", "gpu_mem": "10.07G", "grad_norm": 10.09708, "iter": "20/60", "loss": 0.13555, "lr": 0.0015330240, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:14:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46928, "dt_data": 0.00062, "dt_net": 0.46865, "epoch": "97/300", "eta": "1:35:29", "gpu_mem": "10.07G", "grad_norm": 3.69039, "iter": "30/60", "loss": 0.12336, "lr": 0.0015315464, "top1_acc": 96.87500, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:14:34][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47188, "dt_data": 0.00053, "dt_net": 0.47134, "epoch": "97/300", "eta": "1:35:56", "gpu_mem": "10.07G", "grad_norm": 8.22339, "iter": "40/60", "loss": 0.12561, "lr": 0.0015300673, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:14:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47265, "dt_data": 0.00041, "dt_net": 0.47224, "epoch": "97/300", "eta": "1:36:01", "gpu_mem": "10.07G", "grad_norm": 7.37848, "iter": "50/60", "loss": 0.18094, "lr": 0.0015285865, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:14:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46915, "dt_data": 0.00016, "dt_net": 0.46899, "epoch": "97/300", "eta": "1:35:14", "gpu_mem": "10.07G", "grad_norm": 8.06219, "iter": "60/60", "loss": 0.12753, "lr": 0.0015271041, "top1_acc": 96.87500, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:14:46][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.69668, "dt_data": 0.69668, "dt_net": 0.46899, "epoch": "97/300", "eta": "2:21:25", "gpu_mem": "10.07G", "grad_norm": 8.06219, "loss": 0.14463, "lr": 0.0015271041, "top1_acc": 95.83333, "top1_err": 4.47917, "top5_acc": 99.68750, "top5_err": 0.15625}
[06/12 19:14:46][INFO] train_net.py:  708: Epoch 96 takes 47.94s. Epochs from 0 to 96 take 48.20s in average and 48.15s in median.
[06/12 19:14:46][INFO] train_net.py:  714: For epoch 96, each iteraction takes 0.80s in average. From epoch 0 to 96, each iteraction takes 0.80s in average.
[06/12 19:15:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47051, "dt_data": 0.00080, "dt_net": 0.46970, "epoch": "98/300", "eta": "1:35:26", "gpu_mem": "10.07G", "grad_norm": 5.55456, "iter": "10/60", "loss": 0.12274, "lr": 0.0015256201, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:15:09][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47507, "dt_data": 0.00063, "dt_net": 0.47443, "epoch": "98/300", "eta": "1:36:16", "gpu_mem": "10.07G", "grad_norm": 4.46195, "iter": "20/60", "loss": 0.08557, "lr": 0.0015241346, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:15:15][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47230, "dt_data": 0.00043, "dt_net": 0.47187, "epoch": "98/300", "eta": "1:35:38", "gpu_mem": "10.07G", "grad_norm": 11.35170, "iter": "30/60", "loss": 0.16362, "lr": 0.0015226474, "top1_acc": 96.87500, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:15:21][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47788, "dt_data": 0.00045, "dt_net": 0.47743, "epoch": "98/300", "eta": "1:36:41", "gpu_mem": "10.07G", "grad_norm": 5.85689, "iter": "40/60", "loss": 0.13794, "lr": 0.0015211586, "top1_acc": 100.00000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:15:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47473, "dt_data": 0.00073, "dt_net": 0.47399, "epoch": "98/300", "eta": "1:35:58", "gpu_mem": "10.07G", "grad_norm": 3.96605, "iter": "50/60", "loss": 0.16369, "lr": 0.0015196682, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:15:34][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46862, "dt_data": 0.00017, "dt_net": 0.46845, "epoch": "98/300", "eta": "1:34:39", "gpu_mem": "10.07G", "grad_norm": 3.34579, "iter": "60/60", "loss": 0.17524, "lr": 0.0015181763, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:15:35][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.70713, "dt_data": 0.70713, "dt_net": 0.46845, "epoch": "98/300", "eta": "2:22:49", "gpu_mem": "10.07G", "grad_norm": 3.34579, "loss": 0.16452, "lr": 0.0015181763, "top1_acc": 95.93750, "top1_err": 5.36458, "top5_acc": 99.58333, "top5_err": 0.41667}
[06/12 19:15:35][INFO] train_net.py:  708: Epoch 97 takes 48.30s. Epochs from 0 to 97 take 48.20s in average and 48.17s in median.
[06/12 19:15:35][INFO] train_net.py:  714: For epoch 97, each iteraction takes 0.80s in average. From epoch 0 to 97, each iteraction takes 0.80s in average.
[06/12 19:15:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47331, "dt_data": 0.00055, "dt_net": 0.47275, "epoch": "99/300", "eta": "1:35:31", "gpu_mem": "10.07G", "grad_norm": 17.23924, "iter": "10/60", "loss": 0.12977, "lr": 0.0015166828, "top1_acc": 100.00000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:15:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47284, "dt_data": 0.00066, "dt_net": 0.47218, "epoch": "99/300", "eta": "1:35:21", "gpu_mem": "10.07G", "grad_norm": 4.92644, "iter": "20/60", "loss": 0.15172, "lr": 0.0015151877, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:16:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47007, "dt_data": 0.00032, "dt_net": 0.46974, "epoch": "99/300", "eta": "1:34:43", "gpu_mem": "10.07G", "grad_norm": 7.71731, "iter": "30/60", "loss": 0.13484, "lr": 0.0015136910, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:16:10][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47506, "dt_data": 0.00054, "dt_net": 0.47452, "epoch": "99/300", "eta": "1:35:38", "gpu_mem": "10.07G", "grad_norm": 3.39013, "iter": "40/60", "loss": 0.14087, "lr": 0.0015121928, "top1_acc": 100.00000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:16:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47286, "dt_data": 0.00041, "dt_net": 0.47245, "epoch": "99/300", "eta": "1:35:07", "gpu_mem": "10.07G", "grad_norm": 10.32448, "iter": "50/60", "loss": 0.17418, "lr": 0.0015106930, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:16:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46994, "dt_data": 0.00019, "dt_net": 0.46975, "epoch": "99/300", "eta": "1:34:27", "gpu_mem": "10.07G", "grad_norm": 8.74096, "iter": "60/60", "loss": 0.14526, "lr": 0.0015091916, "top1_acc": 96.87500, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:16:23][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.70307, "dt_data": 0.70307, "dt_net": 0.46975, "epoch": "99/300", "eta": "2:21:18", "gpu_mem": "10.07G", "grad_norm": 8.74096, "loss": 0.15803, "lr": 0.0015091916, "top1_acc": 94.58333, "top1_err": 5.41667, "top5_acc": 99.58333, "top5_err": 0.36458}
[06/12 19:16:23][INFO] train_net.py:  708: Epoch 98 takes 47.94s. Epochs from 0 to 98 take 48.19s in average and 48.15s in median.
[06/12 19:16:23][INFO] train_net.py:  714: For epoch 98, each iteraction takes 0.80s in average. From epoch 0 to 98, each iteraction takes 0.80s in average.
[06/12 19:16:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46993, "dt_data": 0.00049, "dt_net": 0.46944, "epoch": "100/300", "eta": "1:34:22", "gpu_mem": "10.07G", "grad_norm": 7.21121, "iter": "10/60", "loss": 0.16030, "lr": 0.0015076887, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:16:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47284, "dt_data": 0.00105, "dt_net": 0.47179, "epoch": "100/300", "eta": "1:34:53", "gpu_mem": "10.07G", "grad_norm": 7.63316, "iter": "20/60", "loss": 0.15337, "lr": 0.0015061843, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:16:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47356, "dt_data": 0.00046, "dt_net": 0.47310, "epoch": "100/300", "eta": "1:34:56", "gpu_mem": "10.07G", "grad_norm": 5.01667, "iter": "30/60", "loss": 0.12281, "lr": 0.0015046783, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:16:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47407, "dt_data": 0.00051, "dt_net": 0.47355, "epoch": "100/300", "eta": "1:34:58", "gpu_mem": "10.07G", "grad_norm": 2.40362, "iter": "40/60", "loss": 0.16899, "lr": 0.0015031708, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:17:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.78235, "dt_data": 0.00068, "dt_net": 0.78167, "epoch": "100/300", "eta": "2:36:36", "gpu_mem": "10.07G", "grad_norm": 8.68038, "iter": "50/60", "loss": 0.12050, "lr": 0.0015016617, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:17:10][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.93274, "dt_data": 0.46592, "dt_net": 0.46682, "epoch": "100/300", "eta": "3:06:32", "gpu_mem": "10.07G", "grad_norm": 3.09512, "iter": "60/60", "loss": 0.14767, "lr": 0.0015001511, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:17:10][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.68976, "dt_data": 0.68976, "dt_net": 0.46682, "epoch": "100/300", "eta": "2:17:56", "gpu_mem": "10.07G", "grad_norm": 3.09512, "loss": 0.15337, "lr": 0.0015001511, "top1_acc": 95.00000, "top1_err": 4.79167, "top5_acc": 99.47917, "top5_err": 0.36458}
[06/12 19:17:10][INFO] train_net.py:  708: Epoch 99 takes 47.58s. Epochs from 0 to 99 take 48.19s in average and 48.15s in median.
[06/12 19:17:10][INFO] train_net.py:  714: For epoch 99, each iteraction takes 0.79s in average. From epoch 0 to 99, each iteraction takes 0.80s in average.
[06/12 19:17:10][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 19:18:13][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "100/300", "eta": "0:00:02", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.44726, "top1_acc": 71.87500, "top1_err": 28.12500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 19:18:15][INFO] logging.py:  101: json_stats: {"RAM": "13.25/31.07G", "_type": "val_epoch", "epoch": "100/300", "gpu_mem": "10.07G", "min_top1_err": 22.82158, "min_top5_err": 2.90456, "time_diff": 0.60517, "top1_acc": 73.23651, "top1_err": 26.76349, "top5_acc": 96.05809, "top5_err": 3.94191}
[06/12 19:18:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47536, "dt_data": 0.00071, "dt_net": 0.47464, "epoch": "101/300", "eta": "1:34:59", "gpu_mem": "10.07G", "grad_norm": 4.76232, "iter": "10/60", "loss": 0.09679, "lr": 0.0014986390, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:18:38][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46760, "dt_data": 0.00057, "dt_net": 0.46702, "epoch": "101/300", "eta": "1:33:21", "gpu_mem": "10.07G", "grad_norm": 4.91133, "iter": "20/60", "loss": 0.11798, "lr": 0.0014971254, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:18:44][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.75147, "dt_data": 0.28402, "dt_net": 0.46745, "epoch": "101/300", "eta": "2:29:55", "gpu_mem": "10.07G", "grad_norm": 5.97213, "iter": "30/60", "loss": 0.10469, "lr": 0.0014956103, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:18:51][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46840, "dt_data": 0.00033, "dt_net": 0.46807, "epoch": "101/300", "eta": "1:33:22", "gpu_mem": "10.07G", "grad_norm": 3.50567, "iter": "40/60", "loss": 0.13377, "lr": 0.0014940936, "top1_acc": 93.75000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:18:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.83106, "dt_data": 0.36160, "dt_net": 0.46946, "epoch": "101/300", "eta": "2:45:31", "gpu_mem": "10.07G", "grad_norm": 8.26985, "iter": "50/60", "loss": 0.08854, "lr": 0.0014925755, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:19:02][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46716, "dt_data": 0.00017, "dt_net": 0.46700, "epoch": "101/300", "eta": "1:32:57", "gpu_mem": "10.07G", "grad_norm": 7.57968, "iter": "60/60", "loss": 0.07576, "lr": 0.0014910558, "top1_acc": 96.87500, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:19:03][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.71309, "dt_data": 0.71309, "dt_net": 0.46700, "epoch": "101/300", "eta": "2:21:53", "gpu_mem": "10.07G", "grad_norm": 7.57968, "loss": 0.13036, "lr": 0.0014910558, "top1_acc": 95.41667, "top1_err": 4.11458, "top5_acc": 99.79167, "top5_err": 0.15625}
[06/12 19:19:03][INFO] train_net.py:  708: Epoch 100 takes 47.86s. Epochs from 0 to 100 take 48.18s in average and 48.14s in median.
[06/12 19:19:03][INFO] train_net.py:  714: For epoch 100, each iteraction takes 0.80s in average. From epoch 0 to 100, each iteraction takes 0.80s in average.
[06/12 19:19:21][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47201, "dt_data": 0.00046, "dt_net": 0.47156, "epoch": "102/300", "eta": "1:33:51", "gpu_mem": "10.07G", "grad_norm": 6.36828, "iter": "10/60", "loss": 0.12182, "lr": 0.0014895346, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:19:26][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47593, "dt_data": 0.00059, "dt_net": 0.47534, "epoch": "102/300", "eta": "1:34:33", "gpu_mem": "10.07G", "grad_norm": 4.08650, "iter": "20/60", "loss": 0.09465, "lr": 0.0014880120, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:19:32][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47117, "dt_data": 0.00033, "dt_net": 0.47085, "epoch": "102/300", "eta": "1:33:31", "gpu_mem": "10.07G", "grad_norm": 11.18735, "iter": "30/60", "loss": 0.13865, "lr": 0.0014864879, "top1_acc": 96.87500, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:19:38][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47390, "dt_data": 0.00032, "dt_net": 0.47358, "epoch": "102/300", "eta": "1:33:59", "gpu_mem": "10.07G", "grad_norm": 10.52305, "iter": "40/60", "loss": 0.12819, "lr": 0.0014849623, "top1_acc": 96.87500, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:19:45][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47182, "dt_data": 0.00086, "dt_net": 0.47096, "epoch": "102/300", "eta": "1:33:29", "gpu_mem": "10.07G", "grad_norm": 8.59294, "iter": "50/60", "loss": 0.15607, "lr": 0.0014834352, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:19:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47076, "dt_data": 0.00016, "dt_net": 0.47061, "epoch": "102/300", "eta": "1:33:12", "gpu_mem": "10.07G", "grad_norm": 10.74036, "iter": "60/60", "loss": 0.12145, "lr": 0.0014819066, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:19:51][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.70466, "dt_data": 0.70466, "dt_net": 0.47061, "epoch": "102/300", "eta": "2:19:30", "gpu_mem": "10.07G", "grad_norm": 10.74036, "loss": 0.13867, "lr": 0.0014819066, "top1_acc": 96.04167, "top1_err": 4.73958, "top5_acc": 99.79167, "top5_err": 0.26042}
[06/12 19:19:51][INFO] train_net.py:  708: Epoch 101 takes 47.40s. Epochs from 0 to 101 take 48.18s in average and 48.14s in median.
[06/12 19:19:51][INFO] train_net.py:  714: For epoch 101, each iteraction takes 0.79s in average. From epoch 0 to 101, each iteraction takes 0.80s in average.
[06/12 19:20:08][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47325, "dt_data": 0.00053, "dt_net": 0.47272, "epoch": "103/300", "eta": "1:33:37", "gpu_mem": "10.07G", "grad_norm": 6.96566, "iter": "10/60", "loss": 0.12876, "lr": 0.0014803766, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:20:14][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47244, "dt_data": 0.00080, "dt_net": 0.47163, "epoch": "103/300", "eta": "1:33:23", "gpu_mem": "10.07G", "grad_norm": 2.33549, "iter": "20/60", "loss": 0.11367, "lr": 0.0014788451, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:20:20][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47173, "dt_data": 0.00037, "dt_net": 0.47136, "epoch": "103/300", "eta": "1:33:10", "gpu_mem": "10.07G", "grad_norm": 5.13777, "iter": "30/60", "loss": 0.09208, "lr": 0.0014773121, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:20:26][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47873, "dt_data": 0.00069, "dt_net": 0.47803, "epoch": "103/300", "eta": "1:34:28", "gpu_mem": "10.07G", "grad_norm": 2.73313, "iter": "40/60", "loss": 0.09742, "lr": 0.0014757777, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:20:32][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47357, "dt_data": 0.00031, "dt_net": 0.47326, "epoch": "103/300", "eta": "1:33:22", "gpu_mem": "10.07G", "grad_norm": 7.77967, "iter": "50/60", "loss": 0.18112, "lr": 0.0014742419, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:20:38][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46911, "dt_data": 0.00016, "dt_net": 0.46894, "epoch": "103/300", "eta": "1:32:24", "gpu_mem": "10.07G", "grad_norm": 7.09274, "iter": "60/60", "loss": 0.19025, "lr": 0.0014727046, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:20:39][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.72041, "dt_data": 0.72040, "dt_net": 0.46894, "epoch": "103/300", "eta": "2:21:54", "gpu_mem": "10.07G", "grad_norm": 7.09274, "loss": 0.14281, "lr": 0.0014727046, "top1_acc": 96.04167, "top1_err": 4.63542, "top5_acc": 99.58333, "top5_err": 0.36458}
[06/12 19:20:39][INFO] train_net.py:  708: Epoch 102 takes 48.58s. Epochs from 0 to 102 take 48.18s in average and 48.14s in median.
[06/12 19:20:39][INFO] train_net.py:  714: For epoch 102, each iteraction takes 0.81s in average. From epoch 0 to 102, each iteraction takes 0.80s in average.
[06/12 19:20:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.12601, "dt_data": 0.00066, "dt_net": 1.12534, "epoch": "104/300", "eta": "3:41:38", "gpu_mem": "10.07G", "grad_norm": 2.62356, "iter": "10/60", "loss": 0.16982, "lr": 0.0014711658, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:21:02][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47562, "dt_data": 0.00048, "dt_net": 0.47514, "epoch": "104/300", "eta": "1:33:32", "gpu_mem": "10.07G", "grad_norm": 6.65496, "iter": "20/60", "loss": 0.12028, "lr": 0.0014696257, "top1_acc": 93.75000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:21:08][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.80043, "dt_data": 0.00036, "dt_net": 0.80006, "epoch": "104/300", "eta": "2:37:17", "gpu_mem": "10.07G", "grad_norm": 3.26698, "iter": "30/60", "loss": 0.13850, "lr": 0.0014680841, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:21:14][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47928, "dt_data": 0.00049, "dt_net": 0.47879, "epoch": "104/300", "eta": "1:34:05", "gpu_mem": "10.07G", "grad_norm": 3.63037, "iter": "40/60", "loss": 0.14498, "lr": 0.0014665410, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:21:20][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.49137, "dt_data": 0.00041, "dt_net": 0.49096, "epoch": "104/300", "eta": "1:36:23", "gpu_mem": "10.07G", "grad_norm": 4.31365, "iter": "50/60", "loss": 0.10700, "lr": 0.0014649966, "top1_acc": 96.87500, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:21:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46925, "dt_data": 0.00016, "dt_net": 0.46909, "epoch": "104/300", "eta": "1:31:58", "gpu_mem": "10.07G", "grad_norm": 5.58803, "iter": "60/60", "loss": 0.13144, "lr": 0.0014634507, "top1_acc": 93.75000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:21:26][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.69546, "dt_data": 0.69546, "dt_net": 0.46909, "epoch": "104/300", "eta": "2:16:17", "gpu_mem": "10.07G", "grad_norm": 5.58803, "loss": 0.14220, "lr": 0.0014634507, "top1_acc": 95.10417, "top1_err": 4.68750, "top5_acc": 99.58333, "top5_err": 0.31250}
[06/12 19:21:26][INFO] train_net.py:  708: Epoch 103 takes 46.91s. Epochs from 0 to 103 take 48.17s in average and 48.14s in median.
[06/12 19:21:26][INFO] train_net.py:  714: For epoch 103, each iteraction takes 0.78s in average. From epoch 0 to 103, each iteraction takes 0.80s in average.
[06/12 19:21:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47008, "dt_data": 0.00037, "dt_net": 0.46970, "epoch": "105/300", "eta": "1:32:03", "gpu_mem": "10.07G", "grad_norm": 4.17967, "iter": "10/60", "loss": 0.12257, "lr": 0.0014619034, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:21:48][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47014, "dt_data": 0.00035, "dt_net": 0.46978, "epoch": "105/300", "eta": "1:31:59", "gpu_mem": "10.07G", "grad_norm": 2.76540, "iter": "20/60", "loss": 0.07088, "lr": 0.0014603547, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:21:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47586, "dt_data": 0.00395, "dt_net": 0.47190, "epoch": "105/300", "eta": "1:33:01", "gpu_mem": "10.07G", "grad_norm": 5.65586, "iter": "30/60", "loss": 0.12796, "lr": 0.0014588046, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:22:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47277, "dt_data": 0.00042, "dt_net": 0.47235, "epoch": "105/300", "eta": "1:32:20", "gpu_mem": "10.07G", "grad_norm": 3.14212, "iter": "40/60", "loss": 0.09921, "lr": 0.0014572532, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:22:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47972, "dt_data": 0.00038, "dt_net": 0.47933, "epoch": "105/300", "eta": "1:33:37", "gpu_mem": "10.07G", "grad_norm": 3.20312, "iter": "50/60", "loss": 0.12717, "lr": 0.0014557003, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:22:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47001, "dt_data": 0.00017, "dt_net": 0.46983, "epoch": "105/300", "eta": "1:31:39", "gpu_mem": "10.07G", "grad_norm": 16.87962, "iter": "60/60", "loss": 0.16579, "lr": 0.0014541460, "top1_acc": 87.50000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:22:13][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.68849, "dt_data": 0.68848, "dt_net": 0.46983, "epoch": "105/300", "eta": "2:14:14", "gpu_mem": "10.07G", "grad_norm": 16.87962, "loss": 0.14642, "lr": 0.0014541460, "top1_acc": 95.00000, "top1_err": 4.68750, "top5_acc": 99.68750, "top5_err": 0.52083}
[06/12 19:22:13][INFO] train_net.py:  708: Epoch 104 takes 47.32s. Epochs from 0 to 104 take 48.16s in average and 48.14s in median.
[06/12 19:22:13][INFO] train_net.py:  714: For epoch 104, each iteraction takes 0.79s in average. From epoch 0 to 104, each iteraction takes 0.80s in average.
[06/12 19:22:13][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 19:23:15][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "105/300", "eta": "0:00:05", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.95629, "top1_acc": 76.56250, "top1_err": 23.43750, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 19:23:17][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "val_epoch", "epoch": "105/300", "gpu_mem": "10.07G", "min_top1_err": 22.82158, "min_top5_err": 2.90456, "time_diff": 0.61481, "top1_acc": 75.31120, "top1_err": 24.68880, "top5_acc": 95.64315, "top5_err": 4.35685}
[06/12 19:23:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.53909, "dt_data": 0.07698, "dt_net": 0.46210, "epoch": "106/300", "eta": "1:45:01", "gpu_mem": "10.07G", "grad_norm": 9.92538, "iter": "10/60", "loss": 0.14089, "lr": 0.0014525904, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:23:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46517, "dt_data": 0.00046, "dt_net": 0.46470, "epoch": "106/300", "eta": "1:30:33", "gpu_mem": "10.07G", "grad_norm": 7.45332, "iter": "20/60", "loss": 0.17084, "lr": 0.0014510333, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:23:47][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.56292, "dt_data": 0.09758, "dt_net": 0.46533, "epoch": "106/300", "eta": "1:49:29", "gpu_mem": "10.07G", "grad_norm": 6.39846, "iter": "30/60", "loss": 0.16093, "lr": 0.0014494749, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:23:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47136, "dt_data": 0.00032, "dt_net": 0.47105, "epoch": "106/300", "eta": "1:31:36", "gpu_mem": "10.07G", "grad_norm": 7.00196, "iter": "40/60", "loss": 0.18355, "lr": 0.0014479151, "top1_acc": 100.00000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:23:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47046, "dt_data": 0.00049, "dt_net": 0.46997, "epoch": "106/300", "eta": "1:31:20", "gpu_mem": "10.07G", "grad_norm": 3.38898, "iter": "50/60", "loss": 0.09052, "lr": 0.0014463540, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:24:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46645, "dt_data": 0.00017, "dt_net": 0.46628, "epoch": "106/300", "eta": "1:30:29", "gpu_mem": "10.07G", "grad_norm": 2.57191, "iter": "60/60", "loss": 0.11772, "lr": 0.0014447915, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:24:05][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.68064, "dt_data": 0.68064, "dt_net": 0.46628, "epoch": "106/300", "eta": "2:12:02", "gpu_mem": "10.07G", "grad_norm": 2.57191, "loss": 0.16314, "lr": 0.0014447915, "top1_acc": 94.58333, "top1_err": 5.62500, "top5_acc": 99.79167, "top5_err": 0.36458}
[06/12 19:24:05][INFO] train_net.py:  708: Epoch 105 takes 47.47s. Epochs from 0 to 105 take 48.15s in average and 48.13s in median.
[06/12 19:24:05][INFO] train_net.py:  714: For epoch 105, each iteraction takes 0.79s in average. From epoch 0 to 105, each iteraction takes 0.80s in average.
[06/12 19:24:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46919, "dt_data": 0.00049, "dt_net": 0.46869, "epoch": "107/300", "eta": "1:30:56", "gpu_mem": "10.07G", "grad_norm": 10.44911, "iter": "10/60", "loss": 0.11757, "lr": 0.0014432277, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:24:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46997, "dt_data": 0.00039, "dt_net": 0.46958, "epoch": "107/300", "eta": "1:31:01", "gpu_mem": "10.07G", "grad_norm": 7.36939, "iter": "20/60", "loss": 0.14319, "lr": 0.0014416624, "top1_acc": 90.62500, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:24:34][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47029, "dt_data": 0.00039, "dt_net": 0.46990, "epoch": "107/300", "eta": "1:31:00", "gpu_mem": "10.07G", "grad_norm": 0.35800, "iter": "30/60", "loss": 0.10947, "lr": 0.0014400959, "top1_acc": 96.87500, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:24:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47062, "dt_data": 0.00034, "dt_net": 0.47028, "epoch": "107/300", "eta": "1:30:59", "gpu_mem": "10.07G", "grad_norm": 4.96385, "iter": "40/60", "loss": 0.10995, "lr": 0.0014385280, "top1_acc": 96.87500, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:24:47][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.76631, "dt_data": 0.29714, "dt_net": 0.46916, "epoch": "107/300", "eta": "2:28:01", "gpu_mem": "10.07G", "grad_norm": 3.45380, "iter": "50/60", "loss": 0.09394, "lr": 0.0014369588, "top1_acc": 93.75000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:24:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46931, "dt_data": 0.00017, "dt_net": 0.46914, "epoch": "107/300", "eta": "1:30:34", "gpu_mem": "10.07G", "grad_norm": 6.75439, "iter": "60/60", "loss": 0.18467, "lr": 0.0014353882, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:24:53][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.69620, "dt_data": 0.69620, "dt_net": 0.46914, "epoch": "107/300", "eta": "2:14:21", "gpu_mem": "10.07G", "grad_norm": 6.75439, "loss": 0.14499, "lr": 0.0014353882, "top1_acc": 95.00000, "top1_err": 4.79167, "top5_acc": 99.79167, "top5_err": 0.36458}
[06/12 19:24:53][INFO] train_net.py:  708: Epoch 106 takes 48.31s. Epochs from 0 to 106 take 48.16s in average and 48.14s in median.
[06/12 19:24:53][INFO] train_net.py:  714: For epoch 106, each iteraction takes 0.81s in average. From epoch 0 to 106, each iteraction takes 0.80s in average.
[06/12 19:25:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47103, "dt_data": 0.00040, "dt_net": 0.47063, "epoch": "108/300", "eta": "1:30:49", "gpu_mem": "10.07G", "grad_norm": 7.43766, "iter": "10/60", "loss": 0.12828, "lr": 0.0014338163, "top1_acc": 96.87500, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:25:17][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47500, "dt_data": 0.00036, "dt_net": 0.47464, "epoch": "108/300", "eta": "1:31:30", "gpu_mem": "10.07G", "grad_norm": 2.97295, "iter": "20/60", "loss": 0.10399, "lr": 0.0014322431, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:25:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47467, "dt_data": 0.00054, "dt_net": 0.47413, "epoch": "108/300", "eta": "1:31:22", "gpu_mem": "10.07G", "grad_norm": 6.68061, "iter": "30/60", "loss": 0.12967, "lr": 0.0014306686, "top1_acc": 100.00000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:25:29][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48114, "dt_data": 0.00214, "dt_net": 0.47898, "epoch": "108/300", "eta": "1:32:32", "gpu_mem": "10.07G", "grad_norm": 3.04069, "iter": "40/60", "loss": 0.08735, "lr": 0.0014290928, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:25:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48663, "dt_data": 0.00070, "dt_net": 0.48592, "epoch": "108/300", "eta": "1:33:30", "gpu_mem": "10.07G", "grad_norm": 10.75620, "iter": "50/60", "loss": 0.10382, "lr": 0.0014275156, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:25:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46988, "dt_data": 0.00018, "dt_net": 0.46970, "epoch": "108/300", "eta": "1:30:12", "gpu_mem": "10.07G", "grad_norm": 7.14029, "iter": "60/60", "loss": 0.09483, "lr": 0.0014259372, "top1_acc": 93.75000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:25:41][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.69645, "dt_data": 0.69645, "dt_net": 0.46970, "epoch": "108/300", "eta": "2:13:42", "gpu_mem": "10.07G", "grad_norm": 7.14029, "loss": 0.12702, "lr": 0.0014259372, "top1_acc": 95.72917, "top1_err": 4.21875, "top5_acc": 99.89583, "top5_err": 0.20833}
[06/12 19:25:41][INFO] train_net.py:  708: Epoch 107 takes 48.10s. Epochs from 0 to 107 take 48.15s in average and 48.13s in median.
[06/12 19:25:41][INFO] train_net.py:  714: For epoch 107, each iteraction takes 0.80s in average. From epoch 0 to 107, each iteraction takes 0.80s in average.
[06/12 19:25:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47035, "dt_data": 0.00035, "dt_net": 0.47000, "epoch": "109/300", "eta": "1:30:13", "gpu_mem": "10.07G", "grad_norm": 3.04642, "iter": "10/60", "loss": 0.06463, "lr": 0.0014243575, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:26:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47488, "dt_data": 0.00045, "dt_net": 0.47443, "epoch": "109/300", "eta": "1:31:01", "gpu_mem": "10.07G", "grad_norm": 7.94785, "iter": "20/60", "loss": 0.09958, "lr": 0.0014227764, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:26:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46923, "dt_data": 0.00043, "dt_net": 0.46879, "epoch": "109/300", "eta": "1:29:51", "gpu_mem": "10.07G", "grad_norm": 2.33515, "iter": "30/60", "loss": 0.10463, "lr": 0.0014211941, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:26:17][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47276, "dt_data": 0.00053, "dt_net": 0.47223, "epoch": "109/300", "eta": "1:30:27", "gpu_mem": "10.07G", "grad_norm": 8.82664, "iter": "40/60", "loss": 0.12742, "lr": 0.0014196105, "top1_acc": 96.87500, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:26:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47346, "dt_data": 0.00048, "dt_net": 0.47297, "epoch": "109/300", "eta": "1:30:30", "gpu_mem": "10.07G", "grad_norm": 1.17750, "iter": "50/60", "loss": 0.10840, "lr": 0.0014180256, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:26:29][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46970, "dt_data": 0.00016, "dt_net": 0.46954, "epoch": "109/300", "eta": "1:29:42", "gpu_mem": "10.07G", "grad_norm": 1.55172, "iter": "60/60", "loss": 0.09650, "lr": 0.0014164395, "top1_acc": 96.87500, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:26:30][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.69985, "dt_data": 0.69985, "dt_net": 0.46954, "epoch": "109/300", "eta": "2:13:39", "gpu_mem": "10.07G", "grad_norm": 1.55172, "loss": 0.12122, "lr": 0.0014164395, "top1_acc": 96.04167, "top1_err": 3.64583, "top5_acc": 99.79167, "top5_err": 0.20833}
[06/12 19:26:30][INFO] train_net.py:  708: Epoch 108 takes 48.84s. Epochs from 0 to 108 take 48.16s in average and 48.14s in median.
[06/12 19:26:30][INFO] train_net.py:  714: For epoch 108, each iteraction takes 0.81s in average. From epoch 0 to 108, each iteraction takes 0.80s in average.
[06/12 19:26:47][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47397, "dt_data": 0.00046, "dt_net": 0.47351, "epoch": "110/300", "eta": "1:30:26", "gpu_mem": "10.07G", "grad_norm": 3.96654, "iter": "10/60", "loss": 0.06565, "lr": 0.0014148521, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:26:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47253, "dt_data": 0.00060, "dt_net": 0.47192, "epoch": "110/300", "eta": "1:30:05", "gpu_mem": "10.07G", "grad_norm": 5.22151, "iter": "20/60", "loss": 0.08672, "lr": 0.0014132634, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:27:00][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47189, "dt_data": 0.00040, "dt_net": 0.47148, "epoch": "110/300", "eta": "1:29:53", "gpu_mem": "10.07G", "grad_norm": 8.44425, "iter": "30/60", "loss": 0.09699, "lr": 0.0014116734, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:27:06][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47438, "dt_data": 0.00062, "dt_net": 0.47375, "epoch": "110/300", "eta": "1:30:17", "gpu_mem": "10.07G", "grad_norm": 12.20667, "iter": "40/60", "loss": 0.05175, "lr": 0.0014100822, "top1_acc": 96.87500, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:27:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47472, "dt_data": 0.00038, "dt_net": 0.47433, "epoch": "110/300", "eta": "1:30:16", "gpu_mem": "10.07G", "grad_norm": 1.40077, "iter": "50/60", "loss": 0.05278, "lr": 0.0014084898, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:27:18][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46989, "dt_data": 0.00017, "dt_net": 0.46972, "epoch": "110/300", "eta": "1:29:16", "gpu_mem": "10.07G", "grad_norm": 4.85310, "iter": "60/60", "loss": 0.11464, "lr": 0.0014068961, "top1_acc": 93.75000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:27:18][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.72074, "dt_data": 0.72074, "dt_net": 0.46972, "epoch": "110/300", "eta": "2:16:55", "gpu_mem": "10.07G", "grad_norm": 4.85310, "loss": 0.10910, "lr": 0.0014068961, "top1_acc": 95.72917, "top1_err": 3.90625, "top5_acc": 99.79167, "top5_err": 0.20833}
[06/12 19:27:18][INFO] train_net.py:  708: Epoch 109 takes 48.16s. Epochs from 0 to 109 take 48.16s in average and 48.14s in median.
[06/12 19:27:18][INFO] train_net.py:  714: For epoch 109, each iteraction takes 0.80s in average. From epoch 0 to 109, each iteraction takes 0.80s in average.
[06/12 19:27:18][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 19:28:20][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "110/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.12991, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 19:28:23][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "val_epoch", "epoch": "110/300", "gpu_mem": "10.07G", "min_top1_err": 22.82158, "min_top5_err": 2.90456, "time_diff": 0.61570, "top1_acc": 74.89627, "top1_err": 25.10373, "top5_acc": 95.85062, "top5_err": 4.14938}
[06/12 19:28:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47264, "dt_data": 0.00037, "dt_net": 0.47227, "epoch": "111/300", "eta": "1:29:43", "gpu_mem": "10.07G", "grad_norm": 8.78353, "iter": "10/60", "loss": 0.14205, "lr": 0.0014053011, "top1_acc": 93.75000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:28:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47981, "dt_data": 0.00048, "dt_net": 0.47934, "epoch": "111/300", "eta": "1:31:00", "gpu_mem": "10.07G", "grad_norm": 7.27953, "iter": "20/60", "loss": 0.17052, "lr": 0.0014037050, "top1_acc": 93.75000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:28:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.65711, "dt_data": 0.18914, "dt_net": 0.46796, "epoch": "111/300", "eta": "2:04:31", "gpu_mem": "10.07G", "grad_norm": 6.83329, "iter": "30/60", "loss": 0.14200, "lr": 0.0014021076, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:28:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47016, "dt_data": 0.00039, "dt_net": 0.46977, "epoch": "111/300", "eta": "1:29:00", "gpu_mem": "10.07G", "grad_norm": 4.87562, "iter": "40/60", "loss": 0.09630, "lr": 0.0014005090, "top1_acc": 93.75000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:29:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46936, "dt_data": 0.00046, "dt_net": 0.46890, "epoch": "111/300", "eta": "1:28:47", "gpu_mem": "10.07G", "grad_norm": 5.71338, "iter": "50/60", "loss": 0.09690, "lr": 0.0013989091, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:29:10][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46718, "dt_data": 0.00020, "dt_net": 0.46698, "epoch": "111/300", "eta": "1:28:17", "gpu_mem": "10.07G", "grad_norm": 4.57317, "iter": "60/60", "loss": 0.14303, "lr": 0.0013973081, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:29:11][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.69954, "dt_data": 0.69954, "dt_net": 0.46698, "epoch": "111/300", "eta": "2:12:12", "gpu_mem": "10.07G", "grad_norm": 4.57317, "loss": 0.12653, "lr": 0.0013973081, "top1_acc": 95.20833, "top1_err": 4.11458, "top5_acc": 99.68750, "top5_err": 0.26042}
[06/12 19:29:11][INFO] train_net.py:  708: Epoch 110 takes 47.87s. Epochs from 0 to 110 take 48.16s in average and 48.14s in median.
[06/12 19:29:11][INFO] train_net.py:  714: For epoch 110, each iteraction takes 0.80s in average. From epoch 0 to 110, each iteraction takes 0.80s in average.
[06/12 19:29:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.50269, "dt_data": 0.00034, "dt_net": 0.50235, "epoch": "112/300", "eta": "1:34:55", "gpu_mem": "10.07G", "grad_norm": 3.00440, "iter": "10/60", "loss": 0.09422, "lr": 0.0013957058, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:29:34][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47294, "dt_data": 0.00032, "dt_net": 0.47262, "epoch": "112/300", "eta": "1:29:13", "gpu_mem": "10.07G", "grad_norm": 7.59751, "iter": "20/60", "loss": 0.13320, "lr": 0.0013941023, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:29:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47255, "dt_data": 0.00072, "dt_net": 0.47183, "epoch": "112/300", "eta": "1:29:04", "gpu_mem": "10.07G", "grad_norm": 4.18053, "iter": "30/60", "loss": 0.17666, "lr": 0.0013924976, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:29:47][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47187, "dt_data": 0.00032, "dt_net": 0.47155, "epoch": "112/300", "eta": "1:28:52", "gpu_mem": "10.07G", "grad_norm": 10.85346, "iter": "40/60", "loss": 0.09131, "lr": 0.0013908918, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:29:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47364, "dt_data": 0.00036, "dt_net": 0.47328, "epoch": "112/300", "eta": "1:29:07", "gpu_mem": "10.07G", "grad_norm": 5.98403, "iter": "50/60", "loss": 0.07822, "lr": 0.0013892847, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:29:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46990, "dt_data": 0.00016, "dt_net": 0.46974, "epoch": "112/300", "eta": "1:28:20", "gpu_mem": "10.07G", "grad_norm": 6.64368, "iter": "60/60", "loss": 0.11771, "lr": 0.0013876765, "top1_acc": 93.75000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:29:59][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.69650, "dt_data": 0.69650, "dt_net": 0.46974, "epoch": "112/300", "eta": "2:10:56", "gpu_mem": "10.07G", "grad_norm": 6.64368, "loss": 0.13906, "lr": 0.0013876765, "top1_acc": 95.20833, "top1_err": 4.53125, "top5_acc": 99.68750, "top5_err": 0.36458}
[06/12 19:29:59][INFO] train_net.py:  708: Epoch 111 takes 47.80s. Epochs from 0 to 111 take 48.16s in average and 48.13s in median.
[06/12 19:29:59][INFO] train_net.py:  714: For epoch 111, each iteraction takes 0.80s in average. From epoch 0 to 111, each iteraction takes 0.80s in average.
[06/12 19:30:17][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47347, "dt_data": 0.00040, "dt_net": 0.47307, "epoch": "113/300", "eta": "1:28:55", "gpu_mem": "10.07G", "grad_norm": 1.97825, "iter": "10/60", "loss": 0.08266, "lr": 0.0013860670, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:30:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47584, "dt_data": 0.00058, "dt_net": 0.47526, "epoch": "113/300", "eta": "1:29:17", "gpu_mem": "10.07G", "grad_norm": 7.07231, "iter": "20/60", "loss": 0.06531, "lr": 0.0013844564, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:30:29][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47219, "dt_data": 0.00088, "dt_net": 0.47130, "epoch": "113/300", "eta": "1:28:32", "gpu_mem": "10.07G", "grad_norm": 3.50976, "iter": "30/60", "loss": 0.08627, "lr": 0.0013828447, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:30:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47587, "dt_data": 0.00049, "dt_net": 0.47537, "epoch": "113/300", "eta": "1:29:08", "gpu_mem": "10.07G", "grad_norm": 3.98886, "iter": "40/60", "loss": 0.11459, "lr": 0.0013812317, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:30:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47515, "dt_data": 0.00031, "dt_net": 0.47483, "epoch": "113/300", "eta": "1:28:55", "gpu_mem": "10.07G", "grad_norm": 7.53059, "iter": "50/60", "loss": 0.15227, "lr": 0.0013796176, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:30:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46946, "dt_data": 0.00016, "dt_net": 0.46930, "epoch": "113/300", "eta": "1:27:47", "gpu_mem": "10.07G", "grad_norm": 11.54425, "iter": "60/60", "loss": 0.08450, "lr": 0.0013780024, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:30:47][INFO] logging.py:  101: json_stats: {"RAM": "13.13/31.07G", "_type": "train_epoch", "dt": 0.70967, "dt_data": 0.70967, "dt_net": 0.46930, "epoch": "113/300", "eta": "2:12:42", "gpu_mem": "10.07G", "grad_norm": 11.54425, "loss": 0.11178, "lr": 0.0013780024, "top1_acc": 96.56250, "top1_err": 3.48958, "top5_acc": 100.00000, "top5_err": 0.20833}
[06/12 19:30:47][INFO] train_net.py:  708: Epoch 112 takes 48.14s. Epochs from 0 to 112 take 48.15s in average and 48.14s in median.
[06/12 19:30:47][INFO] train_net.py:  714: For epoch 112, each iteraction takes 0.80s in average. From epoch 0 to 112, each iteraction takes 0.80s in average.
[06/12 19:31:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47340, "dt_data": 0.00057, "dt_net": 0.47282, "epoch": "114/300", "eta": "1:28:26", "gpu_mem": "10.07G", "grad_norm": 3.31142, "iter": "10/60", "loss": 0.08651, "lr": 0.0013763860, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:31:10][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47253, "dt_data": 0.00065, "dt_net": 0.47187, "epoch": "114/300", "eta": "1:28:12", "gpu_mem": "10.07G", "grad_norm": 2.82249, "iter": "20/60", "loss": 0.11772, "lr": 0.0013747684, "top1_acc": 100.00000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:31:17][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47385, "dt_data": 0.00035, "dt_net": 0.47350, "epoch": "114/300", "eta": "1:28:22", "gpu_mem": "10.07G", "grad_norm": 8.90557, "iter": "30/60", "loss": 0.12330, "lr": 0.0013731497, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:31:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47545, "dt_data": 0.00069, "dt_net": 0.47476, "epoch": "114/300", "eta": "1:28:35", "gpu_mem": "10.07G", "grad_norm": 3.58869, "iter": "40/60", "loss": 0.12359, "lr": 0.0013715299, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:31:29][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47398, "dt_data": 0.00039, "dt_net": 0.47359, "epoch": "114/300", "eta": "1:28:14", "gpu_mem": "10.07G", "grad_norm": 4.21432, "iter": "50/60", "loss": 0.09031, "lr": 0.0013699089, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:31:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46913, "dt_data": 0.00016, "dt_net": 0.46897, "epoch": "114/300", "eta": "1:27:15", "gpu_mem": "10.07G", "grad_norm": 0.99712, "iter": "60/60", "loss": 0.11453, "lr": 0.0013682868, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:31:36][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.71383, "dt_data": 0.71383, "dt_net": 0.46897, "epoch": "114/300", "eta": "2:12:45", "gpu_mem": "10.07G", "grad_norm": 0.99712, "loss": 0.11438, "lr": 0.0013682868, "top1_acc": 96.77083, "top1_err": 3.59375, "top5_acc": 99.68750, "top5_err": 0.15625}
[06/12 19:31:36][INFO] train_net.py:  708: Epoch 113 takes 48.64s. Epochs from 0 to 113 take 48.16s in average and 48.14s in median.
[06/12 19:31:36][INFO] train_net.py:  714: For epoch 113, each iteraction takes 0.81s in average. From epoch 0 to 113, each iteraction takes 0.80s in average.
[06/12 19:31:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47217, "dt_data": 0.00040, "dt_net": 0.47177, "epoch": "115/300", "eta": "1:27:44", "gpu_mem": "10.07G", "grad_norm": 6.82213, "iter": "10/60", "loss": 0.16341, "lr": 0.0013666636, "top1_acc": 96.87500, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:31:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47356, "dt_data": 0.00035, "dt_net": 0.47321, "epoch": "115/300", "eta": "1:27:55", "gpu_mem": "10.07G", "grad_norm": 4.08147, "iter": "20/60", "loss": 0.07129, "lr": 0.0013650393, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:32:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47421, "dt_data": 0.00033, "dt_net": 0.47388, "epoch": "115/300", "eta": "1:27:57", "gpu_mem": "10.07G", "grad_norm": 9.92504, "iter": "30/60", "loss": 0.08426, "lr": 0.0013634138, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:32:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48896, "dt_data": 0.00090, "dt_net": 0.48805, "epoch": "115/300", "eta": "1:30:37", "gpu_mem": "10.07G", "grad_norm": 5.73188, "iter": "40/60", "loss": 0.14315, "lr": 0.0013617873, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:32:17][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47700, "dt_data": 0.00040, "dt_net": 0.47660, "epoch": "115/300", "eta": "1:28:19", "gpu_mem": "10.07G", "grad_norm": 5.81877, "iter": "50/60", "loss": 0.10344, "lr": 0.0013601596, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:32:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47053, "dt_data": 0.00019, "dt_net": 0.47033, "epoch": "115/300", "eta": "1:27:02", "gpu_mem": "10.07G", "grad_norm": 13.56879, "iter": "60/60", "loss": 0.11789, "lr": 0.0013585309, "top1_acc": 100.00000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:32:24][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.70314, "dt_data": 0.70314, "dt_net": 0.47033, "epoch": "115/300", "eta": "2:10:04", "gpu_mem": "10.07G", "grad_norm": 13.56879, "loss": 0.13545, "lr": 0.0013585309, "top1_acc": 97.18750, "top1_err": 3.85417, "top5_acc": 99.68750, "top5_err": 0.26042}
[06/12 19:32:24][INFO] train_net.py:  708: Epoch 114 takes 47.88s. Epochs from 0 to 114 take 48.16s in average and 48.14s in median.
[06/12 19:32:24][INFO] train_net.py:  714: For epoch 114, each iteraction takes 0.80s in average. From epoch 0 to 114, each iteraction takes 0.80s in average.
[06/12 19:32:24][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 19:33:25][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "115/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.12986, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 19:33:28][INFO] logging.py:  101: json_stats: {"RAM": "13.26/31.07G", "_type": "val_epoch", "epoch": "115/300", "gpu_mem": "10.07G", "min_top1_err": 22.82158, "min_top5_err": 2.69710, "time_diff": 0.60830, "top1_acc": 74.68880, "top1_err": 25.31120, "top5_acc": 97.30290, "top5_err": 2.69710}
[06/12 19:33:45][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46754, "dt_data": 0.00038, "dt_net": 0.46715, "epoch": "116/300", "eta": "1:26:24", "gpu_mem": "10.07G", "grad_norm": 6.10954, "iter": "10/60", "loss": 0.16143, "lr": 0.0013569010, "top1_acc": 93.75000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:33:51][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46871, "dt_data": 0.00066, "dt_net": 0.46804, "epoch": "116/300", "eta": "1:26:33", "gpu_mem": "10.07G", "grad_norm": 0.52835, "iter": "20/60", "loss": 0.05970, "lr": 0.0013552701, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:33:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46616, "dt_data": 0.00048, "dt_net": 0.46568, "epoch": "116/300", "eta": "1:26:00", "gpu_mem": "10.07G", "grad_norm": 7.76884, "iter": "30/60", "loss": 0.11791, "lr": 0.0013536381, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:34:03][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48358, "dt_data": 0.00049, "dt_net": 0.48309, "epoch": "116/300", "eta": "1:29:08", "gpu_mem": "10.07G", "grad_norm": 5.03727, "iter": "40/60", "loss": 0.10440, "lr": 0.0013520050, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:34:09][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47067, "dt_data": 0.00048, "dt_net": 0.47019, "epoch": "116/300", "eta": "1:26:40", "gpu_mem": "10.07G", "grad_norm": 6.81771, "iter": "50/60", "loss": 0.08750, "lr": 0.0013503709, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:34:15][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46728, "dt_data": 0.00019, "dt_net": 0.46709, "epoch": "116/300", "eta": "1:25:58", "gpu_mem": "10.07G", "grad_norm": 4.41132, "iter": "60/60", "loss": 0.13931, "lr": 0.0013487356, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:34:15][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.68563, "dt_data": 0.68563, "dt_net": 0.46709, "epoch": "116/300", "eta": "2:06:08", "gpu_mem": "10.07G", "grad_norm": 4.41132, "loss": 0.12907, "lr": 0.0013487356, "top1_acc": 95.41667, "top1_err": 4.06250, "top5_acc": 99.79167, "top5_err": 0.20833}
[06/12 19:34:15][INFO] train_net.py:  708: Epoch 115 takes 47.17s. Epochs from 0 to 115 take 48.15s in average and 48.13s in median.
[06/12 19:34:15][INFO] train_net.py:  714: For epoch 115, each iteraction takes 0.79s in average. From epoch 0 to 115, each iteraction takes 0.80s in average.
[06/12 19:34:32][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47189, "dt_data": 0.00058, "dt_net": 0.47130, "epoch": "117/300", "eta": "1:26:44", "gpu_mem": "10.07G", "grad_norm": 3.83338, "iter": "10/60", "loss": 0.13257, "lr": 0.0013470993, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:34:38][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47214, "dt_data": 0.00067, "dt_net": 0.47146, "epoch": "117/300", "eta": "1:26:42", "gpu_mem": "10.07G", "grad_norm": 4.23585, "iter": "20/60", "loss": 0.10932, "lr": 0.0013454620, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:34:44][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.08243, "dt_data": 0.00055, "dt_net": 1.08189, "epoch": "117/300", "eta": "3:18:37", "gpu_mem": "10.07G", "grad_norm": 8.78176, "iter": "30/60", "loss": 0.07749, "lr": 0.0013438236, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:34:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47298, "dt_data": 0.00033, "dt_net": 0.47265, "epoch": "117/300", "eta": "1:26:42", "gpu_mem": "10.07G", "grad_norm": 3.04655, "iter": "40/60", "loss": 0.07548, "lr": 0.0013421841, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:34:56][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47467, "dt_data": 0.00053, "dt_net": 0.47413, "epoch": "117/300", "eta": "1:26:56", "gpu_mem": "10.07G", "grad_norm": 10.27425, "iter": "50/60", "loss": 0.13680, "lr": 0.0013405437, "top1_acc": 93.75000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:35:02][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46787, "dt_data": 0.00016, "dt_net": 0.46771, "epoch": "117/300", "eta": "1:25:37", "gpu_mem": "10.07G", "grad_norm": 7.98822, "iter": "60/60", "loss": 0.10108, "lr": 0.0013389021, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:35:03][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.69509, "dt_data": 0.69509, "dt_net": 0.46771, "epoch": "117/300", "eta": "2:07:10", "gpu_mem": "10.07G", "grad_norm": 7.98822, "loss": 0.11713, "lr": 0.0013389021, "top1_acc": 96.35417, "top1_err": 3.80208, "top5_acc": 99.68750, "top5_err": 0.36458}
[06/12 19:35:03][INFO] train_net.py:  708: Epoch 116 takes 47.48s. Epochs from 0 to 116 take 48.14s in average and 48.13s in median.
[06/12 19:35:03][INFO] train_net.py:  714: For epoch 116, each iteraction takes 0.79s in average. From epoch 0 to 116, each iteraction takes 0.80s in average.
[06/12 19:35:20][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.56651, "dt_data": 0.09761, "dt_net": 0.46890, "epoch": "118/300", "eta": "1:43:34", "gpu_mem": "10.07G", "grad_norm": 9.95417, "iter": "10/60", "loss": 0.10521, "lr": 0.0013372596, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:35:26][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47416, "dt_data": 0.00050, "dt_net": 0.47365, "epoch": "118/300", "eta": "1:26:36", "gpu_mem": "10.07G", "grad_norm": 5.02041, "iter": "20/60", "loss": 0.09769, "lr": 0.0013356160, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:35:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.54910, "dt_data": 0.07899, "dt_net": 0.47011, "epoch": "118/300", "eta": "1:40:12", "gpu_mem": "10.07G", "grad_norm": 4.62157, "iter": "30/60", "loss": 0.10789, "lr": 0.0013339714, "top1_acc": 93.75000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:35:39][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47523, "dt_data": 0.00056, "dt_net": 0.47466, "epoch": "118/300", "eta": "1:26:38", "gpu_mem": "10.07G", "grad_norm": 2.06365, "iter": "40/60", "loss": 0.06405, "lr": 0.0013323258, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:35:45][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47592, "dt_data": 0.00110, "dt_net": 0.47478, "epoch": "118/300", "eta": "1:26:41", "gpu_mem": "10.07G", "grad_norm": 10.26454, "iter": "50/60", "loss": 0.10004, "lr": 0.0013306791, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:35:51][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47007, "dt_data": 0.00016, "dt_net": 0.46991, "epoch": "118/300", "eta": "1:25:33", "gpu_mem": "10.07G", "grad_norm": 3.40100, "iter": "60/60", "loss": 0.08529, "lr": 0.0013290315, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:35:51][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.70053, "dt_data": 0.70053, "dt_net": 0.46991, "epoch": "118/300", "eta": "2:07:29", "gpu_mem": "10.07G", "grad_norm": 3.40100, "loss": 0.10750, "lr": 0.0013290315, "top1_acc": 96.35417, "top1_err": 3.48958, "top5_acc": 99.79167, "top5_err": 0.10417}
[06/12 19:35:51][INFO] train_net.py:  708: Epoch 117 takes 48.48s. Epochs from 0 to 117 take 48.15s in average and 48.13s in median.
[06/12 19:35:51][INFO] train_net.py:  714: For epoch 117, each iteraction takes 0.81s in average. From epoch 0 to 117, each iteraction takes 0.80s in average.
[06/12 19:36:09][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47768, "dt_data": 0.00035, "dt_net": 0.47733, "epoch": "119/300", "eta": "1:26:51", "gpu_mem": "10.07G", "grad_norm": 7.22613, "iter": "10/60", "loss": 0.15148, "lr": 0.0013273828, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:36:15][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47128, "dt_data": 0.00100, "dt_net": 0.47027, "epoch": "119/300", "eta": "1:25:36", "gpu_mem": "10.07G", "grad_norm": 1.12401, "iter": "20/60", "loss": 0.07777, "lr": 0.0013257332, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:36:21][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47401, "dt_data": 0.00042, "dt_net": 0.47358, "epoch": "119/300", "eta": "1:26:01", "gpu_mem": "10.07G", "grad_norm": 3.22984, "iter": "30/60", "loss": 0.05384, "lr": 0.0013240825, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:36:26][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.58779, "dt_data": 0.11451, "dt_net": 0.47327, "epoch": "119/300", "eta": "1:46:35", "gpu_mem": "10.07G", "grad_norm": 7.28938, "iter": "40/60", "loss": 0.16895, "lr": 0.0013224309, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:36:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47984, "dt_data": 0.00072, "dt_net": 0.47911, "epoch": "119/300", "eta": "1:26:55", "gpu_mem": "10.07G", "grad_norm": 3.79517, "iter": "50/60", "loss": 0.06028, "lr": 0.0013207783, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:36:38][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.60579, "dt_data": 0.13629, "dt_net": 0.46950, "epoch": "119/300", "eta": "1:49:38", "gpu_mem": "10.07G", "grad_norm": 6.24384, "iter": "60/60", "loss": 0.06665, "lr": 0.0013191247, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:36:38][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.70461, "dt_data": 0.70461, "dt_net": 0.46950, "epoch": "119/300", "eta": "2:07:31", "gpu_mem": "10.07G", "grad_norm": 6.24384, "loss": 0.10070, "lr": 0.0013191247, "top1_acc": 96.87500, "top1_err": 3.38542, "top5_acc": 99.89583, "top5_err": 0.20833}
[06/12 19:36:38][INFO] train_net.py:  708: Epoch 118 takes 47.25s. Epochs from 0 to 118 take 48.14s in average and 48.13s in median.
[06/12 19:36:38][INFO] train_net.py:  714: For epoch 118, each iteraction takes 0.79s in average. From epoch 0 to 118, each iteraction takes 0.80s in average.
[06/12 19:36:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46838, "dt_data": 0.00050, "dt_net": 0.46788, "epoch": "120/300", "eta": "1:24:41", "gpu_mem": "10.07G", "grad_norm": 7.68706, "iter": "10/60", "loss": 0.16654, "lr": 0.0013174702, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:37:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47382, "dt_data": 0.00073, "dt_net": 0.47308, "epoch": "120/300", "eta": "1:25:36", "gpu_mem": "10.07G", "grad_norm": 1.54613, "iter": "20/60", "loss": 0.07469, "lr": 0.0013158146, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:37:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47165, "dt_data": 0.00036, "dt_net": 0.47129, "epoch": "120/300", "eta": "1:25:07", "gpu_mem": "10.07G", "grad_norm": 4.08544, "iter": "30/60", "loss": 0.06865, "lr": 0.0013141582, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:37:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47515, "dt_data": 0.00036, "dt_net": 0.47479, "epoch": "120/300", "eta": "1:25:41", "gpu_mem": "10.07G", "grad_norm": 3.75522, "iter": "40/60", "loss": 0.09317, "lr": 0.0013125007, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:37:20][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48077, "dt_data": 0.00051, "dt_net": 0.48026, "epoch": "120/300", "eta": "1:26:37", "gpu_mem": "10.07G", "grad_norm": 4.47057, "iter": "50/60", "loss": 0.12853, "lr": 0.0013108423, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:37:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46971, "dt_data": 0.00018, "dt_net": 0.46953, "epoch": "120/300", "eta": "1:24:32", "gpu_mem": "10.07G", "grad_norm": 6.20523, "iter": "60/60", "loss": 0.11333, "lr": 0.0013091830, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:37:26][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.70284, "dt_data": 0.70284, "dt_net": 0.46953, "epoch": "120/300", "eta": "2:06:30", "gpu_mem": "10.07G", "grad_norm": 6.20523, "loss": 0.11965, "lr": 0.0013091830, "top1_acc": 96.35417, "top1_err": 3.38542, "top5_acc": 99.68750, "top5_err": 0.36458}
[06/12 19:37:26][INFO] train_net.py:  708: Epoch 119 takes 47.54s. Epochs from 0 to 119 take 48.13s in average and 48.12s in median.
[06/12 19:37:26][INFO] train_net.py:  714: For epoch 119, each iteraction takes 0.79s in average. From epoch 0 to 119, each iteraction takes 0.80s in average.
[06/12 19:37:26][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 19:38:27][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "120/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.12952, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 19:38:30][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "val_epoch", "epoch": "120/300", "gpu_mem": "10.07G", "min_top1_err": 22.82158, "min_top5_err": 2.69710, "time_diff": 0.61409, "top1_acc": 74.48133, "top1_err": 25.51867, "top5_acc": 95.64315, "top5_err": 4.35685}
[06/12 19:38:48][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46478, "dt_data": 0.00031, "dt_net": 0.46447, "epoch": "121/300", "eta": "1:23:34", "gpu_mem": "10.07G", "grad_norm": 2.99408, "iter": "10/60", "loss": 0.10510, "lr": 0.0013075227, "top1_acc": 100.00000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:38:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46742, "dt_data": 0.00032, "dt_net": 0.46710, "epoch": "121/300", "eta": "1:23:58", "gpu_mem": "10.07G", "grad_norm": 5.25331, "iter": "20/60", "loss": 0.08013, "lr": 0.0013058615, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:39:00][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47071, "dt_data": 0.00042, "dt_net": 0.47029, "epoch": "121/300", "eta": "1:24:29", "gpu_mem": "10.07G", "grad_norm": 4.91282, "iter": "30/60", "loss": 0.12576, "lr": 0.0013041993, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:39:06][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47285, "dt_data": 0.00056, "dt_net": 0.47229, "epoch": "121/300", "eta": "1:24:47", "gpu_mem": "10.07G", "grad_norm": 4.18321, "iter": "40/60", "loss": 0.10169, "lr": 0.0013025362, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:39:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47524, "dt_data": 0.00094, "dt_net": 0.47430, "epoch": "121/300", "eta": "1:25:08", "gpu_mem": "10.07G", "grad_norm": 1.72729, "iter": "50/60", "loss": 0.05884, "lr": 0.0013008722, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:39:17][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46566, "dt_data": 0.00017, "dt_net": 0.46549, "epoch": "121/300", "eta": "1:23:21", "gpu_mem": "10.07G", "grad_norm": 3.94296, "iter": "60/60", "loss": 0.05983, "lr": 0.0012992073, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:39:17][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.69225, "dt_data": 0.69225, "dt_net": 0.46549, "epoch": "121/300", "eta": "2:03:54", "gpu_mem": "10.07G", "grad_norm": 3.94296, "loss": 0.10046, "lr": 0.0012992073, "top1_acc": 97.60417, "top1_err": 3.12500, "top5_acc": 99.89583, "top5_err": 0.26042}
[06/12 19:39:17][INFO] train_net.py:  708: Epoch 120 takes 46.83s. Epochs from 0 to 120 take 48.12s in average and 48.12s in median.
[06/12 19:39:17][INFO] train_net.py:  714: For epoch 120, each iteraction takes 0.78s in average. From epoch 0 to 120, each iteraction takes 0.80s in average.
[06/12 19:39:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46732, "dt_data": 0.00058, "dt_net": 0.46674, "epoch": "122/300", "eta": "1:23:34", "gpu_mem": "10.07G", "grad_norm": 3.10440, "iter": "10/60", "loss": 0.04804, "lr": 0.0012975415, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:39:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47132, "dt_data": 0.00033, "dt_net": 0.47099, "epoch": "122/300", "eta": "1:24:12", "gpu_mem": "10.07G", "grad_norm": 3.21690, "iter": "20/60", "loss": 0.08008, "lr": 0.0012958748, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:39:47][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.52814, "dt_data": 0.06079, "dt_net": 0.46735, "epoch": "122/300", "eta": "1:34:16", "gpu_mem": "10.07G", "grad_norm": 9.46048, "iter": "30/60", "loss": 0.11049, "lr": 0.0012942071, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:39:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47737, "dt_data": 0.00038, "dt_net": 0.47699, "epoch": "122/300", "eta": "1:25:07", "gpu_mem": "10.07G", "grad_norm": 4.79625, "iter": "40/60", "loss": 0.13643, "lr": 0.0012925386, "top1_acc": 96.87500, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:39:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.75403, "dt_data": 0.28330, "dt_net": 0.47072, "epoch": "122/300", "eta": "2:14:20", "gpu_mem": "10.07G", "grad_norm": 2.36486, "iter": "50/60", "loss": 0.06084, "lr": 0.0012908692, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:40:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47162, "dt_data": 0.00016, "dt_net": 0.47146, "epoch": "122/300", "eta": "1:23:56", "gpu_mem": "10.07G", "grad_norm": 10.35107, "iter": "60/60", "loss": 0.13192, "lr": 0.0012891989, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:40:05][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.70467, "dt_data": 0.70467, "dt_net": 0.47146, "epoch": "122/300", "eta": "2:05:25", "gpu_mem": "10.07G", "grad_norm": 10.35107, "loss": 0.11497, "lr": 0.0012891989, "top1_acc": 96.45833, "top1_err": 3.90625, "top5_acc": 99.79167, "top5_err": 0.20833}
[06/12 19:40:05][INFO] train_net.py:  708: Epoch 121 takes 48.03s. Epochs from 0 to 121 take 48.12s in average and 48.11s in median.
[06/12 19:40:05][INFO] train_net.py:  714: For epoch 121, each iteraction takes 0.80s in average. From epoch 0 to 121, each iteraction takes 0.80s in average.
[06/12 19:40:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.74981, "dt_data": 0.00040, "dt_net": 0.74941, "epoch": "123/300", "eta": "2:13:20", "gpu_mem": "10.07G", "grad_norm": 7.32872, "iter": "10/60", "loss": 0.07578, "lr": 0.0012875277, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:40:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48316, "dt_data": 0.00048, "dt_net": 0.48267, "epoch": "123/300", "eta": "1:25:50", "gpu_mem": "10.07G", "grad_norm": 3.76742, "iter": "20/60", "loss": 0.07687, "lr": 0.0012858556, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:40:34][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47103, "dt_data": 0.00038, "dt_net": 0.47065, "epoch": "123/300", "eta": "1:23:36", "gpu_mem": "10.07G", "grad_norm": 3.34242, "iter": "30/60", "loss": 0.08208, "lr": 0.0012841827, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:40:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47314, "dt_data": 0.00039, "dt_net": 0.47275, "epoch": "123/300", "eta": "1:23:54", "gpu_mem": "10.07G", "grad_norm": 6.13978, "iter": "40/60", "loss": 0.11524, "lr": 0.0012825089, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:40:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.49674, "dt_data": 0.00044, "dt_net": 0.49629, "epoch": "123/300", "eta": "1:28:00", "gpu_mem": "10.07G", "grad_norm": 4.41056, "iter": "50/60", "loss": 0.05879, "lr": 0.0012808342, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:40:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46843, "dt_data": 0.00016, "dt_net": 0.46826, "epoch": "123/300", "eta": "1:22:54", "gpu_mem": "10.07G", "grad_norm": 5.43643, "iter": "60/60", "loss": 0.09477, "lr": 0.0012791587, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:40:53][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.70537, "dt_data": 0.70537, "dt_net": 0.46826, "epoch": "123/300", "eta": "2:04:50", "gpu_mem": "10.07G", "grad_norm": 5.43643, "loss": 0.10134, "lr": 0.0012791587, "top1_acc": 97.08333, "top1_err": 2.91667, "top5_acc": 99.89583, "top5_err": 0.20833}
[06/12 19:40:53][INFO] train_net.py:  708: Epoch 122 takes 47.40s. Epochs from 0 to 122 take 48.12s in average and 48.10s in median.
[06/12 19:40:53][INFO] train_net.py:  714: For epoch 122, each iteraction takes 0.79s in average. From epoch 0 to 122, each iteraction takes 0.80s in average.
[06/12 19:41:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47849, "dt_data": 0.00042, "dt_net": 0.47807, "epoch": "124/300", "eta": "1:24:36", "gpu_mem": "10.07G", "grad_norm": 2.16127, "iter": "10/60", "loss": 0.04351, "lr": 0.0012774823, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:41:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47769, "dt_data": 0.00061, "dt_net": 0.47707, "epoch": "124/300", "eta": "1:24:23", "gpu_mem": "10.07G", "grad_norm": 5.54713, "iter": "20/60", "loss": 0.07932, "lr": 0.0012758051, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:41:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.98863, "dt_data": 0.51785, "dt_net": 0.47077, "epoch": "124/300", "eta": "2:54:29", "gpu_mem": "10.07G", "grad_norm": 9.31705, "iter": "30/60", "loss": 0.11209, "lr": 0.0012741271, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:41:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47660, "dt_data": 0.00035, "dt_net": 0.47625, "epoch": "124/300", "eta": "1:24:02", "gpu_mem": "10.07G", "grad_norm": 3.50353, "iter": "40/60", "loss": 0.09759, "lr": 0.0012724482, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:41:34][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47460, "dt_data": 0.00068, "dt_net": 0.47391, "epoch": "124/300", "eta": "1:23:36", "gpu_mem": "10.07G", "grad_norm": 10.82444, "iter": "50/60", "loss": 0.06530, "lr": 0.0012707685, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:41:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47284, "dt_data": 0.00016, "dt_net": 0.47268, "epoch": "124/300", "eta": "1:23:13", "gpu_mem": "10.07G", "grad_norm": 0.87289, "iter": "60/60", "loss": 0.10190, "lr": 0.0012690879, "top1_acc": 96.87500, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:41:41][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.68987, "dt_data": 0.68987, "dt_net": 0.47268, "epoch": "124/300", "eta": "2:01:24", "gpu_mem": "10.07G", "grad_norm": 0.87289, "loss": 0.10644, "lr": 0.0012690879, "top1_acc": 95.93750, "top1_err": 3.69792, "top5_acc": 99.79167, "top5_err": 0.15625}
[06/12 19:41:41][INFO] train_net.py:  708: Epoch 123 takes 47.90s. Epochs from 0 to 123 take 48.11s in average and 48.10s in median.
[06/12 19:41:41][INFO] train_net.py:  714: For epoch 123, each iteraction takes 0.80s in average. From epoch 0 to 123, each iteraction takes 0.80s in average.
[06/12 19:41:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47515, "dt_data": 0.00083, "dt_net": 0.47432, "epoch": "125/300", "eta": "1:23:32", "gpu_mem": "10.07G", "grad_norm": 5.01654, "iter": "10/60", "loss": 0.06929, "lr": 0.0012674066, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:42:03][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47263, "dt_data": 0.00057, "dt_net": 0.47206, "epoch": "125/300", "eta": "1:23:01", "gpu_mem": "10.07G", "grad_norm": 4.98712, "iter": "20/60", "loss": 0.16844, "lr": 0.0012657244, "top1_acc": 93.75000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:42:10][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47440, "dt_data": 0.00032, "dt_net": 0.47408, "epoch": "125/300", "eta": "1:23:15", "gpu_mem": "10.07G", "grad_norm": 4.03923, "iter": "30/60", "loss": 0.17988, "lr": 0.0012640414, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:42:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47633, "dt_data": 0.00051, "dt_net": 0.47582, "epoch": "125/300", "eta": "1:23:30", "gpu_mem": "10.07G", "grad_norm": 2.75203, "iter": "40/60", "loss": 0.08981, "lr": 0.0012623576, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:42:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47480, "dt_data": 0.00050, "dt_net": 0.47430, "epoch": "125/300", "eta": "1:23:10", "gpu_mem": "10.07G", "grad_norm": 10.79354, "iter": "50/60", "loss": 0.13471, "lr": 0.0012606730, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:42:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47126, "dt_data": 0.00019, "dt_net": 0.47107, "epoch": "125/300", "eta": "1:22:28", "gpu_mem": "10.07G", "grad_norm": 0.62702, "iter": "60/60", "loss": 0.06588, "lr": 0.0012589876, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:42:29][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.70972, "dt_data": 0.70972, "dt_net": 0.47107, "epoch": "125/300", "eta": "2:04:11", "gpu_mem": "10.07G", "grad_norm": 0.62702, "loss": 0.11641, "lr": 0.0012589876, "top1_acc": 96.56250, "top1_err": 3.43750, "top5_acc": 99.79167, "top5_err": 0.10417}
[06/12 19:42:29][INFO] train_net.py:  708: Epoch 124 takes 48.12s. Epochs from 0 to 124 take 48.11s in average and 48.10s in median.
[06/12 19:42:29][INFO] train_net.py:  714: For epoch 124, each iteraction takes 0.80s in average. From epoch 0 to 124, each iteraction takes 0.80s in average.
[06/12 19:42:29][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 19:43:30][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "125/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.12976, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 19:43:33][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "val_epoch", "epoch": "125/300", "gpu_mem": "10.07G", "min_top1_err": 22.82158, "min_top5_err": 2.69710, "time_diff": 0.59617, "top1_acc": 74.48133, "top1_err": 25.51867, "top5_acc": 95.85062, "top5_err": 4.14938}
[06/12 19:43:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46417, "dt_data": 0.00033, "dt_net": 0.46385, "epoch": "126/300", "eta": "1:21:09", "gpu_mem": "10.07G", "grad_norm": 7.30031, "iter": "10/60", "loss": 0.09265, "lr": 0.0012573015, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:43:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47038, "dt_data": 0.00051, "dt_net": 0.46986, "epoch": "126/300", "eta": "1:22:09", "gpu_mem": "10.07G", "grad_norm": 4.19733, "iter": "20/60", "loss": 0.08920, "lr": 0.0012556145, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:44:02][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46920, "dt_data": 0.00042, "dt_net": 0.46878, "epoch": "126/300", "eta": "1:21:52", "gpu_mem": "10.07G", "grad_norm": 2.28748, "iter": "30/60", "loss": 0.12580, "lr": 0.0012539268, "top1_acc": 96.87500, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:44:08][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47083, "dt_data": 0.00071, "dt_net": 0.47011, "epoch": "126/300", "eta": "1:22:04", "gpu_mem": "10.07G", "grad_norm": 8.50346, "iter": "40/60", "loss": 0.11030, "lr": 0.0012522383, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:44:15][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47291, "dt_data": 0.00031, "dt_net": 0.47261, "epoch": "126/300", "eta": "1:22:21", "gpu_mem": "10.07G", "grad_norm": 5.47764, "iter": "50/60", "loss": 0.11389, "lr": 0.0012505490, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:44:20][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46732, "dt_data": 0.00016, "dt_net": 0.46715, "epoch": "126/300", "eta": "1:21:18", "gpu_mem": "10.07G", "grad_norm": 4.99728, "iter": "60/60", "loss": 0.07448, "lr": 0.0012488589, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:44:21][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.69880, "dt_data": 0.69880, "dt_net": 0.46715, "epoch": "126/300", "eta": "2:01:34", "gpu_mem": "10.07G", "grad_norm": 4.99728, "loss": 0.11579, "lr": 0.0012488589, "top1_acc": 96.35417, "top1_err": 3.64583, "top5_acc": 99.89583, "top5_err": 0.31250}
[06/12 19:44:21][INFO] train_net.py:  708: Epoch 125 takes 47.82s. Epochs from 0 to 125 take 48.11s in average and 48.10s in median.
[06/12 19:44:21][INFO] train_net.py:  714: For epoch 125, each iteraction takes 0.80s in average. From epoch 0 to 125, each iteraction takes 0.80s in average.
[06/12 19:44:38][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46820, "dt_data": 0.00040, "dt_net": 0.46780, "epoch": "127/300", "eta": "1:21:23", "gpu_mem": "10.07G", "grad_norm": 5.93528, "iter": "10/60", "loss": 0.08571, "lr": 0.0012471681, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:44:44][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47028, "dt_data": 0.00035, "dt_net": 0.46993, "epoch": "127/300", "eta": "1:21:40", "gpu_mem": "10.07G", "grad_norm": 7.61978, "iter": "20/60", "loss": 0.10026, "lr": 0.0012454766, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:44:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47528, "dt_data": 0.00044, "dt_net": 0.47484, "epoch": "127/300", "eta": "1:22:27", "gpu_mem": "10.07G", "grad_norm": 2.80429, "iter": "30/60", "loss": 0.08358, "lr": 0.0012437843, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:44:56][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47342, "dt_data": 0.00059, "dt_net": 0.47282, "epoch": "127/300", "eta": "1:22:03", "gpu_mem": "10.07G", "grad_norm": 1.99349, "iter": "40/60", "loss": 0.03164, "lr": 0.0012420912, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:45:03][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47132, "dt_data": 0.00038, "dt_net": 0.47094, "epoch": "127/300", "eta": "1:21:36", "gpu_mem": "10.07G", "grad_norm": 2.76855, "iter": "50/60", "loss": 0.06510, "lr": 0.0012403975, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:45:08][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46830, "dt_data": 0.00020, "dt_net": 0.46810, "epoch": "127/300", "eta": "1:21:00", "gpu_mem": "10.07G", "grad_norm": 6.59166, "iter": "60/60", "loss": 0.06535, "lr": 0.0012387029, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:45:09][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.71738, "dt_data": 0.71738, "dt_net": 0.46810, "epoch": "127/300", "eta": "2:04:05", "gpu_mem": "10.07G", "grad_norm": 6.59166, "loss": 0.08815, "lr": 0.0012387029, "top1_acc": 96.56250, "top1_err": 3.28125, "top5_acc": 100.00000, "top5_err": 0.05208}
[06/12 19:45:09][INFO] train_net.py:  708: Epoch 126 takes 48.08s. Epochs from 0 to 126 take 48.11s in average and 48.09s in median.
[06/12 19:45:09][INFO] train_net.py:  714: For epoch 126, each iteraction takes 0.80s in average. From epoch 0 to 126, each iteraction takes 0.80s in average.
[06/12 19:45:26][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47509, "dt_data": 0.00048, "dt_net": 0.47460, "epoch": "128/300", "eta": "1:22:06", "gpu_mem": "10.07G", "grad_norm": 0.98001, "iter": "10/60", "loss": 0.04311, "lr": 0.0012370077, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:45:32][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47135, "dt_data": 0.00028, "dt_net": 0.47107, "epoch": "128/300", "eta": "1:21:23", "gpu_mem": "10.07G", "grad_norm": 4.76387, "iter": "20/60", "loss": 0.10510, "lr": 0.0012353117, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:45:38][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47469, "dt_data": 0.00030, "dt_net": 0.47439, "epoch": "128/300", "eta": "1:21:53", "gpu_mem": "10.07G", "grad_norm": 3.35528, "iter": "30/60", "loss": 0.06003, "lr": 0.0012336151, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:45:44][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47317, "dt_data": 0.00049, "dt_net": 0.47268, "epoch": "128/300", "eta": "1:21:32", "gpu_mem": "10.07G", "grad_norm": 3.43981, "iter": "40/60", "loss": 0.09515, "lr": 0.0012319177, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:45:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47370, "dt_data": 0.00063, "dt_net": 0.47307, "epoch": "128/300", "eta": "1:21:33", "gpu_mem": "10.07G", "grad_norm": 2.70331, "iter": "50/60", "loss": 0.04888, "lr": 0.0012302196, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:45:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47096, "dt_data": 0.00016, "dt_net": 0.47079, "epoch": "128/300", "eta": "1:21:00", "gpu_mem": "10.07G", "grad_norm": 3.61469, "iter": "60/60", "loss": 0.06161, "lr": 0.0012285208, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:45:57][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.69382, "dt_data": 0.69382, "dt_net": 0.47079, "epoch": "128/300", "eta": "1:59:19", "gpu_mem": "10.07G", "grad_norm": 3.61469, "loss": 0.08388, "lr": 0.0012285208, "top1_acc": 97.60417, "top1_err": 2.55208, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:45:57][INFO] train_net.py:  708: Epoch 127 takes 48.39s. Epochs from 0 to 127 take 48.11s in average and 48.10s in median.
[06/12 19:45:57][INFO] train_net.py:  714: For epoch 127, each iteraction takes 0.81s in average. From epoch 0 to 127, each iteraction takes 0.80s in average.
[06/12 19:46:15][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47412, "dt_data": 0.00057, "dt_net": 0.47355, "epoch": "129/300", "eta": "1:21:28", "gpu_mem": "10.07G", "grad_norm": 12.17346, "iter": "10/60", "loss": 0.07673, "lr": 0.0012268213, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:46:20][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47103, "dt_data": 0.00035, "dt_net": 0.47067, "epoch": "129/300", "eta": "1:20:51", "gpu_mem": "10.07G", "grad_norm": 4.54406, "iter": "20/60", "loss": 0.13412, "lr": 0.0012251211, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:46:27][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47548, "dt_data": 0.00034, "dt_net": 0.47513, "epoch": "129/300", "eta": "1:21:32", "gpu_mem": "10.07G", "grad_norm": 2.85572, "iter": "30/60", "loss": 0.09588, "lr": 0.0012234202, "top1_acc": 100.00000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:46:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47505, "dt_data": 0.00042, "dt_net": 0.47463, "epoch": "129/300", "eta": "1:21:23", "gpu_mem": "10.07G", "grad_norm": 5.33366, "iter": "40/60", "loss": 0.05611, "lr": 0.0012217187, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:46:39][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47452, "dt_data": 0.00054, "dt_net": 0.47398, "epoch": "129/300", "eta": "1:21:13", "gpu_mem": "10.07G", "grad_norm": 5.63208, "iter": "50/60", "loss": 0.11285, "lr": 0.0012200165, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:46:45][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46989, "dt_data": 0.00016, "dt_net": 0.46973, "epoch": "129/300", "eta": "1:20:21", "gpu_mem": "10.07G", "grad_norm": 8.32827, "iter": "60/60", "loss": 0.09207, "lr": 0.0012183136, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:46:45][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.68603, "dt_data": 0.68603, "dt_net": 0.46973, "epoch": "129/300", "eta": "1:57:18", "gpu_mem": "10.07G", "grad_norm": 8.32827, "loss": 0.10341, "lr": 0.0012183136, "top1_acc": 96.56250, "top1_err": 3.54167, "top5_acc": 100.00000, "top5_err": 0.05208}
[06/12 19:46:45][INFO] train_net.py:  708: Epoch 128 takes 47.93s. Epochs from 0 to 128 take 48.11s in average and 48.09s in median.
[06/12 19:46:45][INFO] train_net.py:  714: For epoch 128, each iteraction takes 0.80s in average. From epoch 0 to 128, each iteraction takes 0.80s in average.
[06/12 19:47:03][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.60781, "dt_data": 0.13801, "dt_net": 0.46980, "epoch": "130/300", "eta": "1:43:50", "gpu_mem": "10.07G", "grad_norm": 11.44113, "iter": "10/60", "loss": 0.11241, "lr": 0.0012166100, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:47:09][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47419, "dt_data": 0.00065, "dt_net": 0.47354, "epoch": "130/300", "eta": "1:20:55", "gpu_mem": "10.07G", "grad_norm": 13.35891, "iter": "20/60", "loss": 0.06180, "lr": 0.0012149058, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:47:15][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.64067, "dt_data": 0.17030, "dt_net": 0.47037, "epoch": "130/300", "eta": "1:49:14", "gpu_mem": "10.07G", "grad_norm": 5.23347, "iter": "30/60", "loss": 0.07769, "lr": 0.0012132009, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:47:21][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47820, "dt_data": 0.00049, "dt_net": 0.47771, "epoch": "130/300", "eta": "1:21:27", "gpu_mem": "10.07G", "grad_norm": 5.40455, "iter": "40/60", "loss": 0.08026, "lr": 0.0012114954, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:47:27][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.15109, "dt_data": 0.67427, "dt_net": 0.47682, "epoch": "130/300", "eta": "3:15:52", "gpu_mem": "10.07G", "grad_norm": 4.88594, "iter": "50/60", "loss": 0.08608, "lr": 0.0012097892, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:47:32][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46962, "dt_data": 0.00016, "dt_net": 0.46946, "epoch": "130/300", "eta": "1:19:50", "gpu_mem": "10.07G", "grad_norm": 6.59270, "iter": "60/60", "loss": 0.15817, "lr": 0.0012080824, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:47:33][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.69124, "dt_data": 0.69124, "dt_net": 0.46946, "epoch": "130/300", "eta": "1:57:30", "gpu_mem": "10.07G", "grad_norm": 6.59270, "loss": 0.10894, "lr": 0.0012080824, "top1_acc": 96.25000, "top1_err": 3.75000, "top5_acc": 99.89583, "top5_err": 0.15625}
[06/12 19:47:33][INFO] train_net.py:  708: Epoch 129 takes 47.93s. Epochs from 0 to 129 take 48.11s in average and 48.09s in median.
[06/12 19:47:33][INFO] train_net.py:  714: For epoch 129, each iteraction takes 0.80s in average. From epoch 0 to 129, each iteraction takes 0.80s in average.
[06/12 19:47:33][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 19:48:35][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "130/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.12983, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 19:48:38][INFO] logging.py:  101: json_stats: {"RAM": "13.17/31.07G", "_type": "val_epoch", "epoch": "130/300", "gpu_mem": "10.07G", "min_top1_err": 22.82158, "min_top5_err": 2.69710, "time_diff": 0.60896, "top1_acc": 75.31120, "top1_err": 24.68880, "top5_acc": 95.64315, "top5_err": 4.35685}
[06/12 19:48:56][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46929, "dt_data": 0.00041, "dt_net": 0.46888, "epoch": "131/300", "eta": "1:19:42", "gpu_mem": "10.07G", "grad_norm": 5.76844, "iter": "10/60", "loss": 0.14215, "lr": 0.0012063750, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:49:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46443, "dt_data": 0.00040, "dt_net": 0.46403, "epoch": "131/300", "eta": "1:18:47", "gpu_mem": "10.07G", "grad_norm": 3.21028, "iter": "20/60", "loss": 0.04628, "lr": 0.0012046669, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:49:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46832, "dt_data": 0.00046, "dt_net": 0.46786, "epoch": "131/300", "eta": "1:19:22", "gpu_mem": "10.07G", "grad_norm": 2.16691, "iter": "30/60", "loss": 0.04495, "lr": 0.0012029582, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:49:14][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47439, "dt_data": 0.00038, "dt_net": 0.47401, "epoch": "131/300", "eta": "1:20:19", "gpu_mem": "10.07G", "grad_norm": 6.02382, "iter": "40/60", "loss": 0.08306, "lr": 0.0012012489, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:49:20][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46783, "dt_data": 0.00040, "dt_net": 0.46743, "epoch": "131/300", "eta": "1:19:08", "gpu_mem": "10.07G", "grad_norm": 3.13604, "iter": "50/60", "loss": 0.08399, "lr": 0.0011995390, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:49:26][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46550, "dt_data": 0.00018, "dt_net": 0.46532, "epoch": "131/300", "eta": "1:18:40", "gpu_mem": "10.07G", "grad_norm": 8.11022, "iter": "60/60", "loss": 0.13884, "lr": 0.0011978284, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:49:26][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.70727, "dt_data": 0.70727, "dt_net": 0.46532, "epoch": "131/300", "eta": "1:59:31", "gpu_mem": "10.07G", "grad_norm": 8.11022, "loss": 0.10508, "lr": 0.0011978284, "top1_acc": 96.77083, "top1_err": 3.33333, "top5_acc": 99.79167, "top5_err": 0.41667}
[06/12 19:49:26][INFO] train_net.py:  708: Epoch 130 takes 48.86s. Epochs from 0 to 130 take 48.12s in average and 48.09s in median.
[06/12 19:49:26][INFO] train_net.py:  714: For epoch 130, each iteraction takes 0.81s in average. From epoch 0 to 130, each iteraction takes 0.80s in average.
[06/12 19:49:44][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46680, "dt_data": 0.00031, "dt_net": 0.46649, "epoch": "132/300", "eta": "1:18:48", "gpu_mem": "10.07G", "grad_norm": 3.93921, "iter": "10/60", "loss": 0.08233, "lr": 0.0011961173, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:49:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47136, "dt_data": 0.00044, "dt_net": 0.47092, "epoch": "132/300", "eta": "1:19:30", "gpu_mem": "10.07G", "grad_norm": 0.64766, "iter": "20/60", "loss": 0.05100, "lr": 0.0011944056, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:49:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.72097, "dt_data": 0.00035, "dt_net": 0.72062, "epoch": "132/300", "eta": "2:01:29", "gpu_mem": "10.07G", "grad_norm": 10.36576, "iter": "30/60", "loss": 0.07705, "lr": 0.0011926932, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:50:02][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47288, "dt_data": 0.00051, "dt_net": 0.47236, "epoch": "132/300", "eta": "1:19:36", "gpu_mem": "10.07G", "grad_norm": 9.99837, "iter": "40/60", "loss": 0.05554, "lr": 0.0011909803, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:50:09][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.59937, "dt_data": 0.00044, "dt_net": 0.59892, "epoch": "132/300", "eta": "1:40:47", "gpu_mem": "10.07G", "grad_norm": 2.76085, "iter": "50/60", "loss": 0.05182, "lr": 0.0011892668, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:50:14][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46806, "dt_data": 0.00019, "dt_net": 0.46786, "epoch": "132/300", "eta": "1:18:37", "gpu_mem": "10.07G", "grad_norm": 7.17927, "iter": "60/60", "loss": 0.08086, "lr": 0.0011875528, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:50:15][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.70893, "dt_data": 0.70893, "dt_net": 0.46786, "epoch": "132/300", "eta": "1:59:05", "gpu_mem": "10.07G", "grad_norm": 7.17927, "loss": 0.09487, "lr": 0.0011875528, "top1_acc": 97.18750, "top1_err": 2.86458, "top5_acc": 99.89583, "top5_err": 0.05208}
[06/12 19:50:15][INFO] train_net.py:  708: Epoch 131 takes 48.51s. Epochs from 0 to 131 take 48.12s in average and 48.10s in median.
[06/12 19:50:15][INFO] train_net.py:  714: For epoch 131, each iteraction takes 0.81s in average. From epoch 0 to 131, each iteraction takes 0.80s in average.
[06/12 19:50:32][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.61909, "dt_data": 0.00039, "dt_net": 0.61870, "epoch": "133/300", "eta": "1:43:54", "gpu_mem": "10.07G", "grad_norm": 5.02247, "iter": "10/60", "loss": 0.04740, "lr": 0.0011858381, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:50:38][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47254, "dt_data": 0.00067, "dt_net": 0.47185, "epoch": "133/300", "eta": "1:19:13", "gpu_mem": "10.07G", "grad_norm": 9.00121, "iter": "20/60", "loss": 0.06252, "lr": 0.0011841229, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:50:45][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47194, "dt_data": 0.00060, "dt_net": 0.47133, "epoch": "133/300", "eta": "1:19:02", "gpu_mem": "10.07G", "grad_norm": 7.33779, "iter": "30/60", "loss": 0.12338, "lr": 0.0011824071, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:50:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47318, "dt_data": 0.00065, "dt_net": 0.47252, "epoch": "133/300", "eta": "1:19:10", "gpu_mem": "10.07G", "grad_norm": 6.87889, "iter": "40/60", "loss": 0.11138, "lr": 0.0011806908, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:50:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47090, "dt_data": 0.00071, "dt_net": 0.47019, "epoch": "133/300", "eta": "1:18:43", "gpu_mem": "10.07G", "grad_norm": 3.85766, "iter": "50/60", "loss": 0.07943, "lr": 0.0011789739, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:51:02][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46909, "dt_data": 0.00023, "dt_net": 0.46886, "epoch": "133/300", "eta": "1:18:20", "gpu_mem": "10.07G", "grad_norm": 12.07802, "iter": "60/60", "loss": 0.09988, "lr": 0.0011772565, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:51:03][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.69993, "dt_data": 0.69993, "dt_net": 0.46886, "epoch": "133/300", "eta": "1:56:52", "gpu_mem": "10.07G", "grad_norm": 12.07802, "loss": 0.10295, "lr": 0.0011772565, "top1_acc": 96.14583, "top1_err": 3.54167, "top5_acc": 99.89583, "top5_err": 0.10417}
[06/12 19:51:03][INFO] train_net.py:  708: Epoch 132 takes 48.13s. Epochs from 0 to 132 take 48.12s in average and 48.10s in median.
[06/12 19:51:03][INFO] train_net.py:  714: For epoch 132, each iteraction takes 0.80s in average. From epoch 0 to 132, each iteraction takes 0.80s in average.
[06/12 19:51:21][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47074, "dt_data": 0.00035, "dt_net": 0.47038, "epoch": "134/300", "eta": "1:18:32", "gpu_mem": "10.07G", "grad_norm": 6.88124, "iter": "10/60", "loss": 0.08824, "lr": 0.0011755386, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:51:26][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47239, "dt_data": 0.00051, "dt_net": 0.47188, "epoch": "134/300", "eta": "1:18:43", "gpu_mem": "10.07G", "grad_norm": 2.54457, "iter": "20/60", "loss": 0.03852, "lr": 0.0011738201, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:51:32][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47464, "dt_data": 0.00078, "dt_net": 0.47386, "epoch": "134/300", "eta": "1:19:01", "gpu_mem": "10.07G", "grad_norm": 4.56543, "iter": "30/60", "loss": 0.11623, "lr": 0.0011721010, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:51:39][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.09718, "dt_data": 0.62591, "dt_net": 0.47126, "epoch": "134/300", "eta": "3:02:29", "gpu_mem": "10.07G", "grad_norm": 4.22813, "iter": "40/60", "loss": 0.07655, "lr": 0.0011703815, "top1_acc": 96.87500, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:51:45][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47715, "dt_data": 0.00059, "dt_net": 0.47656, "epoch": "134/300", "eta": "1:19:17", "gpu_mem": "10.07G", "grad_norm": 1.07349, "iter": "50/60", "loss": 0.08985, "lr": 0.0011686614, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:51:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.50633, "dt_data": 0.03780, "dt_net": 0.46853, "epoch": "134/300", "eta": "1:24:03", "gpu_mem": "10.07G", "grad_norm": 14.06070, "iter": "60/60", "loss": 0.16329, "lr": 0.0011669408, "top1_acc": 93.75000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:51:51][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.69587, "dt_data": 0.69587, "dt_net": 0.46853, "epoch": "134/300", "eta": "1:55:30", "gpu_mem": "10.07G", "grad_norm": 14.06070, "loss": 0.11059, "lr": 0.0011669408, "top1_acc": 96.56250, "top1_err": 3.48958, "top5_acc": 99.79167, "top5_err": 0.10417}
[06/12 19:51:51][INFO] train_net.py:  708: Epoch 133 takes 47.87s. Epochs from 0 to 133 take 48.12s in average and 48.10s in median.
[06/12 19:51:51][INFO] train_net.py:  714: For epoch 133, each iteraction takes 0.80s in average. From epoch 0 to 133, each iteraction takes 0.80s in average.
[06/12 19:52:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47099, "dt_data": 0.00046, "dt_net": 0.47053, "epoch": "135/300", "eta": "1:18:06", "gpu_mem": "10.07G", "grad_norm": 8.06773, "iter": "10/60", "loss": 0.08001, "lr": 0.0011652197, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:52:14][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47482, "dt_data": 0.00051, "dt_net": 0.47430, "epoch": "135/300", "eta": "1:18:39", "gpu_mem": "10.07G", "grad_norm": 4.69405, "iter": "20/60", "loss": 0.04195, "lr": 0.0011634981, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:52:20][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47571, "dt_data": 0.00050, "dt_net": 0.47520, "epoch": "135/300", "eta": "1:18:43", "gpu_mem": "10.07G", "grad_norm": 0.33274, "iter": "30/60", "loss": 0.04142, "lr": 0.0011617761, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:52:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47325, "dt_data": 0.00110, "dt_net": 0.47214, "epoch": "135/300", "eta": "1:18:14", "gpu_mem": "10.07G", "grad_norm": 1.06704, "iter": "40/60", "loss": 0.05603, "lr": 0.0011600535, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:52:32][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47366, "dt_data": 0.00048, "dt_net": 0.47318, "epoch": "135/300", "eta": "1:18:14", "gpu_mem": "10.07G", "grad_norm": 3.86778, "iter": "50/60", "loss": 0.08925, "lr": 0.0011583304, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:52:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46952, "dt_data": 0.00014, "dt_net": 0.46938, "epoch": "135/300", "eta": "1:17:28", "gpu_mem": "10.07G", "grad_norm": 4.92815, "iter": "60/60", "loss": 0.08191, "lr": 0.0011566068, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:52:38][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.68598, "dt_data": 0.68598, "dt_net": 0.46938, "epoch": "135/300", "eta": "1:53:10", "gpu_mem": "10.07G", "grad_norm": 4.92815, "loss": 0.08206, "lr": 0.0011566068, "top1_acc": 97.81250, "top1_err": 2.70833, "top5_acc": 99.89583, "top5_err": 0.05208}
[06/12 19:52:38][INFO] train_net.py:  708: Epoch 134 takes 46.90s. Epochs from 0 to 134 take 48.11s in average and 48.09s in median.
[06/12 19:52:38][INFO] train_net.py:  714: For epoch 134, each iteraction takes 0.78s in average. From epoch 0 to 134, each iteraction takes 0.80s in average.
[06/12 19:52:38][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 19:53:39][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "135/300", "eta": "0:00:01", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.19972, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 19:53:42][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "val_epoch", "epoch": "135/300", "gpu_mem": "10.07G", "min_top1_err": 22.40664, "min_top5_err": 2.69710, "time_diff": 0.62331, "top1_acc": 77.59336, "top1_err": 22.40664, "top5_acc": 96.05809, "top5_err": 3.94191}
[06/12 19:53:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46613, "dt_data": 0.00065, "dt_net": 0.46547, "epoch": "136/300", "eta": "1:16:49", "gpu_mem": "10.07G", "grad_norm": 4.81536, "iter": "10/60", "loss": 0.06583, "lr": 0.0011548828, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:54:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46779, "dt_data": 0.00051, "dt_net": 0.46728, "epoch": "136/300", "eta": "1:17:01", "gpu_mem": "10.07G", "grad_norm": 6.59948, "iter": "20/60", "loss": 0.07252, "lr": 0.0011531583, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:54:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.86563, "dt_data": 0.00042, "dt_net": 0.86521, "epoch": "136/300", "eta": "2:22:23", "gpu_mem": "10.07G", "grad_norm": 3.60758, "iter": "30/60", "loss": 0.11092, "lr": 0.0011514333, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:54:17][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47088, "dt_data": 0.00054, "dt_net": 0.47034, "epoch": "136/300", "eta": "1:17:22", "gpu_mem": "10.07G", "grad_norm": 3.13940, "iter": "40/60", "loss": 0.04153, "lr": 0.0011497079, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:54:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.86303, "dt_data": 0.00038, "dt_net": 0.86264, "epoch": "136/300", "eta": "2:21:40", "gpu_mem": "10.07G", "grad_norm": 10.65021, "iter": "50/60", "loss": 0.05672, "lr": 0.0011479820, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:54:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47121, "dt_data": 0.00014, "dt_net": 0.47107, "epoch": "136/300", "eta": "1:17:16", "gpu_mem": "10.07G", "grad_norm": 9.73221, "iter": "60/60", "loss": 0.11748, "lr": 0.0011462557, "top1_acc": 93.75000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:54:28][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.68935, "dt_data": 0.68935, "dt_net": 0.47107, "epoch": "136/300", "eta": "1:53:02", "gpu_mem": "10.07G", "grad_norm": 9.73221, "loss": 0.09978, "lr": 0.0011462557, "top1_acc": 97.50000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.05208}
[06/12 19:54:28][INFO] train_net.py:  708: Epoch 135 takes 46.50s. Epochs from 0 to 135 take 48.10s in average and 48.09s in median.
[06/12 19:54:28][INFO] train_net.py:  714: For epoch 135, each iteraction takes 0.78s in average. From epoch 0 to 135, each iteraction takes 0.80s in average.
[06/12 19:54:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46669, "dt_data": 0.00062, "dt_net": 0.46607, "epoch": "137/300", "eta": "1:16:27", "gpu_mem": "10.07G", "grad_norm": 5.22563, "iter": "10/60", "loss": 0.10053, "lr": 0.0011445289, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:54:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47263, "dt_data": 0.00068, "dt_net": 0.47195, "epoch": "137/300", "eta": "1:17:21", "gpu_mem": "10.07G", "grad_norm": 7.69600, "iter": "20/60", "loss": 0.11206, "lr": 0.0011428017, "top1_acc": 100.00000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:54:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47790, "dt_data": 0.00034, "dt_net": 0.47756, "epoch": "137/300", "eta": "1:18:08", "gpu_mem": "10.07G", "grad_norm": 6.07689, "iter": "30/60", "loss": 0.09629, "lr": 0.0011410740, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:55:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47094, "dt_data": 0.00039, "dt_net": 0.47054, "epoch": "137/300", "eta": "1:16:55", "gpu_mem": "10.07G", "grad_norm": 7.39901, "iter": "40/60", "loss": 0.06524, "lr": 0.0011393459, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:55:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47400, "dt_data": 0.00049, "dt_net": 0.47350, "epoch": "137/300", "eta": "1:17:20", "gpu_mem": "10.07G", "grad_norm": 1.19608, "iter": "50/60", "loss": 0.09860, "lr": 0.0011376174, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:55:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47154, "dt_data": 0.00016, "dt_net": 0.47138, "epoch": "137/300", "eta": "1:16:51", "gpu_mem": "10.07G", "grad_norm": 1.91491, "iter": "60/60", "loss": 0.11779, "lr": 0.0011358885, "top1_acc": 96.87500, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:55:17][INFO] logging.py:  101: json_stats: {"RAM": "13.16/31.07G", "_type": "train_epoch", "dt": 0.69339, "dt_data": 0.69338, "dt_net": 0.47138, "epoch": "137/300", "eta": "1:53:00", "gpu_mem": "10.07G", "grad_norm": 1.91491, "loss": 0.11030, "lr": 0.0011358885, "top1_acc": 95.52083, "top1_err": 3.95833, "top5_acc": 99.89583, "top5_err": 0.15625}
[06/12 19:55:17][INFO] train_net.py:  708: Epoch 136 takes 48.43s. Epochs from 0 to 136 take 48.10s in average and 48.09s in median.
[06/12 19:55:17][INFO] train_net.py:  714: For epoch 136, each iteraction takes 0.81s in average. From epoch 0 to 136, each iteraction takes 0.80s in average.
[06/12 19:55:34][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47289, "dt_data": 0.00083, "dt_net": 0.47205, "epoch": "138/300", "eta": "1:17:00", "gpu_mem": "10.07G", "grad_norm": 9.20852, "iter": "10/60", "loss": 0.07714, "lr": 0.0011341591, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:55:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47319, "dt_data": 0.00066, "dt_net": 0.47253, "epoch": "138/300", "eta": "1:16:58", "gpu_mem": "10.07G", "grad_norm": 5.50720, "iter": "20/60", "loss": 0.03839, "lr": 0.0011324294, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:55:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47416, "dt_data": 0.00035, "dt_net": 0.47381, "epoch": "138/300", "eta": "1:17:03", "gpu_mem": "10.07G", "grad_norm": 3.09326, "iter": "30/60", "loss": 0.05220, "lr": 0.0011306992, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:55:51][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47341, "dt_data": 0.00036, "dt_net": 0.47304, "epoch": "138/300", "eta": "1:16:51", "gpu_mem": "10.07G", "grad_norm": 3.07912, "iter": "40/60", "loss": 0.08028, "lr": 0.0011289687, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:55:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47101, "dt_data": 0.00036, "dt_net": 0.47064, "epoch": "138/300", "eta": "1:16:22", "gpu_mem": "10.07G", "grad_norm": 7.70679, "iter": "50/60", "loss": 0.06123, "lr": 0.0011272377, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:56:03][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.68114, "dt_data": 0.00017, "dt_net": 0.68096, "epoch": "138/300", "eta": "1:50:20", "gpu_mem": "10.07G", "grad_norm": 2.15262, "iter": "60/60", "loss": 0.04940, "lr": 0.0011255064, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:56:04][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.70538, "dt_data": 0.70538, "dt_net": 0.68096, "epoch": "138/300", "eta": "1:54:15", "gpu_mem": "10.07G", "grad_norm": 2.15262, "loss": 0.08161, "lr": 0.0011255064, "top1_acc": 96.97917, "top1_err": 2.91667, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:56:04][INFO] train_net.py:  708: Epoch 137 takes 46.99s. Epochs from 0 to 137 take 48.09s in average and 48.09s in median.
[06/12 19:56:04][INFO] train_net.py:  714: For epoch 137, each iteraction takes 0.78s in average. From epoch 0 to 137, each iteraction takes 0.80s in average.
[06/12 19:56:21][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47053, "dt_data": 0.00058, "dt_net": 0.46995, "epoch": "139/300", "eta": "1:16:08", "gpu_mem": "10.07G", "grad_norm": 10.10555, "iter": "10/60", "loss": 0.07000, "lr": 0.0011237747, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:56:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46902, "dt_data": 0.00043, "dt_net": 0.46859, "epoch": "139/300", "eta": "1:15:49", "gpu_mem": "10.07G", "grad_norm": 3.45141, "iter": "20/60", "loss": 0.06330, "lr": 0.0011220426, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:56:34][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46988, "dt_data": 0.00036, "dt_net": 0.46952, "epoch": "139/300", "eta": "1:15:53", "gpu_mem": "10.07G", "grad_norm": 2.95014, "iter": "30/60", "loss": 0.04608, "lr": 0.0011203101, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:56:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47172, "dt_data": 0.00042, "dt_net": 0.47129, "epoch": "139/300", "eta": "1:16:06", "gpu_mem": "10.07G", "grad_norm": 6.48654, "iter": "40/60", "loss": 0.09581, "lr": 0.0011185773, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:56:45][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.64144, "dt_data": 0.16786, "dt_net": 0.47359, "epoch": "139/300", "eta": "1:43:22", "gpu_mem": "10.07G", "grad_norm": 2.88592, "iter": "50/60", "loss": 0.04834, "lr": 0.0011168441, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:56:51][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46983, "dt_data": 0.00016, "dt_net": 0.46967, "epoch": "139/300", "eta": "1:15:38", "gpu_mem": "10.07G", "grad_norm": 5.53616, "iter": "60/60", "loss": 0.09954, "lr": 0.0011151105, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:56:52][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.71063, "dt_data": 0.71063, "dt_net": 0.46967, "epoch": "139/300", "eta": "1:54:24", "gpu_mem": "10.07G", "grad_norm": 5.53616, "loss": 0.08289, "lr": 0.0011151105, "top1_acc": 96.66667, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:56:52][INFO] train_net.py:  708: Epoch 138 takes 48.05s. Epochs from 0 to 138 take 48.09s in average and 48.08s in median.
[06/12 19:56:52][INFO] train_net.py:  714: For epoch 138, each iteraction takes 0.80s in average. From epoch 0 to 138, each iteraction takes 0.80s in average.
[06/12 19:57:10][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47784, "dt_data": 0.00065, "dt_net": 0.47719, "epoch": "140/300", "eta": "1:16:51", "gpu_mem": "10.07G", "grad_norm": 4.34721, "iter": "10/60", "loss": 0.08613, "lr": 0.0011133766, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:57:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46997, "dt_data": 0.00048, "dt_net": 0.46949, "epoch": "140/300", "eta": "1:15:30", "gpu_mem": "10.07G", "grad_norm": 7.91508, "iter": "20/60", "loss": 0.07095, "lr": 0.0011116424, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:57:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.92814, "dt_data": 0.00041, "dt_net": 0.92773, "epoch": "140/300", "eta": "2:28:57", "gpu_mem": "10.07G", "grad_norm": 5.07757, "iter": "30/60", "loss": 0.11657, "lr": 0.0011099078, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:57:27][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47269, "dt_data": 0.00038, "dt_net": 0.47230, "epoch": "140/300", "eta": "1:15:47", "gpu_mem": "10.07G", "grad_norm": 4.90597, "iter": "40/60", "loss": 0.09867, "lr": 0.0011081729, "top1_acc": 93.75000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:57:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.09132, "dt_data": 0.00047, "dt_net": 1.09084, "epoch": "140/300", "eta": "2:54:47", "gpu_mem": "10.07G", "grad_norm": 0.97330, "iter": "50/60", "loss": 0.06192, "lr": 0.0011064376, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:57:39][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46841, "dt_data": 0.00019, "dt_net": 0.46822, "epoch": "140/300", "eta": "1:14:56", "gpu_mem": "10.07G", "grad_norm": 4.02948, "iter": "60/60", "loss": 0.05106, "lr": 0.0011047020, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:57:40][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.68929, "dt_data": 0.68929, "dt_net": 0.46822, "epoch": "140/300", "eta": "1:50:16", "gpu_mem": "10.07G", "grad_norm": 4.02948, "loss": 0.08185, "lr": 0.0011047020, "top1_acc": 96.87500, "top1_err": 2.81250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:57:40][INFO] train_net.py:  708: Epoch 139 takes 48.04s. Epochs from 0 to 139 take 48.09s in average and 48.08s in median.
[06/12 19:57:40][INFO] train_net.py:  714: For epoch 139, each iteraction takes 0.80s in average. From epoch 0 to 139, each iteraction takes 0.80s in average.
[06/12 19:57:40][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 19:58:42][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "140/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.12965, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 19:58:45][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "val_epoch", "epoch": "140/300", "gpu_mem": "10.07G", "min_top1_err": 22.40664, "min_top5_err": 2.69710, "time_diff": 0.60851, "top1_acc": 74.48133, "top1_err": 25.51867, "top5_acc": 96.26556, "top5_err": 3.73444}
[06/12 19:59:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46697, "dt_data": 0.00048, "dt_net": 0.46649, "epoch": "141/300", "eta": "1:14:38", "gpu_mem": "10.07G", "grad_norm": 9.48734, "iter": "10/60", "loss": 0.05421, "lr": 0.0011029661, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:59:08][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46619, "dt_data": 0.00050, "dt_net": 0.46568, "epoch": "141/300", "eta": "1:14:26", "gpu_mem": "10.07G", "grad_norm": 2.39036, "iter": "20/60", "loss": 0.06554, "lr": 0.0011012299, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:59:14][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47065, "dt_data": 0.00052, "dt_net": 0.47012, "epoch": "141/300", "eta": "1:15:04", "gpu_mem": "10.07G", "grad_norm": 7.49727, "iter": "30/60", "loss": 0.10208, "lr": 0.0010994934, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:59:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46844, "dt_data": 0.00044, "dt_net": 0.46800, "epoch": "141/300", "eta": "1:14:38", "gpu_mem": "10.07G", "grad_norm": 3.66043, "iter": "40/60", "loss": 0.04883, "lr": 0.0010977566, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:59:26][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46853, "dt_data": 0.00056, "dt_net": 0.46797, "epoch": "141/300", "eta": "1:14:34", "gpu_mem": "10.07G", "grad_norm": 5.75525, "iter": "50/60", "loss": 0.08876, "lr": 0.0010960195, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:59:32][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46715, "dt_data": 0.00016, "dt_net": 0.46699, "epoch": "141/300", "eta": "1:14:16", "gpu_mem": "10.07G", "grad_norm": 7.34253, "iter": "60/60", "loss": 0.07378, "lr": 0.0010942821, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:59:32][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.70712, "dt_data": 0.70712, "dt_net": 0.46699, "epoch": "141/300", "eta": "1:52:25", "gpu_mem": "10.07G", "grad_norm": 7.34253, "loss": 0.09153, "lr": 0.0010942821, "top1_acc": 96.45833, "top1_err": 3.33333, "top5_acc": 100.00000, "top5_err": 0.10417}
[06/12 19:59:32][INFO] train_net.py:  708: Epoch 140 takes 47.10s. Epochs from 0 to 140 take 48.08s in average and 48.08s in median.
[06/12 19:59:32][INFO] train_net.py:  714: For epoch 140, each iteraction takes 0.79s in average. From epoch 0 to 140, each iteraction takes 0.80s in average.
[06/12 19:59:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.95094, "dt_data": 0.00034, "dt_net": 0.95060, "epoch": "142/300", "eta": "2:31:02", "gpu_mem": "10.07G", "grad_norm": 6.81211, "iter": "10/60", "loss": 0.05683, "lr": 0.0010925444, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 19:59:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47123, "dt_data": 0.00037, "dt_net": 0.47086, "epoch": "142/300", "eta": "1:14:46", "gpu_mem": "10.07G", "grad_norm": 6.34295, "iter": "20/60", "loss": 0.03165, "lr": 0.0010908064, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:00:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.02211, "dt_data": 0.08164, "dt_net": 0.94047, "epoch": "142/300", "eta": "2:42:00", "gpu_mem": "10.07G", "grad_norm": 3.11379, "iter": "30/60", "loss": 0.07052, "lr": 0.0010890681, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:00:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47490, "dt_data": 0.00048, "dt_net": 0.47442, "epoch": "142/300", "eta": "1:15:11", "gpu_mem": "10.07G", "grad_norm": 2.52388, "iter": "40/60", "loss": 0.11949, "lr": 0.0010873296, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:00:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.71744, "dt_data": 0.00039, "dt_net": 0.71705, "epoch": "142/300", "eta": "1:53:28", "gpu_mem": "10.07G", "grad_norm": 4.52808, "iter": "50/60", "loss": 0.10222, "lr": 0.0010855908, "top1_acc": 100.00000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:00:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47269, "dt_data": 0.00015, "dt_net": 0.47254, "epoch": "142/300", "eta": "1:14:41", "gpu_mem": "10.07G", "grad_norm": 5.13650, "iter": "60/60", "loss": 0.09299, "lr": 0.0010838518, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:00:20][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.69651, "dt_data": 0.69651, "dt_net": 0.47254, "epoch": "142/300", "eta": "1:50:02", "gpu_mem": "10.07G", "grad_norm": 5.13650, "loss": 0.10202, "lr": 0.0010838518, "top1_acc": 96.56250, "top1_err": 3.38542, "top5_acc": 99.79167, "top5_err": 0.20833}
[06/12 20:00:20][INFO] train_net.py:  708: Epoch 141 takes 47.56s. Epochs from 0 to 141 take 48.08s in average and 48.06s in median.
[06/12 20:00:20][INFO] train_net.py:  714: For epoch 141, each iteraction takes 0.79s in average. From epoch 0 to 141, each iteraction takes 0.80s in average.
[06/12 20:00:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.53863, "dt_data": 0.06886, "dt_net": 0.46976, "epoch": "143/300", "eta": "1:25:00", "gpu_mem": "10.07G", "grad_norm": 4.28393, "iter": "10/60", "loss": 0.07850, "lr": 0.0010821125, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:00:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47088, "dt_data": 0.00050, "dt_net": 0.47038, "epoch": "143/300", "eta": "1:14:14", "gpu_mem": "10.07G", "grad_norm": 4.98453, "iter": "20/60", "loss": 0.07822, "lr": 0.0010803729, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:00:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47175, "dt_data": 0.00065, "dt_net": 0.47109, "epoch": "143/300", "eta": "1:14:18", "gpu_mem": "10.07G", "grad_norm": 4.41378, "iter": "30/60", "loss": 0.07672, "lr": 0.0010786331, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:00:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47379, "dt_data": 0.00054, "dt_net": 0.47325, "epoch": "143/300", "eta": "1:14:32", "gpu_mem": "10.07G", "grad_norm": 4.28135, "iter": "40/60", "loss": 0.05575, "lr": 0.0010768930, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:01:02][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47372, "dt_data": 0.00036, "dt_net": 0.47336, "epoch": "143/300", "eta": "1:14:27", "gpu_mem": "10.07G", "grad_norm": 8.78933, "iter": "50/60", "loss": 0.10426, "lr": 0.0010751528, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:01:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46873, "dt_data": 0.00016, "dt_net": 0.46857, "epoch": "143/300", "eta": "1:13:35", "gpu_mem": "10.07G", "grad_norm": 5.03571, "iter": "60/60", "loss": 0.08263, "lr": 0.0010734123, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:01:08][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.68914, "dt_data": 0.68914, "dt_net": 0.46857, "epoch": "143/300", "eta": "1:48:11", "gpu_mem": "10.07G", "grad_norm": 5.03571, "loss": 0.09296, "lr": 0.0010734123, "top1_acc": 96.97917, "top1_err": 2.86458, "top5_acc": 99.89583, "top5_err": 0.10417}
[06/12 20:01:08][INFO] train_net.py:  708: Epoch 142 takes 48.37s. Epochs from 0 to 142 take 48.08s in average and 48.08s in median.
[06/12 20:01:08][INFO] train_net.py:  714: For epoch 142, each iteraction takes 0.81s in average. From epoch 0 to 142, each iteraction takes 0.80s in average.
[06/12 20:01:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.54751, "dt_data": 0.00073, "dt_net": 0.54677, "epoch": "144/300", "eta": "1:25:52", "gpu_mem": "10.07G", "grad_norm": 2.23984, "iter": "10/60", "loss": 0.04761, "lr": 0.0010716715, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:01:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47641, "dt_data": 0.00049, "dt_net": 0.47592, "epoch": "144/300", "eta": "1:14:38", "gpu_mem": "10.07G", "grad_norm": 2.49494, "iter": "20/60", "loss": 0.03785, "lr": 0.0010699306, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:01:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.73223, "dt_data": 0.25984, "dt_net": 0.47238, "epoch": "144/300", "eta": "1:54:35", "gpu_mem": "10.07G", "grad_norm": 3.04205, "iter": "30/60", "loss": 0.04691, "lr": 0.0010681894, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:01:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47283, "dt_data": 0.00063, "dt_net": 0.47220, "epoch": "144/300", "eta": "1:13:55", "gpu_mem": "10.07G", "grad_norm": 6.47797, "iter": "40/60", "loss": 0.09433, "lr": 0.0010664480, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:01:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.02634, "dt_data": 0.55417, "dt_net": 0.47217, "epoch": "144/300", "eta": "2:40:16", "gpu_mem": "10.07G", "grad_norm": 8.75472, "iter": "50/60", "loss": 0.05335, "lr": 0.0010647065, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:01:56][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46961, "dt_data": 0.00016, "dt_net": 0.46945, "epoch": "144/300", "eta": "1:13:15", "gpu_mem": "10.07G", "grad_norm": 3.80623, "iter": "60/60", "loss": 0.06884, "lr": 0.0010629647, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:01:57][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.70830, "dt_data": 0.70830, "dt_net": 0.46945, "epoch": "144/300", "eta": "1:50:29", "gpu_mem": "10.07G", "grad_norm": 3.80623, "loss": 0.07451, "lr": 0.0010629647, "top1_acc": 97.81250, "top1_err": 2.29167, "top5_acc": 99.79167, "top5_err": 0.10417}
[06/12 20:01:57][INFO] train_net.py:  708: Epoch 143 takes 48.48s. Epochs from 0 to 143 take 48.08s in average and 48.08s in median.
[06/12 20:01:57][INFO] train_net.py:  714: For epoch 143, each iteraction takes 0.81s in average. From epoch 0 to 143, each iteraction takes 0.80s in average.
[06/12 20:02:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47390, "dt_data": 0.00077, "dt_net": 0.47312, "epoch": "145/300", "eta": "1:13:51", "gpu_mem": "10.07G", "grad_norm": 3.54043, "iter": "10/60", "loss": 0.09386, "lr": 0.0010612227, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:02:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47049, "dt_data": 0.00045, "dt_net": 0.47003, "epoch": "145/300", "eta": "1:13:14", "gpu_mem": "10.07G", "grad_norm": 5.28944, "iter": "20/60", "loss": 0.06344, "lr": 0.0010594806, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:02:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47319, "dt_data": 0.00056, "dt_net": 0.47263, "epoch": "145/300", "eta": "1:13:34", "gpu_mem": "10.07G", "grad_norm": 14.73432, "iter": "30/60", "loss": 0.04164, "lr": 0.0010577383, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:02:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.82585, "dt_data": 0.00086, "dt_net": 0.82498, "epoch": "145/300", "eta": "2:08:16", "gpu_mem": "10.07G", "grad_norm": 8.10711, "iter": "40/60", "loss": 0.07614, "lr": 0.0010559958, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:02:38][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47489, "dt_data": 0.00047, "dt_net": 0.47442, "epoch": "145/300", "eta": "1:13:41", "gpu_mem": "10.07G", "grad_norm": 5.94015, "iter": "50/60", "loss": 0.05938, "lr": 0.0010542531, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:02:44][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46955, "dt_data": 0.00017, "dt_net": 0.46938, "epoch": "145/300", "eta": "1:12:46", "gpu_mem": "10.07G", "grad_norm": 5.50145, "iter": "60/60", "loss": 0.04785, "lr": 0.0010525102, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:02:45][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.69866, "dt_data": 0.69866, "dt_net": 0.46938, "epoch": "145/300", "eta": "1:48:17", "gpu_mem": "10.07G", "grad_norm": 5.50145, "loss": 0.08755, "lr": 0.0010525102, "top1_acc": 96.97917, "top1_err": 2.91667, "top5_acc": 99.79167, "top5_err": 0.10417}
[06/12 20:02:45][INFO] train_net.py:  708: Epoch 144 takes 48.06s. Epochs from 0 to 144 take 48.08s in average and 48.08s in median.
[06/12 20:02:45][INFO] train_net.py:  714: For epoch 144, each iteraction takes 0.80s in average. From epoch 0 to 144, each iteraction takes 0.80s in average.
[06/12 20:02:45][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 20:03:46][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "145/300", "eta": "0:00:02", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.47729, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:03:49][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "val_epoch", "epoch": "145/300", "gpu_mem": "10.07G", "min_top1_err": 22.40664, "min_top5_err": 2.69710, "time_diff": 0.61290, "top1_acc": 76.34855, "top1_err": 23.65145, "top5_acc": 97.30290, "top5_err": 2.69710}
[06/12 20:04:06][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47303, "dt_data": 0.00086, "dt_net": 0.47216, "epoch": "146/300", "eta": "1:13:14", "gpu_mem": "10.07G", "grad_norm": 4.55235, "iter": "10/60", "loss": 0.05434, "lr": 0.0010507672, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:04:12][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47061, "dt_data": 0.00066, "dt_net": 0.46993, "epoch": "146/300", "eta": "1:12:47", "gpu_mem": "10.07G", "grad_norm": 3.15625, "iter": "20/60", "loss": 0.03019, "lr": 0.0010490241, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:04:18][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47189, "dt_data": 0.00065, "dt_net": 0.47123, "epoch": "146/300", "eta": "1:12:54", "gpu_mem": "10.07G", "grad_norm": 2.15720, "iter": "30/60", "loss": 0.06567, "lr": 0.0010472808, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:04:24][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46963, "dt_data": 0.00039, "dt_net": 0.46924, "epoch": "146/300", "eta": "1:12:28", "gpu_mem": "10.07G", "grad_norm": 4.25222, "iter": "40/60", "loss": 0.05470, "lr": 0.0010455373, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:04:30][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.85365, "dt_data": 0.38450, "dt_net": 0.46914, "epoch": "146/300", "eta": "2:11:36", "gpu_mem": "10.07G", "grad_norm": 1.82135, "iter": "50/60", "loss": 0.11373, "lr": 0.0010437938, "top1_acc": 93.75000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:04:36][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46701, "dt_data": 0.00018, "dt_net": 0.46683, "epoch": "146/300", "eta": "1:11:55", "gpu_mem": "10.07G", "grad_norm": 2.60256, "iter": "60/60", "loss": 0.11534, "lr": 0.0010420500, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:04:37][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.68909, "dt_data": 0.68909, "dt_net": 0.46683, "epoch": "146/300", "eta": "1:46:06", "gpu_mem": "10.07G", "grad_norm": 2.60256, "loss": 0.07830, "lr": 0.0010420500, "top1_acc": 97.50000, "top1_err": 2.65625, "top5_acc": 100.00000, "top5_err": 0.05208}
[06/12 20:04:37][INFO] train_net.py:  708: Epoch 145 takes 47.55s. Epochs from 0 to 145 take 48.08s in average and 48.07s in median.
[06/12 20:04:37][INFO] train_net.py:  714: For epoch 145, each iteraction takes 0.79s in average. From epoch 0 to 145, each iteraction takes 0.80s in average.
[06/12 20:04:54][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46958, "dt_data": 0.00037, "dt_net": 0.46921, "epoch": "147/300", "eta": "1:12:14", "gpu_mem": "10.07G", "grad_norm": 6.84228, "iter": "10/60", "loss": 0.06408, "lr": 0.0010403062, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:04:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47181, "dt_data": 0.00076, "dt_net": 0.47103, "epoch": "147/300", "eta": "1:12:30", "gpu_mem": "10.07G", "grad_norm": 7.45984, "iter": "20/60", "loss": 0.06144, "lr": 0.0010385622, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:05:06][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.72578, "dt_data": 0.25658, "dt_net": 0.46919, "epoch": "147/300", "eta": "1:51:24", "gpu_mem": "10.07G", "grad_norm": 5.12138, "iter": "30/60", "loss": 0.04584, "lr": 0.0010368181, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:05:12][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47488, "dt_data": 0.00033, "dt_net": 0.47455, "epoch": "147/300", "eta": "1:12:48", "gpu_mem": "10.07G", "grad_norm": 0.47153, "iter": "40/60", "loss": 0.09400, "lr": 0.0010350739, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:05:18][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.69734, "dt_data": 0.22903, "dt_net": 0.46831, "epoch": "147/300", "eta": "1:46:48", "gpu_mem": "10.07G", "grad_norm": 5.12478, "iter": "50/60", "loss": 0.06568, "lr": 0.0010333296, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:05:24][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46841, "dt_data": 0.00031, "dt_net": 0.46810, "epoch": "147/300", "eta": "1:11:40", "gpu_mem": "10.07G", "grad_norm": 1.69129, "iter": "60/60", "loss": 0.03836, "lr": 0.0010315852, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:05:25][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.71208, "dt_data": 0.71208, "dt_net": 0.46810, "epoch": "147/300", "eta": "1:48:56", "gpu_mem": "10.07G", "grad_norm": 1.69129, "loss": 0.08661, "lr": 0.0010315852, "top1_acc": 97.29167, "top1_err": 2.76042, "top5_acc": 100.00000, "top5_err": 0.05208}
[06/12 20:05:25][INFO] train_net.py:  708: Epoch 146 takes 48.14s. Epochs from 0 to 146 take 48.08s in average and 48.08s in median.
[06/12 20:05:25][INFO] train_net.py:  714: For epoch 146, each iteraction takes 0.80s in average. From epoch 0 to 146, each iteraction takes 0.80s in average.
[06/12 20:05:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47208, "dt_data": 0.00053, "dt_net": 0.47154, "epoch": "148/300", "eta": "1:12:08", "gpu_mem": "10.07G", "grad_norm": 7.41855, "iter": "10/60", "loss": 0.06966, "lr": 0.0010298407, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:05:48][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47456, "dt_data": 0.00071, "dt_net": 0.47384, "epoch": "148/300", "eta": "1:12:26", "gpu_mem": "10.07G", "grad_norm": 1.42089, "iter": "20/60", "loss": 0.07001, "lr": 0.0010280961, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:05:54][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46999, "dt_data": 0.00059, "dt_net": 0.46940, "epoch": "148/300", "eta": "1:11:40", "gpu_mem": "10.07G", "grad_norm": 8.38097, "iter": "30/60", "loss": 0.10252, "lr": 0.0010263514, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:06:00][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47513, "dt_data": 0.00041, "dt_net": 0.47472, "epoch": "148/300", "eta": "1:12:22", "gpu_mem": "10.07G", "grad_norm": 10.48299, "iter": "40/60", "loss": 0.13927, "lr": 0.0010246067, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:06:06][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.07700, "dt_data": 0.60805, "dt_net": 0.46895, "epoch": "148/300", "eta": "2:43:53", "gpu_mem": "10.07G", "grad_norm": 3.01472, "iter": "50/60", "loss": 0.09451, "lr": 0.0010228618, "top1_acc": 100.00000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:06:12][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46925, "dt_data": 0.00024, "dt_net": 0.46901, "epoch": "148/300", "eta": "1:11:19", "gpu_mem": "10.07G", "grad_norm": 4.22499, "iter": "60/60", "loss": 0.03280, "lr": 0.0010211169, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:06:13][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.69949, "dt_data": 0.69949, "dt_net": 0.46901, "epoch": "148/300", "eta": "1:46:19", "gpu_mem": "10.07G", "grad_norm": 4.22499, "loss": 0.09100, "lr": 0.0010211169, "top1_acc": 96.87500, "top1_err": 3.22917, "top5_acc": 99.79167, "top5_err": 0.20833}
[06/12 20:06:13][INFO] train_net.py:  708: Epoch 147 takes 47.97s. Epochs from 0 to 147 take 48.08s in average and 48.07s in median.
[06/12 20:06:13][INFO] train_net.py:  714: For epoch 147, each iteraction takes 0.80s in average. From epoch 0 to 147, each iteraction takes 0.80s in average.
[06/12 20:06:30][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47096, "dt_data": 0.00039, "dt_net": 0.47057, "epoch": "149/300", "eta": "1:11:30", "gpu_mem": "10.07G", "grad_norm": 5.59092, "iter": "10/60", "loss": 0.03705, "lr": 0.0010193719, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:06:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.55928, "dt_data": 0.08374, "dt_net": 0.47554, "epoch": "149/300", "eta": "1:24:49", "gpu_mem": "10.07G", "grad_norm": 7.71019, "iter": "20/60", "loss": 0.09616, "lr": 0.0010176269, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:06:42][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47140, "dt_data": 0.00070, "dt_net": 0.47069, "epoch": "149/300", "eta": "1:11:25", "gpu_mem": "10.07G", "grad_norm": 0.36208, "iter": "30/60", "loss": 0.06401, "lr": 0.0010158818, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:06:48][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47648, "dt_data": 0.00039, "dt_net": 0.47608, "epoch": "149/300", "eta": "1:12:06", "gpu_mem": "10.07G", "grad_norm": 2.07605, "iter": "40/60", "loss": 0.08677, "lr": 0.0010141367, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:06:54][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48098, "dt_data": 0.00036, "dt_net": 0.48062, "epoch": "149/300", "eta": "1:12:42", "gpu_mem": "10.07G", "grad_norm": 7.07390, "iter": "50/60", "loss": 0.05303, "lr": 0.0010123915, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:07:00][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47162, "dt_data": 0.00019, "dt_net": 0.47142, "epoch": "149/300", "eta": "1:11:12", "gpu_mem": "10.07G", "grad_norm": 1.00243, "iter": "60/60", "loss": 0.04250, "lr": 0.0010106463, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:07:01][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.69793, "dt_data": 0.69793, "dt_net": 0.47142, "epoch": "149/300", "eta": "1:45:22", "gpu_mem": "10.07G", "grad_norm": 1.00243, "loss": 0.07711, "lr": 0.0010106463, "top1_acc": 97.81250, "top1_err": 2.55208, "top5_acc": 99.89583, "top5_err": 0.10417}
[06/12 20:07:01][INFO] train_net.py:  708: Epoch 148 takes 47.79s. Epochs from 0 to 148 take 48.08s in average and 48.06s in median.
[06/12 20:07:01][INFO] train_net.py:  714: For epoch 148, each iteraction takes 0.80s in average. From epoch 0 to 148, each iteraction takes 0.80s in average.
[06/12 20:07:18][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47278, "dt_data": 0.00040, "dt_net": 0.47238, "epoch": "150/300", "eta": "1:11:18", "gpu_mem": "10.07G", "grad_norm": 2.82161, "iter": "10/60", "loss": 0.04782, "lr": 0.0010089011, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:07:24][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47074, "dt_data": 0.00041, "dt_net": 0.47033, "epoch": "150/300", "eta": "1:10:55", "gpu_mem": "10.07G", "grad_norm": 2.01404, "iter": "20/60", "loss": 0.03116, "lr": 0.0010071558, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:07:30][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47026, "dt_data": 0.00039, "dt_net": 0.46987, "epoch": "150/300", "eta": "1:10:46", "gpu_mem": "10.07G", "grad_norm": 6.72653, "iter": "30/60", "loss": 0.08040, "lr": 0.0010054105, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:07:36][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47011, "dt_data": 0.00052, "dt_net": 0.46958, "epoch": "150/300", "eta": "1:10:40", "gpu_mem": "10.07G", "grad_norm": 3.93571, "iter": "40/60", "loss": 0.04501, "lr": 0.0010036652, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:07:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47404, "dt_data": 0.00034, "dt_net": 0.47370, "epoch": "150/300", "eta": "1:11:11", "gpu_mem": "10.07G", "grad_norm": 12.59058, "iter": "50/60", "loss": 0.08931, "lr": 0.0010019199, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:07:48][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47092, "dt_data": 0.00019, "dt_net": 0.47073, "epoch": "150/300", "eta": "1:10:38", "gpu_mem": "10.07G", "grad_norm": 4.33057, "iter": "60/60", "loss": 0.06733, "lr": 0.0010001745, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:07:48][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.68063, "dt_data": 0.68063, "dt_net": 0.47073, "epoch": "150/300", "eta": "1:42:05", "gpu_mem": "10.07G", "grad_norm": 4.33057, "loss": 0.07432, "lr": 0.0010001745, "top1_acc": 97.18750, "top1_err": 2.70833, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:07:48][INFO] train_net.py:  708: Epoch 149 takes 47.89s. Epochs from 0 to 149 take 48.08s in average and 48.06s in median.
[06/12 20:07:48][INFO] train_net.py:  714: For epoch 149, each iteraction takes 0.80s in average. From epoch 0 to 149, each iteraction takes 0.80s in average.
[06/12 20:07:48][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 20:08:49][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "150/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.15490, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:08:52][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "val_epoch", "epoch": "150/300", "gpu_mem": "10.07G", "min_top1_err": 22.40664, "min_top5_err": 2.69710, "time_diff": 0.60591, "top1_acc": 77.17842, "top1_err": 22.82158, "top5_acc": 97.30290, "top5_err": 2.69710}
[06/12 20:09:09][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46739, "dt_data": 0.00048, "dt_net": 0.46690, "epoch": "151/300", "eta": "1:10:01", "gpu_mem": "10.07G", "grad_norm": 11.95882, "iter": "10/60", "loss": 0.07261, "lr": 0.0009984292, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:09:15][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46904, "dt_data": 0.00040, "dt_net": 0.46864, "epoch": "151/300", "eta": "1:10:12", "gpu_mem": "10.07G", "grad_norm": 12.38673, "iter": "20/60", "loss": 0.05005, "lr": 0.0009966839, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:09:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46872, "dt_data": 0.00069, "dt_net": 0.46802, "epoch": "151/300", "eta": "1:10:04", "gpu_mem": "10.07G", "grad_norm": 6.94469, "iter": "30/60", "loss": 0.07429, "lr": 0.0009949386, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:09:27][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47092, "dt_data": 0.00063, "dt_net": 0.47028, "epoch": "151/300", "eta": "1:10:19", "gpu_mem": "10.07G", "grad_norm": 8.31681, "iter": "40/60", "loss": 0.10737, "lr": 0.0009931933, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:09:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46844, "dt_data": 0.00042, "dt_net": 0.46802, "epoch": "151/300", "eta": "1:09:52", "gpu_mem": "10.07G", "grad_norm": 6.50789, "iter": "50/60", "loss": 0.04294, "lr": 0.0009914480, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:09:39][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46673, "dt_data": 0.00020, "dt_net": 0.46653, "epoch": "151/300", "eta": "1:09:32", "gpu_mem": "10.07G", "grad_norm": 7.70360, "iter": "60/60", "loss": 0.10133, "lr": 0.0009897027, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:09:39][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.68551, "dt_data": 0.68551, "dt_net": 0.46653, "epoch": "151/300", "eta": "1:42:08", "gpu_mem": "10.07G", "grad_norm": 7.70360, "loss": 0.08645, "lr": 0.0009897027, "top1_acc": 96.77083, "top1_err": 3.02083, "top5_acc": 99.89583, "top5_err": 0.15625}
[06/12 20:09:39][INFO] train_net.py:  708: Epoch 150 takes 47.16s. Epochs from 0 to 150 take 48.07s in average and 48.05s in median.
[06/12 20:09:39][INFO] train_net.py:  714: For epoch 150, each iteraction takes 0.79s in average. From epoch 0 to 150, each iteraction takes 0.80s in average.
[06/12 20:09:56][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46711, "dt_data": 0.00031, "dt_net": 0.46680, "epoch": "152/300", "eta": "1:09:31", "gpu_mem": "10.07G", "grad_norm": 4.82816, "iter": "10/60", "loss": 0.05358, "lr": 0.0009879575, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:10:02][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47094, "dt_data": 0.00064, "dt_net": 0.47029, "epoch": "152/300", "eta": "1:10:00", "gpu_mem": "10.07G", "grad_norm": 11.75766, "iter": "20/60", "loss": 0.08097, "lr": 0.0009862123, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:10:08][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47676, "dt_data": 0.00049, "dt_net": 0.47626, "epoch": "152/300", "eta": "1:10:47", "gpu_mem": "10.07G", "grad_norm": 3.11658, "iter": "30/60", "loss": 0.05251, "lr": 0.0009844672, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:10:14][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48703, "dt_data": 0.00066, "dt_net": 0.48636, "epoch": "152/300", "eta": "1:12:14", "gpu_mem": "10.07G", "grad_norm": 2.88027, "iter": "40/60", "loss": 0.06584, "lr": 0.0009827221, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:10:20][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47763, "dt_data": 0.00071, "dt_net": 0.47691, "epoch": "152/300", "eta": "1:10:46", "gpu_mem": "10.07G", "grad_norm": 2.95739, "iter": "50/60", "loss": 0.02518, "lr": 0.0009809771, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:10:26][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46860, "dt_data": 0.00015, "dt_net": 0.46845, "epoch": "152/300", "eta": "1:09:21", "gpu_mem": "10.07G", "grad_norm": 2.15901, "iter": "60/60", "loss": 0.08069, "lr": 0.0009792321, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:10:26][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.69435, "dt_data": 0.69435, "dt_net": 0.46845, "epoch": "152/300", "eta": "1:42:45", "gpu_mem": "10.07G", "grad_norm": 2.15901, "loss": 0.06897, "lr": 0.0009792321, "top1_acc": 97.39583, "top1_err": 2.39583, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:10:26][INFO] train_net.py:  708: Epoch 151 takes 47.26s. Epochs from 0 to 151 take 48.07s in average and 48.05s in median.
[06/12 20:10:26][INFO] train_net.py:  714: For epoch 151, each iteraction takes 0.79s in average. From epoch 0 to 151, each iteraction takes 0.80s in average.
[06/12 20:10:44][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46760, "dt_data": 0.00033, "dt_net": 0.46728, "epoch": "153/300", "eta": "1:09:07", "gpu_mem": "10.07G", "grad_norm": 0.89705, "iter": "10/60", "loss": 0.06258, "lr": 0.0009774872, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:10:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47415, "dt_data": 0.00031, "dt_net": 0.47385, "epoch": "153/300", "eta": "1:10:00", "gpu_mem": "10.07G", "grad_norm": 2.36500, "iter": "20/60", "loss": 0.07632, "lr": 0.0009757423, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:10:56][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47799, "dt_data": 0.00169, "dt_net": 0.47630, "epoch": "153/300", "eta": "1:10:30", "gpu_mem": "10.07G", "grad_norm": 2.67785, "iter": "30/60", "loss": 0.05199, "lr": 0.0009739975, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:11:02][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47438, "dt_data": 0.00078, "dt_net": 0.47359, "epoch": "153/300", "eta": "1:09:53", "gpu_mem": "10.07G", "grad_norm": 3.28427, "iter": "40/60", "loss": 0.08536, "lr": 0.0009722528, "top1_acc": 100.00000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:11:09][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47526, "dt_data": 0.00041, "dt_net": 0.47485, "epoch": "153/300", "eta": "1:09:56", "gpu_mem": "10.07G", "grad_norm": 7.23835, "iter": "50/60", "loss": 0.05988, "lr": 0.0009705082, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:11:14][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46907, "dt_data": 0.00017, "dt_net": 0.46890, "epoch": "153/300", "eta": "1:08:57", "gpu_mem": "10.07G", "grad_norm": 1.93896, "iter": "60/60", "loss": 0.04152, "lr": 0.0009687637, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:11:15][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.70131, "dt_data": 0.70131, "dt_net": 0.46890, "epoch": "153/300", "eta": "1:43:05", "gpu_mem": "10.07G", "grad_norm": 1.93896, "loss": 0.08195, "lr": 0.0009687637, "top1_acc": 98.12500, "top1_err": 2.76042, "top5_acc": 100.00000, "top5_err": 0.05208}
[06/12 20:11:15][INFO] train_net.py:  708: Epoch 152 takes 48.39s. Epochs from 0 to 152 take 48.07s in average and 48.05s in median.
[06/12 20:11:15][INFO] train_net.py:  714: For epoch 152, each iteraction takes 0.81s in average. From epoch 0 to 152, each iteraction takes 0.80s in average.
[06/12 20:11:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.74991, "dt_data": 0.28059, "dt_net": 0.46932, "epoch": "154/300", "eta": "1:50:06", "gpu_mem": "10.07G", "grad_norm": 3.73040, "iter": "10/60", "loss": 0.09863, "lr": 0.0009670193, "top1_acc": 100.00000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:11:38][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47456, "dt_data": 0.00077, "dt_net": 0.47379, "epoch": "154/300", "eta": "1:09:36", "gpu_mem": "10.07G", "grad_norm": 6.06795, "iter": "20/60", "loss": 0.04908, "lr": 0.0009652749, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:11:45][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.24032, "dt_data": 0.77303, "dt_net": 0.46728, "epoch": "154/300", "eta": "3:01:42", "gpu_mem": "10.07G", "grad_norm": 2.92874, "iter": "30/60", "loss": 0.04208, "lr": 0.0009635307, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:11:51][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47297, "dt_data": 0.00086, "dt_net": 0.47209, "epoch": "154/300", "eta": "1:09:12", "gpu_mem": "10.07G", "grad_norm": 4.86727, "iter": "40/60", "loss": 0.06472, "lr": 0.0009617866, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:11:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.03471, "dt_data": 0.56429, "dt_net": 0.47042, "epoch": "154/300", "eta": "2:31:14", "gpu_mem": "10.07G", "grad_norm": 2.20193, "iter": "50/60", "loss": 0.10706, "lr": 0.0009600426, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:12:03][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46983, "dt_data": 0.00016, "dt_net": 0.46966, "epoch": "154/300", "eta": "1:08:35", "gpu_mem": "10.07G", "grad_norm": 0.77999, "iter": "60/60", "loss": 0.03496, "lr": 0.0009582987, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:12:04][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.72110, "dt_data": 0.72110, "dt_net": 0.46966, "epoch": "154/300", "eta": "1:45:16", "gpu_mem": "10.07G", "grad_norm": 0.77999, "loss": 0.09296, "lr": 0.0009582987, "top1_acc": 97.70833, "top1_err": 2.70833, "top5_acc": 99.79167, "top5_err": 0.26042}
[06/12 20:12:04][INFO] train_net.py:  708: Epoch 153 takes 49.12s. Epochs from 0 to 153 take 48.07s in average and 48.06s in median.
[06/12 20:12:04][INFO] train_net.py:  714: For epoch 153, each iteraction takes 0.82s in average. From epoch 0 to 153, each iteraction takes 0.80s in average.
[06/12 20:12:21][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47166, "dt_data": 0.00048, "dt_net": 0.47118, "epoch": "155/300", "eta": "1:08:47", "gpu_mem": "10.07G", "grad_norm": 6.67173, "iter": "10/60", "loss": 0.04174, "lr": 0.0009565550, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:12:27][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47208, "dt_data": 0.00094, "dt_net": 0.47113, "epoch": "155/300", "eta": "1:08:46", "gpu_mem": "10.07G", "grad_norm": 5.92985, "iter": "20/60", "loss": 0.11257, "lr": 0.0009548114, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:12:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47537, "dt_data": 0.00058, "dt_net": 0.47478, "epoch": "155/300", "eta": "1:09:09", "gpu_mem": "10.07G", "grad_norm": 5.01765, "iter": "30/60", "loss": 0.06488, "lr": 0.0009530679, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:12:39][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47586, "dt_data": 0.00048, "dt_net": 0.47538, "epoch": "155/300", "eta": "1:09:09", "gpu_mem": "10.07G", "grad_norm": 0.36197, "iter": "40/60", "loss": 0.02518, "lr": 0.0009513246, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:12:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47133, "dt_data": 0.00034, "dt_net": 0.47099, "epoch": "155/300", "eta": "1:08:25", "gpu_mem": "10.07G", "grad_norm": 3.66453, "iter": "50/60", "loss": 0.02816, "lr": 0.0009495814, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:12:51][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46993, "dt_data": 0.00016, "dt_net": 0.46976, "epoch": "155/300", "eta": "1:08:08", "gpu_mem": "10.07G", "grad_norm": 4.06253, "iter": "60/60", "loss": 0.08670, "lr": 0.0009478383, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:12:52][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.69583, "dt_data": 0.69583, "dt_net": 0.46976, "epoch": "155/300", "eta": "1:40:53", "gpu_mem": "10.07G", "grad_norm": 4.06253, "loss": 0.08958, "lr": 0.0009478383, "top1_acc": 96.97917, "top1_err": 2.91667, "top5_acc": 99.89583, "top5_err": 0.26042}
[06/12 20:12:52][INFO] train_net.py:  708: Epoch 154 takes 47.98s. Epochs from 0 to 154 take 48.07s in average and 48.05s in median.
[06/12 20:12:52][INFO] train_net.py:  714: For epoch 154, each iteraction takes 0.80s in average. From epoch 0 to 154, each iteraction takes 0.80s in average.
[06/12 20:12:52][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 20:13:53][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "155/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.12967, "top1_acc": 76.56250, "top1_err": 23.43750, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 20:13:56][INFO] logging.py:  101: json_stats: {"RAM": "13.18/31.07G", "_type": "val_epoch", "epoch": "155/300", "gpu_mem": "10.07G", "min_top1_err": 22.40664, "min_top5_err": 2.69710, "time_diff": 0.60399, "top1_acc": 76.14108, "top1_err": 23.85892, "top5_acc": 96.47303, "top5_err": 3.52697}
[06/12 20:14:14][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46743, "dt_data": 0.00068, "dt_net": 0.46675, "epoch": "156/300", "eta": "1:07:41", "gpu_mem": "10.07G", "grad_norm": 10.36119, "iter": "10/60", "loss": 0.04987, "lr": 0.0009460955, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:14:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46856, "dt_data": 0.00040, "dt_net": 0.46816, "epoch": "156/300", "eta": "1:07:47", "gpu_mem": "10.07G", "grad_norm": 6.15309, "iter": "20/60", "loss": 0.08538, "lr": 0.0009443528, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:14:26][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48068, "dt_data": 0.00033, "dt_net": 0.48035, "epoch": "156/300", "eta": "1:09:27", "gpu_mem": "10.07G", "grad_norm": 3.71444, "iter": "30/60", "loss": 0.10100, "lr": 0.0009426102, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:14:32][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46830, "dt_data": 0.00038, "dt_net": 0.46792, "epoch": "156/300", "eta": "1:07:35", "gpu_mem": "10.07G", "grad_norm": 4.71161, "iter": "40/60", "loss": 0.02923, "lr": 0.0009408679, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:14:38][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46997, "dt_data": 0.00066, "dt_net": 0.46931, "epoch": "156/300", "eta": "1:07:45", "gpu_mem": "10.07G", "grad_norm": 4.80678, "iter": "50/60", "loss": 0.04656, "lr": 0.0009391257, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:14:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46623, "dt_data": 0.00017, "dt_net": 0.46606, "epoch": "156/300", "eta": "1:07:08", "gpu_mem": "10.07G", "grad_norm": 4.76180, "iter": "60/60", "loss": 0.12170, "lr": 0.0009373837, "top1_acc": 90.62500, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:14:44][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.69646, "dt_data": 0.69646, "dt_net": 0.46606, "epoch": "156/300", "eta": "1:40:17", "gpu_mem": "10.07G", "grad_norm": 4.76180, "loss": 0.08424, "lr": 0.0009373837, "top1_acc": 96.97917, "top1_err": 2.86458, "top5_acc": 99.89583, "top5_err": 0.10417}
[06/12 20:14:44][INFO] train_net.py:  708: Epoch 155 takes 47.93s. Epochs from 0 to 155 take 48.07s in average and 48.05s in median.
[06/12 20:14:44][INFO] train_net.py:  714: For epoch 155, each iteraction takes 0.80s in average. From epoch 0 to 155, each iteraction takes 0.80s in average.
[06/12 20:15:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46926, "dt_data": 0.00057, "dt_net": 0.46868, "epoch": "157/300", "eta": "1:07:29", "gpu_mem": "10.07G", "grad_norm": 3.75839, "iter": "10/60", "loss": 0.10816, "lr": 0.0009356419, "top1_acc": 96.87500, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:15:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47391, "dt_data": 0.00070, "dt_net": 0.47321, "epoch": "157/300", "eta": "1:08:05", "gpu_mem": "10.07G", "grad_norm": 4.28207, "iter": "20/60", "loss": 0.09628, "lr": 0.0009339002, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:15:14][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47183, "dt_data": 0.00048, "dt_net": 0.47135, "epoch": "157/300", "eta": "1:07:42", "gpu_mem": "10.07G", "grad_norm": 2.51164, "iter": "30/60", "loss": 0.05797, "lr": 0.0009321588, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:15:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47500, "dt_data": 0.00065, "dt_net": 0.47434, "epoch": "157/300", "eta": "1:08:04", "gpu_mem": "10.07G", "grad_norm": 0.35674, "iter": "40/60", "loss": 0.01293, "lr": 0.0009304176, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:15:26][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47644, "dt_data": 0.00042, "dt_net": 0.47602, "epoch": "157/300", "eta": "1:08:12", "gpu_mem": "10.07G", "grad_norm": 4.62488, "iter": "50/60", "loss": 0.03927, "lr": 0.0009286766, "top1_acc": 96.87500, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:15:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46808, "dt_data": 0.00014, "dt_net": 0.46793, "epoch": "157/300", "eta": "1:06:56", "gpu_mem": "10.07G", "grad_norm": 3.53803, "iter": "60/60", "loss": 0.06233, "lr": 0.0009269359, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:15:32][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.69384, "dt_data": 0.69384, "dt_net": 0.46793, "epoch": "157/300", "eta": "1:39:12", "gpu_mem": "10.07G", "grad_norm": 3.53803, "loss": 0.08117, "lr": 0.0009269359, "top1_acc": 96.25000, "top1_err": 2.96875, "top5_acc": 99.79167, "top5_err": 0.10417}
[06/12 20:15:32][INFO] train_net.py:  708: Epoch 156 takes 47.80s. Epochs from 0 to 156 take 48.07s in average and 48.04s in median.
[06/12 20:15:32][INFO] train_net.py:  714: For epoch 156, each iteraction takes 0.80s in average. From epoch 0 to 156, each iteraction takes 0.80s in average.
[06/12 20:15:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47090, "dt_data": 0.00088, "dt_net": 0.47001, "epoch": "158/300", "eta": "1:07:15", "gpu_mem": "10.07G", "grad_norm": 2.01817, "iter": "10/60", "loss": 0.04172, "lr": 0.0009251953, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:15:56][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47713, "dt_data": 0.00055, "dt_net": 0.47657, "epoch": "158/300", "eta": "1:08:04", "gpu_mem": "10.07G", "grad_norm": 0.96946, "iter": "20/60", "loss": 0.04975, "lr": 0.0009234550, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:16:02][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47719, "dt_data": 0.00051, "dt_net": 0.47668, "epoch": "158/300", "eta": "1:08:00", "gpu_mem": "10.07G", "grad_norm": 7.53957, "iter": "30/60", "loss": 0.09947, "lr": 0.0009217149, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:16:08][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47168, "dt_data": 0.00043, "dt_net": 0.47125, "epoch": "158/300", "eta": "1:07:08", "gpu_mem": "10.07G", "grad_norm": 5.17368, "iter": "40/60", "loss": 0.11708, "lr": 0.0009199750, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:16:14][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47645, "dt_data": 0.00043, "dt_net": 0.47601, "epoch": "158/300", "eta": "1:07:44", "gpu_mem": "10.07G", "grad_norm": 2.42551, "iter": "50/60", "loss": 0.07529, "lr": 0.0009182354, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:16:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46835, "dt_data": 0.00018, "dt_net": 0.46817, "epoch": "158/300", "eta": "1:06:30", "gpu_mem": "10.07G", "grad_norm": 1.80091, "iter": "60/60", "loss": 0.03732, "lr": 0.0009164961, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:16:20][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.69775, "dt_data": 0.69775, "dt_net": 0.46817, "epoch": "158/300", "eta": "1:39:04", "gpu_mem": "10.07G", "grad_norm": 1.80091, "loss": 0.08379, "lr": 0.0009164961, "top1_acc": 97.81250, "top1_err": 2.60417, "top5_acc": 99.79167, "top5_err": 0.20833}
[06/12 20:16:20][INFO] train_net.py:  708: Epoch 157 takes 48.01s. Epochs from 0 to 157 take 48.07s in average and 48.04s in median.
[06/12 20:16:20][INFO] train_net.py:  714: For epoch 157, each iteraction takes 0.80s in average. From epoch 0 to 157, each iteraction takes 0.80s in average.
[06/12 20:16:38][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47117, "dt_data": 0.00120, "dt_net": 0.46996, "epoch": "159/300", "eta": "1:06:49", "gpu_mem": "10.07G", "grad_norm": 2.48630, "iter": "10/60", "loss": 0.04710, "lr": 0.0009147570, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:16:44][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47309, "dt_data": 0.00057, "dt_net": 0.47252, "epoch": "159/300", "eta": "1:07:01", "gpu_mem": "10.07G", "grad_norm": 4.81992, "iter": "20/60", "loss": 0.09624, "lr": 0.0009130181, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:16:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47202, "dt_data": 0.00032, "dt_net": 0.47170, "epoch": "159/300", "eta": "1:06:47", "gpu_mem": "10.07G", "grad_norm": 2.45730, "iter": "30/60", "loss": 0.09385, "lr": 0.0009112795, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:16:56][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47537, "dt_data": 0.00045, "dt_net": 0.47491, "epoch": "159/300", "eta": "1:07:11", "gpu_mem": "10.07G", "grad_norm": 3.90838, "iter": "40/60", "loss": 0.05066, "lr": 0.0009095412, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:17:03][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47239, "dt_data": 0.00039, "dt_net": 0.47200, "epoch": "159/300", "eta": "1:06:41", "gpu_mem": "10.07G", "grad_norm": 5.68995, "iter": "50/60", "loss": 0.03991, "lr": 0.0009078032, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:17:08][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46939, "dt_data": 0.00017, "dt_net": 0.46922, "epoch": "159/300", "eta": "1:06:11", "gpu_mem": "10.07G", "grad_norm": 6.41787, "iter": "60/60", "loss": 0.07029, "lr": 0.0009060654, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:17:09][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.71712, "dt_data": 0.71712, "dt_net": 0.46922, "epoch": "159/300", "eta": "1:41:06", "gpu_mem": "10.07G", "grad_norm": 6.41787, "loss": 0.07524, "lr": 0.0009060654, "top1_acc": 97.08333, "top1_err": 2.70833, "top5_acc": 100.00000, "top5_err": 0.10417}
[06/12 20:17:09][INFO] train_net.py:  708: Epoch 158 takes 48.95s. Epochs from 0 to 158 take 48.08s in average and 48.04s in median.
[06/12 20:17:09][INFO] train_net.py:  714: For epoch 158, each iteraction takes 0.82s in average. From epoch 0 to 158, each iteraction takes 0.80s in average.
[06/12 20:17:26][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47359, "dt_data": 0.00037, "dt_net": 0.47322, "epoch": "160/300", "eta": "1:06:41", "gpu_mem": "10.07G", "grad_norm": 2.66464, "iter": "10/60", "loss": 0.03953, "lr": 0.0009043280, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:17:32][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47292, "dt_data": 0.00038, "dt_net": 0.47254, "epoch": "160/300", "eta": "1:06:31", "gpu_mem": "10.07G", "grad_norm": 1.10139, "iter": "20/60", "loss": 0.02961, "lr": 0.0009025908, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:17:38][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.61810, "dt_data": 0.00041, "dt_net": 0.61768, "epoch": "160/300", "eta": "1:26:50", "gpu_mem": "10.07G", "grad_norm": 1.45993, "iter": "30/60", "loss": 0.03606, "lr": 0.0009008539, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:17:44][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47502, "dt_data": 0.00041, "dt_net": 0.47461, "epoch": "160/300", "eta": "1:06:39", "gpu_mem": "10.07G", "grad_norm": 8.68152, "iter": "40/60", "loss": 0.04575, "lr": 0.0008991173, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:17:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.93410, "dt_data": 0.00036, "dt_net": 0.93374, "epoch": "160/300", "eta": "2:10:55", "gpu_mem": "10.07G", "grad_norm": 5.56501, "iter": "50/60", "loss": 0.07878, "lr": 0.0008973811, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:17:56][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46962, "dt_data": 0.00019, "dt_net": 0.46942, "epoch": "160/300", "eta": "1:05:44", "gpu_mem": "10.07G", "grad_norm": 4.44924, "iter": "60/60", "loss": 0.05745, "lr": 0.0008956451, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:17:57][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.69335, "dt_data": 0.69335, "dt_net": 0.46942, "epoch": "160/300", "eta": "1:37:03", "gpu_mem": "10.07G", "grad_norm": 4.44924, "loss": 0.06440, "lr": 0.0008956451, "top1_acc": 97.50000, "top1_err": 2.03125, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:17:57][INFO] train_net.py:  708: Epoch 159 takes 47.81s. Epochs from 0 to 159 take 48.07s in average and 48.04s in median.
[06/12 20:17:57][INFO] train_net.py:  714: For epoch 159, each iteraction takes 0.80s in average. From epoch 0 to 159, each iteraction takes 0.80s in average.
[06/12 20:17:57][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 20:18:58][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "160/300", "eta": "0:00:03", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.64672, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 20:19:01][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "val_epoch", "epoch": "160/300", "gpu_mem": "10.07G", "min_top1_err": 22.40664, "min_top5_err": 2.69710, "time_diff": 0.61018, "top1_acc": 74.27386, "top1_err": 25.72614, "top5_acc": 97.09544, "top5_err": 2.90456}
[06/12 20:19:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.27526, "dt_data": 0.00067, "dt_net": 1.27459, "epoch": "161/300", "eta": "2:58:19", "gpu_mem": "10.07G", "grad_norm": 3.29719, "iter": "10/60", "loss": 0.03703, "lr": 0.0008939095, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:19:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46565, "dt_data": 0.00042, "dt_net": 0.46523, "epoch": "161/300", "eta": "1:05:02", "gpu_mem": "10.07G", "grad_norm": 8.78753, "iter": "20/60", "loss": 0.01631, "lr": 0.0008921742, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:19:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.05303, "dt_data": 0.00040, "dt_net": 1.05263, "epoch": "161/300", "eta": "2:26:53", "gpu_mem": "10.07G", "grad_norm": 8.27794, "iter": "30/60", "loss": 0.06025, "lr": 0.0008904392, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:19:36][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46948, "dt_data": 0.00049, "dt_net": 0.46899, "epoch": "161/300", "eta": "1:05:24", "gpu_mem": "10.07G", "grad_norm": 5.34043, "iter": "40/60", "loss": 0.06044, "lr": 0.0008887045, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:19:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.70561, "dt_data": 0.00032, "dt_net": 0.70529, "epoch": "161/300", "eta": "1:38:11", "gpu_mem": "10.07G", "grad_norm": 0.21926, "iter": "50/60", "loss": 0.06275, "lr": 0.0008869702, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:19:48][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46673, "dt_data": 0.00016, "dt_net": 0.46656, "epoch": "161/300", "eta": "1:04:52", "gpu_mem": "10.07G", "grad_norm": 8.42777, "iter": "60/60", "loss": 0.02619, "lr": 0.0008852362, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:19:49][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.70257, "dt_data": 0.70257, "dt_net": 0.46656, "epoch": "161/300", "eta": "1:37:39", "gpu_mem": "10.07G", "grad_norm": 8.42777, "loss": 0.06479, "lr": 0.0008852362, "top1_acc": 98.02083, "top1_err": 2.18750, "top5_acc": 99.89583, "top5_err": 0.05208}
[06/12 20:19:49][INFO] train_net.py:  708: Epoch 160 takes 47.63s. Epochs from 0 to 160 take 48.07s in average and 48.04s in median.
[06/12 20:19:49][INFO] train_net.py:  714: For epoch 160, each iteraction takes 0.79s in average. From epoch 0 to 160, each iteraction takes 0.80s in average.
[06/12 20:20:06][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47473, "dt_data": 0.00080, "dt_net": 0.47392, "epoch": "162/300", "eta": "1:05:54", "gpu_mem": "10.07G", "grad_norm": 10.48450, "iter": "10/60", "loss": 0.04961, "lr": 0.0008835026, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:20:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47261, "dt_data": 0.00038, "dt_net": 0.47222, "epoch": "162/300", "eta": "1:05:32", "gpu_mem": "10.07G", "grad_norm": 0.64376, "iter": "20/60", "loss": 0.03433, "lr": 0.0008817693, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:20:18][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.83191, "dt_data": 0.00040, "dt_net": 0.83150, "epoch": "162/300", "eta": "1:55:13", "gpu_mem": "10.07G", "grad_norm": 4.61144, "iter": "30/60", "loss": 0.03366, "lr": 0.0008800364, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:20:24][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47387, "dt_data": 0.00097, "dt_net": 0.47289, "epoch": "162/300", "eta": "1:05:33", "gpu_mem": "10.07G", "grad_norm": 3.36659, "iter": "40/60", "loss": 0.06187, "lr": 0.0008783039, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:20:29][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.75213, "dt_data": 0.00999, "dt_net": 0.74213, "epoch": "162/300", "eta": "1:43:55", "gpu_mem": "10.07G", "grad_norm": 3.43724, "iter": "50/60", "loss": 0.10780, "lr": 0.0008765717, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:20:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46775, "dt_data": 0.00017, "dt_net": 0.46758, "epoch": "162/300", "eta": "1:04:33", "gpu_mem": "10.07G", "grad_norm": 0.80884, "iter": "60/60", "loss": 0.04558, "lr": 0.0008748399, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:20:36][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.69095, "dt_data": 0.69095, "dt_net": 0.46758, "epoch": "162/300", "eta": "1:35:20", "gpu_mem": "10.07G", "grad_norm": 0.80884, "loss": 0.07856, "lr": 0.0008748399, "top1_acc": 97.08333, "top1_err": 2.60417, "top5_acc": 99.89583, "top5_err": 0.05208}
[06/12 20:20:36][INFO] train_net.py:  708: Epoch 161 takes 46.85s. Epochs from 0 to 161 take 48.06s in average and 48.04s in median.
[06/12 20:20:36][INFO] train_net.py:  714: For epoch 161, each iteraction takes 0.78s in average. From epoch 0 to 161, each iteraction takes 0.80s in average.
[06/12 20:20:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47069, "dt_data": 0.00034, "dt_net": 0.47035, "epoch": "163/300", "eta": "1:04:52", "gpu_mem": "10.07G", "grad_norm": 2.72741, "iter": "10/60", "loss": 0.06338, "lr": 0.0008731085, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:20:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47419, "dt_data": 0.00041, "dt_net": 0.47378, "epoch": "163/300", "eta": "1:05:16", "gpu_mem": "10.07G", "grad_norm": 1.89051, "iter": "20/60", "loss": 0.04021, "lr": 0.0008713775, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:21:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.98435, "dt_data": 0.00073, "dt_net": 0.98361, "epoch": "163/300", "eta": "2:15:20", "gpu_mem": "10.07G", "grad_norm": 0.98543, "iter": "30/60", "loss": 0.04656, "lr": 0.0008696468, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:21:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47160, "dt_data": 0.00039, "dt_net": 0.47120, "epoch": "163/300", "eta": "1:04:45", "gpu_mem": "10.07G", "grad_norm": 6.81224, "iter": "40/60", "loss": 0.03545, "lr": 0.0008679166, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:21:17][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39877, "dt_data": 0.92872, "dt_net": 0.47005, "epoch": "163/300", "eta": "3:11:51", "gpu_mem": "10.07G", "grad_norm": 0.28310, "iter": "50/60", "loss": 0.05813, "lr": 0.0008661868, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:21:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46995, "dt_data": 0.00016, "dt_net": 0.46979, "epoch": "163/300", "eta": "1:04:22", "gpu_mem": "10.07G", "grad_norm": 4.76241, "iter": "60/60", "loss": 0.07071, "lr": 0.0008644573, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:21:24][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.69861, "dt_data": 0.69861, "dt_net": 0.46979, "epoch": "163/300", "eta": "1:35:42", "gpu_mem": "10.07G", "grad_norm": 4.76241, "loss": 0.07464, "lr": 0.0008644573, "top1_acc": 97.91667, "top1_err": 2.29167, "top5_acc": 100.00000, "top5_err": 0.05208}
[06/12 20:21:24][INFO] train_net.py:  708: Epoch 162 takes 48.02s. Epochs from 0 to 162 take 48.06s in average and 48.04s in median.
[06/12 20:21:24][INFO] train_net.py:  714: For epoch 162, each iteraction takes 0.80s in average. From epoch 0 to 162, each iteraction takes 0.80s in average.
[06/12 20:21:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47114, "dt_data": 0.00043, "dt_net": 0.47070, "epoch": "164/300", "eta": "1:04:28", "gpu_mem": "10.07G", "grad_norm": 5.99442, "iter": "10/60", "loss": 0.04011, "lr": 0.0008627283, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:21:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47069, "dt_data": 0.00049, "dt_net": 0.47020, "epoch": "164/300", "eta": "1:04:19", "gpu_mem": "10.07G", "grad_norm": 1.03872, "iter": "20/60", "loss": 0.02827, "lr": 0.0008609997, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:21:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47987, "dt_data": 0.00070, "dt_net": 0.47916, "epoch": "164/300", "eta": "1:05:30", "gpu_mem": "10.07G", "grad_norm": 3.53228, "iter": "30/60", "loss": 0.04383, "lr": 0.0008592716, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:21:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47356, "dt_data": 0.00033, "dt_net": 0.47323, "epoch": "164/300", "eta": "1:04:33", "gpu_mem": "10.07G", "grad_norm": 2.69775, "iter": "40/60", "loss": 0.02795, "lr": 0.0008575438, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:22:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47470, "dt_data": 0.00066, "dt_net": 0.47403, "epoch": "164/300", "eta": "1:04:38", "gpu_mem": "10.07G", "grad_norm": 5.90745, "iter": "50/60", "loss": 0.04790, "lr": 0.0008558165, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:22:10][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46859, "dt_data": 0.00022, "dt_net": 0.46837, "epoch": "164/300", "eta": "1:03:43", "gpu_mem": "10.07G", "grad_norm": 6.30779, "iter": "60/60", "loss": 0.07204, "lr": 0.0008540896, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:22:11][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.70425, "dt_data": 0.70425, "dt_net": 0.46837, "epoch": "164/300", "eta": "1:35:45", "gpu_mem": "10.07G", "grad_norm": 6.30779, "loss": 0.06404, "lr": 0.0008540896, "top1_acc": 98.22917, "top1_err": 2.03125, "top5_acc": 99.79167, "top5_err": 0.15625}
[06/12 20:22:11][INFO] train_net.py:  708: Epoch 163 takes 47.40s. Epochs from 0 to 163 take 48.06s in average and 48.04s in median.
[06/12 20:22:11][INFO] train_net.py:  714: For epoch 163, each iteraction takes 0.79s in average. From epoch 0 to 163, each iteraction takes 0.80s in average.
[06/12 20:22:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.97467, "dt_data": 0.50305, "dt_net": 0.47161, "epoch": "165/300", "eta": "2:12:23", "gpu_mem": "10.07G", "grad_norm": 2.00610, "iter": "10/60", "loss": 0.06531, "lr": 0.0008523632, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:22:34][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47288, "dt_data": 0.00034, "dt_net": 0.47254, "epoch": "165/300", "eta": "1:04:09", "gpu_mem": "10.07G", "grad_norm": 2.56118, "iter": "20/60", "loss": 0.01565, "lr": 0.0008506372, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:22:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.84611, "dt_data": 0.37410, "dt_net": 0.47200, "epoch": "165/300", "eta": "1:54:38", "gpu_mem": "10.07G", "grad_norm": 4.69124, "iter": "30/60", "loss": 0.06189, "lr": 0.0008489117, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:22:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47474, "dt_data": 0.00078, "dt_net": 0.47397, "epoch": "165/300", "eta": "1:04:14", "gpu_mem": "10.07G", "grad_norm": 8.05284, "iter": "40/60", "loss": 0.10683, "lr": 0.0008471866, "top1_acc": 96.87500, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:22:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47441, "dt_data": 0.00062, "dt_net": 0.47379, "epoch": "165/300", "eta": "1:04:07", "gpu_mem": "10.07G", "grad_norm": 3.41767, "iter": "50/60", "loss": 0.09048, "lr": 0.0008454620, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:22:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46938, "dt_data": 0.00039, "dt_net": 0.46899, "epoch": "165/300", "eta": "1:03:22", "gpu_mem": "10.07G", "grad_norm": 0.15229, "iter": "60/60", "loss": 0.03749, "lr": 0.0008437379, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:22:58][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.68747, "dt_data": 0.68747, "dt_net": 0.46899, "epoch": "165/300", "eta": "1:32:48", "gpu_mem": "10.07G", "grad_norm": 0.15229, "loss": 0.06562, "lr": 0.0008437379, "top1_acc": 97.81250, "top1_err": 2.39583, "top5_acc": 100.00000, "top5_err": 0.10417}
[06/12 20:22:58][INFO] train_net.py:  708: Epoch 164 takes 47.14s. Epochs from 0 to 164 take 48.05s in average and 48.04s in median.
[06/12 20:22:58][INFO] train_net.py:  714: For epoch 164, each iteraction takes 0.79s in average. From epoch 0 to 164, each iteraction takes 0.80s in average.
[06/12 20:22:58][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 20:23:59][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "165/300", "eta": "0:00:01", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.19608, "top1_acc": 76.56250, "top1_err": 23.43750, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 20:24:03][INFO] logging.py:  101: json_stats: {"RAM": "13.16/31.07G", "_type": "val_epoch", "epoch": "165/300", "gpu_mem": "10.07G", "min_top1_err": 22.40664, "min_top5_err": 2.69710, "time_diff": 0.60247, "top1_acc": 75.10373, "top1_err": 24.89627, "top5_acc": 96.26556, "top5_err": 3.73444}
[06/12 20:24:20][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.91175, "dt_data": 0.00043, "dt_net": 0.91131, "epoch": "166/300", "eta": "2:02:56", "gpu_mem": "10.07G", "grad_norm": 7.37787, "iter": "10/60", "loss": 0.05192, "lr": 0.0008420143, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:24:26][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47129, "dt_data": 0.00095, "dt_net": 0.47033, "epoch": "166/300", "eta": "1:03:27", "gpu_mem": "10.07G", "grad_norm": 9.89813, "iter": "20/60", "loss": 0.05485, "lr": 0.0008402911, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:24:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47296, "dt_data": 0.00039, "dt_net": 0.47257, "epoch": "166/300", "eta": "1:03:36", "gpu_mem": "10.07G", "grad_norm": 0.87457, "iter": "30/60", "loss": 0.03224, "lr": 0.0008385684, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:24:38][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46951, "dt_data": 0.00042, "dt_net": 0.46909, "epoch": "166/300", "eta": "1:03:04", "gpu_mem": "10.07G", "grad_norm": 1.34222, "iter": "40/60", "loss": 0.04554, "lr": 0.0008368462, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:24:44][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47621, "dt_data": 0.00065, "dt_net": 0.47556, "epoch": "166/300", "eta": "1:03:53", "gpu_mem": "10.07G", "grad_norm": 5.51927, "iter": "50/60", "loss": 0.04458, "lr": 0.0008351245, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:24:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46720, "dt_data": 0.00019, "dt_net": 0.46701, "epoch": "166/300", "eta": "1:02:36", "gpu_mem": "10.07G", "grad_norm": 1.54039, "iter": "60/60", "loss": 0.04230, "lr": 0.0008334033, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:24:50][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.69581, "dt_data": 0.69581, "dt_net": 0.46701, "epoch": "166/300", "eta": "1:33:14", "gpu_mem": "10.07G", "grad_norm": 1.54039, "loss": 0.06207, "lr": 0.0008334033, "top1_acc": 97.81250, "top1_err": 2.18750, "top5_acc": 99.79167, "top5_err": 0.10417}
[06/12 20:24:50][INFO] train_net.py:  708: Epoch 165 takes 47.65s. Epochs from 0 to 165 take 48.05s in average and 48.03s in median.
[06/12 20:24:50][INFO] train_net.py:  714: For epoch 165, each iteraction takes 0.79s in average. From epoch 0 to 165, each iteraction takes 0.80s in average.
[06/12 20:25:08][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48646, "dt_data": 0.01725, "dt_net": 0.46920, "epoch": "167/300", "eta": "1:05:06", "gpu_mem": "10.07G", "grad_norm": 10.71219, "iter": "10/60", "loss": 0.09689, "lr": 0.0008316827, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:25:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47369, "dt_data": 0.00037, "dt_net": 0.47332, "epoch": "167/300", "eta": "1:03:18", "gpu_mem": "10.07G", "grad_norm": 9.02036, "iter": "20/60", "loss": 0.03540, "lr": 0.0008299625, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:25:20][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47498, "dt_data": 0.00038, "dt_net": 0.47459, "epoch": "167/300", "eta": "1:03:24", "gpu_mem": "10.07G", "grad_norm": 3.02930, "iter": "30/60", "loss": 0.04933, "lr": 0.0008282428, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:25:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47735, "dt_data": 0.00043, "dt_net": 0.47692, "epoch": "167/300", "eta": "1:03:38", "gpu_mem": "10.07G", "grad_norm": 11.77054, "iter": "40/60", "loss": 0.08142, "lr": 0.0008265237, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:25:32][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47362, "dt_data": 0.00050, "dt_net": 0.47311, "epoch": "167/300", "eta": "1:03:04", "gpu_mem": "10.07G", "grad_norm": 7.45213, "iter": "50/60", "loss": 0.02477, "lr": 0.0008248051, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:25:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.76172, "dt_data": 0.29524, "dt_net": 0.46647, "epoch": "167/300", "eta": "1:41:18", "gpu_mem": "10.07G", "grad_norm": 0.15233, "iter": "60/60", "loss": 0.05942, "lr": 0.0008230870, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:25:38][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.68691, "dt_data": 0.68690, "dt_net": 0.46647, "epoch": "167/300", "eta": "1:31:21", "gpu_mem": "10.07G", "grad_norm": 0.15233, "loss": 0.07299, "lr": 0.0008230870, "top1_acc": 97.70833, "top1_err": 2.91667, "top5_acc": 99.89583, "top5_err": 0.10417}
[06/12 20:25:38][INFO] train_net.py:  708: Epoch 166 takes 47.69s. Epochs from 0 to 166 take 48.05s in average and 48.03s in median.
[06/12 20:25:38][INFO] train_net.py:  714: For epoch 166, each iteraction takes 0.79s in average. From epoch 0 to 166, each iteraction takes 0.80s in average.
[06/12 20:25:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47344, "dt_data": 0.00035, "dt_net": 0.47308, "epoch": "168/300", "eta": "1:02:53", "gpu_mem": "10.07G", "grad_norm": 0.80179, "iter": "10/60", "loss": 0.04553, "lr": 0.0008213695, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:26:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47749, "dt_data": 0.00055, "dt_net": 0.47694, "epoch": "168/300", "eta": "1:03:20", "gpu_mem": "10.07G", "grad_norm": 3.05713, "iter": "20/60", "loss": 0.05464, "lr": 0.0008196525, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:26:08][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47683, "dt_data": 0.00081, "dt_net": 0.47601, "epoch": "168/300", "eta": "1:03:10", "gpu_mem": "10.07G", "grad_norm": 0.40951, "iter": "30/60", "loss": 0.01695, "lr": 0.0008179361, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:26:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47565, "dt_data": 0.00033, "dt_net": 0.47533, "epoch": "168/300", "eta": "1:02:56", "gpu_mem": "10.07G", "grad_norm": 3.33218, "iter": "40/60", "loss": 0.04860, "lr": 0.0008162202, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:26:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47663, "dt_data": 0.00040, "dt_net": 0.47623, "epoch": "168/300", "eta": "1:02:59", "gpu_mem": "10.07G", "grad_norm": 7.64909, "iter": "50/60", "loss": 0.02475, "lr": 0.0008145049, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:26:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47103, "dt_data": 0.00016, "dt_net": 0.47086, "epoch": "168/300", "eta": "1:02:10", "gpu_mem": "10.07G", "grad_norm": 7.71020, "iter": "60/60", "loss": 0.06019, "lr": 0.0008127901, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:26:26][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.69389, "dt_data": 0.69389, "dt_net": 0.47086, "epoch": "168/300", "eta": "1:31:35", "gpu_mem": "10.07G", "grad_norm": 7.71020, "loss": 0.05789, "lr": 0.0008127901, "top1_acc": 98.02083, "top1_err": 1.77083, "top5_acc": 100.00000, "top5_err": 0.05208}
[06/12 20:26:26][INFO] train_net.py:  708: Epoch 167 takes 47.36s. Epochs from 0 to 167 take 48.05s in average and 48.03s in median.
[06/12 20:26:26][INFO] train_net.py:  714: For epoch 167, each iteraction takes 0.79s in average. From epoch 0 to 167, each iteraction takes 0.80s in average.
[06/12 20:26:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47584, "dt_data": 0.00057, "dt_net": 0.47526, "epoch": "169/300", "eta": "1:02:43", "gpu_mem": "10.07G", "grad_norm": 0.30476, "iter": "10/60", "loss": 0.06540, "lr": 0.0008110759, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:26:48][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47711, "dt_data": 0.00050, "dt_net": 0.47661, "epoch": "169/300", "eta": "1:02:49", "gpu_mem": "10.07G", "grad_norm": 8.56347, "iter": "20/60", "loss": 0.06108, "lr": 0.0008093623, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:26:54][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47334, "dt_data": 0.00047, "dt_net": 0.47286, "epoch": "169/300", "eta": "1:02:14", "gpu_mem": "10.07G", "grad_norm": 4.70573, "iter": "30/60", "loss": 0.03998, "lr": 0.0008076493, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:27:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47226, "dt_data": 0.00037, "dt_net": 0.47189, "epoch": "169/300", "eta": "1:02:01", "gpu_mem": "10.07G", "grad_norm": 3.24914, "iter": "40/60", "loss": 0.03488, "lr": 0.0008059369, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:27:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47367, "dt_data": 0.00060, "dt_net": 0.47307, "epoch": "169/300", "eta": "1:02:07", "gpu_mem": "10.07G", "grad_norm": 4.19603, "iter": "50/60", "loss": 0.04454, "lr": 0.0008042250, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:27:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47156, "dt_data": 0.00016, "dt_net": 0.47140, "epoch": "169/300", "eta": "1:01:46", "gpu_mem": "10.07G", "grad_norm": 1.20028, "iter": "60/60", "loss": 0.02948, "lr": 0.0008025138, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:27:13][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.69020, "dt_data": 0.69020, "dt_net": 0.47140, "epoch": "169/300", "eta": "1:30:24", "gpu_mem": "10.07G", "grad_norm": 1.20028, "loss": 0.06302, "lr": 0.0008025138, "top1_acc": 98.12500, "top1_err": 2.08333, "top5_acc": 99.89583, "top5_err": 0.10417}
[06/12 20:27:13][INFO] train_net.py:  708: Epoch 168 takes 47.86s. Epochs from 0 to 168 take 48.04s in average and 48.03s in median.
[06/12 20:27:13][INFO] train_net.py:  714: For epoch 168, each iteraction takes 0.80s in average. From epoch 0 to 168, each iteraction takes 0.80s in average.
[06/12 20:27:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47361, "dt_data": 0.00059, "dt_net": 0.47301, "epoch": "170/300", "eta": "1:01:57", "gpu_mem": "10.07G", "grad_norm": 3.59652, "iter": "10/60", "loss": 0.05110, "lr": 0.0008008031, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:27:36][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47922, "dt_data": 0.00106, "dt_net": 0.47814, "epoch": "170/300", "eta": "1:02:37", "gpu_mem": "10.07G", "grad_norm": 4.75789, "iter": "20/60", "loss": 0.06616, "lr": 0.0007990931, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:27:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47335, "dt_data": 0.00029, "dt_net": 0.47307, "epoch": "170/300", "eta": "1:01:46", "gpu_mem": "10.07G", "grad_norm": 7.70661, "iter": "30/60", "loss": 0.04496, "lr": 0.0007973836, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:27:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47264, "dt_data": 0.00039, "dt_net": 0.47225, "epoch": "170/300", "eta": "1:01:36", "gpu_mem": "10.07G", "grad_norm": 0.15687, "iter": "40/60", "loss": 0.06972, "lr": 0.0007956748, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:27:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47414, "dt_data": 0.00072, "dt_net": 0.47342, "epoch": "170/300", "eta": "1:01:43", "gpu_mem": "10.07G", "grad_norm": 1.59849, "iter": "50/60", "loss": 0.05732, "lr": 0.0007939666, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:28:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46958, "dt_data": 0.00019, "dt_net": 0.46939, "epoch": "170/300", "eta": "1:01:02", "gpu_mem": "10.07G", "grad_norm": 1.83447, "iter": "60/60", "loss": 0.07954, "lr": 0.0007922590, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:28:01][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.70017, "dt_data": 0.70017, "dt_net": 0.46939, "epoch": "170/300", "eta": "1:31:00", "gpu_mem": "10.07G", "grad_norm": 1.83447, "loss": 0.07699, "lr": 0.0007922590, "top1_acc": 97.39583, "top1_err": 2.50000, "top5_acc": 100.00000, "top5_err": 0.05208}
[06/12 20:28:01][INFO] train_net.py:  708: Epoch 169 takes 47.88s. Epochs from 0 to 169 take 48.04s in average and 48.03s in median.
[06/12 20:28:01][INFO] train_net.py:  714: For epoch 169, each iteraction takes 0.80s in average. From epoch 0 to 169, each iteraction takes 0.80s in average.
[06/12 20:28:01][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 20:29:02][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "170/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.13013, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 20:29:05][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "val_epoch", "epoch": "170/300", "gpu_mem": "10.07G", "min_top1_err": 22.40664, "min_top5_err": 2.69710, "time_diff": 0.60970, "top1_acc": 76.14108, "top1_err": 23.85892, "top5_acc": 95.85062, "top5_err": 4.14938}
[06/12 20:29:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46603, "dt_data": 0.00034, "dt_net": 0.46569, "epoch": "171/300", "eta": "1:00:30", "gpu_mem": "10.07G", "grad_norm": 4.14382, "iter": "10/60", "loss": 0.03890, "lr": 0.0007905521, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:29:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46661, "dt_data": 0.00038, "dt_net": 0.46623, "epoch": "171/300", "eta": "1:00:30", "gpu_mem": "10.07G", "grad_norm": 6.56499, "iter": "20/60", "loss": 0.06909, "lr": 0.0007888458, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:29:34][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47273, "dt_data": 0.00039, "dt_net": 0.47234, "epoch": "171/300", "eta": "1:01:13", "gpu_mem": "10.07G", "grad_norm": 1.38116, "iter": "30/60", "loss": 0.03933, "lr": 0.0007871401, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:29:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47363, "dt_data": 0.00044, "dt_net": 0.47319, "epoch": "171/300", "eta": "1:01:15", "gpu_mem": "10.07G", "grad_norm": 1.11576, "iter": "40/60", "loss": 0.03761, "lr": 0.0007854351, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:29:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.72998, "dt_data": 0.24987, "dt_net": 0.48010, "epoch": "171/300", "eta": "1:34:17", "gpu_mem": "10.07G", "grad_norm": 9.05215, "iter": "50/60", "loss": 0.06768, "lr": 0.0007837308, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:29:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46783, "dt_data": 0.00017, "dt_net": 0.46766, "epoch": "171/300", "eta": "1:00:20", "gpu_mem": "10.07G", "grad_norm": 7.32985, "iter": "60/60", "loss": 0.03537, "lr": 0.0007820271, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:29:53][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.69651, "dt_data": 0.69651, "dt_net": 0.46766, "epoch": "171/300", "eta": "1:29:50", "gpu_mem": "10.07G", "grad_norm": 7.32985, "loss": 0.06258, "lr": 0.0007820271, "top1_acc": 98.12500, "top1_err": 2.18750, "top5_acc": 99.89583, "top5_err": 0.05208}
[06/12 20:29:53][INFO] train_net.py:  708: Epoch 170 takes 47.37s. Epochs from 0 to 170 take 48.04s in average and 48.03s in median.
[06/12 20:29:53][INFO] train_net.py:  714: For epoch 170, each iteraction takes 0.79s in average. From epoch 0 to 170, each iteraction takes 0.80s in average.
[06/12 20:30:10][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.94102, "dt_data": 0.47173, "dt_net": 0.46930, "epoch": "172/300", "eta": "2:01:14", "gpu_mem": "10.07G", "grad_norm": 4.98934, "iter": "10/60", "loss": 0.02468, "lr": 0.0007803241, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:30:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47256, "dt_data": 0.00035, "dt_net": 0.47220, "epoch": "172/300", "eta": "1:00:48", "gpu_mem": "10.07G", "grad_norm": 4.89591, "iter": "20/60", "loss": 0.04162, "lr": 0.0007786217, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:30:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.08027, "dt_data": 0.61362, "dt_net": 0.46664, "epoch": "172/300", "eta": "2:18:48", "gpu_mem": "10.07G", "grad_norm": 2.09834, "iter": "30/60", "loss": 0.04678, "lr": 0.0007769200, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:30:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47697, "dt_data": 0.00060, "dt_net": 0.47637, "epoch": "172/300", "eta": "1:01:12", "gpu_mem": "10.07G", "grad_norm": 5.17383, "iter": "40/60", "loss": 0.11664, "lr": 0.0007752190, "top1_acc": 100.00000, "top1_err": 4.68750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:30:34][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.83768, "dt_data": 0.37052, "dt_net": 0.46715, "epoch": "172/300", "eta": "1:47:21", "gpu_mem": "10.07G", "grad_norm": 2.34445, "iter": "50/60", "loss": 0.09060, "lr": 0.0007735187, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:30:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46844, "dt_data": 0.00021, "dt_net": 0.46823, "epoch": "172/300", "eta": "0:59:57", "gpu_mem": "10.07G", "grad_norm": 3.67556, "iter": "60/60", "loss": 0.05387, "lr": 0.0007718191, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:30:40][INFO] logging.py:  101: json_stats: {"RAM": "13.16/31.07G", "_type": "train_epoch", "dt": 0.69567, "dt_data": 0.69567, "dt_net": 0.46823, "epoch": "172/300", "eta": "1:29:02", "gpu_mem": "10.07G", "grad_norm": 3.67556, "loss": 0.09126, "lr": 0.0007718191, "top1_acc": 97.08333, "top1_err": 2.91667, "top5_acc": 100.00000, "top5_err": 0.15625}
[06/12 20:30:40][INFO] train_net.py:  708: Epoch 171 takes 47.61s. Epochs from 0 to 171 take 48.04s in average and 48.02s in median.
[06/12 20:30:40][INFO] train_net.py:  714: For epoch 171, each iteraction takes 0.79s in average. From epoch 0 to 171, each iteraction takes 0.80s in average.
[06/12 20:30:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47076, "dt_data": 0.00047, "dt_net": 0.47028, "epoch": "173/300", "eta": "1:00:10", "gpu_mem": "10.07G", "grad_norm": 1.54339, "iter": "10/60", "loss": 0.07410, "lr": 0.0007701201, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:31:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47107, "dt_data": 0.00053, "dt_net": 0.47054, "epoch": "173/300", "eta": "1:00:08", "gpu_mem": "10.07G", "grad_norm": 3.02533, "iter": "20/60", "loss": 0.07451, "lr": 0.0007684219, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:31:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47692, "dt_data": 0.00102, "dt_net": 0.47588, "epoch": "173/300", "eta": "1:00:48", "gpu_mem": "10.07G", "grad_norm": 3.20887, "iter": "30/60", "loss": 0.04883, "lr": 0.0007667244, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:31:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47456, "dt_data": 0.00058, "dt_net": 0.47397, "epoch": "173/300", "eta": "1:00:25", "gpu_mem": "10.07G", "grad_norm": 9.13690, "iter": "40/60", "loss": 0.02687, "lr": 0.0007650275, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:31:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47480, "dt_data": 0.00074, "dt_net": 0.47405, "epoch": "173/300", "eta": "1:00:22", "gpu_mem": "10.07G", "grad_norm": 4.74949, "iter": "50/60", "loss": 0.09934, "lr": 0.0007633314, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:31:27][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47027, "dt_data": 0.00016, "dt_net": 0.47010, "epoch": "173/300", "eta": "0:59:43", "gpu_mem": "10.07G", "grad_norm": 3.25453, "iter": "60/60", "loss": 0.05748, "lr": 0.0007616360, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:31:28][INFO] logging.py:  101: json_stats: {"RAM": "13.16/31.07G", "_type": "train_epoch", "dt": 0.68791, "dt_data": 0.68791, "dt_net": 0.47010, "epoch": "173/300", "eta": "1:27:21", "gpu_mem": "10.07G", "grad_norm": 3.25453, "loss": 0.06729, "lr": 0.0007616360, "top1_acc": 96.97917, "top1_err": 2.60417, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:31:28][INFO] train_net.py:  708: Epoch 172 takes 47.86s. Epochs from 0 to 172 take 48.04s in average and 48.02s in median.
[06/12 20:31:28][INFO] train_net.py:  714: For epoch 172, each iteraction takes 0.80s in average. From epoch 0 to 172, each iteraction takes 0.80s in average.
[06/12 20:31:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47635, "dt_data": 0.00031, "dt_net": 0.47604, "epoch": "174/300", "eta": "1:00:24", "gpu_mem": "10.07G", "grad_norm": 2.00918, "iter": "10/60", "loss": 0.03423, "lr": 0.0007599414, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:31:51][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47273, "dt_data": 0.00031, "dt_net": 0.47242, "epoch": "174/300", "eta": "0:59:52", "gpu_mem": "10.07G", "grad_norm": 7.34641, "iter": "20/60", "loss": 0.03578, "lr": 0.0007582475, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:31:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47689, "dt_data": 0.00087, "dt_net": 0.47601, "epoch": "174/300", "eta": "1:00:19", "gpu_mem": "10.07G", "grad_norm": 2.86401, "iter": "30/60", "loss": 0.02801, "lr": 0.0007565543, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:32:03][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47355, "dt_data": 0.00050, "dt_net": 0.47304, "epoch": "174/300", "eta": "0:59:49", "gpu_mem": "10.07G", "grad_norm": 4.20706, "iter": "40/60", "loss": 0.04654, "lr": 0.0007548618, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:32:09][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47346, "dt_data": 0.00072, "dt_net": 0.47274, "epoch": "174/300", "eta": "0:59:44", "gpu_mem": "10.07G", "grad_norm": 1.59797, "iter": "50/60", "loss": 0.05872, "lr": 0.0007531701, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:32:15][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46980, "dt_data": 0.00015, "dt_net": 0.46965, "epoch": "174/300", "eta": "0:59:11", "gpu_mem": "10.07G", "grad_norm": 10.30750, "iter": "60/60", "loss": 0.07794, "lr": 0.0007514792, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:32:15][INFO] logging.py:  101: json_stats: {"RAM": "13.16/31.07G", "_type": "train_epoch", "dt": 0.71334, "dt_data": 0.71334, "dt_net": 0.46965, "epoch": "174/300", "eta": "1:29:52", "gpu_mem": "10.07G", "grad_norm": 10.30750, "loss": 0.07356, "lr": 0.0007514792, "top1_acc": 98.12500, "top1_err": 2.23958, "top5_acc": 99.89583, "top5_err": 0.05208}
[06/12 20:32:15][INFO] train_net.py:  708: Epoch 173 takes 47.38s. Epochs from 0 to 173 take 48.03s in average and 48.02s in median.
[06/12 20:32:15][INFO] train_net.py:  714: For epoch 173, each iteraction takes 0.79s in average. From epoch 0 to 173, each iteraction takes 0.80s in average.
[06/12 20:32:32][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.06920, "dt_data": 0.59985, "dt_net": 0.46935, "epoch": "175/300", "eta": "2:14:32", "gpu_mem": "10.07G", "grad_norm": 8.02379, "iter": "10/60", "loss": 0.03635, "lr": 0.0007497890, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:32:38][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47508, "dt_data": 0.00074, "dt_net": 0.47434, "epoch": "175/300", "eta": "0:59:42", "gpu_mem": "10.07G", "grad_norm": 4.01807, "iter": "20/60", "loss": 0.05587, "lr": 0.0007480995, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:32:44][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48358, "dt_data": 0.00089, "dt_net": 0.48269, "epoch": "175/300", "eta": "1:00:41", "gpu_mem": "10.07G", "grad_norm": 0.24155, "iter": "30/60", "loss": 0.02521, "lr": 0.0007464109, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:32:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47356, "dt_data": 0.00039, "dt_net": 0.47317, "epoch": "175/300", "eta": "0:59:21", "gpu_mem": "10.07G", "grad_norm": 7.32647, "iter": "40/60", "loss": 0.05316, "lr": 0.0007447230, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:32:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.08987, "dt_data": 0.00043, "dt_net": 1.08944, "epoch": "175/300", "eta": "2:16:24", "gpu_mem": "10.07G", "grad_norm": 3.20360, "iter": "50/60", "loss": 0.06510, "lr": 0.0007430359, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:33:02][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46945, "dt_data": 0.00015, "dt_net": 0.46930, "epoch": "175/300", "eta": "0:58:40", "gpu_mem": "10.07G", "grad_norm": 5.61629, "iter": "60/60", "loss": 0.05110, "lr": 0.0007413495, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:33:03][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.68790, "dt_data": 0.68790, "dt_net": 0.46930, "epoch": "175/300", "eta": "1:25:58", "gpu_mem": "10.07G", "grad_norm": 5.61629, "loss": 0.06406, "lr": 0.0007413495, "top1_acc": 97.70833, "top1_err": 2.13542, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:33:03][INFO] train_net.py:  708: Epoch 174 takes 47.32s. Epochs from 0 to 174 take 48.03s in average and 48.02s in median.
[06/12 20:33:03][INFO] train_net.py:  714: For epoch 174, each iteraction takes 0.79s in average. From epoch 0 to 174, each iteraction takes 0.80s in average.
[06/12 20:33:03][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 20:34:05][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "175/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.12953, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 95.31250, "top5_err": 4.68750}
[06/12 20:34:08][INFO] logging.py:  101: json_stats: {"RAM": "13.20/31.07G", "_type": "val_epoch", "epoch": "175/300", "gpu_mem": "10.07G", "min_top1_err": 22.40664, "min_top5_err": 2.69710, "time_diff": 0.60323, "top1_acc": 73.85892, "top1_err": 26.14108, "top5_acc": 96.05809, "top5_err": 3.94191}
[06/12 20:34:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47365, "dt_data": 0.00034, "dt_net": 0.47331, "epoch": "176/300", "eta": "0:59:07", "gpu_mem": "10.07G", "grad_norm": 3.90048, "iter": "10/60", "loss": 0.03375, "lr": 0.0007396640, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:34:32][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46877, "dt_data": 0.00050, "dt_net": 0.46826, "epoch": "176/300", "eta": "0:58:26", "gpu_mem": "10.07G", "grad_norm": 2.66662, "iter": "20/60", "loss": 0.03342, "lr": 0.0007379793, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:34:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46974, "dt_data": 0.00051, "dt_net": 0.46922, "epoch": "176/300", "eta": "0:58:28", "gpu_mem": "10.07G", "grad_norm": 4.56710, "iter": "30/60", "loss": 0.12749, "lr": 0.0007362953, "top1_acc": 93.75000, "top1_err": 6.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:34:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47928, "dt_data": 0.00059, "dt_net": 0.47869, "epoch": "176/300", "eta": "0:59:35", "gpu_mem": "10.07G", "grad_norm": 11.70267, "iter": "40/60", "loss": 0.04362, "lr": 0.0007346122, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:34:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47415, "dt_data": 0.00055, "dt_net": 0.47359, "epoch": "176/300", "eta": "0:58:52", "gpu_mem": "10.07G", "grad_norm": 6.76323, "iter": "50/60", "loss": 0.09099, "lr": 0.0007329298, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:34:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46594, "dt_data": 0.00017, "dt_net": 0.46576, "epoch": "176/300", "eta": "0:57:46", "gpu_mem": "10.07G", "grad_norm": 3.02606, "iter": "60/60", "loss": 0.03957, "lr": 0.0007312483, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:34:56][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.69435, "dt_data": 0.69435, "dt_net": 0.46576, "epoch": "176/300", "eta": "1:26:05", "gpu_mem": "10.07G", "grad_norm": 3.02606, "loss": 0.07509, "lr": 0.0007312483, "top1_acc": 97.81250, "top1_err": 2.44792, "top5_acc": 100.00000, "top5_err": 0.10417}
[06/12 20:34:56][INFO] train_net.py:  708: Epoch 175 takes 48.08s. Epochs from 0 to 175 take 48.03s in average and 48.02s in median.
[06/12 20:34:56][INFO] train_net.py:  714: For epoch 175, each iteraction takes 0.80s in average. From epoch 0 to 175, each iteraction takes 0.80s in average.
[06/12 20:35:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47107, "dt_data": 0.00101, "dt_net": 0.47005, "epoch": "177/300", "eta": "0:58:20", "gpu_mem": "10.07G", "grad_norm": 5.83430, "iter": "10/60", "loss": 0.04527, "lr": 0.0007295676, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:35:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47397, "dt_data": 0.00056, "dt_net": 0.47340, "epoch": "177/300", "eta": "0:58:36", "gpu_mem": "10.07G", "grad_norm": 5.62490, "iter": "20/60", "loss": 0.02885, "lr": 0.0007278877, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:35:26][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.32980, "dt_data": 0.86347, "dt_net": 0.46632, "epoch": "177/300", "eta": "2:44:13", "gpu_mem": "10.07G", "grad_norm": 6.44819, "iter": "30/60", "loss": 0.05256, "lr": 0.0007262086, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:35:32][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47310, "dt_data": 0.00063, "dt_net": 0.47247, "epoch": "177/300", "eta": "0:58:20", "gpu_mem": "10.07G", "grad_norm": 1.93653, "iter": "40/60", "loss": 0.05680, "lr": 0.0007245304, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:35:38][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.96877, "dt_data": 0.49761, "dt_net": 0.47116, "epoch": "177/300", "eta": "1:59:19", "gpu_mem": "10.07G", "grad_norm": 10.49256, "iter": "50/60", "loss": 0.05142, "lr": 0.0007228530, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:35:44][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47684, "dt_data": 0.00017, "dt_net": 0.47667, "epoch": "177/300", "eta": "0:58:39", "gpu_mem": "10.07G", "grad_norm": 1.98451, "iter": "60/60", "loss": 0.03380, "lr": 0.0007211765, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:35:45][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.70591, "dt_data": 0.70591, "dt_net": 0.47667, "epoch": "177/300", "eta": "1:26:49", "gpu_mem": "10.07G", "grad_norm": 1.98451, "loss": 0.05443, "lr": 0.0007211765, "top1_acc": 97.81250, "top1_err": 2.03125, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:35:45][INFO] train_net.py:  708: Epoch 176 takes 48.61s. Epochs from 0 to 176 take 48.03s in average and 48.02s in median.
[06/12 20:35:45][INFO] train_net.py:  714: For epoch 176, each iteraction takes 0.81s in average. From epoch 0 to 176, each iteraction takes 0.80s in average.
[06/12 20:36:02][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46886, "dt_data": 0.00035, "dt_net": 0.46850, "epoch": "178/300", "eta": "0:57:35", "gpu_mem": "10.07G", "grad_norm": 4.83849, "iter": "10/60", "loss": 0.06875, "lr": 0.0007195008, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:36:08][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47165, "dt_data": 0.00034, "dt_net": 0.47131, "epoch": "178/300", "eta": "0:57:51", "gpu_mem": "10.07G", "grad_norm": 2.47191, "iter": "20/60", "loss": 0.08635, "lr": 0.0007178260, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:36:14][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47071, "dt_data": 0.00042, "dt_net": 0.47029, "epoch": "178/300", "eta": "0:57:39", "gpu_mem": "10.07G", "grad_norm": 6.38411, "iter": "30/60", "loss": 0.06956, "lr": 0.0007161520, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:36:20][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47170, "dt_data": 0.00052, "dt_net": 0.47117, "epoch": "178/300", "eta": "0:57:42", "gpu_mem": "10.07G", "grad_norm": 2.35118, "iter": "40/60", "loss": 0.05948, "lr": 0.0007144789, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:36:26][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48075, "dt_data": 0.00049, "dt_net": 0.48026, "epoch": "178/300", "eta": "0:58:43", "gpu_mem": "10.07G", "grad_norm": 6.15791, "iter": "50/60", "loss": 0.05973, "lr": 0.0007128067, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:36:32][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46905, "dt_data": 0.00019, "dt_net": 0.46886, "epoch": "178/300", "eta": "0:57:13", "gpu_mem": "10.07G", "grad_norm": 0.53370, "iter": "60/60", "loss": 0.04750, "lr": 0.0007111353, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:36:32][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.68511, "dt_data": 0.68511, "dt_net": 0.46886, "epoch": "178/300", "eta": "1:23:34", "gpu_mem": "10.07G", "grad_norm": 0.53370, "loss": 0.07652, "lr": 0.0007111353, "top1_acc": 96.97917, "top1_err": 2.76042, "top5_acc": 99.89583, "top5_err": 0.10417}
[06/12 20:36:32][INFO] train_net.py:  708: Epoch 177 takes 47.55s. Epochs from 0 to 177 take 48.03s in average and 48.02s in median.
[06/12 20:36:32][INFO] train_net.py:  714: For epoch 177, each iteraction takes 0.79s in average. From epoch 0 to 177, each iteraction takes 0.80s in average.
[06/12 20:36:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47091, "dt_data": 0.00057, "dt_net": 0.47034, "epoch": "179/300", "eta": "0:57:22", "gpu_mem": "10.07G", "grad_norm": 5.69264, "iter": "10/60", "loss": 0.04202, "lr": 0.0007094648, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:36:54][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47263, "dt_data": 0.00056, "dt_net": 0.47206, "epoch": "179/300", "eta": "0:57:30", "gpu_mem": "10.07G", "grad_norm": 7.00278, "iter": "20/60", "loss": 0.04684, "lr": 0.0007077952, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:37:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.07122, "dt_data": 0.59886, "dt_net": 0.47235, "epoch": "179/300", "eta": "2:10:09", "gpu_mem": "10.07G", "grad_norm": 4.74157, "iter": "30/60", "loss": 0.05878, "lr": 0.0007061265, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:37:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47593, "dt_data": 0.00034, "dt_net": 0.47558, "epoch": "179/300", "eta": "0:57:44", "gpu_mem": "10.07G", "grad_norm": 0.71755, "iter": "40/60", "loss": 0.05370, "lr": 0.0007044587, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:37:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.94001, "dt_data": 0.47167, "dt_net": 0.46834, "epoch": "179/300", "eta": "1:53:53", "gpu_mem": "10.07G", "grad_norm": 3.19612, "iter": "50/60", "loss": 0.08468, "lr": 0.0007027918, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:37:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46924, "dt_data": 0.00016, "dt_net": 0.46907, "epoch": "179/300", "eta": "0:56:46", "gpu_mem": "10.07G", "grad_norm": 2.28466, "iter": "60/60", "loss": 0.05346, "lr": 0.0007011258, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:37:20][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.68561, "dt_data": 0.68561, "dt_net": 0.46907, "epoch": "179/300", "eta": "1:22:57", "gpu_mem": "10.07G", "grad_norm": 2.28466, "loss": 0.06613, "lr": 0.0007011258, "top1_acc": 97.18750, "top1_err": 2.60417, "top5_acc": 100.00000, "top5_err": 0.05208}
[06/12 20:37:20][INFO] train_net.py:  708: Epoch 178 takes 47.34s. Epochs from 0 to 178 take 48.03s in average and 48.02s in median.
[06/12 20:37:20][INFO] train_net.py:  714: For epoch 178, each iteraction takes 0.79s in average. From epoch 0 to 178, each iteraction takes 0.80s in average.
[06/12 20:37:38][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.11090, "dt_data": 0.00048, "dt_net": 1.11042, "epoch": "180/300", "eta": "2:14:14", "gpu_mem": "10.07G", "grad_norm": 2.63779, "iter": "10/60", "loss": 0.03028, "lr": 0.0006994607, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:37:44][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47211, "dt_data": 0.00057, "dt_net": 0.47153, "epoch": "180/300", "eta": "0:56:58", "gpu_mem": "10.07G", "grad_norm": 1.98217, "iter": "20/60", "loss": 0.08325, "lr": 0.0006977965, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:37:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.96347, "dt_data": 0.00029, "dt_net": 0.96318, "epoch": "180/300", "eta": "1:56:05", "gpu_mem": "10.07G", "grad_norm": 1.43305, "iter": "30/60", "loss": 0.04659, "lr": 0.0006961332, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:37:56][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47361, "dt_data": 0.00038, "dt_net": 0.47323, "epoch": "180/300", "eta": "0:56:59", "gpu_mem": "10.07G", "grad_norm": 1.91926, "iter": "40/60", "loss": 0.04545, "lr": 0.0006944709, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:38:02][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.92038, "dt_data": 0.00034, "dt_net": 0.92004, "epoch": "180/300", "eta": "1:50:35", "gpu_mem": "10.07G", "grad_norm": 7.96537, "iter": "50/60", "loss": 0.05308, "lr": 0.0006928095, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:38:08][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46947, "dt_data": 0.00015, "dt_net": 0.46932, "epoch": "180/300", "eta": "0:56:20", "gpu_mem": "10.07G", "grad_norm": 1.70251, "iter": "60/60", "loss": 0.08759, "lr": 0.0006911490, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:38:08][INFO] logging.py:  101: json_stats: {"RAM": "13.16/31.07G", "_type": "train_epoch", "dt": 0.71319, "dt_data": 0.71319, "dt_net": 0.46932, "epoch": "180/300", "eta": "1:25:34", "gpu_mem": "10.07G", "grad_norm": 1.70251, "loss": 0.07636, "lr": 0.0006911490, "top1_acc": 97.18750, "top1_err": 2.60417, "top5_acc": 100.00000, "top5_err": 0.05208}
[06/12 20:38:08][INFO] train_net.py:  708: Epoch 179 takes 48.71s. Epochs from 0 to 179 take 48.03s in average and 48.02s in median.
[06/12 20:38:08][INFO] train_net.py:  714: For epoch 179, each iteraction takes 0.81s in average. From epoch 0 to 179, each iteraction takes 0.80s in average.
[06/12 20:38:08][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 20:39:10][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "180/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.13073, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 98.43750, "top5_err": 1.56250}
[06/12 20:39:13][INFO] logging.py:  101: json_stats: {"RAM": "13.16/31.07G", "_type": "val_epoch", "epoch": "180/300", "gpu_mem": "10.07G", "min_top1_err": 21.99170, "min_top5_err": 2.69710, "time_diff": 0.62407, "top1_acc": 78.00830, "top1_err": 21.99170, "top5_acc": 96.88797, "top5_err": 3.11203}
[06/12 20:39:30][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46559, "dt_data": 0.00043, "dt_net": 0.46516, "epoch": "181/300", "eta": "0:55:47", "gpu_mem": "10.07G", "grad_norm": 5.36997, "iter": "10/60", "loss": 0.02252, "lr": 0.0006894895, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:39:36][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46694, "dt_data": 0.00060, "dt_net": 0.46634, "epoch": "181/300", "eta": "0:55:52", "gpu_mem": "10.07G", "grad_norm": 8.54574, "iter": "20/60", "loss": 0.09377, "lr": 0.0006878309, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:39:42][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.55954, "dt_data": 0.00045, "dt_net": 0.55908, "epoch": "181/300", "eta": "1:06:51", "gpu_mem": "10.07G", "grad_norm": 5.74019, "iter": "30/60", "loss": 0.05228, "lr": 0.0006861733, "top1_acc": 96.87500, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:39:48][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47087, "dt_data": 0.00034, "dt_net": 0.47053, "epoch": "181/300", "eta": "0:56:11", "gpu_mem": "10.07G", "grad_norm": 11.00016, "iter": "40/60", "loss": 0.04797, "lr": 0.0006845166, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:39:54][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47443, "dt_data": 0.00046, "dt_net": 0.47396, "epoch": "181/300", "eta": "0:56:32", "gpu_mem": "10.07G", "grad_norm": 0.69256, "iter": "50/60", "loss": 0.04911, "lr": 0.0006828609, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:39:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46662, "dt_data": 0.00021, "dt_net": 0.46641, "epoch": "181/300", "eta": "0:55:31", "gpu_mem": "10.07G", "grad_norm": 4.16351, "iter": "60/60", "loss": 0.05540, "lr": 0.0006812061, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:40:00][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.70924, "dt_data": 0.70924, "dt_net": 0.46641, "epoch": "181/300", "eta": "1:24:23", "gpu_mem": "10.07G", "grad_norm": 4.16351, "loss": 0.06402, "lr": 0.0006812061, "top1_acc": 97.60417, "top1_err": 2.13542, "top5_acc": 100.00000, "top5_err": 0.05208}
[06/12 20:40:00][INFO] train_net.py:  708: Epoch 180 takes 47.34s. Epochs from 0 to 180 take 48.03s in average and 48.02s in median.
[06/12 20:40:00][INFO] train_net.py:  714: For epoch 180, each iteraction takes 0.79s in average. From epoch 0 to 180, each iteraction takes 0.80s in average.
[06/12 20:40:18][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46932, "dt_data": 0.00038, "dt_net": 0.46893, "epoch": "182/300", "eta": "0:55:46", "gpu_mem": "10.07G", "grad_norm": 4.20634, "iter": "10/60", "loss": 0.04804, "lr": 0.0006795523, "top1_acc": 96.87500, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:40:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47017, "dt_data": 0.00063, "dt_net": 0.46954, "epoch": "182/300", "eta": "0:55:47", "gpu_mem": "10.07G", "grad_norm": 2.82898, "iter": "20/60", "loss": 0.04919, "lr": 0.0006778995, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:40:30][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47206, "dt_data": 0.00030, "dt_net": 0.47176, "epoch": "182/300", "eta": "0:55:56", "gpu_mem": "10.07G", "grad_norm": 1.64332, "iter": "30/60", "loss": 0.02494, "lr": 0.0006762477, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:40:36][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47093, "dt_data": 0.00039, "dt_net": 0.47053, "epoch": "182/300", "eta": "0:55:43", "gpu_mem": "10.07G", "grad_norm": 2.13086, "iter": "40/60", "loss": 0.03599, "lr": 0.0006745969, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:40:42][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47161, "dt_data": 0.00043, "dt_net": 0.47117, "epoch": "182/300", "eta": "0:55:43", "gpu_mem": "10.07G", "grad_norm": 3.21734, "iter": "50/60", "loss": 0.05254, "lr": 0.0006729470, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:40:47][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.59292, "dt_data": 0.12578, "dt_net": 0.46714, "epoch": "182/300", "eta": "1:09:57", "gpu_mem": "10.07G", "grad_norm": 1.06333, "iter": "60/60", "loss": 0.04092, "lr": 0.0006712982, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:40:48][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.70670, "dt_data": 0.70670, "dt_net": 0.46714, "epoch": "182/300", "eta": "1:23:23", "gpu_mem": "10.07G", "grad_norm": 1.06333, "loss": 0.05119, "lr": 0.0006712982, "top1_acc": 98.22917, "top1_err": 1.71875, "top5_acc": 99.89583, "top5_err": 0.05208}
[06/12 20:40:48][INFO] train_net.py:  708: Epoch 181 takes 48.05s. Epochs from 0 to 181 take 48.03s in average and 48.02s in median.
[06/12 20:40:48][INFO] train_net.py:  714: For epoch 181, each iteraction takes 0.80s in average. From epoch 0 to 181, each iteraction takes 0.80s in average.
[06/12 20:41:06][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47233, "dt_data": 0.00037, "dt_net": 0.47196, "epoch": "183/300", "eta": "0:55:39", "gpu_mem": "10.07G", "grad_norm": 6.27896, "iter": "10/60", "loss": 0.05624, "lr": 0.0006696503, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:41:12][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47050, "dt_data": 0.00048, "dt_net": 0.47001, "epoch": "183/300", "eta": "0:55:21", "gpu_mem": "10.07G", "grad_norm": 6.34882, "iter": "20/60", "loss": 0.04055, "lr": 0.0006680035, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:41:18][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47234, "dt_data": 0.00053, "dt_net": 0.47181, "epoch": "183/300", "eta": "0:55:29", "gpu_mem": "10.07G", "grad_norm": 8.39444, "iter": "30/60", "loss": 0.04368, "lr": 0.0006663577, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:41:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47291, "dt_data": 0.00063, "dt_net": 0.47227, "epoch": "183/300", "eta": "0:55:29", "gpu_mem": "10.07G", "grad_norm": 1.76415, "iter": "40/60", "loss": 0.01741, "lr": 0.0006647129, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:41:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47207, "dt_data": 0.00031, "dt_net": 0.47175, "epoch": "183/300", "eta": "0:55:18", "gpu_mem": "10.07G", "grad_norm": 0.88444, "iter": "50/60", "loss": 0.04793, "lr": 0.0006630691, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:41:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46878, "dt_data": 0.00016, "dt_net": 0.46861, "epoch": "183/300", "eta": "0:54:50", "gpu_mem": "10.07G", "grad_norm": 9.99697, "iter": "60/60", "loss": 0.04111, "lr": 0.0006614263, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:41:38][INFO] logging.py:  101: json_stats: {"RAM": "13.14/31.07G", "_type": "train_epoch", "dt": 0.67977, "dt_data": 0.67976, "dt_net": 0.46861, "epoch": "183/300", "eta": "1:19:31", "gpu_mem": "10.07G", "grad_norm": 9.99697, "loss": 0.05300, "lr": 0.0006614263, "top1_acc": 97.70833, "top1_err": 2.03125, "top5_acc": 99.89583, "top5_err": 0.05208}
[06/12 20:41:38][INFO] train_net.py:  708: Epoch 182 takes 49.32s. Epochs from 0 to 182 take 48.03s in average and 48.02s in median.
[06/12 20:41:38][INFO] train_net.py:  714: For epoch 182, each iteraction takes 0.82s in average. From epoch 0 to 182, each iteraction takes 0.80s in average.
[06/12 20:41:56][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.33828, "dt_data": 0.00035, "dt_net": 1.33793, "epoch": "184/300", "eta": "2:36:21", "gpu_mem": "10.07G", "grad_norm": 2.82918, "iter": "10/60", "loss": 0.01379, "lr": 0.0006597846, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:42:02][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47141, "dt_data": 0.00056, "dt_net": 0.47085, "epoch": "184/300", "eta": "0:54:59", "gpu_mem": "10.07G", "grad_norm": 1.99744, "iter": "20/60", "loss": 0.03910, "lr": 0.0006581439, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:42:08][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.79813, "dt_data": 0.00049, "dt_net": 0.79763, "epoch": "184/300", "eta": "1:32:58", "gpu_mem": "10.07G", "grad_norm": 8.53533, "iter": "30/60", "loss": 0.04204, "lr": 0.0006565042, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:42:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47439, "dt_data": 0.00073, "dt_net": 0.47365, "epoch": "184/300", "eta": "0:55:11", "gpu_mem": "10.07G", "grad_norm": 3.03387, "iter": "40/60", "loss": 0.04657, "lr": 0.0006548656, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:42:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.67306, "dt_data": 0.00040, "dt_net": 0.67265, "epoch": "184/300", "eta": "1:18:11", "gpu_mem": "10.07G", "grad_norm": 6.72515, "iter": "50/60", "loss": 0.03814, "lr": 0.0006532280, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:42:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46984, "dt_data": 0.00017, "dt_net": 0.46967, "epoch": "184/300", "eta": "0:54:30", "gpu_mem": "10.07G", "grad_norm": 0.39946, "iter": "60/60", "loss": 0.07680, "lr": 0.0006515915, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:42:26][INFO] logging.py:  101: json_stats: {"RAM": "13.16/31.07G", "_type": "train_epoch", "dt": 0.68958, "dt_data": 0.68958, "dt_net": 0.46967, "epoch": "184/300", "eta": "1:19:59", "gpu_mem": "10.07G", "grad_norm": 0.39946, "loss": 0.05862, "lr": 0.0006515915, "top1_acc": 98.22917, "top1_err": 1.82292, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:42:26][INFO] train_net.py:  708: Epoch 183 takes 48.14s. Epochs from 0 to 183 take 48.03s in average and 48.02s in median.
[06/12 20:42:26][INFO] train_net.py:  714: For epoch 183, each iteraction takes 0.80s in average. From epoch 0 to 183, each iteraction takes 0.80s in average.
[06/12 20:42:42][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.50156, "dt_data": 0.03184, "dt_net": 0.46971, "epoch": "185/300", "eta": "0:58:05", "gpu_mem": "10.07G", "grad_norm": 7.21895, "iter": "10/60", "loss": 0.02072, "lr": 0.0006499561, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:42:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47559, "dt_data": 0.00053, "dt_net": 0.47506, "epoch": "185/300", "eta": "0:55:00", "gpu_mem": "10.07G", "grad_norm": 0.90179, "iter": "20/60", "loss": 0.08614, "lr": 0.0006483217, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:42:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.08914, "dt_data": 0.60910, "dt_net": 0.48003, "epoch": "185/300", "eta": "2:05:47", "gpu_mem": "10.07G", "grad_norm": 4.22018, "iter": "30/60", "loss": 0.04039, "lr": 0.0006466884, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:43:02][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47388, "dt_data": 0.00035, "dt_net": 0.47352, "epoch": "185/300", "eta": "0:54:39", "gpu_mem": "10.07G", "grad_norm": 8.06055, "iter": "40/60", "loss": 0.05327, "lr": 0.0006450562, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:43:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.97756, "dt_data": 0.50600, "dt_net": 0.47155, "epoch": "185/300", "eta": "1:52:34", "gpu_mem": "10.07G", "grad_norm": 1.24878, "iter": "50/60", "loss": 0.02684, "lr": 0.0006434251, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:43:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47058, "dt_data": 0.00015, "dt_net": 0.47043, "epoch": "185/300", "eta": "0:54:07", "gpu_mem": "10.07G", "grad_norm": 1.63270, "iter": "60/60", "loss": 0.03324, "lr": 0.0006417950, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:43:14][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.68957, "dt_data": 0.68957, "dt_net": 0.47043, "epoch": "185/300", "eta": "1:19:17", "gpu_mem": "10.07G", "grad_norm": 1.63270, "loss": 0.06395, "lr": 0.0006417950, "top1_acc": 97.81250, "top1_err": 2.08333, "top5_acc": 99.79167, "top5_err": 0.10417}
[06/12 20:43:14][INFO] train_net.py:  708: Epoch 184 takes 48.23s. Epochs from 0 to 184 take 48.03s in average and 48.03s in median.
[06/12 20:43:14][INFO] train_net.py:  714: For epoch 184, each iteraction takes 0.80s in average. From epoch 0 to 184, each iteraction takes 0.80s in average.
[06/12 20:43:14][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 20:44:14][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "185/300", "eta": "0:00:01", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.29283, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:44:18][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "val_epoch", "epoch": "185/300", "gpu_mem": "10.07G", "min_top1_err": 21.99170, "min_top5_err": 2.69710, "time_diff": 0.61633, "top1_acc": 75.72614, "top1_err": 24.27386, "top5_acc": 97.30290, "top5_err": 2.69710}
[06/12 20:44:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46829, "dt_data": 0.00061, "dt_net": 0.46767, "epoch": "186/300", "eta": "0:53:46", "gpu_mem": "10.07G", "grad_norm": 2.90068, "iter": "10/60", "loss": 0.06060, "lr": 0.0006401660, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:44:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46575, "dt_data": 0.00045, "dt_net": 0.46529, "epoch": "186/300", "eta": "0:53:24", "gpu_mem": "10.07G", "grad_norm": 3.24037, "iter": "20/60", "loss": 0.05363, "lr": 0.0006385382, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:44:47][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47061, "dt_data": 0.00046, "dt_net": 0.47014, "epoch": "186/300", "eta": "0:53:53", "gpu_mem": "10.07G", "grad_norm": 7.37000, "iter": "30/60", "loss": 0.02047, "lr": 0.0006369114, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:44:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47347, "dt_data": 0.00053, "dt_net": 0.47293, "epoch": "186/300", "eta": "0:54:07", "gpu_mem": "10.07G", "grad_norm": 0.71480, "iter": "40/60", "loss": 0.01600, "lr": 0.0006352857, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:44:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.49817, "dt_data": 0.00039, "dt_net": 0.49777, "epoch": "186/300", "eta": "0:56:52", "gpu_mem": "10.07G", "grad_norm": 0.28760, "iter": "50/60", "loss": 0.04919, "lr": 0.0006336612, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:45:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46765, "dt_data": 0.00015, "dt_net": 0.46750, "epoch": "186/300", "eta": "0:53:18", "gpu_mem": "10.07G", "grad_norm": 3.65937, "iter": "60/60", "loss": 0.02745, "lr": 0.0006320377, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:45:05][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.70851, "dt_data": 0.70851, "dt_net": 0.46750, "epoch": "186/300", "eta": "1:20:45", "gpu_mem": "10.07G", "grad_norm": 3.65937, "loss": 0.05174, "lr": 0.0006320377, "top1_acc": 98.22917, "top1_err": 1.87500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:45:05][INFO] train_net.py:  708: Epoch 185 takes 47.17s. Epochs from 0 to 185 take 48.03s in average and 48.02s in median.
[06/12 20:45:05][INFO] train_net.py:  714: For epoch 185, each iteraction takes 0.79s in average. From epoch 0 to 185, each iteraction takes 0.80s in average.
[06/12 20:45:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46818, "dt_data": 0.00045, "dt_net": 0.46774, "epoch": "187/300", "eta": "0:53:17", "gpu_mem": "10.07G", "grad_norm": 0.72109, "iter": "10/60", "loss": 0.01700, "lr": 0.0006304154, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:45:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47319, "dt_data": 0.00049, "dt_net": 0.47269, "epoch": "187/300", "eta": "0:53:47", "gpu_mem": "10.07G", "grad_norm": 6.02194, "iter": "20/60", "loss": 0.04443, "lr": 0.0006287942, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:45:34][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48906, "dt_data": 0.00045, "dt_net": 0.48860, "epoch": "187/300", "eta": "0:55:30", "gpu_mem": "10.07G", "grad_norm": 3.66001, "iter": "30/60", "loss": 0.04924, "lr": 0.0006271742, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:45:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47203, "dt_data": 0.00073, "dt_net": 0.47128, "epoch": "187/300", "eta": "0:53:29", "gpu_mem": "10.07G", "grad_norm": 4.71602, "iter": "40/60", "loss": 0.04245, "lr": 0.0006255552, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:45:47][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47751, "dt_data": 0.00059, "dt_net": 0.47692, "epoch": "187/300", "eta": "0:54:02", "gpu_mem": "10.07G", "grad_norm": 2.35148, "iter": "50/60", "loss": 0.05006, "lr": 0.0006239375, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:45:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46938, "dt_data": 0.00020, "dt_net": 0.46918, "epoch": "187/300", "eta": "0:53:02", "gpu_mem": "10.07G", "grad_norm": 9.26140, "iter": "60/60", "loss": 0.04787, "lr": 0.0006223208, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:45:53][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.71001, "dt_data": 0.71001, "dt_net": 0.46918, "epoch": "187/300", "eta": "1:20:13", "gpu_mem": "10.07G", "grad_norm": 9.26140, "loss": 0.04681, "lr": 0.0006223208, "top1_acc": 98.22917, "top1_err": 2.03125, "top5_acc": 100.00000, "top5_err": 0.05208}
[06/12 20:45:53][INFO] train_net.py:  708: Epoch 186 takes 47.79s. Epochs from 0 to 186 take 48.03s in average and 48.02s in median.
[06/12 20:45:53][INFO] train_net.py:  714: For epoch 186, each iteraction takes 0.80s in average. From epoch 0 to 186, each iteraction takes 0.80s in average.
[06/12 20:46:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47071, "dt_data": 0.00053, "dt_net": 0.47017, "epoch": "188/300", "eta": "0:53:06", "gpu_mem": "10.07G", "grad_norm": 4.87071, "iter": "10/60", "loss": 0.04752, "lr": 0.0006207053, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:46:17][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47168, "dt_data": 0.00032, "dt_net": 0.47137, "epoch": "188/300", "eta": "0:53:08", "gpu_mem": "10.07G", "grad_norm": 0.77358, "iter": "20/60", "loss": 0.08512, "lr": 0.0006190910, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:46:24][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46994, "dt_data": 0.00039, "dt_net": 0.46955, "epoch": "188/300", "eta": "0:52:52", "gpu_mem": "10.07G", "grad_norm": 3.14452, "iter": "30/60", "loss": 0.02470, "lr": 0.0006174778, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:46:29][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48033, "dt_data": 0.00029, "dt_net": 0.48004, "epoch": "188/300", "eta": "0:53:57", "gpu_mem": "10.07G", "grad_norm": 1.15006, "iter": "40/60", "loss": 0.04857, "lr": 0.0006158658, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:46:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47090, "dt_data": 0.00045, "dt_net": 0.47044, "epoch": "188/300", "eta": "0:52:49", "gpu_mem": "10.07G", "grad_norm": 1.63931, "iter": "50/60", "loss": 0.01727, "lr": 0.0006142550, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:46:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46958, "dt_data": 0.00016, "dt_net": 0.46942, "epoch": "188/300", "eta": "0:52:35", "gpu_mem": "10.07G", "grad_norm": 7.59280, "iter": "60/60", "loss": 0.11302, "lr": 0.0006126453, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:46:42][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.70627, "dt_data": 0.70627, "dt_net": 0.46942, "epoch": "188/300", "eta": "1:19:05", "gpu_mem": "10.07G", "grad_norm": 7.59280, "loss": 0.06081, "lr": 0.0006126453, "top1_acc": 97.60417, "top1_err": 2.18750, "top5_acc": 99.89583, "top5_err": 0.10417}
[06/12 20:46:42][INFO] train_net.py:  708: Epoch 187 takes 48.76s. Epochs from 0 to 187 take 48.03s in average and 48.02s in median.
[06/12 20:46:42][INFO] train_net.py:  714: For epoch 187, each iteraction takes 0.81s in average. From epoch 0 to 187, each iteraction takes 0.80s in average.
[06/12 20:46:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47384, "dt_data": 0.00062, "dt_net": 0.47322, "epoch": "189/300", "eta": "0:52:59", "gpu_mem": "10.07G", "grad_norm": 10.05465, "iter": "10/60", "loss": 0.04039, "lr": 0.0006110368, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:47:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47534, "dt_data": 0.00036, "dt_net": 0.47497, "epoch": "189/300", "eta": "0:53:04", "gpu_mem": "10.07G", "grad_norm": 1.21001, "iter": "20/60", "loss": 0.03162, "lr": 0.0006094295, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:47:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.87690, "dt_data": 0.00052, "dt_net": 0.87638, "epoch": "189/300", "eta": "1:37:46", "gpu_mem": "10.07G", "grad_norm": 1.27896, "iter": "30/60", "loss": 0.04194, "lr": 0.0006078234, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:47:17][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48189, "dt_data": 0.00047, "dt_net": 0.48141, "epoch": "189/300", "eta": "0:53:39", "gpu_mem": "10.07G", "grad_norm": 3.67308, "iter": "40/60", "loss": 0.03314, "lr": 0.0006062185, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:47:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47599, "dt_data": 0.00059, "dt_net": 0.47540, "epoch": "189/300", "eta": "0:52:54", "gpu_mem": "10.07G", "grad_norm": 2.96237, "iter": "50/60", "loss": 0.03614, "lr": 0.0006046148, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:47:29][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46875, "dt_data": 0.00020, "dt_net": 0.46855, "epoch": "189/300", "eta": "0:52:01", "gpu_mem": "10.07G", "grad_norm": 0.77656, "iter": "60/60", "loss": 0.05467, "lr": 0.0006030123, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:47:30][INFO] logging.py:  101: json_stats: {"RAM": "13.16/31.07G", "_type": "train_epoch", "dt": 0.69271, "dt_data": 0.69271, "dt_net": 0.46855, "epoch": "189/300", "eta": "1:16:53", "gpu_mem": "10.07G", "grad_norm": 0.77656, "loss": 0.05853, "lr": 0.0006030123, "top1_acc": 98.22917, "top1_err": 1.71875, "top5_acc": 99.89583, "top5_err": 0.05208}
[06/12 20:47:30][INFO] train_net.py:  708: Epoch 188 takes 48.29s. Epochs from 0 to 188 take 48.03s in average and 48.03s in median.
[06/12 20:47:30][INFO] train_net.py:  714: For epoch 188, each iteraction takes 0.80s in average. From epoch 0 to 188, each iteraction takes 0.80s in average.
[06/12 20:47:47][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.59399, "dt_data": 0.00066, "dt_net": 0.59332, "epoch": "190/300", "eta": "1:05:50", "gpu_mem": "10.07G", "grad_norm": 1.09760, "iter": "10/60", "loss": 0.01479, "lr": 0.0006014110, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:47:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47455, "dt_data": 0.00042, "dt_net": 0.47414, "epoch": "190/300", "eta": "0:52:31", "gpu_mem": "10.07G", "grad_norm": 7.02526, "iter": "20/60", "loss": 0.08971, "lr": 0.0005998109, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:48:00][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47449, "dt_data": 0.00033, "dt_net": 0.47416, "epoch": "190/300", "eta": "0:52:25", "gpu_mem": "10.07G", "grad_norm": 1.31290, "iter": "30/60", "loss": 0.02320, "lr": 0.0005982120, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:48:06][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47578, "dt_data": 0.00074, "dt_net": 0.47504, "epoch": "190/300", "eta": "0:52:29", "gpu_mem": "10.07G", "grad_norm": 4.07715, "iter": "40/60", "loss": 0.04246, "lr": 0.0005966144, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:48:12][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47552, "dt_data": 0.00049, "dt_net": 0.47503, "epoch": "190/300", "eta": "0:52:23", "gpu_mem": "10.07G", "grad_norm": 8.39227, "iter": "50/60", "loss": 0.05131, "lr": 0.0005950180, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:48:17][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46927, "dt_data": 0.00020, "dt_net": 0.46907, "epoch": "190/300", "eta": "0:51:37", "gpu_mem": "10.07G", "grad_norm": 3.93828, "iter": "60/60", "loss": 0.01329, "lr": 0.0005934228, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:48:18][INFO] logging.py:  101: json_stats: {"RAM": "13.15/31.07G", "_type": "train_epoch", "dt": 0.69143, "dt_data": 0.69143, "dt_net": 0.46907, "epoch": "190/300", "eta": "1:16:03", "gpu_mem": "10.07G", "grad_norm": 3.93828, "loss": 0.04881, "lr": 0.0005934228, "top1_acc": 98.33333, "top1_err": 1.87500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:48:18][INFO] train_net.py:  708: Epoch 189 takes 48.29s. Epochs from 0 to 189 take 48.03s in average and 48.03s in median.
[06/12 20:48:18][INFO] train_net.py:  714: For epoch 189, each iteraction takes 0.80s in average. From epoch 0 to 189, each iteraction takes 0.80s in average.
[06/12 20:48:18][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 20:49:20][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "190/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.13003, "top1_acc": 76.56250, "top1_err": 23.43750, "top5_acc": 95.31250, "top5_err": 4.68750}
[06/12 20:49:23][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "val_epoch", "epoch": "190/300", "gpu_mem": "10.07G", "min_top1_err": 21.99170, "min_top5_err": 2.69710, "time_diff": 0.60460, "top1_acc": 76.55602, "top1_err": 23.44398, "top5_acc": 95.85062, "top5_err": 4.14938}
[06/12 20:49:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46415, "dt_data": 0.00096, "dt_net": 0.46319, "epoch": "191/300", "eta": "0:50:58", "gpu_mem": "10.07G", "grad_norm": 2.12843, "iter": "10/60", "loss": 0.02733, "lr": 0.0005918289, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:49:47][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46686, "dt_data": 0.00057, "dt_net": 0.46629, "epoch": "191/300", "eta": "0:51:11", "gpu_mem": "10.07G", "grad_norm": 4.56337, "iter": "20/60", "loss": 0.03097, "lr": 0.0005902362, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:49:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.67523, "dt_data": 0.00055, "dt_net": 0.67468, "epoch": "191/300", "eta": "1:13:56", "gpu_mem": "10.07G", "grad_norm": 4.12507, "iter": "30/60", "loss": 0.05206, "lr": 0.0005886447, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:49:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46814, "dt_data": 0.00052, "dt_net": 0.46761, "epoch": "191/300", "eta": "0:51:10", "gpu_mem": "10.07G", "grad_norm": 7.02395, "iter": "40/60", "loss": 0.01824, "lr": 0.0005870545, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:50:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.88765, "dt_data": 0.00040, "dt_net": 0.88725, "epoch": "191/300", "eta": "1:36:54", "gpu_mem": "10.07G", "grad_norm": 4.52265, "iter": "50/60", "loss": 0.05916, "lr": 0.0005854656, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:50:10][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46752, "dt_data": 0.00019, "dt_net": 0.46733, "epoch": "191/300", "eta": "0:50:57", "gpu_mem": "10.07G", "grad_norm": 1.77572, "iter": "60/60", "loss": 0.04262, "lr": 0.0005838779, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:50:11][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.68394, "dt_data": 0.68394, "dt_net": 0.46733, "epoch": "191/300", "eta": "1:14:32", "gpu_mem": "10.07G", "grad_norm": 1.77572, "loss": 0.05426, "lr": 0.0005838779, "top1_acc": 98.43750, "top1_err": 2.03125, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:50:11][INFO] train_net.py:  708: Epoch 190 takes 47.40s. Epochs from 0 to 190 take 48.03s in average and 48.03s in median.
[06/12 20:50:11][INFO] train_net.py:  714: For epoch 190, each iteraction takes 0.79s in average. From epoch 0 to 190, each iteraction takes 0.80s in average.
[06/12 20:50:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47414, "dt_data": 0.00031, "dt_net": 0.47383, "epoch": "192/300", "eta": "0:51:36", "gpu_mem": "10.07G", "grad_norm": 0.57272, "iter": "10/60", "loss": 0.05187, "lr": 0.0005822915, "top1_acc": 96.87500, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:50:34][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47547, "dt_data": 0.00042, "dt_net": 0.47505, "epoch": "192/300", "eta": "0:51:40", "gpu_mem": "10.07G", "grad_norm": 10.15894, "iter": "20/60", "loss": 0.02259, "lr": 0.0005807064, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:50:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47203, "dt_data": 0.00046, "dt_net": 0.47157, "epoch": "192/300", "eta": "0:51:12", "gpu_mem": "10.07G", "grad_norm": 1.50771, "iter": "30/60", "loss": 0.07247, "lr": 0.0005791225, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:50:47][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47714, "dt_data": 0.00084, "dt_net": 0.47629, "epoch": "192/300", "eta": "0:51:41", "gpu_mem": "10.07G", "grad_norm": 6.33667, "iter": "40/60", "loss": 0.04052, "lr": 0.0005775399, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:50:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47151, "dt_data": 0.00039, "dt_net": 0.47112, "epoch": "192/300", "eta": "0:51:00", "gpu_mem": "10.07G", "grad_norm": 0.24897, "iter": "50/60", "loss": 0.04052, "lr": 0.0005759586, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:50:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46915, "dt_data": 0.00027, "dt_net": 0.46888, "epoch": "192/300", "eta": "0:50:40", "gpu_mem": "10.07G", "grad_norm": 0.05157, "iter": "60/60", "loss": 0.01514, "lr": 0.0005743786, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:50:59][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.70024, "dt_data": 0.70024, "dt_net": 0.46888, "epoch": "192/300", "eta": "1:15:37", "gpu_mem": "10.07G", "grad_norm": 0.05157, "loss": 0.05639, "lr": 0.0005743786, "top1_acc": 97.70833, "top1_err": 1.97917, "top5_acc": 99.89583, "top5_err": 0.05208}
[06/12 20:50:59][INFO] train_net.py:  708: Epoch 191 takes 48.30s. Epochs from 0 to 191 take 48.03s in average and 48.03s in median.
[06/12 20:50:59][INFO] train_net.py:  714: For epoch 191, each iteraction takes 0.81s in average. From epoch 0 to 191, each iteraction takes 0.80s in average.
[06/12 20:51:17][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47294, "dt_data": 0.00030, "dt_net": 0.47264, "epoch": "193/300", "eta": "0:50:59", "gpu_mem": "10.07G", "grad_norm": 0.53068, "iter": "10/60", "loss": 0.04488, "lr": 0.0005727999, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:51:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47808, "dt_data": 0.00034, "dt_net": 0.47774, "epoch": "193/300", "eta": "0:51:28", "gpu_mem": "10.07G", "grad_norm": 3.35955, "iter": "20/60", "loss": 0.03548, "lr": 0.0005712225, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:51:29][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47548, "dt_data": 0.00063, "dt_net": 0.47484, "epoch": "193/300", "eta": "0:51:06", "gpu_mem": "10.07G", "grad_norm": 2.32016, "iter": "30/60", "loss": 0.03393, "lr": 0.0005696464, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:51:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47008, "dt_data": 0.00058, "dt_net": 0.46949, "epoch": "193/300", "eta": "0:50:27", "gpu_mem": "10.07G", "grad_norm": 3.03675, "iter": "40/60", "loss": 0.03068, "lr": 0.0005680717, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:51:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47645, "dt_data": 0.00047, "dt_net": 0.47598, "epoch": "193/300", "eta": "0:51:03", "gpu_mem": "10.07G", "grad_norm": 4.59900, "iter": "50/60", "loss": 0.07309, "lr": 0.0005664982, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:51:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46886, "dt_data": 0.00019, "dt_net": 0.46867, "epoch": "193/300", "eta": "0:50:10", "gpu_mem": "10.07G", "grad_norm": 1.11193, "iter": "60/60", "loss": 0.02688, "lr": 0.0005649260, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:51:47][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.69165, "dt_data": 0.69165, "dt_net": 0.46867, "epoch": "193/300", "eta": "1:14:00", "gpu_mem": "10.07G", "grad_norm": 1.11193, "loss": 0.04608, "lr": 0.0005649260, "top1_acc": 98.02083, "top1_err": 1.66667, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:51:47][INFO] train_net.py:  708: Epoch 192 takes 47.73s. Epochs from 0 to 192 take 48.03s in average and 48.03s in median.
[06/12 20:51:47][INFO] train_net.py:  714: For epoch 192, each iteraction takes 0.80s in average. From epoch 0 to 192, each iteraction takes 0.80s in average.
[06/12 20:52:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47186, "dt_data": 0.00042, "dt_net": 0.47143, "epoch": "194/300", "eta": "0:50:24", "gpu_mem": "10.07G", "grad_norm": 11.01508, "iter": "10/60", "loss": 0.04085, "lr": 0.0005633552, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:52:09][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47652, "dt_data": 0.00052, "dt_net": 0.47599, "epoch": "194/300", "eta": "0:50:49", "gpu_mem": "10.07G", "grad_norm": 6.95769, "iter": "20/60", "loss": 0.03206, "lr": 0.0005617857, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:52:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47207, "dt_data": 0.00045, "dt_net": 0.47161, "epoch": "194/300", "eta": "0:50:16", "gpu_mem": "10.07G", "grad_norm": 10.56659, "iter": "30/60", "loss": 0.05870, "lr": 0.0005602176, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:52:21][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47591, "dt_data": 0.00085, "dt_net": 0.47506, "epoch": "194/300", "eta": "0:50:36", "gpu_mem": "10.07G", "grad_norm": 6.31520, "iter": "40/60", "loss": 0.04234, "lr": 0.0005586508, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:52:27][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.66568, "dt_data": 0.19297, "dt_net": 0.47270, "epoch": "194/300", "eta": "1:10:40", "gpu_mem": "10.07G", "grad_norm": 5.69900, "iter": "50/60", "loss": 0.03234, "lr": 0.0005570853, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:52:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46940, "dt_data": 0.00017, "dt_net": 0.46923, "epoch": "194/300", "eta": "0:49:45", "gpu_mem": "10.07G", "grad_norm": 7.32784, "iter": "60/60", "loss": 0.01611, "lr": 0.0005555212, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:52:34][INFO] logging.py:  101: json_stats: {"RAM": "13.45/31.07G", "_type": "train_epoch", "dt": 0.70048, "dt_data": 0.70048, "dt_net": 0.46923, "epoch": "194/300", "eta": "1:14:14", "gpu_mem": "10.07G", "grad_norm": 7.32784, "loss": 0.05953, "lr": 0.0005555212, "top1_acc": 97.81250, "top1_err": 1.87500, "top5_acc": 99.89583, "top5_err": 0.05208}
[06/12 20:52:34][INFO] train_net.py:  708: Epoch 193 takes 47.21s. Epochs from 0 to 193 take 48.03s in average and 48.02s in median.
[06/12 20:52:34][INFO] train_net.py:  714: For epoch 193, each iteraction takes 0.79s in average. From epoch 0 to 193, each iteraction takes 0.80s in average.
[06/12 20:52:51][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47596, "dt_data": 0.00053, "dt_net": 0.47543, "epoch": "195/300", "eta": "0:50:22", "gpu_mem": "10.07G", "grad_norm": 1.35250, "iter": "10/60", "loss": 0.01853, "lr": 0.0005539584, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:52:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47732, "dt_data": 0.00032, "dt_net": 0.47700, "epoch": "195/300", "eta": "0:50:26", "gpu_mem": "10.07G", "grad_norm": 6.35763, "iter": "20/60", "loss": 0.04063, "lr": 0.0005523970, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:53:03][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48032, "dt_data": 0.00116, "dt_net": 0.47915, "epoch": "195/300", "eta": "0:50:40", "gpu_mem": "10.07G", "grad_norm": 2.36995, "iter": "30/60", "loss": 0.02928, "lr": 0.0005508369, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:53:09][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47589, "dt_data": 0.00068, "dt_net": 0.47520, "epoch": "195/300", "eta": "0:50:07", "gpu_mem": "10.07G", "grad_norm": 3.16748, "iter": "40/60", "loss": 0.03759, "lr": 0.0005492783, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:53:15][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47582, "dt_data": 0.00093, "dt_net": 0.47487, "epoch": "195/300", "eta": "0:50:02", "gpu_mem": "10.07G", "grad_norm": 7.70834, "iter": "50/60", "loss": 0.05218, "lr": 0.0005477209, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:53:21][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47041, "dt_data": 0.00018, "dt_net": 0.47023, "epoch": "195/300", "eta": "0:49:23", "gpu_mem": "10.07G", "grad_norm": 1.76161, "iter": "60/60", "loss": 0.06979, "lr": 0.0005461650, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:53:21][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.70258, "dt_data": 0.70258, "dt_net": 0.47023, "epoch": "195/300", "eta": "1:13:45", "gpu_mem": "10.07G", "grad_norm": 1.76161, "loss": 0.06205, "lr": 0.0005461650, "top1_acc": 98.12500, "top1_err": 1.77083, "top5_acc": 99.89583, "top5_err": 0.05208}
[06/12 20:53:21][INFO] train_net.py:  708: Epoch 194 takes 47.50s. Epochs from 0 to 194 take 48.02s in average and 48.02s in median.
[06/12 20:53:21][INFO] train_net.py:  714: For epoch 194, each iteraction takes 0.79s in average. From epoch 0 to 194, each iteraction takes 0.80s in average.
[06/12 20:53:21][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 20:54:23][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "195/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.12969, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 20:54:26][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "val_epoch", "epoch": "195/300", "gpu_mem": "10.07G", "min_top1_err": 21.99170, "min_top5_err": 2.69710, "time_diff": 0.59953, "top1_acc": 75.31120, "top1_err": 24.68880, "top5_acc": 97.09544, "top5_err": 2.90456}
[06/12 20:54:42][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46850, "dt_data": 0.00065, "dt_net": 0.46785, "epoch": "196/300", "eta": "0:49:06", "gpu_mem": "10.07G", "grad_norm": 1.30649, "iter": "10/60", "loss": 0.02168, "lr": 0.0005446105, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:54:48][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46971, "dt_data": 0.00067, "dt_net": 0.46904, "epoch": "196/300", "eta": "0:49:09", "gpu_mem": "10.07G", "grad_norm": 2.80023, "iter": "20/60", "loss": 0.03410, "lr": 0.0005430573, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:54:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47091, "dt_data": 0.00033, "dt_net": 0.47059, "epoch": "196/300", "eta": "0:49:12", "gpu_mem": "10.07G", "grad_norm": 0.64239, "iter": "30/60", "loss": 0.04823, "lr": 0.0005415055, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:55:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47777, "dt_data": 0.00057, "dt_net": 0.47720, "epoch": "196/300", "eta": "0:49:50", "gpu_mem": "10.07G", "grad_norm": 11.15212, "iter": "40/60", "loss": 0.02891, "lr": 0.0005399552, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:55:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46831, "dt_data": 0.00058, "dt_net": 0.46773, "epoch": "196/300", "eta": "0:48:46", "gpu_mem": "10.07G", "grad_norm": 14.89988, "iter": "50/60", "loss": 0.05989, "lr": 0.0005384062, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:55:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46546, "dt_data": 0.00022, "dt_net": 0.46525, "epoch": "196/300", "eta": "0:48:24", "gpu_mem": "10.07G", "grad_norm": 2.30990, "iter": "60/60", "loss": 0.02572, "lr": 0.0005368586, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:55:14][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.68735, "dt_data": 0.68735, "dt_net": 0.46525, "epoch": "196/300", "eta": "1:11:28", "gpu_mem": "10.07G", "grad_norm": 2.30990, "loss": 0.05249, "lr": 0.0005368586, "top1_acc": 98.43750, "top1_err": 1.92708, "top5_acc": 99.89583, "top5_err": 0.05208}
[06/12 20:55:14][INFO] train_net.py:  708: Epoch 195 takes 48.04s. Epochs from 0 to 195 take 48.02s in average and 48.02s in median.
[06/12 20:55:14][INFO] train_net.py:  714: For epoch 195, each iteraction takes 0.80s in average. From epoch 0 to 195, each iteraction takes 0.80s in average.
[06/12 20:55:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.62840, "dt_data": 0.15916, "dt_net": 0.46924, "epoch": "197/300", "eta": "1:05:14", "gpu_mem": "10.07G", "grad_norm": 3.49436, "iter": "10/60", "loss": 0.02606, "lr": 0.0005353125, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:55:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47190, "dt_data": 0.00042, "dt_net": 0.47148, "epoch": "197/300", "eta": "0:48:55", "gpu_mem": "10.07G", "grad_norm": 1.56484, "iter": "20/60", "loss": 0.02297, "lr": 0.0005337678, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:55:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.77165, "dt_data": 0.30204, "dt_net": 0.46960, "epoch": "197/300", "eta": "1:19:51", "gpu_mem": "10.07G", "grad_norm": 2.25056, "iter": "30/60", "loss": 0.02094, "lr": 0.0005322244, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:55:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.85118, "dt_data": 0.38202, "dt_net": 0.46915, "epoch": "197/300", "eta": "1:27:57", "gpu_mem": "10.07G", "grad_norm": 4.42576, "iter": "40/60", "loss": 0.01229, "lr": 0.0005306825, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:55:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47843, "dt_data": 0.00081, "dt_net": 0.47762, "epoch": "197/300", "eta": "0:49:21", "gpu_mem": "10.07G", "grad_norm": 1.23047, "iter": "50/60", "loss": 0.02176, "lr": 0.0005291421, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:56:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46973, "dt_data": 0.00018, "dt_net": 0.46955, "epoch": "197/300", "eta": "0:48:22", "gpu_mem": "10.07G", "grad_norm": 0.93344, "iter": "60/60", "loss": 0.02269, "lr": 0.0005276031, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:56:01][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.69421, "dt_data": 0.69421, "dt_net": 0.46955, "epoch": "197/300", "eta": "1:11:29", "gpu_mem": "10.07G", "grad_norm": 0.93344, "loss": 0.04273, "lr": 0.0005276031, "top1_acc": 98.54167, "top1_err": 1.25000, "top5_acc": 100.00000, "top5_err": 0.05208}
[06/12 20:56:01][INFO] train_net.py:  708: Epoch 196 takes 47.44s. Epochs from 0 to 196 take 48.02s in average and 48.02s in median.
[06/12 20:56:01][INFO] train_net.py:  714: For epoch 196, each iteraction takes 0.79s in average. From epoch 0 to 196, each iteraction takes 0.80s in average.
[06/12 20:56:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47239, "dt_data": 0.00071, "dt_net": 0.47167, "epoch": "198/300", "eta": "0:48:34", "gpu_mem": "10.07G", "grad_norm": 0.63620, "iter": "10/60", "loss": 0.03604, "lr": 0.0005260655, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:56:24][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47378, "dt_data": 0.00057, "dt_net": 0.47321, "epoch": "198/300", "eta": "0:48:38", "gpu_mem": "10.07G", "grad_norm": 1.33689, "iter": "20/60", "loss": 0.06736, "lr": 0.0005245293, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:56:30][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47707, "dt_data": 0.00078, "dt_net": 0.47628, "epoch": "198/300", "eta": "0:48:53", "gpu_mem": "10.07G", "grad_norm": 3.21636, "iter": "30/60", "loss": 0.02975, "lr": 0.0005229946, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:56:36][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47215, "dt_data": 0.00043, "dt_net": 0.47173, "epoch": "198/300", "eta": "0:48:19", "gpu_mem": "10.07G", "grad_norm": 6.95817, "iter": "40/60", "loss": 0.04430, "lr": 0.0005214614, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:56:42][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47373, "dt_data": 0.00045, "dt_net": 0.47327, "epoch": "198/300", "eta": "0:48:23", "gpu_mem": "10.07G", "grad_norm": 3.41017, "iter": "50/60", "loss": 0.02761, "lr": 0.0005199296, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:56:48][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46931, "dt_data": 0.00017, "dt_net": 0.46914, "epoch": "198/300", "eta": "0:47:52", "gpu_mem": "10.07G", "grad_norm": 4.90406, "iter": "60/60", "loss": 0.03832, "lr": 0.0005183993, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:56:49][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.69973, "dt_data": 0.69973, "dt_net": 0.46914, "epoch": "198/300", "eta": "1:11:22", "gpu_mem": "10.07G", "grad_norm": 4.90406, "loss": 0.05863, "lr": 0.0005183993, "top1_acc": 98.12500, "top1_err": 1.87500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:56:49][INFO] train_net.py:  708: Epoch 197 takes 47.62s. Epochs from 0 to 197 take 48.02s in average and 48.02s in median.
[06/12 20:56:49][INFO] train_net.py:  714: For epoch 197, each iteraction takes 0.79s in average. From epoch 0 to 197, each iteraction takes 0.80s in average.
[06/12 20:57:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.49473, "dt_data": 0.00041, "dt_net": 0.49432, "epoch": "199/300", "eta": "0:50:22", "gpu_mem": "10.07G", "grad_norm": 2.48659, "iter": "10/60", "loss": 0.01067, "lr": 0.0005168704, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:57:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47457, "dt_data": 0.00041, "dt_net": 0.47415, "epoch": "199/300", "eta": "0:48:14", "gpu_mem": "10.07G", "grad_norm": 0.21210, "iter": "20/60", "loss": 0.01218, "lr": 0.0005153430, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:57:17][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47703, "dt_data": 0.00083, "dt_net": 0.47620, "epoch": "199/300", "eta": "0:48:25", "gpu_mem": "10.07G", "grad_norm": 1.96802, "iter": "30/60", "loss": 0.03762, "lr": 0.0005138171, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:57:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46924, "dt_data": 0.00045, "dt_net": 0.46879, "epoch": "199/300", "eta": "0:47:32", "gpu_mem": "10.07G", "grad_norm": 8.97501, "iter": "40/60", "loss": 0.02861, "lr": 0.0005122927, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:57:30][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.12890, "dt_data": 0.00056, "dt_net": 1.12833, "epoch": "199/300", "eta": "1:54:12", "gpu_mem": "10.07G", "grad_norm": 2.23975, "iter": "50/60", "loss": 0.00715, "lr": 0.0005107698, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:57:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46924, "dt_data": 0.00016, "dt_net": 0.46908, "epoch": "199/300", "eta": "0:47:23", "gpu_mem": "10.07G", "grad_norm": 0.71658, "iter": "60/60", "loss": 0.02724, "lr": 0.0005092483, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:57:36][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.67159, "dt_data": 0.67159, "dt_net": 0.46908, "epoch": "199/300", "eta": "1:07:49", "gpu_mem": "10.07G", "grad_norm": 0.71658, "loss": 0.03485, "lr": 0.0005092483, "top1_acc": 98.54167, "top1_err": 1.30208, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:57:36][INFO] train_net.py:  708: Epoch 198 takes 46.70s. Epochs from 0 to 198 take 48.01s in average and 48.02s in median.
[06/12 20:57:36][INFO] train_net.py:  714: For epoch 198, each iteraction takes 0.78s in average. From epoch 0 to 198, each iteraction takes 0.80s in average.
[06/12 20:57:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47612, "dt_data": 0.00049, "dt_net": 0.47562, "epoch": "200/300", "eta": "0:48:00", "gpu_mem": "10.07G", "grad_norm": 3.31695, "iter": "10/60", "loss": 0.04320, "lr": 0.0005077284, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:57:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47226, "dt_data": 0.00032, "dt_net": 0.47194, "epoch": "200/300", "eta": "0:47:32", "gpu_mem": "10.07G", "grad_norm": 2.11004, "iter": "20/60", "loss": 0.03386, "lr": 0.0005062099, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:58:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47462, "dt_data": 0.00105, "dt_net": 0.47355, "epoch": "200/300", "eta": "0:47:41", "gpu_mem": "10.07G", "grad_norm": 0.88876, "iter": "30/60", "loss": 0.03971, "lr": 0.0005046929, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:58:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47572, "dt_data": 0.00036, "dt_net": 0.47536, "epoch": "200/300", "eta": "0:47:43", "gpu_mem": "10.07G", "grad_norm": 4.13594, "iter": "40/60", "loss": 0.04740, "lr": 0.0005031775, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:58:18][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47395, "dt_data": 0.00054, "dt_net": 0.47341, "epoch": "200/300", "eta": "0:47:28", "gpu_mem": "10.07G", "grad_norm": 2.03129, "iter": "50/60", "loss": 0.02098, "lr": 0.0005016636, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:58:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47161, "dt_data": 0.00034, "dt_net": 0.47127, "epoch": "200/300", "eta": "0:47:09", "gpu_mem": "10.07G", "grad_norm": 8.97686, "iter": "60/60", "loss": 0.05108, "lr": 0.0005001512, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:58:24][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.70259, "dt_data": 0.70259, "dt_net": 0.47127, "epoch": "200/300", "eta": "1:10:15", "gpu_mem": "10.07G", "grad_norm": 8.97686, "loss": 0.05816, "lr": 0.0005001512, "top1_acc": 97.91667, "top1_err": 1.92708, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:58:24][INFO] train_net.py:  708: Epoch 199 takes 48.26s. Epochs from 0 to 199 take 48.01s in average and 48.02s in median.
[06/12 20:58:24][INFO] train_net.py:  714: For epoch 199, each iteraction takes 0.80s in average. From epoch 0 to 199, each iteraction takes 0.80s in average.
[06/12 20:58:24][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 20:59:25][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "200/300", "eta": "0:00:02", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.37216, "top1_acc": 82.81250, "top1_err": 17.18750, "top5_acc": 98.43750, "top5_err": 1.56250}
[06/12 20:59:28][INFO] logging.py:  101: json_stats: {"RAM": "14.02/31.07G", "_type": "val_epoch", "epoch": "200/300", "gpu_mem": "10.07G", "min_top1_err": 21.99170, "min_top5_err": 2.69710, "time_diff": 0.59546, "top1_acc": 77.38589, "top1_err": 22.61411, "top5_acc": 96.88797, "top5_err": 3.11203}
[06/12 20:59:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46348, "dt_data": 0.00048, "dt_net": 0.46300, "epoch": "201/300", "eta": "0:46:16", "gpu_mem": "10.07G", "grad_norm": 1.78190, "iter": "10/60", "loss": 0.02324, "lr": 0.0004986403, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:59:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46835, "dt_data": 0.00057, "dt_net": 0.46777, "epoch": "201/300", "eta": "0:46:40", "gpu_mem": "10.07G", "grad_norm": 0.50008, "iter": "20/60", "loss": 0.05840, "lr": 0.0004971309, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 20:59:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46889, "dt_data": 0.00065, "dt_net": 0.46823, "epoch": "201/300", "eta": "0:46:39", "gpu_mem": "10.07G", "grad_norm": 0.07628, "iter": "30/60", "loss": 0.01773, "lr": 0.0004956231, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:00:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46889, "dt_data": 0.00035, "dt_net": 0.46853, "epoch": "201/300", "eta": "0:46:34", "gpu_mem": "10.07G", "grad_norm": 6.10742, "iter": "40/60", "loss": 0.06466, "lr": 0.0004941168, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:00:09][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47077, "dt_data": 0.00066, "dt_net": 0.47010, "epoch": "201/300", "eta": "0:46:41", "gpu_mem": "10.07G", "grad_norm": 11.45064, "iter": "50/60", "loss": 0.03084, "lr": 0.0004926120, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:00:15][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46785, "dt_data": 0.00018, "dt_net": 0.46766, "epoch": "201/300", "eta": "0:46:19", "gpu_mem": "10.07G", "grad_norm": 8.54741, "iter": "60/60", "loss": 0.07658, "lr": 0.0004911088, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:00:16][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.70282, "dt_data": 0.70282, "dt_net": 0.46766, "epoch": "201/300", "eta": "1:09:34", "gpu_mem": "10.07G", "grad_norm": 8.54741, "loss": 0.05732, "lr": 0.0004911088, "top1_acc": 97.81250, "top1_err": 2.34375, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:00:16][INFO] train_net.py:  708: Epoch 200 takes 47.33s. Epochs from 0 to 200 take 48.01s in average and 48.02s in median.
[06/12 21:00:16][INFO] train_net.py:  714: For epoch 200, each iteraction takes 0.79s in average. From epoch 0 to 200, each iteraction takes 0.80s in average.
[06/12 21:00:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47048, "dt_data": 0.00045, "dt_net": 0.47002, "epoch": "202/300", "eta": "0:46:29", "gpu_mem": "10.07G", "grad_norm": 0.49782, "iter": "10/60", "loss": 0.04506, "lr": 0.0004896072, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:00:39][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47338, "dt_data": 0.00039, "dt_net": 0.47299, "epoch": "202/300", "eta": "0:46:42", "gpu_mem": "10.07G", "grad_norm": 6.48877, "iter": "20/60", "loss": 0.04198, "lr": 0.0004881071, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:00:45][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.52006, "dt_data": 0.05015, "dt_net": 0.46991, "epoch": "202/300", "eta": "0:51:13", "gpu_mem": "10.07G", "grad_norm": 4.12757, "iter": "30/60", "loss": 0.02532, "lr": 0.0004866085, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:00:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47499, "dt_data": 0.00048, "dt_net": 0.47450, "epoch": "202/300", "eta": "0:46:42", "gpu_mem": "10.07G", "grad_norm": 6.17035, "iter": "40/60", "loss": 0.02835, "lr": 0.0004851115, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:00:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47478, "dt_data": 0.00036, "dt_net": 0.47442, "epoch": "202/300", "eta": "0:46:36", "gpu_mem": "10.07G", "grad_norm": 3.08824, "iter": "50/60", "loss": 0.03114, "lr": 0.0004836161, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:01:02][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46937, "dt_data": 0.00018, "dt_net": 0.46918, "epoch": "202/300", "eta": "0:45:59", "gpu_mem": "10.07G", "grad_norm": 1.59830, "iter": "60/60", "loss": 0.04221, "lr": 0.0004821223, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:01:03][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.69925, "dt_data": 0.69925, "dt_net": 0.46918, "epoch": "202/300", "eta": "1:08:31", "gpu_mem": "10.07G", "grad_norm": 1.59830, "loss": 0.06231, "lr": 0.0004821223, "top1_acc": 97.39583, "top1_err": 2.18750, "top5_acc": 100.00000, "top5_err": 0.05208}
[06/12 21:01:03][INFO] train_net.py:  708: Epoch 201 takes 47.53s. Epochs from 0 to 201 take 48.01s in average and 48.02s in median.
[06/12 21:01:03][INFO] train_net.py:  714: For epoch 201, each iteraction takes 0.79s in average. From epoch 0 to 201, each iteraction takes 0.80s in average.
[06/12 21:01:20][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47083, "dt_data": 0.00033, "dt_net": 0.47050, "epoch": "203/300", "eta": "0:46:03", "gpu_mem": "10.07G", "grad_norm": 8.09651, "iter": "10/60", "loss": 0.06630, "lr": 0.0004806300, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:01:26][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47442, "dt_data": 0.00067, "dt_net": 0.47375, "epoch": "203/300", "eta": "0:46:20", "gpu_mem": "10.07G", "grad_norm": 3.17655, "iter": "20/60", "loss": 0.01739, "lr": 0.0004791393, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:01:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47433, "dt_data": 0.00053, "dt_net": 0.47380, "epoch": "203/300", "eta": "0:46:14", "gpu_mem": "10.07G", "grad_norm": 5.82680, "iter": "30/60", "loss": 0.01558, "lr": 0.0004776503, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:01:38][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47239, "dt_data": 0.00048, "dt_net": 0.47191, "epoch": "203/300", "eta": "0:45:58", "gpu_mem": "10.07G", "grad_norm": 0.84315, "iter": "40/60", "loss": 0.01887, "lr": 0.0004761628, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:01:44][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48286, "dt_data": 0.00042, "dt_net": 0.48244, "epoch": "203/300", "eta": "0:46:55", "gpu_mem": "10.07G", "grad_norm": 0.18901, "iter": "50/60", "loss": 0.03263, "lr": 0.0004746769, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:01:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47075, "dt_data": 0.00019, "dt_net": 0.47055, "epoch": "203/300", "eta": "0:45:39", "gpu_mem": "10.07G", "grad_norm": 2.74555, "iter": "60/60", "loss": 0.01805, "lr": 0.0004731925, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:01:50][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.69639, "dt_data": 0.69639, "dt_net": 0.47055, "epoch": "203/300", "eta": "1:07:32", "gpu_mem": "10.07G", "grad_norm": 2.74555, "loss": 0.04276, "lr": 0.0004731925, "top1_acc": 98.22917, "top1_err": 1.66667, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:01:50][INFO] train_net.py:  708: Epoch 202 takes 47.40s. Epochs from 0 to 202 take 48.01s in average and 48.01s in median.
[06/12 21:01:50][INFO] train_net.py:  714: For epoch 202, each iteraction takes 0.79s in average. From epoch 0 to 202, each iteraction takes 0.80s in average.
[06/12 21:02:08][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47183, "dt_data": 0.00036, "dt_net": 0.47147, "epoch": "204/300", "eta": "0:45:41", "gpu_mem": "10.07G", "grad_norm": 0.46747, "iter": "10/60", "loss": 0.01934, "lr": 0.0004717098, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:02:14][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47631, "dt_data": 0.00044, "dt_net": 0.47587, "epoch": "204/300", "eta": "0:46:02", "gpu_mem": "10.07G", "grad_norm": 4.97427, "iter": "20/60", "loss": 0.03856, "lr": 0.0004702288, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:02:20][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47416, "dt_data": 0.00036, "dt_net": 0.47379, "epoch": "204/300", "eta": "0:45:45", "gpu_mem": "10.07G", "grad_norm": 4.67907, "iter": "30/60", "loss": 0.09364, "lr": 0.0004687493, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:02:26][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47598, "dt_data": 0.00044, "dt_net": 0.47554, "epoch": "204/300", "eta": "0:45:51", "gpu_mem": "10.07G", "grad_norm": 5.43980, "iter": "40/60", "loss": 0.03473, "lr": 0.0004672714, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:02:32][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47458, "dt_data": 0.00049, "dt_net": 0.47409, "epoch": "204/300", "eta": "0:45:38", "gpu_mem": "10.07G", "grad_norm": 4.92059, "iter": "50/60", "loss": 0.03926, "lr": 0.0004657952, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:02:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47051, "dt_data": 0.00019, "dt_net": 0.47032, "epoch": "204/300", "eta": "0:45:10", "gpu_mem": "10.07G", "grad_norm": 1.31181, "iter": "60/60", "loss": 0.04112, "lr": 0.0004643206, "top1_acc": 96.87500, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:02:38][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.71445, "dt_data": 0.71445, "dt_net": 0.47032, "epoch": "204/300", "eta": "1:08:35", "gpu_mem": "10.07G", "grad_norm": 1.31181, "loss": 0.05367, "lr": 0.0004643206, "top1_acc": 97.91667, "top1_err": 1.87500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:02:38][INFO] train_net.py:  708: Epoch 203 takes 47.75s. Epochs from 0 to 203 take 48.00s in average and 48.01s in median.
[06/12 21:02:38][INFO] train_net.py:  714: For epoch 203, each iteraction takes 0.80s in average. From epoch 0 to 203, each iteraction takes 0.80s in average.
[06/12 21:02:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47687, "dt_data": 0.00068, "dt_net": 0.47619, "epoch": "205/300", "eta": "0:45:42", "gpu_mem": "10.07G", "grad_norm": 0.41854, "iter": "10/60", "loss": 0.01129, "lr": 0.0004628476, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:03:02][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47624, "dt_data": 0.00029, "dt_net": 0.47595, "epoch": "205/300", "eta": "0:45:33", "gpu_mem": "10.07G", "grad_norm": 4.19398, "iter": "20/60", "loss": 0.02792, "lr": 0.0004613763, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:03:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47377, "dt_data": 0.00048, "dt_net": 0.47329, "epoch": "205/300", "eta": "0:45:14", "gpu_mem": "10.07G", "grad_norm": 0.23406, "iter": "30/60", "loss": 0.02986, "lr": 0.0004599066, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:03:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47995, "dt_data": 0.00042, "dt_net": 0.47952, "epoch": "205/300", "eta": "0:45:45", "gpu_mem": "10.07G", "grad_norm": 0.21066, "iter": "40/60", "loss": 0.04064, "lr": 0.0004584385, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:03:20][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47886, "dt_data": 0.00032, "dt_net": 0.47855, "epoch": "205/300", "eta": "0:45:34", "gpu_mem": "10.07G", "grad_norm": 5.55842, "iter": "50/60", "loss": 0.02404, "lr": 0.0004569721, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:03:26][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47103, "dt_data": 0.00019, "dt_net": 0.47084, "epoch": "205/300", "eta": "0:44:44", "gpu_mem": "10.07G", "grad_norm": 6.18173, "iter": "60/60", "loss": 0.02458, "lr": 0.0004555073, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:03:27][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.70444, "dt_data": 0.70444, "dt_net": 0.47084, "epoch": "205/300", "eta": "1:06:55", "gpu_mem": "10.07G", "grad_norm": 6.18173, "loss": 0.04773, "lr": 0.0004555073, "top1_acc": 98.64583, "top1_err": 1.61458, "top5_acc": 99.89583, "top5_err": 0.10417}
[06/12 21:03:27][INFO] train_net.py:  708: Epoch 204 takes 48.39s. Epochs from 0 to 204 take 48.01s in average and 48.01s in median.
[06/12 21:03:27][INFO] train_net.py:  714: For epoch 204, each iteraction takes 0.81s in average. From epoch 0 to 204, each iteraction takes 0.80s in average.
[06/12 21:03:27][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 21:04:27][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "205/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.13017, "top1_acc": 79.68750, "top1_err": 20.31250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:04:31][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "val_epoch", "epoch": "205/300", "gpu_mem": "10.07G", "min_top1_err": 21.99170, "min_top5_err": 2.28216, "time_diff": 0.63028, "top1_acc": 75.72614, "top1_err": 24.27386, "top5_acc": 97.71784, "top5_err": 2.28216}
[06/12 21:04:48][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46689, "dt_data": 0.00065, "dt_net": 0.46623, "epoch": "206/300", "eta": "0:44:16", "gpu_mem": "10.07G", "grad_norm": 7.01578, "iter": "10/60", "loss": 0.02406, "lr": 0.0004540443, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:04:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47259, "dt_data": 0.00101, "dt_net": 0.47157, "epoch": "206/300", "eta": "0:44:44", "gpu_mem": "10.07G", "grad_norm": 1.11967, "iter": "20/60", "loss": 0.02862, "lr": 0.0004525828, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:05:00][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.97910, "dt_data": 0.00036, "dt_net": 0.97874, "epoch": "206/300", "eta": "1:32:31", "gpu_mem": "10.07G", "grad_norm": 1.04508, "iter": "30/60", "loss": 0.02018, "lr": 0.0004511231, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:05:06][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46741, "dt_data": 0.00036, "dt_net": 0.46705, "epoch": "206/300", "eta": "0:44:05", "gpu_mem": "10.07G", "grad_norm": 2.01094, "iter": "40/60", "loss": 0.02493, "lr": 0.0004496650, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:05:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.93959, "dt_data": 0.00042, "dt_net": 0.93916, "epoch": "206/300", "eta": "1:28:28", "gpu_mem": "10.07G", "grad_norm": 3.20962, "iter": "50/60", "loss": 0.02680, "lr": 0.0004482086, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:05:18][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46709, "dt_data": 0.00018, "dt_net": 0.46690, "epoch": "206/300", "eta": "0:43:54", "gpu_mem": "10.07G", "grad_norm": 2.77876, "iter": "60/60", "loss": 0.03912, "lr": 0.0004467538, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:05:19][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.71011, "dt_data": 0.71011, "dt_net": 0.46690, "epoch": "206/300", "eta": "1:06:44", "gpu_mem": "10.07G", "grad_norm": 2.77876, "loss": 0.04170, "lr": 0.0004467538, "top1_acc": 99.06250, "top1_err": 1.40625, "top5_acc": 100.00000, "top5_err": 0.05208}
[06/12 21:05:19][INFO] train_net.py:  708: Epoch 205 takes 48.13s. Epochs from 0 to 205 take 48.01s in average and 48.02s in median.
[06/12 21:05:19][INFO] train_net.py:  714: For epoch 205, each iteraction takes 0.80s in average. From epoch 0 to 205, each iteraction takes 0.80s in average.
[06/12 21:05:36][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.63355, "dt_data": 0.00058, "dt_net": 0.63297, "epoch": "207/300", "eta": "0:59:26", "gpu_mem": "10.07G", "grad_norm": 1.27687, "iter": "10/60", "loss": 0.03225, "lr": 0.0004453008, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:05:42][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47108, "dt_data": 0.00070, "dt_net": 0.47037, "epoch": "207/300", "eta": "0:44:07", "gpu_mem": "10.07G", "grad_norm": 5.47628, "iter": "20/60", "loss": 0.02580, "lr": 0.0004438494, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:05:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47246, "dt_data": 0.00048, "dt_net": 0.47198, "epoch": "207/300", "eta": "0:44:10", "gpu_mem": "10.07G", "grad_norm": 0.80620, "iter": "30/60", "loss": 0.01187, "lr": 0.0004423998, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:05:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47713, "dt_data": 0.00055, "dt_net": 0.47658, "epoch": "207/300", "eta": "0:44:31", "gpu_mem": "10.07G", "grad_norm": 0.30202, "iter": "40/60", "loss": 0.01243, "lr": 0.0004409518, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:06:02][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47497, "dt_data": 0.00135, "dt_net": 0.47360, "epoch": "207/300", "eta": "0:44:15", "gpu_mem": "10.07G", "grad_norm": 4.01701, "iter": "50/60", "loss": 0.02356, "lr": 0.0004395055, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:06:08][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46988, "dt_data": 0.00019, "dt_net": 0.46969, "epoch": "207/300", "eta": "0:43:41", "gpu_mem": "10.07G", "grad_norm": 0.47043, "iter": "60/60", "loss": 0.01469, "lr": 0.0004380610, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:06:08][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.70678, "dt_data": 0.70679, "dt_net": 0.46969, "epoch": "207/300", "eta": "1:05:43", "gpu_mem": "10.07G", "grad_norm": 0.47043, "loss": 0.03841, "lr": 0.0004380610, "top1_acc": 98.75000, "top1_err": 1.45833, "top5_acc": 100.00000, "top5_err": 0.05208}
[06/12 21:06:08][INFO] train_net.py:  708: Epoch 206 takes 49.57s. Epochs from 0 to 206 take 48.01s in average and 48.02s in median.
[06/12 21:06:08][INFO] train_net.py:  714: For epoch 206, each iteraction takes 0.83s in average. From epoch 0 to 206, each iteraction takes 0.80s in average.
[06/12 21:06:26][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46764, "dt_data": 0.00041, "dt_net": 0.46723, "epoch": "208/300", "eta": "0:43:24", "gpu_mem": "10.07G", "grad_norm": 2.82151, "iter": "10/60", "loss": 0.04959, "lr": 0.0004366181, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:06:32][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47720, "dt_data": 0.00050, "dt_net": 0.47670, "epoch": "208/300", "eta": "0:44:13", "gpu_mem": "10.07G", "grad_norm": 2.98868, "iter": "20/60", "loss": 0.02751, "lr": 0.0004351770, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:06:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47254, "dt_data": 0.00038, "dt_net": 0.47216, "epoch": "208/300", "eta": "0:43:42", "gpu_mem": "10.07G", "grad_norm": 0.05446, "iter": "30/60", "loss": 0.03672, "lr": 0.0004337376, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:06:44][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47392, "dt_data": 0.00061, "dt_net": 0.47331, "epoch": "208/300", "eta": "0:43:45", "gpu_mem": "10.07G", "grad_norm": 2.08341, "iter": "40/60", "loss": 0.04440, "lr": 0.0004322999, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:06:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48916, "dt_data": 0.00074, "dt_net": 0.48841, "epoch": "208/300", "eta": "0:45:05", "gpu_mem": "10.07G", "grad_norm": 0.97452, "iter": "50/60", "loss": 0.03450, "lr": 0.0004308640, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:06:56][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46984, "dt_data": 0.00015, "dt_net": 0.46968, "epoch": "208/300", "eta": "0:43:13", "gpu_mem": "10.07G", "grad_norm": 3.85046, "iter": "60/60", "loss": 0.02373, "lr": 0.0004294298, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:06:56][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.69233, "dt_data": 0.69233, "dt_net": 0.46968, "epoch": "208/300", "eta": "1:03:41", "gpu_mem": "10.07G", "grad_norm": 3.85046, "loss": 0.05136, "lr": 0.0004294298, "top1_acc": 97.60417, "top1_err": 1.92708, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:06:56][INFO] train_net.py:  708: Epoch 207 takes 47.89s. Epochs from 0 to 207 take 48.01s in average and 48.02s in median.
[06/12 21:06:56][INFO] train_net.py:  714: For epoch 207, each iteraction takes 0.80s in average. From epoch 0 to 207, each iteraction takes 0.80s in average.
[06/12 21:07:14][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46965, "dt_data": 0.00055, "dt_net": 0.46909, "epoch": "209/300", "eta": "0:43:07", "gpu_mem": "10.07G", "grad_norm": 2.06357, "iter": "10/60", "loss": 0.01958, "lr": 0.0004279973, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:07:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47407, "dt_data": 0.00039, "dt_net": 0.47367, "epoch": "209/300", "eta": "0:43:27", "gpu_mem": "10.07G", "grad_norm": 0.71495, "iter": "20/60", "loss": 0.02215, "lr": 0.0004265665, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:07:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47192, "dt_data": 0.00037, "dt_net": 0.47156, "epoch": "209/300", "eta": "0:43:10", "gpu_mem": "10.07G", "grad_norm": 1.77752, "iter": "30/60", "loss": 0.01011, "lr": 0.0004251376, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:07:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.79639, "dt_data": 0.00065, "dt_net": 0.79574, "epoch": "209/300", "eta": "1:12:44", "gpu_mem": "10.07G", "grad_norm": 9.15761, "iter": "40/60", "loss": 0.02272, "lr": 0.0004237103, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:07:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47883, "dt_data": 0.00074, "dt_net": 0.47808, "epoch": "209/300", "eta": "0:43:39", "gpu_mem": "10.07G", "grad_norm": 0.84376, "iter": "50/60", "loss": 0.01398, "lr": 0.0004222848, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:07:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.75074, "dt_data": 0.00021, "dt_net": 0.75053, "epoch": "209/300", "eta": "1:08:19", "gpu_mem": "10.07G", "grad_norm": 2.54784, "iter": "60/60", "loss": 0.06165, "lr": 0.0004208611, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:07:43][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.70122, "dt_data": 0.70122, "dt_net": 0.75053, "epoch": "209/300", "eta": "1:03:48", "gpu_mem": "10.07G", "grad_norm": 2.54784, "loss": 0.03733, "lr": 0.0004208611, "top1_acc": 98.95833, "top1_err": 1.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:07:43][INFO] train_net.py:  708: Epoch 208 takes 47.14s. Epochs from 0 to 208 take 48.01s in average and 48.01s in median.
[06/12 21:07:43][INFO] train_net.py:  714: For epoch 208, each iteraction takes 0.79s in average. From epoch 0 to 208, each iteraction takes 0.80s in average.
[06/12 21:08:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48361, "dt_data": 0.00039, "dt_net": 0.48322, "epoch": "210/300", "eta": "0:43:55", "gpu_mem": "10.07G", "grad_norm": 3.09466, "iter": "10/60", "loss": 0.05081, "lr": 0.0004194391, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:08:08][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47360, "dt_data": 0.00030, "dt_net": 0.47330, "epoch": "210/300", "eta": "0:42:56", "gpu_mem": "10.07G", "grad_norm": 0.51291, "iter": "20/60", "loss": 0.03187, "lr": 0.0004180190, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:08:14][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48137, "dt_data": 0.00034, "dt_net": 0.48103, "epoch": "210/300", "eta": "0:43:33", "gpu_mem": "10.07G", "grad_norm": 5.23954, "iter": "30/60", "loss": 0.00693, "lr": 0.0004166005, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:08:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47644, "dt_data": 0.00046, "dt_net": 0.47598, "epoch": "210/300", "eta": "0:43:02", "gpu_mem": "10.07G", "grad_norm": 3.65053, "iter": "40/60", "loss": 0.02850, "lr": 0.0004151839, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:08:26][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47940, "dt_data": 0.00050, "dt_net": 0.47890, "epoch": "210/300", "eta": "0:43:13", "gpu_mem": "10.07G", "grad_norm": 2.07704, "iter": "50/60", "loss": 0.02435, "lr": 0.0004137690, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:08:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47024, "dt_data": 0.00016, "dt_net": 0.47008, "epoch": "210/300", "eta": "0:42:19", "gpu_mem": "10.07G", "grad_norm": 6.33639, "iter": "60/60", "loss": 0.03608, "lr": 0.0004123560, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:08:32][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.71841, "dt_data": 0.71841, "dt_net": 0.47008, "epoch": "210/300", "eta": "1:04:39", "gpu_mem": "10.07G", "grad_norm": 6.33639, "loss": 0.04184, "lr": 0.0004123560, "top1_acc": 98.75000, "top1_err": 1.30208, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:08:32][INFO] train_net.py:  708: Epoch 209 takes 48.26s. Epochs from 0 to 209 take 48.01s in average and 48.02s in median.
[06/12 21:08:32][INFO] train_net.py:  714: For epoch 209, each iteraction takes 0.80s in average. From epoch 0 to 209, each iteraction takes 0.80s in average.
[06/12 21:08:32][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 21:09:34][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "210/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.12967, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 21:09:37][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "val_epoch", "epoch": "210/300", "gpu_mem": "10.07G", "min_top1_err": 21.99170, "min_top5_err": 2.28216, "time_diff": 0.61953, "top1_acc": 73.65145, "top1_err": 26.34855, "top5_acc": 96.68050, "top5_err": 3.31950}
[06/12 21:09:54][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46568, "dt_data": 0.00049, "dt_net": 0.46518, "epoch": "211/300", "eta": "0:41:49", "gpu_mem": "10.07G", "grad_norm": 0.19933, "iter": "10/60", "loss": 0.02187, "lr": 0.0004109447, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:10:00][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46628, "dt_data": 0.00061, "dt_net": 0.46567, "epoch": "211/300", "eta": "0:41:48", "gpu_mem": "10.07G", "grad_norm": 2.34600, "iter": "20/60", "loss": 0.05185, "lr": 0.0004095352, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:10:06][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46951, "dt_data": 0.00045, "dt_net": 0.46905, "epoch": "211/300", "eta": "0:42:01", "gpu_mem": "10.07G", "grad_norm": 3.18745, "iter": "30/60", "loss": 0.03141, "lr": 0.0004081275, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:10:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47042, "dt_data": 0.00059, "dt_net": 0.46983, "epoch": "211/300", "eta": "0:42:01", "gpu_mem": "10.07G", "grad_norm": 3.46773, "iter": "40/60", "loss": 0.02993, "lr": 0.0004067216, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:10:18][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.72988, "dt_data": 0.00039, "dt_net": 0.72949, "epoch": "211/300", "eta": "1:05:04", "gpu_mem": "10.07G", "grad_norm": 6.28574, "iter": "50/60", "loss": 0.03459, "lr": 0.0004053175, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:10:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47113, "dt_data": 0.00017, "dt_net": 0.47096, "epoch": "211/300", "eta": "0:41:55", "gpu_mem": "10.07G", "grad_norm": 3.57365, "iter": "60/60", "loss": 0.02283, "lr": 0.0004039153, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:10:24][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.70601, "dt_data": 0.70601, "dt_net": 0.47096, "epoch": "211/300", "eta": "1:02:49", "gpu_mem": "10.07G", "grad_norm": 3.57365, "loss": 0.06251, "lr": 0.0004039153, "top1_acc": 97.39583, "top1_err": 1.97917, "top5_acc": 99.79167, "top5_err": 0.10417}
[06/12 21:10:24][INFO] train_net.py:  708: Epoch 210 takes 47.19s. Epochs from 0 to 210 take 48.01s in average and 48.01s in median.
[06/12 21:10:24][INFO] train_net.py:  714: For epoch 210, each iteraction takes 0.79s in average. From epoch 0 to 210, each iteraction takes 0.80s in average.
[06/12 21:10:42][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48841, "dt_data": 0.00074, "dt_net": 0.48766, "epoch": "212/300", "eta": "0:43:23", "gpu_mem": "10.07G", "grad_norm": 4.81855, "iter": "10/60", "loss": 0.03343, "lr": 0.0004025148, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:10:47][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47277, "dt_data": 0.00040, "dt_net": 0.47237, "epoch": "212/300", "eta": "0:41:55", "gpu_mem": "10.07G", "grad_norm": 2.12684, "iter": "20/60", "loss": 0.01022, "lr": 0.0004011162, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:10:54][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.11833, "dt_data": 0.00049, "dt_net": 1.11783, "epoch": "212/300", "eta": "1:38:58", "gpu_mem": "10.07G", "grad_norm": 7.24794, "iter": "30/60", "loss": 0.02201, "lr": 0.0003997194, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:10:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47586, "dt_data": 0.00038, "dt_net": 0.47548, "epoch": "212/300", "eta": "0:42:02", "gpu_mem": "10.07G", "grad_norm": 2.54284, "iter": "40/60", "loss": 0.01629, "lr": 0.0003983244, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:11:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.57495, "dt_data": 0.00038, "dt_net": 0.57456, "epoch": "212/300", "eta": "0:50:41", "gpu_mem": "10.07G", "grad_norm": 0.26624, "iter": "50/60", "loss": 0.03657, "lr": 0.0003969312, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:11:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47214, "dt_data": 0.00025, "dt_net": 0.47189, "epoch": "212/300", "eta": "0:41:32", "gpu_mem": "10.07G", "grad_norm": 5.93019, "iter": "60/60", "loss": 0.02788, "lr": 0.0003955399, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:11:11][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.71274, "dt_data": 0.71274, "dt_net": 0.47189, "epoch": "212/300", "eta": "1:02:42", "gpu_mem": "10.07G", "grad_norm": 5.93019, "loss": 0.04358, "lr": 0.0003955399, "top1_acc": 98.64583, "top1_err": 1.45833, "top5_acc": 100.00000, "top5_err": 0.05208}
[06/12 21:11:11][INFO] train_net.py:  708: Epoch 211 takes 47.45s. Epochs from 0 to 211 take 48.00s in average and 48.01s in median.
[06/12 21:11:11][INFO] train_net.py:  714: For epoch 211, each iteraction takes 0.79s in average. From epoch 0 to 211, each iteraction takes 0.80s in average.
[06/12 21:11:29][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46979, "dt_data": 0.00041, "dt_net": 0.46937, "epoch": "213/300", "eta": "0:41:15", "gpu_mem": "10.07G", "grad_norm": 0.60785, "iter": "10/60", "loss": 0.01794, "lr": 0.0003941504, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:11:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48137, "dt_data": 0.00034, "dt_net": 0.48103, "epoch": "213/300", "eta": "0:42:12", "gpu_mem": "10.07G", "grad_norm": 2.46274, "iter": "20/60", "loss": 0.04723, "lr": 0.0003927628, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:11:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47147, "dt_data": 0.00036, "dt_net": 0.47110, "epoch": "213/300", "eta": "0:41:15", "gpu_mem": "10.07G", "grad_norm": 1.17017, "iter": "30/60", "loss": 0.03266, "lr": 0.0003913770, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:11:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47723, "dt_data": 0.00048, "dt_net": 0.47675, "epoch": "213/300", "eta": "0:41:40", "gpu_mem": "10.07G", "grad_norm": 0.54038, "iter": "40/60", "loss": 0.01125, "lr": 0.0003899931, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:11:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.24533, "dt_data": 0.00085, "dt_net": 1.24447, "epoch": "213/300", "eta": "1:48:33", "gpu_mem": "10.07G", "grad_norm": 4.36845, "iter": "50/60", "loss": 0.03849, "lr": 0.0003886111, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:11:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46865, "dt_data": 0.00017, "dt_net": 0.46848, "epoch": "213/300", "eta": "0:40:46", "gpu_mem": "10.07G", "grad_norm": 5.67291, "iter": "60/60", "loss": 0.04861, "lr": 0.0003872309, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:11:59][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.70811, "dt_data": 0.70811, "dt_net": 0.46848, "epoch": "213/300", "eta": "1:01:36", "gpu_mem": "10.07G", "grad_norm": 5.67291, "loss": 0.04430, "lr": 0.0003872309, "top1_acc": 98.02083, "top1_err": 1.56250, "top5_acc": 99.89583, "top5_err": 0.05208}
[06/12 21:11:59][INFO] train_net.py:  708: Epoch 212 takes 47.74s. Epochs from 0 to 212 take 48.00s in average and 48.01s in median.
[06/12 21:11:59][INFO] train_net.py:  714: For epoch 212, each iteraction takes 0.80s in average. From epoch 0 to 212, each iteraction takes 0.80s in average.
[06/12 21:12:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.53395, "dt_data": 0.06149, "dt_net": 0.47245, "epoch": "214/300", "eta": "0:46:21", "gpu_mem": "10.07G", "grad_norm": 1.52893, "iter": "10/60", "loss": 0.04833, "lr": 0.0003858525, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:12:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47088, "dt_data": 0.00048, "dt_net": 0.47040, "epoch": "214/300", "eta": "0:40:48", "gpu_mem": "10.07G", "grad_norm": 4.73731, "iter": "20/60", "loss": 0.05136, "lr": 0.0003844761, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:12:29][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46978, "dt_data": 0.00037, "dt_net": 0.46941, "epoch": "214/300", "eta": "0:40:38", "gpu_mem": "10.07G", "grad_norm": 3.39370, "iter": "30/60", "loss": 0.05480, "lr": 0.0003831015, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:12:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47715, "dt_data": 0.00038, "dt_net": 0.47677, "epoch": "214/300", "eta": "0:41:11", "gpu_mem": "10.07G", "grad_norm": 0.43759, "iter": "40/60", "loss": 0.01555, "lr": 0.0003817288, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:12:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47573, "dt_data": 0.00039, "dt_net": 0.47534, "epoch": "214/300", "eta": "0:40:59", "gpu_mem": "10.07G", "grad_norm": 0.17287, "iter": "50/60", "loss": 0.02654, "lr": 0.0003803579, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:12:47][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46905, "dt_data": 0.00016, "dt_net": 0.46888, "epoch": "214/300", "eta": "0:40:20", "gpu_mem": "10.07G", "grad_norm": 3.18950, "iter": "60/60", "loss": 0.02009, "lr": 0.0003789890, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:12:47][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.70470, "dt_data": 0.70470, "dt_net": 0.46888, "epoch": "214/300", "eta": "1:00:36", "gpu_mem": "10.07G", "grad_norm": 3.18950, "loss": 0.05122, "lr": 0.0003789890, "top1_acc": 98.12500, "top1_err": 1.77083, "top5_acc": 99.89583, "top5_err": 0.10417}
[06/12 21:12:47][INFO] train_net.py:  708: Epoch 213 takes 48.15s. Epochs from 0 to 213 take 48.00s in average and 48.01s in median.
[06/12 21:12:47][INFO] train_net.py:  714: For epoch 213, each iteraction takes 0.80s in average. From epoch 0 to 213, each iteraction takes 0.80s in average.
[06/12 21:13:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47067, "dt_data": 0.00060, "dt_net": 0.47006, "epoch": "215/300", "eta": "0:40:23", "gpu_mem": "10.07G", "grad_norm": 2.03280, "iter": "10/60", "loss": 0.00763, "lr": 0.0003776220, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:13:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47303, "dt_data": 0.00057, "dt_net": 0.47246, "epoch": "215/300", "eta": "0:40:31", "gpu_mem": "10.07G", "grad_norm": 2.17059, "iter": "20/60", "loss": 0.02871, "lr": 0.0003762568, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:13:17][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47575, "dt_data": 0.00044, "dt_net": 0.47531, "epoch": "215/300", "eta": "0:40:40", "gpu_mem": "10.07G", "grad_norm": 6.37179, "iter": "30/60", "loss": 0.02670, "lr": 0.0003748936, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:13:24][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47145, "dt_data": 0.00053, "dt_net": 0.47091, "epoch": "215/300", "eta": "0:40:13", "gpu_mem": "10.07G", "grad_norm": 6.42452, "iter": "40/60", "loss": 0.03635, "lr": 0.0003735322, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:13:30][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47539, "dt_data": 0.00050, "dt_net": 0.47489, "epoch": "215/300", "eta": "0:40:29", "gpu_mem": "10.07G", "grad_norm": 8.29682, "iter": "50/60", "loss": 0.02170, "lr": 0.0003721728, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:13:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46958, "dt_data": 0.00016, "dt_net": 0.46942, "epoch": "215/300", "eta": "0:39:54", "gpu_mem": "10.07G", "grad_norm": 0.32190, "iter": "60/60", "loss": 0.02556, "lr": 0.0003708153, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:13:36][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.70852, "dt_data": 0.70852, "dt_net": 0.46942, "epoch": "215/300", "eta": "1:00:13", "gpu_mem": "10.07G", "grad_norm": 0.32190, "loss": 0.04063, "lr": 0.0003708153, "top1_acc": 99.06250, "top1_err": 1.14583, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:13:36][INFO] train_net.py:  708: Epoch 214 takes 48.36s. Epochs from 0 to 214 take 48.01s in average and 48.01s in median.
[06/12 21:13:36][INFO] train_net.py:  714: For epoch 214, each iteraction takes 0.81s in average. From epoch 0 to 214, each iteraction takes 0.80s in average.
[06/12 21:13:36][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 21:14:37][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "215/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.12948, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 98.43750, "top5_err": 1.56250}
[06/12 21:14:41][INFO] logging.py:  101: json_stats: {"RAM": "13.52/31.07G", "_type": "val_epoch", "epoch": "215/300", "gpu_mem": "10.07G", "min_top1_err": 21.99170, "min_top5_err": 2.28216, "time_diff": 0.61363, "top1_acc": 75.72614, "top1_err": 24.27386, "top5_acc": 97.09544, "top5_err": 2.90456}
[06/12 21:14:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46448, "dt_data": 0.00053, "dt_net": 0.46394, "epoch": "216/300", "eta": "0:39:24", "gpu_mem": "10.07G", "grad_norm": 12.19040, "iter": "10/60", "loss": 0.05025, "lr": 0.0003694596, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:15:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46916, "dt_data": 0.00044, "dt_net": 0.46871, "epoch": "216/300", "eta": "0:39:43", "gpu_mem": "10.07G", "grad_norm": 4.54030, "iter": "20/60", "loss": 0.03075, "lr": 0.0003681060, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:15:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46611, "dt_data": 0.00043, "dt_net": 0.46568, "epoch": "216/300", "eta": "0:39:23", "gpu_mem": "10.07G", "grad_norm": 0.47446, "iter": "30/60", "loss": 0.01218, "lr": 0.0003667542, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:15:18][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46909, "dt_data": 0.00047, "dt_net": 0.46862, "epoch": "216/300", "eta": "0:39:33", "gpu_mem": "10.07G", "grad_norm": 9.34814, "iter": "40/60", "loss": 0.03741, "lr": 0.0003654044, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:15:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46997, "dt_data": 0.00040, "dt_net": 0.46957, "epoch": "216/300", "eta": "0:39:33", "gpu_mem": "10.07G", "grad_norm": 0.17487, "iter": "50/60", "loss": 0.02638, "lr": 0.0003640565, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:15:29][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46631, "dt_data": 0.00016, "dt_net": 0.46615, "epoch": "216/300", "eta": "0:39:10", "gpu_mem": "10.07G", "grad_norm": 2.22223, "iter": "60/60", "loss": 0.02212, "lr": 0.0003627105, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:15:30][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.68704, "dt_data": 0.68704, "dt_net": 0.46615, "epoch": "216/300", "eta": "0:57:42", "gpu_mem": "10.07G", "grad_norm": 2.22223, "loss": 0.04779, "lr": 0.0003627105, "top1_acc": 98.02083, "top1_err": 1.77083, "top5_acc": 99.89583, "top5_err": 0.05208}
[06/12 21:15:30][INFO] train_net.py:  708: Epoch 215 takes 49.08s. Epochs from 0 to 215 take 48.01s in average and 48.02s in median.
[06/12 21:15:30][INFO] train_net.py:  714: For epoch 215, each iteraction takes 0.82s in average. From epoch 0 to 215, each iteraction takes 0.80s in average.
[06/12 21:15:47][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47886, "dt_data": 0.00063, "dt_net": 0.47822, "epoch": "217/300", "eta": "0:40:08", "gpu_mem": "10.07G", "grad_norm": 5.26695, "iter": "10/60", "loss": 0.02686, "lr": 0.0003613665, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:15:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47199, "dt_data": 0.00053, "dt_net": 0.47146, "epoch": "217/300", "eta": "0:39:29", "gpu_mem": "10.07G", "grad_norm": 2.31415, "iter": "20/60", "loss": 0.01024, "lr": 0.0003600244, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:15:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.92150, "dt_data": 0.45191, "dt_net": 0.46958, "epoch": "217/300", "eta": "1:16:56", "gpu_mem": "10.07G", "grad_norm": 5.39053, "iter": "30/60", "loss": 0.06999, "lr": 0.0003586843, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:16:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47502, "dt_data": 0.00091, "dt_net": 0.47411, "epoch": "217/300", "eta": "0:39:35", "gpu_mem": "10.07G", "grad_norm": 1.75488, "iter": "40/60", "loss": 0.01707, "lr": 0.0003573461, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:16:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.96735, "dt_data": 0.49860, "dt_net": 0.46874, "epoch": "217/300", "eta": "1:20:27", "gpu_mem": "10.07G", "grad_norm": 2.67980, "iter": "50/60", "loss": 0.05592, "lr": 0.0003560099, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:16:17][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46780, "dt_data": 0.00015, "dt_net": 0.46765, "epoch": "217/300", "eta": "0:38:49", "gpu_mem": "10.07G", "grad_norm": 5.67788, "iter": "60/60", "loss": 0.03424, "lr": 0.0003546756, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:16:18][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.73241, "dt_data": 0.73241, "dt_net": 0.46765, "epoch": "217/300", "eta": "1:00:47", "gpu_mem": "10.07G", "grad_norm": 5.67788, "loss": 0.04387, "lr": 0.0003546756, "top1_acc": 98.43750, "top1_err": 1.45833, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:16:18][INFO] train_net.py:  708: Epoch 216 takes 47.84s. Epochs from 0 to 216 take 48.01s in average and 48.01s in median.
[06/12 21:16:18][INFO] train_net.py:  714: For epoch 216, each iteraction takes 0.80s in average. From epoch 0 to 216, each iteraction takes 0.80s in average.
[06/12 21:16:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46953, "dt_data": 0.00034, "dt_net": 0.46918, "epoch": "218/300", "eta": "0:38:53", "gpu_mem": "10.07G", "grad_norm": 7.14504, "iter": "10/60", "loss": 0.02736, "lr": 0.0003533433, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:16:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47344, "dt_data": 0.00044, "dt_net": 0.47300, "epoch": "218/300", "eta": "0:39:08", "gpu_mem": "10.07G", "grad_norm": 7.49225, "iter": "20/60", "loss": 0.05538, "lr": 0.0003520130, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:16:48][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46931, "dt_data": 0.00043, "dt_net": 0.46887, "epoch": "218/300", "eta": "0:38:43", "gpu_mem": "10.07G", "grad_norm": 3.31561, "iter": "30/60", "loss": 0.04876, "lr": 0.0003506847, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:16:54][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47138, "dt_data": 0.00047, "dt_net": 0.47091, "epoch": "218/300", "eta": "0:38:48", "gpu_mem": "10.07G", "grad_norm": 0.71084, "iter": "40/60", "loss": 0.01883, "lr": 0.0003493583, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:16:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47363, "dt_data": 0.00058, "dt_net": 0.47305, "epoch": "218/300", "eta": "0:38:55", "gpu_mem": "10.07G", "grad_norm": 0.21152, "iter": "50/60", "loss": 0.02584, "lr": 0.0003480339, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:17:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.59842, "dt_data": 0.00022, "dt_net": 0.59820, "epoch": "218/300", "eta": "0:49:04", "gpu_mem": "10.07G", "grad_norm": 2.46264, "iter": "60/60", "loss": 0.02250, "lr": 0.0003467115, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:17:05][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.69128, "dt_data": 0.69128, "dt_net": 0.59820, "epoch": "218/300", "eta": "0:56:40", "gpu_mem": "10.07G", "grad_norm": 2.46264, "loss": 0.04030, "lr": 0.0003467115, "top1_acc": 98.54167, "top1_err": 1.61458, "top5_acc": 99.89583, "top5_err": 0.05208}
[06/12 21:17:05][INFO] train_net.py:  708: Epoch 217 takes 47.81s. Epochs from 0 to 217 take 48.01s in average and 48.01s in median.
[06/12 21:17:05][INFO] train_net.py:  714: For epoch 217, each iteraction takes 0.80s in average. From epoch 0 to 217, each iteraction takes 0.80s in average.
[06/12 21:17:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46976, "dt_data": 0.00052, "dt_net": 0.46924, "epoch": "219/300", "eta": "0:38:26", "gpu_mem": "10.07G", "grad_norm": 0.49835, "iter": "10/60", "loss": 0.04519, "lr": 0.0003453911, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:17:29][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47417, "dt_data": 0.00041, "dt_net": 0.47376, "epoch": "219/300", "eta": "0:38:43", "gpu_mem": "10.07G", "grad_norm": 1.20609, "iter": "20/60", "loss": 0.03610, "lr": 0.0003440727, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:17:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.96706, "dt_data": 0.49005, "dt_net": 0.47701, "epoch": "219/300", "eta": "1:18:48", "gpu_mem": "10.07G", "grad_norm": 5.52183, "iter": "30/60", "loss": 0.05673, "lr": 0.0003427563, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:17:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47722, "dt_data": 0.00068, "dt_net": 0.47653, "epoch": "219/300", "eta": "0:38:48", "gpu_mem": "10.07G", "grad_norm": 12.88543, "iter": "40/60", "loss": 0.03297, "lr": 0.0003414419, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:17:47][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.05737, "dt_data": 0.58640, "dt_net": 0.47096, "epoch": "219/300", "eta": "1:25:49", "gpu_mem": "10.07G", "grad_norm": 4.11474, "iter": "50/60", "loss": 0.01620, "lr": 0.0003401295, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:17:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47007, "dt_data": 0.00016, "dt_net": 0.46992, "epoch": "219/300", "eta": "0:38:04", "gpu_mem": "10.07G", "grad_norm": 5.22810, "iter": "60/60", "loss": 0.02608, "lr": 0.0003388191, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:17:54][INFO] logging.py:  101: json_stats: {"RAM": "13.45/31.07G", "_type": "train_epoch", "dt": 0.69344, "dt_data": 0.69344, "dt_net": 0.46992, "epoch": "219/300", "eta": "0:56:09", "gpu_mem": "10.07G", "grad_norm": 5.22810, "loss": 0.05272, "lr": 0.0003388191, "top1_acc": 97.70833, "top1_err": 1.82292, "top5_acc": 99.89583, "top5_err": 0.05208}
[06/12 21:17:54][INFO] train_net.py:  708: Epoch 218 takes 48.23s. Epochs from 0 to 218 take 48.01s in average and 48.01s in median.
[06/12 21:17:54][INFO] train_net.py:  714: For epoch 218, each iteraction takes 0.80s in average. From epoch 0 to 218, each iteraction takes 0.80s in average.
[06/12 21:18:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47150, "dt_data": 0.00078, "dt_net": 0.47071, "epoch": "220/300", "eta": "0:38:06", "gpu_mem": "10.07G", "grad_norm": 6.72331, "iter": "10/60", "loss": 0.03074, "lr": 0.0003375107, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:18:17][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47075, "dt_data": 0.00040, "dt_net": 0.47034, "epoch": "220/300", "eta": "0:37:58", "gpu_mem": "10.07G", "grad_norm": 0.62272, "iter": "20/60", "loss": 0.02212, "lr": 0.0003362043, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:18:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.82583, "dt_data": 0.00047, "dt_net": 0.82535, "epoch": "220/300", "eta": "1:06:28", "gpu_mem": "10.07G", "grad_norm": 6.89752, "iter": "30/60", "loss": 0.03461, "lr": 0.0003349000, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:18:29][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47722, "dt_data": 0.00055, "dt_net": 0.47666, "epoch": "220/300", "eta": "0:38:20", "gpu_mem": "10.07G", "grad_norm": 6.02938, "iter": "40/60", "loss": 0.04573, "lr": 0.0003335977, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:18:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.67829, "dt_data": 0.00048, "dt_net": 0.67781, "epoch": "220/300", "eta": "0:54:22", "gpu_mem": "10.07G", "grad_norm": 4.00903, "iter": "50/60", "loss": 0.02402, "lr": 0.0003322974, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:18:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46987, "dt_data": 0.00017, "dt_net": 0.46970, "epoch": "220/300", "eta": "0:37:35", "gpu_mem": "10.07G", "grad_norm": 4.60746, "iter": "60/60", "loss": 0.06231, "lr": 0.0003309991, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:18:42][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.70750, "dt_data": 0.70750, "dt_net": 0.46970, "epoch": "220/300", "eta": "0:56:35", "gpu_mem": "10.07G", "grad_norm": 4.60746, "loss": 0.05171, "lr": 0.0003309991, "top1_acc": 98.02083, "top1_err": 1.92708, "top5_acc": 99.89583, "top5_err": 0.10417}
[06/12 21:18:42][INFO] train_net.py:  708: Epoch 219 takes 48.30s. Epochs from 0 to 219 take 48.01s in average and 48.02s in median.
[06/12 21:18:42][INFO] train_net.py:  714: For epoch 219, each iteraction takes 0.80s in average. From epoch 0 to 219, each iteraction takes 0.80s in average.
[06/12 21:18:42][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 21:19:45][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "220/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.12953, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:19:48][INFO] logging.py:  101: json_stats: {"RAM": "14.07/31.07G", "_type": "val_epoch", "epoch": "220/300", "gpu_mem": "10.07G", "min_top1_err": 21.99170, "min_top5_err": 2.07469, "time_diff": 0.59410, "top1_acc": 75.51867, "top1_err": 24.48133, "top5_acc": 97.92531, "top5_err": 2.07469}
[06/12 21:20:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46940, "dt_data": 0.00068, "dt_net": 0.46872, "epoch": "221/300", "eta": "0:37:28", "gpu_mem": "10.07G", "grad_norm": 3.09021, "iter": "10/60", "loss": 0.02400, "lr": 0.0003297029, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:20:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46919, "dt_data": 0.00046, "dt_net": 0.46872, "epoch": "221/300", "eta": "0:37:22", "gpu_mem": "10.07G", "grad_norm": 1.24492, "iter": "20/60", "loss": 0.03935, "lr": 0.0003284087, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:20:18][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46864, "dt_data": 0.00052, "dt_net": 0.46811, "epoch": "221/300", "eta": "0:37:15", "gpu_mem": "10.07G", "grad_norm": 1.36852, "iter": "30/60", "loss": 0.02043, "lr": 0.0003271166, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:20:24][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47170, "dt_data": 0.00070, "dt_net": 0.47099, "epoch": "221/300", "eta": "0:37:25", "gpu_mem": "10.07G", "grad_norm": 5.21189, "iter": "40/60", "loss": 0.00823, "lr": 0.0003258265, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:20:29][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46995, "dt_data": 0.00047, "dt_net": 0.46947, "epoch": "221/300", "eta": "0:37:12", "gpu_mem": "10.07G", "grad_norm": 4.17266, "iter": "50/60", "loss": 0.03636, "lr": 0.0003245385, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:20:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46669, "dt_data": 0.00015, "dt_net": 0.46653, "epoch": "221/300", "eta": "0:36:52", "gpu_mem": "10.07G", "grad_norm": 6.96831, "iter": "60/60", "loss": 0.05748, "lr": 0.0003232525, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:20:36][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.71422, "dt_data": 0.71422, "dt_net": 0.46653, "epoch": "221/300", "eta": "0:56:24", "gpu_mem": "10.07G", "grad_norm": 6.96831, "loss": 0.04648, "lr": 0.0003232525, "top1_acc": 98.43750, "top1_err": 1.71875, "top5_acc": 99.89583, "top5_err": 0.05208}
[06/12 21:20:36][INFO] train_net.py:  708: Epoch 220 takes 47.68s. Epochs from 0 to 220 take 48.01s in average and 48.01s in median.
[06/12 21:20:36][INFO] train_net.py:  714: For epoch 220, each iteraction takes 0.79s in average. From epoch 0 to 220, each iteraction takes 0.80s in average.
[06/12 21:20:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47001, "dt_data": 0.00033, "dt_net": 0.46967, "epoch": "222/300", "eta": "0:37:03", "gpu_mem": "10.07G", "grad_norm": 0.57973, "iter": "10/60", "loss": 0.04381, "lr": 0.0003219686, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:20:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47622, "dt_data": 0.00034, "dt_net": 0.47587, "epoch": "222/300", "eta": "0:37:27", "gpu_mem": "10.07G", "grad_norm": 0.24172, "iter": "20/60", "loss": 0.05529, "lr": 0.0003206868, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:21:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47095, "dt_data": 0.00044, "dt_net": 0.47050, "epoch": "222/300", "eta": "0:36:58", "gpu_mem": "10.07G", "grad_norm": 1.79517, "iter": "30/60", "loss": 0.02534, "lr": 0.0003194070, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:21:10][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47300, "dt_data": 0.00040, "dt_net": 0.47260, "epoch": "222/300", "eta": "0:37:03", "gpu_mem": "10.07G", "grad_norm": 3.46180, "iter": "40/60", "loss": 0.03371, "lr": 0.0003181293, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:21:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47246, "dt_data": 0.00042, "dt_net": 0.47203, "epoch": "222/300", "eta": "0:36:55", "gpu_mem": "10.07G", "grad_norm": 6.29128, "iter": "50/60", "loss": 0.02817, "lr": 0.0003168537, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:21:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46926, "dt_data": 0.00016, "dt_net": 0.46909, "epoch": "222/300", "eta": "0:36:36", "gpu_mem": "10.07G", "grad_norm": 1.03112, "iter": "60/60", "loss": 0.04518, "lr": 0.0003155801, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:21:23][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.69476, "dt_data": 0.69476, "dt_net": 0.46909, "epoch": "222/300", "eta": "0:54:11", "gpu_mem": "10.07G", "grad_norm": 1.03112, "loss": 0.05226, "lr": 0.0003155801, "top1_acc": 98.22917, "top1_err": 1.71875, "top5_acc": 99.89583, "top5_err": 0.05208}
[06/12 21:21:23][INFO] train_net.py:  708: Epoch 221 takes 47.06s. Epochs from 0 to 221 take 48.01s in average and 48.01s in median.
[06/12 21:21:23][INFO] train_net.py:  714: For epoch 221, each iteraction takes 0.78s in average. From epoch 0 to 221, each iteraction takes 0.80s in average.
[06/12 21:21:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47038, "dt_data": 0.00044, "dt_net": 0.46994, "epoch": "223/300", "eta": "0:36:36", "gpu_mem": "10.07G", "grad_norm": 6.15658, "iter": "10/60", "loss": 0.01834, "lr": 0.0003143087, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:21:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47334, "dt_data": 0.00054, "dt_net": 0.47280, "epoch": "223/300", "eta": "0:36:45", "gpu_mem": "10.07G", "grad_norm": 1.53246, "iter": "20/60", "loss": 0.02999, "lr": 0.0003130393, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:21:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47373, "dt_data": 0.00053, "dt_net": 0.47320, "epoch": "223/300", "eta": "0:36:42", "gpu_mem": "10.07G", "grad_norm": 1.55985, "iter": "30/60", "loss": 0.02230, "lr": 0.0003117720, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:21:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47302, "dt_data": 0.00052, "dt_net": 0.47250, "epoch": "223/300", "eta": "0:36:34", "gpu_mem": "10.07G", "grad_norm": 1.74645, "iter": "40/60", "loss": 0.01212, "lr": 0.0003105069, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:22:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.90914, "dt_data": 0.43575, "dt_net": 0.47338, "epoch": "223/300", "eta": "1:10:09", "gpu_mem": "10.07G", "grad_norm": 1.39110, "iter": "50/60", "loss": 0.03527, "lr": 0.0003092438, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:22:10][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46919, "dt_data": 0.00017, "dt_net": 0.46902, "epoch": "223/300", "eta": "0:36:07", "gpu_mem": "10.07G", "grad_norm": 9.01211, "iter": "60/60", "loss": 0.02815, "lr": 0.0003079828, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:22:11][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.69632, "dt_data": 0.69632, "dt_net": 0.46902, "epoch": "223/300", "eta": "0:53:36", "gpu_mem": "10.07G", "grad_norm": 9.01211, "loss": 0.04164, "lr": 0.0003079828, "top1_acc": 98.33333, "top1_err": 1.61458, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:22:11][INFO] train_net.py:  708: Epoch 222 takes 48.10s. Epochs from 0 to 222 take 48.01s in average and 48.01s in median.
[06/12 21:22:11][INFO] train_net.py:  714: For epoch 222, each iteraction takes 0.80s in average. From epoch 0 to 222, each iteraction takes 0.80s in average.
[06/12 21:22:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47255, "dt_data": 0.00108, "dt_net": 0.47147, "epoch": "224/300", "eta": "0:36:18", "gpu_mem": "10.07G", "grad_norm": 3.84176, "iter": "10/60", "loss": 0.03505, "lr": 0.0003067239, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:22:34][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47564, "dt_data": 0.00035, "dt_net": 0.47528, "epoch": "224/300", "eta": "0:36:27", "gpu_mem": "10.07G", "grad_norm": 0.86109, "iter": "20/60", "loss": 0.02263, "lr": 0.0003054672, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:22:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47528, "dt_data": 0.00078, "dt_net": 0.47450, "epoch": "224/300", "eta": "0:36:21", "gpu_mem": "10.07G", "grad_norm": 1.75338, "iter": "30/60", "loss": 0.02674, "lr": 0.0003042126, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:22:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47321, "dt_data": 0.00050, "dt_net": 0.47271, "epoch": "224/300", "eta": "0:36:07", "gpu_mem": "10.07G", "grad_norm": 0.37212, "iter": "40/60", "loss": 0.00857, "lr": 0.0003029600, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:22:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47571, "dt_data": 0.00052, "dt_net": 0.47519, "epoch": "224/300", "eta": "0:36:13", "gpu_mem": "10.07G", "grad_norm": 0.18131, "iter": "50/60", "loss": 0.02796, "lr": 0.0003017096, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:22:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46910, "dt_data": 0.00017, "dt_net": 0.46893, "epoch": "224/300", "eta": "0:35:39", "gpu_mem": "10.07G", "grad_norm": 10.94157, "iter": "60/60", "loss": 0.02559, "lr": 0.0003004614, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:22:58][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.69706, "dt_data": 0.69706, "dt_net": 0.46893, "epoch": "224/300", "eta": "0:52:58", "gpu_mem": "10.07G", "grad_norm": 10.94157, "loss": 0.04001, "lr": 0.0003004614, "top1_acc": 98.33333, "top1_err": 1.66667, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:22:58][INFO] train_net.py:  708: Epoch 223 takes 47.59s. Epochs from 0 to 223 take 48.00s in average and 48.01s in median.
[06/12 21:22:58][INFO] train_net.py:  714: For epoch 223, each iteraction takes 0.79s in average. From epoch 0 to 223, each iteraction takes 0.80s in average.
[06/12 21:23:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47368, "dt_data": 0.00057, "dt_net": 0.47311, "epoch": "225/300", "eta": "0:35:55", "gpu_mem": "10.07G", "grad_norm": 2.40681, "iter": "10/60", "loss": 0.02380, "lr": 0.0002992152, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:23:21][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47186, "dt_data": 0.00042, "dt_net": 0.47143, "epoch": "225/300", "eta": "0:35:42", "gpu_mem": "10.07G", "grad_norm": 4.38047, "iter": "20/60", "loss": 0.02705, "lr": 0.0002979712, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:23:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47307, "dt_data": 0.00063, "dt_net": 0.47243, "epoch": "225/300", "eta": "0:35:43", "gpu_mem": "10.07G", "grad_norm": 7.27239, "iter": "30/60", "loss": 0.02803, "lr": 0.0002967294, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:23:34][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47478, "dt_data": 0.00050, "dt_net": 0.47427, "epoch": "225/300", "eta": "0:35:45", "gpu_mem": "10.07G", "grad_norm": 0.37257, "iter": "40/60", "loss": 0.01703, "lr": 0.0002954896, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:23:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48112, "dt_data": 0.00049, "dt_net": 0.48063, "epoch": "225/300", "eta": "0:36:09", "gpu_mem": "10.07G", "grad_norm": 3.29902, "iter": "50/60", "loss": 0.02589, "lr": 0.0002942521, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:23:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46918, "dt_data": 0.00017, "dt_net": 0.46901, "epoch": "225/300", "eta": "0:35:11", "gpu_mem": "10.07G", "grad_norm": 2.35368, "iter": "60/60", "loss": 0.02792, "lr": 0.0002930166, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:23:47][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.68512, "dt_data": 0.68512, "dt_net": 0.46901, "epoch": "225/300", "eta": "0:51:22", "gpu_mem": "10.07G", "grad_norm": 2.35368, "loss": 0.03579, "lr": 0.0002930166, "top1_acc": 98.95833, "top1_err": 1.30208, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:23:47][INFO] train_net.py:  708: Epoch 224 takes 48.35s. Epochs from 0 to 224 take 48.01s in average and 48.01s in median.
[06/12 21:23:47][INFO] train_net.py:  714: For epoch 224, each iteraction takes 0.81s in average. From epoch 0 to 224, each iteraction takes 0.80s in average.
[06/12 21:23:47][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 21:24:47][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "225/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.13032, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 21:24:51][INFO] logging.py:  101: json_stats: {"RAM": "13.48/31.07G", "_type": "val_epoch", "epoch": "225/300", "gpu_mem": "10.07G", "min_top1_err": 21.99170, "min_top5_err": 2.07469, "time_diff": 0.61720, "top1_acc": 76.34855, "top1_err": 23.65145, "top5_acc": 95.64315, "top5_err": 4.35685}
[06/12 21:25:08][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46716, "dt_data": 0.00040, "dt_net": 0.46676, "epoch": "226/300", "eta": "0:34:57", "gpu_mem": "10.07G", "grad_norm": 0.90807, "iter": "10/60", "loss": 0.03090, "lr": 0.0002917834, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:25:14][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47229, "dt_data": 0.00047, "dt_net": 0.47181, "epoch": "226/300", "eta": "0:35:15", "gpu_mem": "10.07G", "grad_norm": 0.38059, "iter": "20/60", "loss": 0.01431, "lr": 0.0002905523, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:25:20][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46825, "dt_data": 0.00062, "dt_net": 0.46763, "epoch": "226/300", "eta": "0:34:53", "gpu_mem": "10.07G", "grad_norm": 3.15640, "iter": "30/60", "loss": 0.02045, "lr": 0.0002893233, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:25:26][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47252, "dt_data": 0.00056, "dt_net": 0.47196, "epoch": "226/300", "eta": "0:35:07", "gpu_mem": "10.07G", "grad_norm": 1.51706, "iter": "40/60", "loss": 0.03261, "lr": 0.0002880965, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:25:32][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47356, "dt_data": 0.00060, "dt_net": 0.47296, "epoch": "226/300", "eta": "0:35:07", "gpu_mem": "10.07G", "grad_norm": 1.68903, "iter": "50/60", "loss": 0.02701, "lr": 0.0002868719, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:25:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46670, "dt_data": 0.00016, "dt_net": 0.46654, "epoch": "226/300", "eta": "0:34:32", "gpu_mem": "10.07G", "grad_norm": 7.55478, "iter": "60/60", "loss": 0.05210, "lr": 0.0002856494, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:25:38][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.71387, "dt_data": 0.71387, "dt_net": 0.46654, "epoch": "226/300", "eta": "0:52:49", "gpu_mem": "10.07G", "grad_norm": 7.55478, "loss": 0.04529, "lr": 0.0002856494, "top1_acc": 98.85417, "top1_err": 1.35417, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:25:38][INFO] train_net.py:  708: Epoch 225 takes 47.42s. Epochs from 0 to 225 take 48.00s in average and 48.01s in median.
[06/12 21:25:38][INFO] train_net.py:  714: For epoch 225, each iteraction takes 0.79s in average. From epoch 0 to 225, each iteraction takes 0.80s in average.
[06/12 21:25:56][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47077, "dt_data": 0.00041, "dt_net": 0.47036, "epoch": "227/300", "eta": "0:34:45", "gpu_mem": "10.07G", "grad_norm": 2.38544, "iter": "10/60", "loss": 0.01901, "lr": 0.0002844292, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:26:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46860, "dt_data": 0.00037, "dt_net": 0.46822, "epoch": "227/300", "eta": "0:34:31", "gpu_mem": "10.07G", "grad_norm": 0.32762, "iter": "20/60", "loss": 0.01570, "lr": 0.0002832111, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:26:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47159, "dt_data": 0.00041, "dt_net": 0.47118, "epoch": "227/300", "eta": "0:34:39", "gpu_mem": "10.07G", "grad_norm": 13.44670, "iter": "30/60", "loss": 0.03809, "lr": 0.0002819952, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:26:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47332, "dt_data": 0.00051, "dt_net": 0.47281, "epoch": "227/300", "eta": "0:34:42", "gpu_mem": "10.07G", "grad_norm": 2.14952, "iter": "40/60", "loss": 0.03600, "lr": 0.0002807815, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:26:20][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47173, "dt_data": 0.00057, "dt_net": 0.47115, "epoch": "227/300", "eta": "0:34:30", "gpu_mem": "10.07G", "grad_norm": 3.82583, "iter": "50/60", "loss": 0.03682, "lr": 0.0002795699, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:26:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46934, "dt_data": 0.00016, "dt_net": 0.46917, "epoch": "227/300", "eta": "0:34:15", "gpu_mem": "10.07G", "grad_norm": 2.23302, "iter": "60/60", "loss": 0.02232, "lr": 0.0002783606, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:26:26][INFO] logging.py:  101: json_stats: {"RAM": "13.45/31.07G", "_type": "train_epoch", "dt": 0.69165, "dt_data": 0.69165, "dt_net": 0.46917, "epoch": "227/300", "eta": "0:50:29", "gpu_mem": "10.07G", "grad_norm": 2.23302, "loss": 0.05445, "lr": 0.0002783606, "top1_acc": 98.02083, "top1_err": 1.87500, "top5_acc": 99.89583, "top5_err": 0.10417}
[06/12 21:26:26][INFO] train_net.py:  708: Epoch 226 takes 47.68s. Epochs from 0 to 226 take 48.00s in average and 48.01s in median.
[06/12 21:26:26][INFO] train_net.py:  714: For epoch 226, each iteraction takes 0.79s in average. From epoch 0 to 226, each iteraction takes 0.80s in average.
[06/12 21:26:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47189, "dt_data": 0.00137, "dt_net": 0.47051, "epoch": "228/300", "eta": "0:34:22", "gpu_mem": "10.07G", "grad_norm": 1.10709, "iter": "10/60", "loss": 0.00880, "lr": 0.0002771534, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:26:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48111, "dt_data": 0.00035, "dt_net": 0.48075, "epoch": "228/300", "eta": "0:34:57", "gpu_mem": "10.07G", "grad_norm": 7.84717, "iter": "20/60", "loss": 0.03537, "lr": 0.0002759485, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:26:56][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47144, "dt_data": 0.00060, "dt_net": 0.47083, "epoch": "228/300", "eta": "0:34:10", "gpu_mem": "10.07G", "grad_norm": 2.44687, "iter": "30/60", "loss": 0.03841, "lr": 0.0002747458, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:27:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47317, "dt_data": 0.00053, "dt_net": 0.47264, "epoch": "228/300", "eta": "0:34:13", "gpu_mem": "10.07G", "grad_norm": 5.55308, "iter": "40/60", "loss": 0.03188, "lr": 0.0002735453, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:27:08][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47302, "dt_data": 0.00056, "dt_net": 0.47245, "epoch": "228/300", "eta": "0:34:08", "gpu_mem": "10.07G", "grad_norm": 9.80742, "iter": "50/60", "loss": 0.02002, "lr": 0.0002723470, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:27:14][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46979, "dt_data": 0.00017, "dt_net": 0.46962, "epoch": "228/300", "eta": "0:33:49", "gpu_mem": "10.07G", "grad_norm": 2.37505, "iter": "60/60", "loss": 0.02919, "lr": 0.0002711509, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:27:15][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.69169, "dt_data": 0.69169, "dt_net": 0.46962, "epoch": "228/300", "eta": "0:49:47", "gpu_mem": "10.07G", "grad_norm": 2.37505, "loss": 0.04511, "lr": 0.0002711509, "top1_acc": 98.12500, "top1_err": 1.61458, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:27:15][INFO] train_net.py:  708: Epoch 227 takes 48.80s. Epochs from 0 to 227 take 48.00s in average and 48.01s in median.
[06/12 21:27:15][INFO] train_net.py:  714: For epoch 227, each iteraction takes 0.81s in average. From epoch 0 to 227, each iteraction takes 0.80s in average.
[06/12 21:27:32][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47213, "dt_data": 0.00031, "dt_net": 0.47181, "epoch": "229/300", "eta": "0:33:54", "gpu_mem": "10.07G", "grad_norm": 0.99100, "iter": "10/60", "loss": 0.01087, "lr": 0.0002699570, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:27:38][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47230, "dt_data": 0.00055, "dt_net": 0.47175, "epoch": "229/300", "eta": "0:33:50", "gpu_mem": "10.07G", "grad_norm": 0.81420, "iter": "20/60", "loss": 0.02736, "lr": 0.0002687653, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:27:44][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46993, "dt_data": 0.00038, "dt_net": 0.46954, "epoch": "229/300", "eta": "0:33:35", "gpu_mem": "10.07G", "grad_norm": 1.61117, "iter": "30/60", "loss": 0.01308, "lr": 0.0002675759, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:27:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47843, "dt_data": 0.00033, "dt_net": 0.47810, "epoch": "229/300", "eta": "0:34:07", "gpu_mem": "10.07G", "grad_norm": 2.71593, "iter": "40/60", "loss": 0.04352, "lr": 0.0002663887, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:27:56][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47565, "dt_data": 0.00049, "dt_net": 0.47516, "epoch": "229/300", "eta": "0:33:51", "gpu_mem": "10.07G", "grad_norm": 8.22021, "iter": "50/60", "loss": 0.03804, "lr": 0.0002652038, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:28:02][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46855, "dt_data": 0.00015, "dt_net": 0.46840, "epoch": "229/300", "eta": "0:33:16", "gpu_mem": "10.07G", "grad_norm": 0.50588, "iter": "60/60", "loss": 0.02576, "lr": 0.0002640211, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:28:02][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.69629, "dt_data": 0.69629, "dt_net": 0.46840, "epoch": "229/300", "eta": "0:49:25", "gpu_mem": "10.07G", "grad_norm": 0.50588, "loss": 0.04381, "lr": 0.0002640211, "top1_acc": 98.02083, "top1_err": 1.82292, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:28:02][INFO] train_net.py:  708: Epoch 228 takes 47.83s. Epochs from 0 to 228 take 48.00s in average and 48.01s in median.
[06/12 21:28:02][INFO] train_net.py:  714: For epoch 228, each iteraction takes 0.80s in average. From epoch 0 to 228, each iteraction takes 0.80s in average.
[06/12 21:28:20][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47637, "dt_data": 0.00086, "dt_net": 0.47550, "epoch": "230/300", "eta": "0:33:44", "gpu_mem": "10.07G", "grad_norm": 2.58030, "iter": "10/60", "loss": 0.02708, "lr": 0.0002628406, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:28:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47378, "dt_data": 0.00061, "dt_net": 0.47317, "epoch": "230/300", "eta": "0:33:28", "gpu_mem": "10.07G", "grad_norm": 0.18110, "iter": "20/60", "loss": 0.01311, "lr": 0.0002616624, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:28:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47389, "dt_data": 0.00036, "dt_net": 0.47353, "epoch": "230/300", "eta": "0:33:24", "gpu_mem": "10.07G", "grad_norm": 0.13786, "iter": "30/60", "loss": 0.03689, "lr": 0.0002604864, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:28:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47269, "dt_data": 0.00038, "dt_net": 0.47231, "epoch": "230/300", "eta": "0:33:14", "gpu_mem": "10.07G", "grad_norm": 0.61028, "iter": "40/60", "loss": 0.01853, "lr": 0.0002593127, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:28:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47228, "dt_data": 0.00078, "dt_net": 0.47150, "epoch": "230/300", "eta": "0:33:08", "gpu_mem": "10.07G", "grad_norm": 1.30471, "iter": "50/60", "loss": 0.03077, "lr": 0.0002581412, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:28:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47000, "dt_data": 0.00017, "dt_net": 0.46983, "epoch": "230/300", "eta": "0:32:53", "gpu_mem": "10.07G", "grad_norm": 4.27363, "iter": "60/60", "loss": 0.09356, "lr": 0.0002569720, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:28:50][INFO] logging.py:  101: json_stats: {"RAM": "13.45/31.07G", "_type": "train_epoch", "dt": 0.69324, "dt_data": 0.69324, "dt_net": 0.46983, "epoch": "230/300", "eta": "0:48:31", "gpu_mem": "10.07G", "grad_norm": 4.27363, "loss": 0.05552, "lr": 0.0002569720, "top1_acc": 98.43750, "top1_err": 1.71875, "top5_acc": 100.00000, "top5_err": 0.05208}
[06/12 21:28:50][INFO] train_net.py:  708: Epoch 229 takes 47.55s. Epochs from 0 to 229 take 48.00s in average and 48.00s in median.
[06/12 21:28:50][INFO] train_net.py:  714: For epoch 229, each iteraction takes 0.79s in average. From epoch 0 to 229, each iteraction takes 0.80s in average.
[06/12 21:28:50][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 21:29:51][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "230/300", "eta": "0:00:05", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.95023, "top1_acc": 73.43750, "top1_err": 26.56250, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 21:29:54][INFO] logging.py:  101: json_stats: {"RAM": "13.49/31.07G", "_type": "val_epoch", "epoch": "230/300", "gpu_mem": "10.07G", "min_top1_err": 21.99170, "min_top5_err": 2.07469, "time_diff": 0.62016, "top1_acc": 75.72614, "top1_err": 24.27386, "top5_acc": 95.85062, "top5_err": 4.14938}
[06/12 21:30:12][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47424, "dt_data": 0.00031, "dt_net": 0.47393, "epoch": "231/300", "eta": "0:33:07", "gpu_mem": "10.07G", "grad_norm": 1.15014, "iter": "10/60", "loss": 0.02789, "lr": 0.0002558050, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:30:18][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46583, "dt_data": 0.00050, "dt_net": 0.46532, "epoch": "231/300", "eta": "0:32:27", "gpu_mem": "10.07G", "grad_norm": 0.22739, "iter": "20/60", "loss": 0.01401, "lr": 0.0002546403, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:30:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.60433, "dt_data": 0.00048, "dt_net": 0.60385, "epoch": "231/300", "eta": "0:42:00", "gpu_mem": "10.07G", "grad_norm": 5.36152, "iter": "30/60", "loss": 0.05143, "lr": 0.0002534779, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:30:29][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47677, "dt_data": 0.00042, "dt_net": 0.47634, "epoch": "231/300", "eta": "0:33:03", "gpu_mem": "10.07G", "grad_norm": 5.75907, "iter": "40/60", "loss": 0.03889, "lr": 0.0002523178, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:30:36][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.86415, "dt_data": 0.00036, "dt_net": 0.86379, "epoch": "231/300", "eta": "0:59:46", "gpu_mem": "10.07G", "grad_norm": 2.73763, "iter": "50/60", "loss": 0.03859, "lr": 0.0002511599, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:30:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46613, "dt_data": 0.00016, "dt_net": 0.46597, "epoch": "231/300", "eta": "0:32:09", "gpu_mem": "10.07G", "grad_norm": 3.12203, "iter": "60/60", "loss": 0.03760, "lr": 0.0002500044, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:30:42][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.68901, "dt_data": 0.68901, "dt_net": 0.46597, "epoch": "231/300", "eta": "0:47:32", "gpu_mem": "10.07G", "grad_norm": 3.12203, "loss": 0.04362, "lr": 0.0002500044, "top1_acc": 98.02083, "top1_err": 1.45833, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:30:42][INFO] train_net.py:  708: Epoch 230 takes 47.91s. Epochs from 0 to 230 take 48.00s in average and 47.98s in median.
[06/12 21:30:42][INFO] train_net.py:  714: For epoch 230, each iteraction takes 0.80s in average. From epoch 0 to 230, each iteraction takes 0.80s in average.
[06/12 21:31:00][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47423, "dt_data": 0.00045, "dt_net": 0.47378, "epoch": "232/300", "eta": "0:32:38", "gpu_mem": "10.07G", "grad_norm": 5.77000, "iter": "10/60", "loss": 0.03321, "lr": 0.0002488511, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:31:06][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47238, "dt_data": 0.00036, "dt_net": 0.47202, "epoch": "232/300", "eta": "0:32:26", "gpu_mem": "10.07G", "grad_norm": 2.53632, "iter": "20/60", "loss": 0.06239, "lr": 0.0002477001, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:31:12][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47370, "dt_data": 0.00050, "dt_net": 0.47319, "epoch": "232/300", "eta": "0:32:26", "gpu_mem": "10.07G", "grad_norm": 1.23985, "iter": "30/60", "loss": 0.01235, "lr": 0.0002465514, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:31:18][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47319, "dt_data": 0.00041, "dt_net": 0.47278, "epoch": "232/300", "eta": "0:32:20", "gpu_mem": "10.07G", "grad_norm": 1.83226, "iter": "40/60", "loss": 0.01385, "lr": 0.0002454049, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:31:24][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47210, "dt_data": 0.00045, "dt_net": 0.47165, "epoch": "232/300", "eta": "0:32:10", "gpu_mem": "10.07G", "grad_norm": 0.41524, "iter": "50/60", "loss": 0.00636, "lr": 0.0002442608, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:31:30][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46805, "dt_data": 0.00019, "dt_net": 0.46786, "epoch": "232/300", "eta": "0:31:49", "gpu_mem": "10.07G", "grad_norm": 2.84049, "iter": "60/60", "loss": 0.03359, "lr": 0.0002431190, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:31:30][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.70240, "dt_data": 0.70240, "dt_net": 0.46786, "epoch": "232/300", "eta": "0:47:45", "gpu_mem": "10.07G", "grad_norm": 2.84049, "loss": 0.04781, "lr": 0.0002431190, "top1_acc": 98.43750, "top1_err": 1.30208, "top5_acc": 100.00000, "top5_err": 0.05208}
[06/12 21:31:30][INFO] train_net.py:  708: Epoch 231 takes 48.25s. Epochs from 0 to 231 take 48.00s in average and 48.00s in median.
[06/12 21:31:30][INFO] train_net.py:  714: For epoch 231, each iteraction takes 0.80s in average. From epoch 0 to 231, each iteraction takes 0.80s in average.
[06/12 21:31:48][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.01429, "dt_data": 0.00076, "dt_net": 1.01352, "epoch": "233/300", "eta": "1:08:48", "gpu_mem": "10.07G", "grad_norm": 5.25504, "iter": "10/60", "loss": 0.02957, "lr": 0.0002419795, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:31:54][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47406, "dt_data": 0.00067, "dt_net": 0.47339, "epoch": "233/300", "eta": "0:32:04", "gpu_mem": "10.07G", "grad_norm": 5.85420, "iter": "20/60", "loss": 0.03127, "lr": 0.0002408423, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:32:00][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47116, "dt_data": 0.00058, "dt_net": 0.47057, "epoch": "233/300", "eta": "0:31:48", "gpu_mem": "10.07G", "grad_norm": 1.30639, "iter": "30/60", "loss": 0.03932, "lr": 0.0002397074, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:32:06][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47240, "dt_data": 0.00059, "dt_net": 0.47180, "epoch": "233/300", "eta": "0:31:48", "gpu_mem": "10.07G", "grad_norm": 2.46577, "iter": "40/60", "loss": 0.04404, "lr": 0.0002385748, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:32:12][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.97174, "dt_data": 0.00040, "dt_net": 0.97134, "epoch": "233/300", "eta": "1:05:16", "gpu_mem": "10.07G", "grad_norm": 0.13604, "iter": "50/60", "loss": 0.01815, "lr": 0.0002374446, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:32:18][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46827, "dt_data": 0.00015, "dt_net": 0.46812, "epoch": "233/300", "eta": "0:31:22", "gpu_mem": "10.07G", "grad_norm": 1.00031, "iter": "60/60", "loss": 0.01748, "lr": 0.0002363166, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:32:18][INFO] logging.py:  101: json_stats: {"RAM": "13.48/31.07G", "_type": "train_epoch", "dt": 0.69577, "dt_data": 0.69577, "dt_net": 0.46812, "epoch": "233/300", "eta": "0:46:36", "gpu_mem": "10.07G", "grad_norm": 1.00031, "loss": 0.05047, "lr": 0.0002363166, "top1_acc": 98.02083, "top1_err": 1.97917, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:32:18][INFO] train_net.py:  708: Epoch 232 takes 48.12s. Epochs from 0 to 232 take 48.00s in average and 48.01s in median.
[06/12 21:32:18][INFO] train_net.py:  714: For epoch 232, each iteraction takes 0.80s in average. From epoch 0 to 232, each iteraction takes 0.80s in average.
[06/12 21:32:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46963, "dt_data": 0.00054, "dt_net": 0.46909, "epoch": "234/300", "eta": "0:31:23", "gpu_mem": "10.07G", "grad_norm": 16.01555, "iter": "10/60", "loss": 0.04149, "lr": 0.0002351910, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:32:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48129, "dt_data": 0.00096, "dt_net": 0.48032, "epoch": "234/300", "eta": "0:32:05", "gpu_mem": "10.07G", "grad_norm": 2.47806, "iter": "20/60", "loss": 0.03844, "lr": 0.0002340678, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:32:47][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47451, "dt_data": 0.00059, "dt_net": 0.47392, "epoch": "234/300", "eta": "0:31:33", "gpu_mem": "10.07G", "grad_norm": 1.32693, "iter": "30/60", "loss": 0.02239, "lr": 0.0002329468, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:32:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47184, "dt_data": 0.00038, "dt_net": 0.47146, "epoch": "234/300", "eta": "0:31:17", "gpu_mem": "10.07G", "grad_norm": 5.52922, "iter": "40/60", "loss": 0.03432, "lr": 0.0002318282, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:33:00][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47232, "dt_data": 0.00037, "dt_net": 0.47195, "epoch": "234/300", "eta": "0:31:15", "gpu_mem": "10.07G", "grad_norm": 1.07590, "iter": "50/60", "loss": 0.01547, "lr": 0.0002307119, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:33:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46907, "dt_data": 0.00015, "dt_net": 0.46892, "epoch": "234/300", "eta": "0:30:57", "gpu_mem": "10.07G", "grad_norm": 11.15428, "iter": "60/60", "loss": 0.05247, "lr": 0.0002295980, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:33:06][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.71727, "dt_data": 0.71727, "dt_net": 0.46892, "epoch": "234/300", "eta": "0:47:20", "gpu_mem": "10.07G", "grad_norm": 11.15428, "loss": 0.04448, "lr": 0.0002295980, "top1_acc": 98.12500, "top1_err": 1.45833, "top5_acc": 100.00000, "top5_err": 0.05208}
[06/12 21:33:06][INFO] train_net.py:  708: Epoch 233 takes 47.50s. Epochs from 0 to 233 take 48.00s in average and 48.00s in median.
[06/12 21:33:06][INFO] train_net.py:  714: For epoch 233, each iteraction takes 0.79s in average. From epoch 0 to 233, each iteraction takes 0.80s in average.
[06/12 21:33:24][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47129, "dt_data": 0.00034, "dt_net": 0.47094, "epoch": "235/300", "eta": "0:31:01", "gpu_mem": "10.07G", "grad_norm": 6.61267, "iter": "10/60", "loss": 0.03018, "lr": 0.0002284864, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:33:30][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47591, "dt_data": 0.00078, "dt_net": 0.47513, "epoch": "235/300", "eta": "0:31:15", "gpu_mem": "10.07G", "grad_norm": 10.57830, "iter": "20/60", "loss": 0.04322, "lr": 0.0002273772, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:33:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47462, "dt_data": 0.00049, "dt_net": 0.47413, "epoch": "235/300", "eta": "0:31:05", "gpu_mem": "10.07G", "grad_norm": 0.28585, "iter": "30/60", "loss": 0.01560, "lr": 0.0002262703, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:33:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47530, "dt_data": 0.00044, "dt_net": 0.47486, "epoch": "235/300", "eta": "0:31:03", "gpu_mem": "10.07G", "grad_norm": 0.71227, "iter": "40/60", "loss": 0.01002, "lr": 0.0002251658, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:33:48][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47097, "dt_data": 0.00052, "dt_net": 0.47045, "epoch": "235/300", "eta": "0:30:41", "gpu_mem": "10.07G", "grad_norm": 8.32242, "iter": "50/60", "loss": 0.03866, "lr": 0.0002240637, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:33:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46905, "dt_data": 0.00017, "dt_net": 0.46888, "epoch": "235/300", "eta": "0:30:29", "gpu_mem": "10.07G", "grad_norm": 2.79326, "iter": "60/60", "loss": 0.03534, "lr": 0.0002229639, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:33:54][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.69368, "dt_data": 0.69368, "dt_net": 0.46888, "epoch": "235/300", "eta": "0:45:05", "gpu_mem": "10.07G", "grad_norm": 2.79326, "loss": 0.03869, "lr": 0.0002229639, "top1_acc": 98.64583, "top1_err": 1.35417, "top5_acc": 99.89583, "top5_err": 0.05208}
[06/12 21:33:54][INFO] train_net.py:  708: Epoch 234 takes 47.67s. Epochs from 0 to 234 take 48.00s in average and 47.98s in median.
[06/12 21:33:54][INFO] train_net.py:  714: For epoch 234, each iteraction takes 0.79s in average. From epoch 0 to 234, each iteraction takes 0.80s in average.
[06/12 21:33:54][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 21:34:55][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "235/300", "eta": "0:00:05", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.97469, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 21:34:58][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "val_epoch", "epoch": "235/300", "gpu_mem": "10.07G", "min_top1_err": 21.99170, "min_top5_err": 2.07469, "time_diff": 0.60827, "top1_acc": 75.72614, "top1_err": 24.27386, "top5_acc": 95.85062, "top5_err": 4.14938}
[06/12 21:35:15][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47012, "dt_data": 0.00032, "dt_net": 0.46980, "epoch": "236/300", "eta": "0:30:28", "gpu_mem": "10.07G", "grad_norm": 5.10452, "iter": "10/60", "loss": 0.01378, "lr": 0.0002218665, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:35:21][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47415, "dt_data": 0.00059, "dt_net": 0.47355, "epoch": "236/300", "eta": "0:30:39", "gpu_mem": "10.07G", "grad_norm": 0.68404, "iter": "20/60", "loss": 0.02186, "lr": 0.0002207714, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:35:27][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.81797, "dt_data": 0.35101, "dt_net": 0.46696, "epoch": "236/300", "eta": "0:52:45", "gpu_mem": "10.07G", "grad_norm": 20.21825, "iter": "30/60", "loss": 0.01261, "lr": 0.0002196787, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:35:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47121, "dt_data": 0.00037, "dt_net": 0.47084, "epoch": "236/300", "eta": "0:30:18", "gpu_mem": "10.07G", "grad_norm": 4.69586, "iter": "40/60", "loss": 0.03157, "lr": 0.0002185884, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:35:39][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.95403, "dt_data": 0.48438, "dt_net": 0.46965, "epoch": "236/300", "eta": "1:01:13", "gpu_mem": "10.07G", "grad_norm": 1.85527, "iter": "50/60", "loss": 0.02558, "lr": 0.0002175005, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:35:45][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46688, "dt_data": 0.00015, "dt_net": 0.46673, "epoch": "236/300", "eta": "0:29:52", "gpu_mem": "10.07G", "grad_norm": 2.34801, "iter": "60/60", "loss": 0.01486, "lr": 0.0002164150, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:35:46][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.68885, "dt_data": 0.68885, "dt_net": 0.46673, "epoch": "236/300", "eta": "0:44:05", "gpu_mem": "10.07G", "grad_norm": 2.34801, "loss": 0.03540, "lr": 0.0002164150, "top1_acc": 98.33333, "top1_err": 1.30208, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:35:46][INFO] train_net.py:  708: Epoch 235 takes 47.71s. Epochs from 0 to 235 take 48.00s in average and 47.98s in median.
[06/12 21:35:46][INFO] train_net.py:  714: For epoch 235, each iteraction takes 0.80s in average. From epoch 0 to 235, each iteraction takes 0.80s in average.
[06/12 21:36:02][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46841, "dt_data": 0.00033, "dt_net": 0.46808, "epoch": "237/300", "eta": "0:29:54", "gpu_mem": "10.07G", "grad_norm": 0.05889, "iter": "10/60", "loss": 0.00816, "lr": 0.0002153318, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:36:09][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47215, "dt_data": 0.00040, "dt_net": 0.47175, "epoch": "237/300", "eta": "0:30:03", "gpu_mem": "10.07G", "grad_norm": 11.67763, "iter": "20/60", "loss": 0.03974, "lr": 0.0002142511, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:36:15][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47002, "dt_data": 0.00035, "dt_net": 0.46967, "epoch": "237/300", "eta": "0:29:50", "gpu_mem": "10.07G", "grad_norm": 1.12106, "iter": "30/60", "loss": 0.02155, "lr": 0.0002131727, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:36:21][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47263, "dt_data": 0.00042, "dt_net": 0.47221, "epoch": "237/300", "eta": "0:29:56", "gpu_mem": "10.07G", "grad_norm": 3.20461, "iter": "40/60", "loss": 0.03055, "lr": 0.0002120967, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:36:27][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47720, "dt_data": 0.00067, "dt_net": 0.47652, "epoch": "237/300", "eta": "0:30:08", "gpu_mem": "10.07G", "grad_norm": 6.79569, "iter": "50/60", "loss": 0.05073, "lr": 0.0002110231, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:36:32][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46865, "dt_data": 0.00019, "dt_net": 0.46847, "epoch": "237/300", "eta": "0:29:31", "gpu_mem": "10.07G", "grad_norm": 0.87480, "iter": "60/60", "loss": 0.03936, "lr": 0.0002099520, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:36:33][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.69067, "dt_data": 0.69067, "dt_net": 0.46847, "epoch": "237/300", "eta": "0:43:30", "gpu_mem": "10.07G", "grad_norm": 0.87480, "loss": 0.04592, "lr": 0.0002099520, "top1_acc": 98.85417, "top1_err": 1.51042, "top5_acc": 99.89583, "top5_err": 0.10417}
[06/12 21:36:33][INFO] train_net.py:  708: Epoch 236 takes 47.39s. Epochs from 0 to 236 take 48.00s in average and 47.98s in median.
[06/12 21:36:33][INFO] train_net.py:  714: For epoch 236, each iteraction takes 0.79s in average. From epoch 0 to 236, each iteraction takes 0.80s in average.
[06/12 21:36:51][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48280, "dt_data": 0.00048, "dt_net": 0.48232, "epoch": "238/300", "eta": "0:30:20", "gpu_mem": "10.07G", "grad_norm": 1.97109, "iter": "10/60", "loss": 0.02200, "lr": 0.0002088832, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:36:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48365, "dt_data": 0.00066, "dt_net": 0.48298, "epoch": "238/300", "eta": "0:30:18", "gpu_mem": "10.07G", "grad_norm": 2.85090, "iter": "20/60", "loss": 0.02436, "lr": 0.0002078169, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:37:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47094, "dt_data": 0.00050, "dt_net": 0.47044, "epoch": "238/300", "eta": "0:29:26", "gpu_mem": "10.07G", "grad_norm": 3.08272, "iter": "30/60", "loss": 0.01799, "lr": 0.0002067529, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:37:09][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47353, "dt_data": 0.00047, "dt_net": 0.47305, "epoch": "238/300", "eta": "0:29:30", "gpu_mem": "10.07G", "grad_norm": 3.72275, "iter": "40/60", "loss": 0.02044, "lr": 0.0002056914, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:37:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47310, "dt_data": 0.00042, "dt_net": 0.47268, "epoch": "238/300", "eta": "0:29:24", "gpu_mem": "10.07G", "grad_norm": 1.82493, "iter": "50/60", "loss": 0.02722, "lr": 0.0002046323, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:37:21][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46856, "dt_data": 0.00016, "dt_net": 0.46840, "epoch": "238/300", "eta": "0:29:03", "gpu_mem": "10.07G", "grad_norm": 1.62993, "iter": "60/60", "loss": 0.01857, "lr": 0.0002035756, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:37:22][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.69229, "dt_data": 0.69229, "dt_net": 0.46840, "epoch": "238/300", "eta": "0:42:54", "gpu_mem": "10.07G", "grad_norm": 1.62993, "loss": 0.03386, "lr": 0.0002035756, "top1_acc": 98.75000, "top1_err": 1.14583, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:37:22][INFO] train_net.py:  708: Epoch 237 takes 49.18s. Epochs from 0 to 237 take 48.00s in average and 47.98s in median.
[06/12 21:37:22][INFO] train_net.py:  714: For epoch 237, each iteraction takes 0.82s in average. From epoch 0 to 237, each iteraction takes 0.80s in average.
[06/12 21:37:39][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47342, "dt_data": 0.00056, "dt_net": 0.47285, "epoch": "239/300", "eta": "0:29:16", "gpu_mem": "10.07G", "grad_norm": 1.56840, "iter": "10/60", "loss": 0.04368, "lr": 0.0002025214, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:37:45][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47457, "dt_data": 0.00044, "dt_net": 0.47413, "epoch": "239/300", "eta": "0:29:15", "gpu_mem": "10.07G", "grad_norm": 4.82664, "iter": "20/60", "loss": 0.03822, "lr": 0.0002014695, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:37:51][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.56902, "dt_data": 0.00053, "dt_net": 0.56848, "epoch": "239/300", "eta": "0:34:59", "gpu_mem": "10.07G", "grad_norm": 0.18357, "iter": "30/60", "loss": 0.01274, "lr": 0.0002004201, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:37:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47387, "dt_data": 0.00049, "dt_net": 0.47337, "epoch": "239/300", "eta": "0:29:03", "gpu_mem": "10.07G", "grad_norm": 2.41396, "iter": "40/60", "loss": 0.03410, "lr": 0.0001993732, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:38:03][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.49706, "dt_data": 0.00042, "dt_net": 0.49663, "epoch": "239/300", "eta": "0:30:24", "gpu_mem": "10.07G", "grad_norm": 6.26899, "iter": "50/60", "loss": 0.01577, "lr": 0.0001983287, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:38:09][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46952, "dt_data": 0.00015, "dt_net": 0.46938, "epoch": "239/300", "eta": "0:28:38", "gpu_mem": "10.07G", "grad_norm": 13.66880, "iter": "60/60", "loss": 0.01535, "lr": 0.0001972866, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:38:10][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.69547, "dt_data": 0.69547, "dt_net": 0.46938, "epoch": "239/300", "eta": "0:42:25", "gpu_mem": "10.07G", "grad_norm": 13.66880, "loss": 0.04056, "lr": 0.0001972866, "top1_acc": 98.85417, "top1_err": 1.25000, "top5_acc": 100.00000, "top5_err": 0.05208}
[06/12 21:38:10][INFO] train_net.py:  708: Epoch 238 takes 47.61s. Epochs from 0 to 238 take 48.00s in average and 47.98s in median.
[06/12 21:38:10][INFO] train_net.py:  714: For epoch 238, each iteraction takes 0.79s in average. From epoch 0 to 238, each iteraction takes 0.80s in average.
[06/12 21:38:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47214, "dt_data": 0.00049, "dt_net": 0.47165, "epoch": "240/300", "eta": "0:28:43", "gpu_mem": "10.07G", "grad_norm": 0.11767, "iter": "10/60", "loss": 0.03028, "lr": 0.0001962470, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:38:34][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47630, "dt_data": 0.00065, "dt_net": 0.47565, "epoch": "240/300", "eta": "0:28:53", "gpu_mem": "10.07G", "grad_norm": 5.24206, "iter": "20/60", "loss": 0.05665, "lr": 0.0001952098, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:38:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47286, "dt_data": 0.00067, "dt_net": 0.47219, "epoch": "240/300", "eta": "0:28:36", "gpu_mem": "10.07G", "grad_norm": 0.17068, "iter": "30/60", "loss": 0.02046, "lr": 0.0001941751, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:38:45][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47194, "dt_data": 0.00034, "dt_net": 0.47160, "epoch": "240/300", "eta": "0:28:28", "gpu_mem": "10.07G", "grad_norm": 5.52529, "iter": "40/60", "loss": 0.02272, "lr": 0.0001931428, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:38:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47878, "dt_data": 0.00049, "dt_net": 0.47829, "epoch": "240/300", "eta": "0:28:48", "gpu_mem": "10.07G", "grad_norm": 1.32932, "iter": "50/60", "loss": 0.01799, "lr": 0.0001921130, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:38:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46966, "dt_data": 0.00018, "dt_net": 0.46948, "epoch": "240/300", "eta": "0:28:10", "gpu_mem": "10.07G", "grad_norm": 0.96722, "iter": "60/60", "loss": 0.04063, "lr": 0.0001910856, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:38:57][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.68480, "dt_data": 0.68480, "dt_net": 0.46948, "epoch": "240/300", "eta": "0:41:05", "gpu_mem": "10.07G", "grad_norm": 0.96722, "loss": 0.04491, "lr": 0.0001910856, "top1_acc": 98.12500, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:38:57][INFO] train_net.py:  708: Epoch 239 takes 47.68s. Epochs from 0 to 239 take 48.00s in average and 47.98s in median.
[06/12 21:38:57][INFO] train_net.py:  714: For epoch 239, each iteraction takes 0.79s in average. From epoch 0 to 239, each iteraction takes 0.80s in average.
[06/12 21:38:57][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 21:39:59][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "240/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.12894, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 21:40:02][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "val_epoch", "epoch": "240/300", "gpu_mem": "10.07G", "min_top1_err": 21.99170, "min_top5_err": 2.07469, "time_diff": 0.60352, "top1_acc": 73.65145, "top1_err": 26.34855, "top5_acc": 97.09544, "top5_err": 2.90456}
[06/12 21:40:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46572, "dt_data": 0.00049, "dt_net": 0.46522, "epoch": "241/300", "eta": "0:27:51", "gpu_mem": "10.07G", "grad_norm": 5.35027, "iter": "10/60", "loss": 0.01492, "lr": 0.0001900607, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:40:26][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46746, "dt_data": 0.00072, "dt_net": 0.46674, "epoch": "241/300", "eta": "0:27:53", "gpu_mem": "10.07G", "grad_norm": 0.71410, "iter": "20/60", "loss": 0.04809, "lr": 0.0001890383, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:40:32][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.97866, "dt_data": 0.50500, "dt_net": 0.47365, "epoch": "241/300", "eta": "0:58:13", "gpu_mem": "10.07G", "grad_norm": 0.73212, "iter": "30/60", "loss": 0.01391, "lr": 0.0001880183, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:40:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46655, "dt_data": 0.00034, "dt_net": 0.46621, "epoch": "241/300", "eta": "0:27:40", "gpu_mem": "10.07G", "grad_norm": 1.53172, "iter": "40/60", "loss": 0.01719, "lr": 0.0001870009, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:40:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.87305, "dt_data": 0.39984, "dt_net": 0.47321, "epoch": "241/300", "eta": "0:51:39", "gpu_mem": "10.07G", "grad_norm": 0.45088, "iter": "50/60", "loss": 0.01110, "lr": 0.0001859858, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:40:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46695, "dt_data": 0.00015, "dt_net": 0.46680, "epoch": "241/300", "eta": "0:27:33", "gpu_mem": "10.07G", "grad_norm": 3.53628, "iter": "60/60", "loss": 0.01202, "lr": 0.0001849733, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:40:50][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.69624, "dt_data": 0.69625, "dt_net": 0.46680, "epoch": "241/300", "eta": "0:41:04", "gpu_mem": "10.07G", "grad_norm": 3.53628, "loss": 0.03398, "lr": 0.0001849733, "top1_acc": 98.75000, "top1_err": 1.04167, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:40:50][INFO] train_net.py:  708: Epoch 240 takes 48.01s. Epochs from 0 to 240 take 48.00s in average and 47.98s in median.
[06/12 21:40:50][INFO] train_net.py:  714: For epoch 240, each iteraction takes 0.80s in average. From epoch 0 to 240, each iteraction takes 0.80s in average.
[06/12 21:41:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47097, "dt_data": 0.00053, "dt_net": 0.47044, "epoch": "242/300", "eta": "0:27:42", "gpu_mem": "10.07G", "grad_norm": 6.18526, "iter": "10/60", "loss": 0.03828, "lr": 0.0001839633, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:41:12][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46977, "dt_data": 0.00066, "dt_net": 0.46911, "epoch": "242/300", "eta": "0:27:33", "gpu_mem": "10.07G", "grad_norm": 6.23302, "iter": "20/60", "loss": 0.03502, "lr": 0.0001829557, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:41:18][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47264, "dt_data": 0.00057, "dt_net": 0.47207, "epoch": "242/300", "eta": "0:27:38", "gpu_mem": "10.07G", "grad_norm": 1.77717, "iter": "30/60", "loss": 0.03794, "lr": 0.0001819507, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:41:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47341, "dt_data": 0.00036, "dt_net": 0.47305, "epoch": "242/300", "eta": "0:27:36", "gpu_mem": "10.07G", "grad_norm": 0.91995, "iter": "40/60", "loss": 0.00884, "lr": 0.0001809481, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:41:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47339, "dt_data": 0.00082, "dt_net": 0.47256, "epoch": "242/300", "eta": "0:27:32", "gpu_mem": "10.07G", "grad_norm": 0.61280, "iter": "50/60", "loss": 0.01551, "lr": 0.0001799480, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:41:36][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46800, "dt_data": 0.00020, "dt_net": 0.46780, "epoch": "242/300", "eta": "0:27:08", "gpu_mem": "10.07G", "grad_norm": 4.16626, "iter": "60/60", "loss": 0.02163, "lr": 0.0001789504, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:41:37][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.71278, "dt_data": 0.71278, "dt_net": 0.46780, "epoch": "242/300", "eta": "0:41:20", "gpu_mem": "10.07G", "grad_norm": 4.16626, "loss": 0.03700, "lr": 0.0001789504, "top1_acc": 98.12500, "top1_err": 1.35417, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:41:37][INFO] train_net.py:  708: Epoch 241 takes 47.00s. Epochs from 0 to 241 take 47.99s in average and 47.98s in median.
[06/12 21:41:37][INFO] train_net.py:  714: For epoch 241, each iteraction takes 0.78s in average. From epoch 0 to 241, each iteraction takes 0.80s in average.
[06/12 21:41:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46913, "dt_data": 0.00036, "dt_net": 0.46877, "epoch": "243/300", "eta": "0:27:07", "gpu_mem": "10.07G", "grad_norm": 2.07374, "iter": "10/60", "loss": 0.05015, "lr": 0.0001779553, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:42:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47213, "dt_data": 0.00051, "dt_net": 0.47162, "epoch": "243/300", "eta": "0:27:13", "gpu_mem": "10.07G", "grad_norm": 0.72701, "iter": "20/60", "loss": 0.03334, "lr": 0.0001769628, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:42:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47088, "dt_data": 0.00030, "dt_net": 0.47058, "epoch": "243/300", "eta": "0:27:04", "gpu_mem": "10.07G", "grad_norm": 2.16234, "iter": "30/60", "loss": 0.01691, "lr": 0.0001759727, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:42:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47625, "dt_data": 0.00068, "dt_net": 0.47556, "epoch": "243/300", "eta": "0:27:18", "gpu_mem": "10.07G", "grad_norm": 0.86846, "iter": "40/60", "loss": 0.04672, "lr": 0.0001749851, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:42:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47467, "dt_data": 0.00094, "dt_net": 0.47373, "epoch": "243/300", "eta": "0:27:08", "gpu_mem": "10.07G", "grad_norm": 1.68944, "iter": "50/60", "loss": 0.01291, "lr": 0.0001740001, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:42:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46920, "dt_data": 0.00017, "dt_net": 0.46903, "epoch": "243/300", "eta": "0:26:44", "gpu_mem": "10.07G", "grad_norm": 0.64757, "iter": "60/60", "loss": 0.01681, "lr": 0.0001730175, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:42:26][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.77923, "dt_data": 0.77923, "dt_net": 0.46903, "epoch": "243/300", "eta": "0:44:24", "gpu_mem": "10.07G", "grad_norm": 0.64757, "loss": 0.04093, "lr": 0.0001730175, "top1_acc": 98.54167, "top1_err": 1.51042, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:42:26][INFO] train_net.py:  708: Epoch 242 takes 48.79s. Epochs from 0 to 242 take 48.00s in average and 47.98s in median.
[06/12 21:42:26][INFO] train_net.py:  714: For epoch 242, each iteraction takes 0.81s in average. From epoch 0 to 242, each iteraction takes 0.80s in average.
[06/12 21:42:44][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46878, "dt_data": 0.00035, "dt_net": 0.46844, "epoch": "244/300", "eta": "0:26:38", "gpu_mem": "10.07G", "grad_norm": 1.21060, "iter": "10/60", "loss": 0.01680, "lr": 0.0001720375, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:42:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47654, "dt_data": 0.00038, "dt_net": 0.47616, "epoch": "244/300", "eta": "0:27:00", "gpu_mem": "10.07G", "grad_norm": 2.52716, "iter": "20/60", "loss": 0.05466, "lr": 0.0001710600, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:42:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47690, "dt_data": 0.00058, "dt_net": 0.47632, "epoch": "244/300", "eta": "0:26:56", "gpu_mem": "10.07G", "grad_norm": 8.79993, "iter": "30/60", "loss": 0.04552, "lr": 0.0001700851, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:43:02][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47460, "dt_data": 0.00049, "dt_net": 0.47411, "epoch": "244/300", "eta": "0:26:44", "gpu_mem": "10.07G", "grad_norm": 0.40945, "iter": "40/60", "loss": 0.02883, "lr": 0.0001691126, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:43:09][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47467, "dt_data": 0.00034, "dt_net": 0.47433, "epoch": "244/300", "eta": "0:26:39", "gpu_mem": "10.07G", "grad_norm": 4.41917, "iter": "50/60", "loss": 0.03098, "lr": 0.0001681427, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:43:14][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46944, "dt_data": 0.00019, "dt_net": 0.46925, "epoch": "244/300", "eta": "0:26:17", "gpu_mem": "10.07G", "grad_norm": 9.68192, "iter": "60/60", "loss": 0.01959, "lr": 0.0001671754, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:43:14][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.69226, "dt_data": 0.69226, "dt_net": 0.46925, "epoch": "244/300", "eta": "0:38:45", "gpu_mem": "10.07G", "grad_norm": 9.68192, "loss": 0.04507, "lr": 0.0001671754, "top1_acc": 98.12500, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:43:14][INFO] train_net.py:  708: Epoch 243 takes 48.61s. Epochs from 0 to 243 take 48.00s in average and 47.98s in median.
[06/12 21:43:14][INFO] train_net.py:  714: For epoch 243, each iteraction takes 0.81s in average. From epoch 0 to 243, each iteraction takes 0.80s in average.
[06/12 21:43:32][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.51324, "dt_data": 0.00079, "dt_net": 0.51244, "epoch": "245/300", "eta": "0:28:39", "gpu_mem": "10.07G", "grad_norm": 5.86715, "iter": "10/60", "loss": 0.03842, "lr": 0.0001662105, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:43:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47838, "dt_data": 0.00079, "dt_net": 0.47758, "epoch": "245/300", "eta": "0:26:37", "gpu_mem": "10.07G", "grad_norm": 2.79260, "iter": "20/60", "loss": 0.01377, "lr": 0.0001652482, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:43:44][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.87295, "dt_data": 0.00094, "dt_net": 0.87199, "epoch": "245/300", "eta": "0:48:26", "gpu_mem": "10.07G", "grad_norm": 3.14809, "iter": "30/60", "loss": 0.02659, "lr": 0.0001642885, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:43:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47569, "dt_data": 0.00085, "dt_net": 0.47483, "epoch": "245/300", "eta": "0:26:19", "gpu_mem": "10.07G", "grad_norm": 0.54777, "iter": "40/60", "loss": 0.00895, "lr": 0.0001633313, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:43:56][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.98678, "dt_data": 0.00034, "dt_net": 0.98643, "epoch": "245/300", "eta": "0:54:26", "gpu_mem": "10.07G", "grad_norm": 1.66534, "iter": "50/60", "loss": 0.04004, "lr": 0.0001623766, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:44:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46883, "dt_data": 0.00017, "dt_net": 0.46866, "epoch": "245/300", "eta": "0:25:47", "gpu_mem": "10.07G", "grad_norm": 6.59746, "iter": "60/60", "loss": 0.03761, "lr": 0.0001614245, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:44:02][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.70022, "dt_data": 0.70022, "dt_net": 0.46866, "epoch": "245/300", "eta": "0:38:30", "gpu_mem": "10.07G", "grad_norm": 6.59746, "loss": 0.03880, "lr": 0.0001614245, "top1_acc": 98.54167, "top1_err": 1.45833, "top5_acc": 99.89583, "top5_err": 0.05208}
[06/12 21:44:02][INFO] train_net.py:  708: Epoch 244 takes 47.50s. Epochs from 0 to 244 take 48.00s in average and 47.98s in median.
[06/12 21:44:02][INFO] train_net.py:  714: For epoch 244, each iteraction takes 0.79s in average. From epoch 0 to 244, each iteraction takes 0.80s in average.
[06/12 21:44:02][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 21:45:02][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "245/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.12963, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 21:45:05][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "val_epoch", "epoch": "245/300", "gpu_mem": "10.07G", "min_top1_err": 21.99170, "min_top5_err": 2.07469, "time_diff": 0.60237, "top1_acc": 76.55602, "top1_err": 23.44398, "top5_acc": 97.30290, "top5_err": 2.69710}
[06/12 21:45:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46699, "dt_data": 0.00042, "dt_net": 0.46656, "epoch": "246/300", "eta": "0:25:36", "gpu_mem": "10.07G", "grad_norm": 0.07662, "iter": "10/60", "loss": 0.02849, "lr": 0.0001604750, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:45:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46874, "dt_data": 0.00070, "dt_net": 0.46804, "epoch": "246/300", "eta": "0:25:37", "gpu_mem": "10.07G", "grad_norm": 0.24162, "iter": "20/60", "loss": 0.04463, "lr": 0.0001595280, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:45:34][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46927, "dt_data": 0.00048, "dt_net": 0.46879, "epoch": "246/300", "eta": "0:25:34", "gpu_mem": "10.07G", "grad_norm": 0.37606, "iter": "30/60", "loss": 0.00845, "lr": 0.0001585835, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:45:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46801, "dt_data": 0.00037, "dt_net": 0.46763, "epoch": "246/300", "eta": "0:25:25", "gpu_mem": "10.07G", "grad_norm": 2.66663, "iter": "40/60", "loss": 0.01494, "lr": 0.0001576416, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:45:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47333, "dt_data": 0.00078, "dt_net": 0.47255, "epoch": "246/300", "eta": "0:25:38", "gpu_mem": "10.07G", "grad_norm": 1.26199, "iter": "50/60", "loss": 0.04194, "lr": 0.0001567023, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:45:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46697, "dt_data": 0.00021, "dt_net": 0.46675, "epoch": "246/300", "eta": "0:25:12", "gpu_mem": "10.07G", "grad_norm": 0.53859, "iter": "60/60", "loss": 0.02086, "lr": 0.0001557656, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:45:53][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.69098, "dt_data": 0.69098, "dt_net": 0.46675, "epoch": "246/300", "eta": "0:37:18", "gpu_mem": "10.07G", "grad_norm": 0.53859, "loss": 0.03922, "lr": 0.0001557656, "top1_acc": 99.06250, "top1_err": 1.35417, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:45:53][INFO] train_net.py:  708: Epoch 245 takes 47.96s. Epochs from 0 to 245 take 48.00s in average and 47.98s in median.
[06/12 21:45:53][INFO] train_net.py:  714: For epoch 245, each iteraction takes 0.80s in average. From epoch 0 to 245, each iteraction takes 0.80s in average.
[06/12 21:46:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47031, "dt_data": 0.00036, "dt_net": 0.46994, "epoch": "247/300", "eta": "0:25:19", "gpu_mem": "10.07G", "grad_norm": 0.98062, "iter": "10/60", "loss": 0.04162, "lr": 0.0001548314, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:46:17][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47234, "dt_data": 0.00037, "dt_net": 0.47197, "epoch": "247/300", "eta": "0:25:20", "gpu_mem": "10.07G", "grad_norm": 7.65429, "iter": "20/60", "loss": 0.02063, "lr": 0.0001538999, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:46:24][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47221, "dt_data": 0.00034, "dt_net": 0.47186, "epoch": "247/300", "eta": "0:25:15", "gpu_mem": "10.07G", "grad_norm": 7.34787, "iter": "30/60", "loss": 0.05849, "lr": 0.0001529708, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:46:29][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47531, "dt_data": 0.00036, "dt_net": 0.47495, "epoch": "247/300", "eta": "0:25:20", "gpu_mem": "10.07G", "grad_norm": 1.42796, "iter": "40/60", "loss": 0.04465, "lr": 0.0001520444, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:46:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47236, "dt_data": 0.00039, "dt_net": 0.47197, "epoch": "247/300", "eta": "0:25:06", "gpu_mem": "10.07G", "grad_norm": 0.30180, "iter": "50/60", "loss": 0.01204, "lr": 0.0001511206, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:46:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46794, "dt_data": 0.00019, "dt_net": 0.46775, "epoch": "247/300", "eta": "0:24:48", "gpu_mem": "10.07G", "grad_norm": 1.13980, "iter": "60/60", "loss": 0.02341, "lr": 0.0001501993, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:46:41][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.68725, "dt_data": 0.68725, "dt_net": 0.46775, "epoch": "247/300", "eta": "0:36:25", "gpu_mem": "10.07G", "grad_norm": 1.13980, "loss": 0.04509, "lr": 0.0001501993, "top1_acc": 98.54167, "top1_err": 1.77083, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:46:41][INFO] train_net.py:  708: Epoch 246 takes 48.23s. Epochs from 0 to 246 take 48.00s in average and 47.98s in median.
[06/12 21:46:41][INFO] train_net.py:  714: For epoch 246, each iteraction takes 0.80s in average. From epoch 0 to 246, each iteraction takes 0.80s in average.
[06/12 21:46:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.70362, "dt_data": 0.23071, "dt_net": 0.47290, "epoch": "248/300", "eta": "0:37:10", "gpu_mem": "10.07G", "grad_norm": 0.73512, "iter": "10/60", "loss": 0.01506, "lr": 0.0001492806, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:47:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47957, "dt_data": 0.00052, "dt_net": 0.47904, "epoch": "248/300", "eta": "0:25:15", "gpu_mem": "10.07G", "grad_norm": 0.58830, "iter": "20/60", "loss": 0.02746, "lr": 0.0001483645, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:47:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47040, "dt_data": 0.00073, "dt_net": 0.46967, "epoch": "248/300", "eta": "0:24:41", "gpu_mem": "10.07G", "grad_norm": 0.78001, "iter": "30/60", "loss": 0.02588, "lr": 0.0001474510, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:47:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47588, "dt_data": 0.00053, "dt_net": 0.47535, "epoch": "248/300", "eta": "0:24:54", "gpu_mem": "10.07G", "grad_norm": 1.64994, "iter": "40/60", "loss": 0.01971, "lr": 0.0001465401, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:47:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47330, "dt_data": 0.00041, "dt_net": 0.47289, "epoch": "248/300", "eta": "0:24:41", "gpu_mem": "10.07G", "grad_norm": 0.48214, "iter": "50/60", "loss": 0.00645, "lr": 0.0001456319, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:47:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47003, "dt_data": 0.00016, "dt_net": 0.46987, "epoch": "248/300", "eta": "0:24:26", "gpu_mem": "10.07G", "grad_norm": 7.12421, "iter": "60/60", "loss": 0.01276, "lr": 0.0001447262, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:47:29][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.69816, "dt_data": 0.69816, "dt_net": 0.46987, "epoch": "248/300", "eta": "0:36:18", "gpu_mem": "10.07G", "grad_norm": 7.12421, "loss": 0.03333, "lr": 0.0001447262, "top1_acc": 98.64583, "top1_err": 1.19792, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:47:29][INFO] train_net.py:  708: Epoch 247 takes 48.06s. Epochs from 0 to 247 take 48.00s in average and 47.98s in median.
[06/12 21:47:29][INFO] train_net.py:  714: For epoch 247, each iteraction takes 0.80s in average. From epoch 0 to 247, each iteraction takes 0.80s in average.
[06/12 21:47:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.67816, "dt_data": 0.00070, "dt_net": 0.67746, "epoch": "249/300", "eta": "0:35:09", "gpu_mem": "10.07G", "grad_norm": 0.44570, "iter": "10/60", "loss": 0.00747, "lr": 0.0001438231, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:47:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47207, "dt_data": 0.00082, "dt_net": 0.47125, "epoch": "249/300", "eta": "0:24:23", "gpu_mem": "10.07G", "grad_norm": 4.68352, "iter": "20/60", "loss": 0.03373, "lr": 0.0001429226, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:47:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47391, "dt_data": 0.00076, "dt_net": 0.47314, "epoch": "249/300", "eta": "0:24:24", "gpu_mem": "10.07G", "grad_norm": 8.78884, "iter": "30/60", "loss": 0.05479, "lr": 0.0001420247, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:48:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47493, "dt_data": 0.00057, "dt_net": 0.47435, "epoch": "249/300", "eta": "0:24:22", "gpu_mem": "10.07G", "grad_norm": 8.38469, "iter": "40/60", "loss": 0.01277, "lr": 0.0001411295, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:48:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.04018, "dt_data": 0.56442, "dt_net": 0.47575, "epoch": "249/300", "eta": "0:53:13", "gpu_mem": "10.07G", "grad_norm": 2.37076, "iter": "50/60", "loss": 0.01836, "lr": 0.0001402368, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:48:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47161, "dt_data": 0.00016, "dt_net": 0.47145, "epoch": "249/300", "eta": "0:24:03", "gpu_mem": "10.07G", "grad_norm": 11.86841, "iter": "60/60", "loss": 0.04317, "lr": 0.0001393468, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:48:17][INFO] logging.py:  101: json_stats: {"RAM": "13.45/31.07G", "_type": "train_epoch", "dt": 0.68492, "dt_data": 0.68492, "dt_net": 0.47145, "epoch": "249/300", "eta": "0:34:55", "gpu_mem": "10.07G", "grad_norm": 11.86841, "loss": 0.04876, "lr": 0.0001393468, "top1_acc": 98.85417, "top1_err": 1.66667, "top5_acc": 99.89583, "top5_err": 0.05208}
[06/12 21:48:17][INFO] train_net.py:  708: Epoch 248 takes 47.75s. Epochs from 0 to 248 take 48.00s in average and 47.98s in median.
[06/12 21:48:17][INFO] train_net.py:  714: For epoch 248, each iteraction takes 0.80s in average. From epoch 0 to 248, each iteraction takes 0.80s in average.
[06/12 21:48:34][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48204, "dt_data": 0.00078, "dt_net": 0.48126, "epoch": "250/300", "eta": "0:24:30", "gpu_mem": "10.07G", "grad_norm": 0.79873, "iter": "10/60", "loss": 0.05031, "lr": 0.0001384594, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:48:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47643, "dt_data": 0.00040, "dt_net": 0.47603, "epoch": "250/300", "eta": "0:24:08", "gpu_mem": "10.07G", "grad_norm": 3.26246, "iter": "20/60", "loss": 0.01470, "lr": 0.0001375747, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:48:47][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47163, "dt_data": 0.00040, "dt_net": 0.47123, "epoch": "250/300", "eta": "0:23:49", "gpu_mem": "10.07G", "grad_norm": 6.45368, "iter": "30/60", "loss": 0.02356, "lr": 0.0001366925, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:48:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47677, "dt_data": 0.00051, "dt_net": 0.47626, "epoch": "250/300", "eta": "0:23:59", "gpu_mem": "10.07G", "grad_norm": 6.80134, "iter": "40/60", "loss": 0.02662, "lr": 0.0001358130, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:48:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.68200, "dt_data": 0.21044, "dt_net": 0.47155, "epoch": "250/300", "eta": "0:34:12", "gpu_mem": "10.07G", "grad_norm": 9.99902, "iter": "50/60", "loss": 0.04899, "lr": 0.0001349361, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:49:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47126, "dt_data": 0.00016, "dt_net": 0.47110, "epoch": "250/300", "eta": "0:23:33", "gpu_mem": "10.07G", "grad_norm": 8.78360, "iter": "60/60", "loss": 0.03989, "lr": 0.0001340619, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:49:05][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.70837, "dt_data": 0.70837, "dt_net": 0.47110, "epoch": "250/300", "eta": "0:35:25", "gpu_mem": "10.07G", "grad_norm": 8.78360, "loss": 0.05666, "lr": 0.0001340619, "top1_acc": 98.33333, "top1_err": 1.82292, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:49:05][INFO] train_net.py:  708: Epoch 249 takes 48.36s. Epochs from 0 to 249 take 48.00s in average and 47.98s in median.
[06/12 21:49:05][INFO] train_net.py:  714: For epoch 249, each iteraction takes 0.81s in average. From epoch 0 to 249, each iteraction takes 0.80s in average.
[06/12 21:49:05][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 21:50:06][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "250/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.13100, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 98.43750, "top5_err": 1.56250}
[06/12 21:50:09][INFO] logging.py:  101: json_stats: {"RAM": "13.45/31.07G", "_type": "val_epoch", "epoch": "250/300", "gpu_mem": "10.07G", "min_top1_err": 21.99170, "min_top5_err": 2.07469, "time_diff": 0.61454, "top1_acc": 74.06639, "top1_err": 25.93361, "top5_acc": 97.09544, "top5_err": 2.90456}
[06/12 21:50:27][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46318, "dt_data": 0.00030, "dt_net": 0.46288, "epoch": "251/300", "eta": "0:23:04", "gpu_mem": "10.07G", "grad_norm": 1.84034, "iter": "10/60", "loss": 0.04985, "lr": 0.0001331903, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:50:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46521, "dt_data": 0.00040, "dt_net": 0.46481, "epoch": "251/300", "eta": "0:23:06", "gpu_mem": "10.07G", "grad_norm": 5.37813, "iter": "20/60", "loss": 0.03402, "lr": 0.0001323213, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:50:39][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47381, "dt_data": 0.00036, "dt_net": 0.47345, "epoch": "251/300", "eta": "0:23:27", "gpu_mem": "10.07G", "grad_norm": 0.84293, "iter": "30/60", "loss": 0.04585, "lr": 0.0001314550, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:50:45][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47047, "dt_data": 0.00031, "dt_net": 0.47016, "epoch": "251/300", "eta": "0:23:12", "gpu_mem": "10.07G", "grad_norm": 0.50017, "iter": "40/60", "loss": 0.01581, "lr": 0.0001305913, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:50:51][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48215, "dt_data": 0.00040, "dt_net": 0.48175, "epoch": "251/300", "eta": "0:23:42", "gpu_mem": "10.07G", "grad_norm": 0.58197, "iter": "50/60", "loss": 0.02674, "lr": 0.0001297303, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:50:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47155, "dt_data": 0.00016, "dt_net": 0.47138, "epoch": "251/300", "eta": "0:23:06", "gpu_mem": "10.07G", "grad_norm": 2.79988, "iter": "60/60", "loss": 0.01112, "lr": 0.0001288719, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:50:58][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.69192, "dt_data": 0.69192, "dt_net": 0.47138, "epoch": "251/300", "eta": "0:33:54", "gpu_mem": "10.07G", "grad_norm": 2.79988, "loss": 0.03853, "lr": 0.0001288719, "top1_acc": 98.22917, "top1_err": 1.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:50:58][INFO] train_net.py:  708: Epoch 250 takes 48.92s. Epochs from 0 to 250 take 48.00s in average and 47.98s in median.
[06/12 21:50:58][INFO] train_net.py:  714: For epoch 250, each iteraction takes 0.82s in average. From epoch 0 to 250, each iteraction takes 0.80s in average.
[06/12 21:51:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47251, "dt_data": 0.00034, "dt_net": 0.47217, "epoch": "252/300", "eta": "0:23:04", "gpu_mem": "10.07G", "grad_norm": 3.13322, "iter": "10/60", "loss": 0.02794, "lr": 0.0001280162, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:51:21][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47911, "dt_data": 0.00035, "dt_net": 0.47876, "epoch": "252/300", "eta": "0:23:19", "gpu_mem": "10.07G", "grad_norm": 2.19856, "iter": "20/60", "loss": 0.02498, "lr": 0.0001271631, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:51:27][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47398, "dt_data": 0.00060, "dt_net": 0.47338, "epoch": "252/300", "eta": "0:22:59", "gpu_mem": "10.07G", "grad_norm": 1.60295, "iter": "30/60", "loss": 0.02878, "lr": 0.0001263127, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:51:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48279, "dt_data": 0.00044, "dt_net": 0.48236, "epoch": "252/300", "eta": "0:23:20", "gpu_mem": "10.07G", "grad_norm": 0.16835, "iter": "40/60", "loss": 0.03918, "lr": 0.0001254649, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:51:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47440, "dt_data": 0.00032, "dt_net": 0.47408, "epoch": "252/300", "eta": "0:22:51", "gpu_mem": "10.07G", "grad_norm": 2.46408, "iter": "50/60", "loss": 0.02246, "lr": 0.0001246198, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:51:45][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46880, "dt_data": 0.00017, "dt_net": 0.46863, "epoch": "252/300", "eta": "0:22:30", "gpu_mem": "10.07G", "grad_norm": 3.50161, "iter": "60/60", "loss": 0.04325, "lr": 0.0001237774, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:51:46][INFO] logging.py:  101: json_stats: {"RAM": "13.48/31.07G", "_type": "train_epoch", "dt": 0.69925, "dt_data": 0.69925, "dt_net": 0.46863, "epoch": "252/300", "eta": "0:33:33", "gpu_mem": "10.07G", "grad_norm": 3.50161, "loss": 0.04050, "lr": 0.0001237774, "top1_acc": 98.75000, "top1_err": 1.35417, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:51:46][INFO] train_net.py:  708: Epoch 251 takes 48.06s. Epochs from 0 to 251 take 48.00s in average and 48.00s in median.
[06/12 21:51:46][INFO] train_net.py:  714: For epoch 251, each iteraction takes 0.80s in average. From epoch 0 to 251, each iteraction takes 0.80s in average.
[06/12 21:52:03][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47021, "dt_data": 0.00037, "dt_net": 0.46984, "epoch": "253/300", "eta": "0:22:29", "gpu_mem": "10.07G", "grad_norm": 4.40647, "iter": "10/60", "loss": 0.02669, "lr": 0.0001229377, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:52:09][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47318, "dt_data": 0.00034, "dt_net": 0.47283, "epoch": "253/300", "eta": "0:22:33", "gpu_mem": "10.07G", "grad_norm": 1.66998, "iter": "20/60", "loss": 0.00645, "lr": 0.0001221006, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:52:15][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47679, "dt_data": 0.00062, "dt_net": 0.47617, "epoch": "253/300", "eta": "0:22:38", "gpu_mem": "10.07G", "grad_norm": 1.94677, "iter": "30/60", "loss": 0.01744, "lr": 0.0001212662, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:52:21][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47992, "dt_data": 0.00033, "dt_net": 0.47959, "epoch": "253/300", "eta": "0:22:42", "gpu_mem": "10.07G", "grad_norm": 0.19197, "iter": "40/60", "loss": 0.01863, "lr": 0.0001204345, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:52:27][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47565, "dt_data": 0.00035, "dt_net": 0.47529, "epoch": "253/300", "eta": "0:22:26", "gpu_mem": "10.07G", "grad_norm": 1.90342, "iter": "50/60", "loss": 0.03186, "lr": 0.0001196054, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:52:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47502, "dt_data": 0.00016, "dt_net": 0.47486, "epoch": "253/300", "eta": "0:22:19", "gpu_mem": "10.07G", "grad_norm": 0.68889, "iter": "60/60", "loss": 0.03397, "lr": 0.0001187790, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:52:33][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.68276, "dt_data": 0.68276, "dt_net": 0.47486, "epoch": "253/300", "eta": "0:32:05", "gpu_mem": "10.07G", "grad_norm": 0.68889, "loss": 0.03402, "lr": 0.0001187790, "top1_acc": 98.85417, "top1_err": 1.14583, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:52:33][INFO] train_net.py:  708: Epoch 252 takes 47.68s. Epochs from 0 to 252 take 48.00s in average and 47.98s in median.
[06/12 21:52:33][INFO] train_net.py:  714: For epoch 252, each iteraction takes 0.79s in average. From epoch 0 to 252, each iteraction takes 0.80s in average.
[06/12 21:52:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47485, "dt_data": 0.00035, "dt_net": 0.47450, "epoch": "254/300", "eta": "0:22:14", "gpu_mem": "10.07G", "grad_norm": 6.28846, "iter": "10/60", "loss": 0.01611, "lr": 0.0001179554, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:52:56][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.99189, "dt_data": 0.00053, "dt_net": 0.99136, "epoch": "254/300", "eta": "0:46:17", "gpu_mem": "10.07G", "grad_norm": 3.38383, "iter": "20/60", "loss": 0.03911, "lr": 0.0001171344, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:53:02][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47302, "dt_data": 0.00041, "dt_net": 0.47261, "epoch": "254/300", "eta": "0:21:59", "gpu_mem": "10.07G", "grad_norm": 0.46831, "iter": "30/60", "loss": 0.04391, "lr": 0.0001163161, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:53:09][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47930, "dt_data": 0.00054, "dt_net": 0.47876, "epoch": "254/300", "eta": "0:22:12", "gpu_mem": "10.07G", "grad_norm": 0.52318, "iter": "40/60", "loss": 0.01605, "lr": 0.0001155004, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:53:15][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47303, "dt_data": 0.00046, "dt_net": 0.47257, "epoch": "254/300", "eta": "0:21:50", "gpu_mem": "10.07G", "grad_norm": 0.39121, "iter": "50/60", "loss": 0.03746, "lr": 0.0001146875, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:53:21][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46833, "dt_data": 0.00022, "dt_net": 0.46812, "epoch": "254/300", "eta": "0:21:32", "gpu_mem": "10.07G", "grad_norm": 0.17315, "iter": "60/60", "loss": 0.01779, "lr": 0.0001138773, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:53:21][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.69630, "dt_data": 0.69630, "dt_net": 0.46812, "epoch": "254/300", "eta": "0:32:01", "gpu_mem": "10.07G", "grad_norm": 0.17315, "loss": 0.03566, "lr": 0.0001138773, "top1_acc": 98.64583, "top1_err": 1.35417, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:53:21][INFO] train_net.py:  708: Epoch 253 takes 48.05s. Epochs from 0 to 253 take 48.00s in average and 48.00s in median.
[06/12 21:53:21][INFO] train_net.py:  714: For epoch 253, each iteraction takes 0.80s in average. From epoch 0 to 253, each iteraction takes 0.80s in average.
[06/12 21:53:39][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47710, "dt_data": 0.00043, "dt_net": 0.47668, "epoch": "255/300", "eta": "0:21:52", "gpu_mem": "10.07G", "grad_norm": 0.10123, "iter": "10/60", "loss": 0.01137, "lr": 0.0001130698, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:53:45][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47617, "dt_data": 0.00126, "dt_net": 0.47491, "epoch": "255/300", "eta": "0:21:44", "gpu_mem": "10.07G", "grad_norm": 5.09554, "iter": "20/60", "loss": 0.04004, "lr": 0.0001122649, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:53:51][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47823, "dt_data": 0.00072, "dt_net": 0.47751, "epoch": "255/300", "eta": "0:21:45", "gpu_mem": "10.07G", "grad_norm": 2.39178, "iter": "30/60", "loss": 0.03465, "lr": 0.0001114628, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:53:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47487, "dt_data": 0.00035, "dt_net": 0.47451, "epoch": "255/300", "eta": "0:21:31", "gpu_mem": "10.07G", "grad_norm": 14.78281, "iter": "40/60", "loss": 0.02199, "lr": 0.0001106634, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:54:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47591, "dt_data": 0.00074, "dt_net": 0.47517, "epoch": "255/300", "eta": "0:21:29", "gpu_mem": "10.07G", "grad_norm": 19.21295, "iter": "50/60", "loss": 0.03325, "lr": 0.0001098667, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:54:09][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47091, "dt_data": 0.00019, "dt_net": 0.47072, "epoch": "255/300", "eta": "0:21:11", "gpu_mem": "10.07G", "grad_norm": 9.76616, "iter": "60/60", "loss": 0.02164, "lr": 0.0001090727, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:54:10][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.70334, "dt_data": 0.70334, "dt_net": 0.47072, "epoch": "255/300", "eta": "0:31:38", "gpu_mem": "10.07G", "grad_norm": 9.76616, "loss": 0.04069, "lr": 0.0001090727, "top1_acc": 98.43750, "top1_err": 1.61458, "top5_acc": 99.89583, "top5_err": 0.05208}
[06/12 21:54:10][INFO] train_net.py:  708: Epoch 254 takes 48.19s. Epochs from 0 to 254 take 48.00s in average and 48.01s in median.
[06/12 21:54:10][INFO] train_net.py:  714: For epoch 254, each iteraction takes 0.80s in average. From epoch 0 to 254, each iteraction takes 0.80s in average.
[06/12 21:54:10][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 21:55:11][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "255/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.12986, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 21:55:14][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "val_epoch", "epoch": "255/300", "gpu_mem": "10.07G", "min_top1_err": 21.99170, "min_top5_err": 2.07469, "time_diff": 0.60922, "top1_acc": 74.89627, "top1_err": 25.10373, "top5_acc": 96.05809, "top5_err": 3.94191}
[06/12 21:55:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46596, "dt_data": 0.00036, "dt_net": 0.46560, "epoch": "256/300", "eta": "0:20:53", "gpu_mem": "10.07G", "grad_norm": 0.20620, "iter": "10/60", "loss": 0.01443, "lr": 0.0001082814, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:55:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47051, "dt_data": 0.00062, "dt_net": 0.46988, "epoch": "256/300", "eta": "0:21:00", "gpu_mem": "10.07G", "grad_norm": 0.83955, "iter": "20/60", "loss": 0.01570, "lr": 0.0001074929, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:55:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47443, "dt_data": 0.00598, "dt_net": 0.46843, "epoch": "256/300", "eta": "0:21:06", "gpu_mem": "10.07G", "grad_norm": 2.27491, "iter": "30/60", "loss": 0.01742, "lr": 0.0001067070, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:55:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47678, "dt_data": 0.00051, "dt_net": 0.47627, "epoch": "256/300", "eta": "0:21:08", "gpu_mem": "10.07G", "grad_norm": 3.83807, "iter": "40/60", "loss": 0.02734, "lr": 0.0001059239, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:55:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47451, "dt_data": 0.00050, "dt_net": 0.47401, "epoch": "256/300", "eta": "0:20:57", "gpu_mem": "10.07G", "grad_norm": 8.34666, "iter": "50/60", "loss": 0.03309, "lr": 0.0001051435, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:56:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46717, "dt_data": 0.00018, "dt_net": 0.46698, "epoch": "256/300", "eta": "0:20:33", "gpu_mem": "10.07G", "grad_norm": 5.34392, "iter": "60/60", "loss": 0.00791, "lr": 0.0001043659, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:56:01][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.68641, "dt_data": 0.68641, "dt_net": 0.46698, "epoch": "256/300", "eta": "0:30:11", "gpu_mem": "10.07G", "grad_norm": 5.34392, "loss": 0.03582, "lr": 0.0001043659, "top1_acc": 98.22917, "top1_err": 1.40625, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:56:01][INFO] train_net.py:  708: Epoch 255 takes 47.46s. Epochs from 0 to 255 take 48.00s in average and 48.00s in median.
[06/12 21:56:01][INFO] train_net.py:  714: For epoch 255, each iteraction takes 0.79s in average. From epoch 0 to 255, each iteraction takes 0.80s in average.
[06/12 21:56:18][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46835, "dt_data": 0.00037, "dt_net": 0.46798, "epoch": "257/300", "eta": "0:20:31", "gpu_mem": "10.07G", "grad_norm": 1.01160, "iter": "10/60", "loss": 0.01534, "lr": 0.0001035909, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:56:24][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47175, "dt_data": 0.00054, "dt_net": 0.47121, "epoch": "257/300", "eta": "0:20:35", "gpu_mem": "10.07G", "grad_norm": 1.18454, "iter": "20/60", "loss": 0.01845, "lr": 0.0001028187, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:56:30][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.81590, "dt_data": 0.34843, "dt_net": 0.46747, "epoch": "257/300", "eta": "0:35:29", "gpu_mem": "10.07G", "grad_norm": 4.61331, "iter": "30/60", "loss": 0.04855, "lr": 0.0001020492, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:56:36][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47252, "dt_data": 0.00046, "dt_net": 0.47206, "epoch": "257/300", "eta": "0:20:28", "gpu_mem": "10.07G", "grad_norm": 4.49735, "iter": "40/60", "loss": 0.00481, "lr": 0.0001012825, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:56:42][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47324, "dt_data": 0.00036, "dt_net": 0.47288, "epoch": "257/300", "eta": "0:20:25", "gpu_mem": "10.07G", "grad_norm": 9.32626, "iter": "50/60", "loss": 0.03968, "lr": 0.0001005185, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:56:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.96800, "dt_data": 0.50031, "dt_net": 0.46769, "epoch": "257/300", "eta": "0:41:37", "gpu_mem": "10.07G", "grad_norm": 1.18932, "iter": "60/60", "loss": 0.01940, "lr": 0.0000997572, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:56:49][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.70194, "dt_data": 0.70194, "dt_net": 0.46769, "epoch": "257/300", "eta": "0:30:10", "gpu_mem": "10.07G", "grad_norm": 1.18932, "loss": 0.04098, "lr": 0.0000997572, "top1_acc": 98.12500, "top1_err": 1.66667, "top5_acc": 100.00000, "top5_err": 0.05208}
[06/12 21:56:49][INFO] train_net.py:  708: Epoch 256 takes 47.97s. Epochs from 0 to 256 take 48.00s in average and 47.98s in median.
[06/12 21:56:49][INFO] train_net.py:  714: For epoch 256, each iteraction takes 0.80s in average. From epoch 0 to 256, each iteraction takes 0.80s in average.
[06/12 21:57:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.73589, "dt_data": 0.26877, "dt_net": 0.46712, "epoch": "258/300", "eta": "0:31:31", "gpu_mem": "10.07G", "grad_norm": 2.17423, "iter": "10/60", "loss": 0.01779, "lr": 0.0000989987, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:57:12][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47560, "dt_data": 0.00045, "dt_net": 0.47514, "epoch": "258/300", "eta": "0:20:17", "gpu_mem": "10.07G", "grad_norm": 0.26057, "iter": "20/60", "loss": 0.01607, "lr": 0.0000982429, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:57:18][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47446, "dt_data": 0.00041, "dt_net": 0.47405, "epoch": "258/300", "eta": "0:20:09", "gpu_mem": "10.07G", "grad_norm": 0.90615, "iter": "30/60", "loss": 0.02427, "lr": 0.0000974899, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:57:24][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47125, "dt_data": 0.00061, "dt_net": 0.47063, "epoch": "258/300", "eta": "0:19:56", "gpu_mem": "10.07G", "grad_norm": 1.48967, "iter": "40/60", "loss": 0.00905, "lr": 0.0000967396, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:57:30][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.90465, "dt_data": 0.43370, "dt_net": 0.47095, "epoch": "258/300", "eta": "0:38:08", "gpu_mem": "10.07G", "grad_norm": 2.23011, "iter": "50/60", "loss": 0.01447, "lr": 0.0000959921, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:57:36][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46771, "dt_data": 0.00014, "dt_net": 0.46757, "epoch": "258/300", "eta": "0:19:38", "gpu_mem": "10.07G", "grad_norm": 0.36829, "iter": "60/60", "loss": 0.02896, "lr": 0.0000952473, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:57:36][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.68634, "dt_data": 0.68634, "dt_net": 0.46757, "epoch": "258/300", "eta": "0:28:49", "gpu_mem": "10.07G", "grad_norm": 0.36829, "loss": 0.03170, "lr": 0.0000952473, "top1_acc": 99.16667, "top1_err": 0.98958, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:57:36][INFO] train_net.py:  708: Epoch 257 takes 46.90s. Epochs from 0 to 257 take 48.00s in average and 47.98s in median.
[06/12 21:57:36][INFO] train_net.py:  714: For epoch 257, each iteraction takes 0.78s in average. From epoch 0 to 257, each iteraction takes 0.80s in average.
[06/12 21:57:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46924, "dt_data": 0.00031, "dt_net": 0.46893, "epoch": "259/300", "eta": "0:19:37", "gpu_mem": "10.07G", "grad_norm": 0.18187, "iter": "10/60", "loss": 0.04143, "lr": 0.0000945053, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:57:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47332, "dt_data": 0.00041, "dt_net": 0.47291, "epoch": "259/300", "eta": "0:19:43", "gpu_mem": "10.07G", "grad_norm": 7.40133, "iter": "20/60", "loss": 0.02034, "lr": 0.0000937660, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:58:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47143, "dt_data": 0.00053, "dt_net": 0.47089, "epoch": "259/300", "eta": "0:19:33", "gpu_mem": "10.07G", "grad_norm": 4.01128, "iter": "30/60", "loss": 0.05100, "lr": 0.0000930295, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:58:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47528, "dt_data": 0.00045, "dt_net": 0.47483, "epoch": "259/300", "eta": "0:19:38", "gpu_mem": "10.07G", "grad_norm": 2.00767, "iter": "40/60", "loss": 0.01489, "lr": 0.0000922957, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:58:17][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.74173, "dt_data": 0.00039, "dt_net": 0.74134, "epoch": "259/300", "eta": "0:30:32", "gpu_mem": "10.07G", "grad_norm": 1.68866, "iter": "50/60", "loss": 0.01178, "lr": 0.0000915648, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:58:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46966, "dt_data": 0.00016, "dt_net": 0.46950, "epoch": "259/300", "eta": "0:19:15", "gpu_mem": "10.07G", "grad_norm": 9.83382, "iter": "60/60", "loss": 0.03424, "lr": 0.0000908366, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:58:23][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.68810, "dt_data": 0.68810, "dt_net": 0.46950, "epoch": "259/300", "eta": "0:28:12", "gpu_mem": "10.07G", "grad_norm": 9.83382, "loss": 0.04179, "lr": 0.0000908366, "top1_acc": 98.43750, "top1_err": 1.61458, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:58:23][INFO] train_net.py:  708: Epoch 258 takes 47.00s. Epochs from 0 to 258 take 47.99s in average and 47.98s in median.
[06/12 21:58:23][INFO] train_net.py:  714: For epoch 258, each iteraction takes 0.78s in average. From epoch 0 to 258, each iteraction takes 0.80s in average.
[06/12 21:58:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.51432, "dt_data": 0.04764, "dt_net": 0.46667, "epoch": "260/300", "eta": "0:21:00", "gpu_mem": "10.07G", "grad_norm": 3.73125, "iter": "10/60", "loss": 0.03113, "lr": 0.0000901111, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:58:48][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48248, "dt_data": 0.00047, "dt_net": 0.48201, "epoch": "260/300", "eta": "0:19:37", "gpu_mem": "10.07G", "grad_norm": 6.83099, "iter": "20/60", "loss": 0.04585, "lr": 0.0000893885, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:58:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.82414, "dt_data": 0.35007, "dt_net": 0.47406, "epoch": "260/300", "eta": "0:33:22", "gpu_mem": "10.07G", "grad_norm": 2.55181, "iter": "30/60", "loss": 0.02183, "lr": 0.0000886686, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:58:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47668, "dt_data": 0.00070, "dt_net": 0.47596, "epoch": "260/300", "eta": "0:19:13", "gpu_mem": "10.07G", "grad_norm": 0.42459, "iter": "40/60", "loss": 0.04168, "lr": 0.0000879514, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:59:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.05546, "dt_data": 0.58562, "dt_net": 0.46984, "epoch": "260/300", "eta": "0:42:23", "gpu_mem": "10.07G", "grad_norm": 0.09714, "iter": "50/60", "loss": 0.02263, "lr": 0.0000872371, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:59:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47045, "dt_data": 0.00017, "dt_net": 0.47028, "epoch": "260/300", "eta": "0:18:49", "gpu_mem": "10.07G", "grad_norm": 2.05183, "iter": "60/60", "loss": 0.01058, "lr": 0.0000865255, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:59:11][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.69493, "dt_data": 0.69493, "dt_net": 0.47028, "epoch": "260/300", "eta": "0:27:47", "gpu_mem": "10.07G", "grad_norm": 2.05183, "loss": 0.04107, "lr": 0.0000865255, "top1_acc": 98.22917, "top1_err": 1.61458, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 21:59:11][INFO] train_net.py:  708: Epoch 259 takes 47.93s. Epochs from 0 to 259 take 47.99s in average and 47.98s in median.
[06/12 21:59:11][INFO] train_net.py:  714: For epoch 259, each iteraction takes 0.80s in average. From epoch 0 to 259, each iteraction takes 0.80s in average.
[06/12 21:59:11][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 22:00:13][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "260/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.12972, "top1_acc": 76.56250, "top1_err": 23.43750, "top5_acc": 95.31250, "top5_err": 4.68750}
[06/12 22:00:16][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "val_epoch", "epoch": "260/300", "gpu_mem": "10.07G", "min_top1_err": 21.99170, "min_top5_err": 2.07469, "time_diff": 0.61553, "top1_acc": 76.34855, "top1_err": 23.65145, "top5_acc": 95.43568, "top5_err": 4.56432}
[06/12 22:00:34][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46500, "dt_data": 0.00034, "dt_net": 0.46466, "epoch": "261/300", "eta": "0:18:31", "gpu_mem": "10.07G", "grad_norm": 0.48525, "iter": "10/60", "loss": 0.02301, "lr": 0.0000858168, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:00:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47151, "dt_data": 0.00063, "dt_net": 0.47088, "epoch": "261/300", "eta": "0:18:42", "gpu_mem": "10.07G", "grad_norm": 5.63276, "iter": "20/60", "loss": 0.04533, "lr": 0.0000851108, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:00:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47762, "dt_data": 0.00042, "dt_net": 0.47720, "epoch": "261/300", "eta": "0:18:51", "gpu_mem": "10.07G", "grad_norm": 4.06592, "iter": "30/60", "loss": 0.01534, "lr": 0.0000844076, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:00:51][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47292, "dt_data": 0.00048, "dt_net": 0.47244, "epoch": "261/300", "eta": "0:18:36", "gpu_mem": "10.07G", "grad_norm": 1.61061, "iter": "40/60", "loss": 0.02717, "lr": 0.0000837072, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:00:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46956, "dt_data": 0.00041, "dt_net": 0.46914, "epoch": "261/300", "eta": "0:18:23", "gpu_mem": "10.07G", "grad_norm": 1.34195, "iter": "50/60", "loss": 0.02635, "lr": 0.0000830095, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:01:03][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46635, "dt_data": 0.00024, "dt_net": 0.46611, "epoch": "261/300", "eta": "0:18:11", "gpu_mem": "10.07G", "grad_norm": 0.26721, "iter": "60/60", "loss": 0.01454, "lr": 0.0000823147, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:01:04][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.69591, "dt_data": 0.69591, "dt_net": 0.46611, "epoch": "261/300", "eta": "0:27:08", "gpu_mem": "10.07G", "grad_norm": 0.26721, "loss": 0.03194, "lr": 0.0000823147, "top1_acc": 99.06250, "top1_err": 1.14583, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:01:04][INFO] train_net.py:  708: Epoch 260 takes 47.41s. Epochs from 0 to 260 take 47.99s in average and 47.97s in median.
[06/12 22:01:04][INFO] train_net.py:  714: For epoch 260, each iteraction takes 0.79s in average. From epoch 0 to 260, each iteraction takes 0.80s in average.
[06/12 22:01:20][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.78437, "dt_data": 0.00072, "dt_net": 0.78365, "epoch": "262/300", "eta": "0:30:27", "gpu_mem": "10.07G", "grad_norm": 1.90583, "iter": "10/60", "loss": 0.01344, "lr": 0.0000816227, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:01:26][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47156, "dt_data": 0.00036, "dt_net": 0.47120, "epoch": "262/300", "eta": "0:18:14", "gpu_mem": "10.07G", "grad_norm": 2.16501, "iter": "20/60", "loss": 0.01185, "lr": 0.0000809334, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:01:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47060, "dt_data": 0.00037, "dt_net": 0.47022, "epoch": "262/300", "eta": "0:18:07", "gpu_mem": "10.07G", "grad_norm": 1.34220, "iter": "30/60", "loss": 0.02351, "lr": 0.0000802470, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:01:39][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47419, "dt_data": 0.00065, "dt_net": 0.47354, "epoch": "262/300", "eta": "0:18:10", "gpu_mem": "10.07G", "grad_norm": 6.69753, "iter": "40/60", "loss": 0.02301, "lr": 0.0000795634, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:01:45][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47874, "dt_data": 0.00043, "dt_net": 0.47831, "epoch": "262/300", "eta": "0:18:16", "gpu_mem": "10.07G", "grad_norm": 4.39471, "iter": "50/60", "loss": 0.04003, "lr": 0.0000788825, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:01:51][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46958, "dt_data": 0.00016, "dt_net": 0.46941, "epoch": "262/300", "eta": "0:17:50", "gpu_mem": "10.07G", "grad_norm": 5.40000, "iter": "60/60", "loss": 0.01170, "lr": 0.0000782045, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:01:51][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.69279, "dt_data": 0.69279, "dt_net": 0.46941, "epoch": "262/300", "eta": "0:26:19", "gpu_mem": "10.07G", "grad_norm": 5.40000, "loss": 0.03635, "lr": 0.0000782045, "top1_acc": 98.85417, "top1_err": 1.30208, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:01:51][INFO] train_net.py:  708: Epoch 261 takes 47.55s. Epochs from 0 to 261 take 47.99s in average and 47.97s in median.
[06/12 22:01:51][INFO] train_net.py:  714: For epoch 261, each iteraction takes 0.79s in average. From epoch 0 to 261, each iteraction takes 0.80s in average.
[06/12 22:02:08][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47070, "dt_data": 0.00047, "dt_net": 0.47022, "epoch": "263/300", "eta": "0:17:48", "gpu_mem": "10.07G", "grad_norm": 2.72969, "iter": "10/60", "loss": 0.01605, "lr": 0.0000775293, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:02:14][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47641, "dt_data": 0.00053, "dt_net": 0.47587, "epoch": "263/300", "eta": "0:17:56", "gpu_mem": "10.07G", "grad_norm": 2.39103, "iter": "20/60", "loss": 0.03707, "lr": 0.0000768569, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:02:20][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47258, "dt_data": 0.00033, "dt_net": 0.47225, "epoch": "263/300", "eta": "0:17:43", "gpu_mem": "10.07G", "grad_norm": 1.18879, "iter": "30/60", "loss": 0.01624, "lr": 0.0000761873, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:02:27][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47548, "dt_data": 0.00043, "dt_net": 0.47505, "epoch": "263/300", "eta": "0:17:45", "gpu_mem": "10.07G", "grad_norm": 6.12145, "iter": "40/60", "loss": 0.02231, "lr": 0.0000755205, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:02:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47866, "dt_data": 0.00045, "dt_net": 0.47821, "epoch": "263/300", "eta": "0:17:47", "gpu_mem": "10.07G", "grad_norm": 4.61224, "iter": "50/60", "loss": 0.03838, "lr": 0.0000748565, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:02:38][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46922, "dt_data": 0.00017, "dt_net": 0.46905, "epoch": "263/300", "eta": "0:17:21", "gpu_mem": "10.07G", "grad_norm": 1.91016, "iter": "60/60", "loss": 0.02053, "lr": 0.0000741954, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:02:39][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.69160, "dt_data": 0.69160, "dt_net": 0.46905, "epoch": "263/300", "eta": "0:25:35", "gpu_mem": "10.07G", "grad_norm": 1.91016, "loss": 0.03386, "lr": 0.0000741954, "top1_acc": 98.33333, "top1_err": 1.09375, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:02:39][INFO] train_net.py:  708: Epoch 262 takes 47.82s. Epochs from 0 to 262 take 47.99s in average and 47.97s in median.
[06/12 22:02:39][INFO] train_net.py:  714: For epoch 262, each iteraction takes 0.80s in average. From epoch 0 to 262, each iteraction takes 0.80s in average.
[06/12 22:02:56][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47796, "dt_data": 0.00045, "dt_net": 0.47751, "epoch": "264/300", "eta": "0:17:36", "gpu_mem": "10.07G", "grad_norm": 5.05887, "iter": "10/60", "loss": 0.01710, "lr": 0.0000735370, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:03:02][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47462, "dt_data": 0.00061, "dt_net": 0.47401, "epoch": "264/300", "eta": "0:17:24", "gpu_mem": "10.07G", "grad_norm": 0.18097, "iter": "20/60", "loss": 0.02655, "lr": 0.0000728815, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:03:08][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47606, "dt_data": 0.00034, "dt_net": 0.47572, "epoch": "264/300", "eta": "0:17:22", "gpu_mem": "10.07G", "grad_norm": 15.06323, "iter": "30/60", "loss": 0.01196, "lr": 0.0000722289, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:03:14][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47792, "dt_data": 0.00040, "dt_net": 0.47752, "epoch": "264/300", "eta": "0:17:21", "gpu_mem": "10.07G", "grad_norm": 2.83626, "iter": "40/60", "loss": 0.03647, "lr": 0.0000715790, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:03:20][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47323, "dt_data": 0.00036, "dt_net": 0.47287, "epoch": "264/300", "eta": "0:17:06", "gpu_mem": "10.07G", "grad_norm": 6.98001, "iter": "50/60", "loss": 0.04308, "lr": 0.0000709320, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:03:26][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46935, "dt_data": 0.00034, "dt_net": 0.46901, "epoch": "264/300", "eta": "0:16:53", "gpu_mem": "10.07G", "grad_norm": 4.16723, "iter": "60/60", "loss": 0.02857, "lr": 0.0000702878, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:03:26][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.68625, "dt_data": 0.68625, "dt_net": 0.46901, "epoch": "264/300", "eta": "0:24:42", "gpu_mem": "10.07G", "grad_norm": 4.16723, "loss": 0.04591, "lr": 0.0000702878, "top1_acc": 98.33333, "top1_err": 1.71875, "top5_acc": 100.00000, "top5_err": 0.05208}
[06/12 22:03:26][INFO] train_net.py:  708: Epoch 263 takes 47.38s. Epochs from 0 to 263 take 47.98s in average and 47.96s in median.
[06/12 22:03:26][INFO] train_net.py:  714: For epoch 263, each iteraction takes 0.79s in average. From epoch 0 to 263, each iteraction takes 0.80s in average.
[06/12 22:03:44][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47191, "dt_data": 0.00047, "dt_net": 0.47144, "epoch": "265/300", "eta": "0:16:54", "gpu_mem": "10.07G", "grad_norm": 0.59728, "iter": "10/60", "loss": 0.01964, "lr": 0.0000696464, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:03:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47265, "dt_data": 0.00065, "dt_net": 0.47200, "epoch": "265/300", "eta": "0:16:51", "gpu_mem": "10.07G", "grad_norm": 0.22237, "iter": "20/60", "loss": 0.05966, "lr": 0.0000690079, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:03:56][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47226, "dt_data": 0.00053, "dt_net": 0.47173, "epoch": "265/300", "eta": "0:16:45", "gpu_mem": "10.07G", "grad_norm": 13.71288, "iter": "30/60", "loss": 0.03037, "lr": 0.0000683722, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:04:02][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48173, "dt_data": 0.00053, "dt_net": 0.48120, "epoch": "265/300", "eta": "0:17:01", "gpu_mem": "10.07G", "grad_norm": 3.91880, "iter": "40/60", "loss": 0.02880, "lr": 0.0000677393, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:04:08][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48060, "dt_data": 0.00050, "dt_net": 0.48010, "epoch": "265/300", "eta": "0:16:54", "gpu_mem": "10.07G", "grad_norm": 0.08336, "iter": "50/60", "loss": 0.01411, "lr": 0.0000671093, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:04:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46969, "dt_data": 0.00019, "dt_net": 0.46950, "epoch": "265/300", "eta": "0:16:26", "gpu_mem": "10.07G", "grad_norm": 7.97344, "iter": "60/60", "loss": 0.03850, "lr": 0.0000664821, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:04:14][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.69737, "dt_data": 0.69737, "dt_net": 0.46950, "epoch": "265/300", "eta": "0:24:24", "gpu_mem": "10.07G", "grad_norm": 7.97344, "loss": 0.05271, "lr": 0.0000664821, "top1_acc": 98.12500, "top1_err": 1.97917, "top5_acc": 99.89583, "top5_err": 0.10417}
[06/12 22:04:14][INFO] train_net.py:  708: Epoch 264 takes 47.41s. Epochs from 0 to 264 take 47.98s in average and 47.96s in median.
[06/12 22:04:14][INFO] train_net.py:  714: For epoch 264, each iteraction takes 0.79s in average. From epoch 0 to 264, each iteraction takes 0.80s in average.
[06/12 22:04:14][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 22:05:14][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "265/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.13085, "top1_acc": 78.12500, "top1_err": 21.87500, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 22:05:17][INFO] logging.py:  101: json_stats: {"RAM": "13.77/31.07G", "_type": "val_epoch", "epoch": "265/300", "gpu_mem": "10.07G", "min_top1_err": 21.99170, "min_top5_err": 2.07469, "time_diff": 0.59236, "top1_acc": 76.76349, "top1_err": 23.23651, "top5_acc": 96.26556, "top5_err": 3.73444}
[06/12 22:05:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46599, "dt_data": 0.00033, "dt_net": 0.46566, "epoch": "266/300", "eta": "0:16:13", "gpu_mem": "10.07G", "grad_norm": 7.39054, "iter": "10/60", "loss": 0.02472, "lr": 0.0000658578, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:05:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46984, "dt_data": 0.00051, "dt_net": 0.46932, "epoch": "266/300", "eta": "0:16:17", "gpu_mem": "10.07G", "grad_norm": 2.49817, "iter": "20/60", "loss": 0.01029, "lr": 0.0000652363, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:05:47][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47569, "dt_data": 0.00085, "dt_net": 0.47483, "epoch": "266/300", "eta": "0:16:24", "gpu_mem": "10.07G", "grad_norm": 1.28677, "iter": "30/60", "loss": 0.00958, "lr": 0.0000646177, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:05:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46797, "dt_data": 0.00060, "dt_net": 0.46737, "epoch": "266/300", "eta": "0:16:04", "gpu_mem": "10.07G", "grad_norm": 0.79184, "iter": "40/60", "loss": 0.02184, "lr": 0.0000640019, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:05:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48289, "dt_data": 0.00072, "dt_net": 0.48216, "epoch": "266/300", "eta": "0:16:29", "gpu_mem": "10.07G", "grad_norm": 0.80031, "iter": "50/60", "loss": 0.00777, "lr": 0.0000633889, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:06:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46781, "dt_data": 0.00017, "dt_net": 0.46764, "epoch": "266/300", "eta": "0:15:54", "gpu_mem": "10.07G", "grad_norm": 0.03767, "iter": "60/60", "loss": 0.02825, "lr": 0.0000627789, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:06:06][INFO] logging.py:  101: json_stats: {"RAM": "13.48/31.07G", "_type": "train_epoch", "dt": 0.68977, "dt_data": 0.68977, "dt_net": 0.46764, "epoch": "266/300", "eta": "0:23:27", "gpu_mem": "10.07G", "grad_norm": 0.03767, "loss": 0.02788, "lr": 0.0000627789, "top1_acc": 98.85417, "top1_err": 0.93750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:06:06][INFO] train_net.py:  708: Epoch 265 takes 48.16s. Epochs from 0 to 265 take 47.98s in average and 47.96s in median.
[06/12 22:06:06][INFO] train_net.py:  714: For epoch 265, each iteraction takes 0.80s in average. From epoch 0 to 265, each iteraction takes 0.80s in average.
[06/12 22:06:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.06702, "dt_data": 0.59495, "dt_net": 0.47206, "epoch": "267/300", "eta": "0:36:06", "gpu_mem": "10.07G", "grad_norm": 3.31886, "iter": "10/60", "loss": 0.05200, "lr": 0.0000621716, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:06:29][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48811, "dt_data": 0.00068, "dt_net": 0.48743, "epoch": "267/300", "eta": "0:16:25", "gpu_mem": "10.07G", "grad_norm": 1.10070, "iter": "20/60", "loss": 0.02946, "lr": 0.0000615673, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:06:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.86911, "dt_data": 0.40125, "dt_net": 0.46786, "epoch": "267/300", "eta": "0:29:06", "gpu_mem": "10.07G", "grad_norm": 3.32615, "iter": "30/60", "loss": 0.02978, "lr": 0.0000609657, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:06:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47455, "dt_data": 0.00077, "dt_net": 0.47377, "epoch": "267/300", "eta": "0:15:49", "gpu_mem": "10.07G", "grad_norm": 0.44603, "iter": "40/60", "loss": 0.02806, "lr": 0.0000603671, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:06:47][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.05890, "dt_data": 0.58364, "dt_net": 0.47526, "epoch": "267/300", "eta": "0:35:07", "gpu_mem": "10.07G", "grad_norm": 3.13962, "iter": "50/60", "loss": 0.01703, "lr": 0.0000597713, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:06:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46872, "dt_data": 0.00015, "dt_net": 0.46856, "epoch": "267/300", "eta": "0:15:28", "gpu_mem": "10.07G", "grad_norm": 7.06047, "iter": "60/60", "loss": 0.03321, "lr": 0.0000591784, "top1_acc": 96.87500, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:06:53][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.69318, "dt_data": 0.69317, "dt_net": 0.46856, "epoch": "267/300", "eta": "0:22:52", "gpu_mem": "10.07G", "grad_norm": 7.06047, "loss": 0.04708, "lr": 0.0000591784, "top1_acc": 98.75000, "top1_err": 1.61458, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:06:53][INFO] train_net.py:  708: Epoch 266 takes 47.78s. Epochs from 0 to 266 take 47.98s in average and 47.96s in median.
[06/12 22:06:53][INFO] train_net.py:  714: For epoch 266, each iteraction takes 0.80s in average. From epoch 0 to 266, each iteraction takes 0.80s in average.
[06/12 22:07:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46856, "dt_data": 0.00044, "dt_net": 0.46811, "epoch": "268/300", "eta": "0:15:23", "gpu_mem": "10.07G", "grad_norm": 1.67545, "iter": "10/60", "loss": 0.00940, "lr": 0.0000585883, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:07:17][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47025, "dt_data": 0.00091, "dt_net": 0.46933, "epoch": "268/300", "eta": "0:15:21", "gpu_mem": "10.07G", "grad_norm": 4.91799, "iter": "20/60", "loss": 0.02539, "lr": 0.0000580011, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:07:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47220, "dt_data": 0.00039, "dt_net": 0.47181, "epoch": "268/300", "eta": "0:15:20", "gpu_mem": "10.07G", "grad_norm": 1.14656, "iter": "30/60", "loss": 0.00956, "lr": 0.0000574168, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:07:29][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47850, "dt_data": 0.00046, "dt_net": 0.47802, "epoch": "268/300", "eta": "0:15:28", "gpu_mem": "10.07G", "grad_norm": 4.23186, "iter": "40/60", "loss": 0.03307, "lr": 0.0000568353, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:07:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47376, "dt_data": 0.00062, "dt_net": 0.47314, "epoch": "268/300", "eta": "0:15:14", "gpu_mem": "10.07G", "grad_norm": 2.74376, "iter": "50/60", "loss": 0.04823, "lr": 0.0000562567, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:07:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46966, "dt_data": 0.00016, "dt_net": 0.46950, "epoch": "268/300", "eta": "0:15:01", "gpu_mem": "10.07G", "grad_norm": 0.99788, "iter": "60/60", "loss": 0.00948, "lr": 0.0000556810, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:07:41][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.68731, "dt_data": 0.68731, "dt_net": 0.46950, "epoch": "268/300", "eta": "0:21:59", "gpu_mem": "10.07G", "grad_norm": 0.99788, "loss": 0.03496, "lr": 0.0000556810, "top1_acc": 98.22917, "top1_err": 1.40625, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:07:41][INFO] train_net.py:  708: Epoch 267 takes 47.75s. Epochs from 0 to 267 take 47.98s in average and 47.96s in median.
[06/12 22:07:41][INFO] train_net.py:  714: For epoch 267, each iteraction takes 0.80s in average. From epoch 0 to 267, each iteraction takes 0.80s in average.
[06/12 22:07:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47272, "dt_data": 0.00087, "dt_net": 0.47184, "epoch": "269/300", "eta": "0:15:02", "gpu_mem": "10.07G", "grad_norm": 4.27289, "iter": "10/60", "loss": 0.01949, "lr": 0.0000551082, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:08:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47835, "dt_data": 0.00045, "dt_net": 0.47789, "epoch": "269/300", "eta": "0:15:08", "gpu_mem": "10.07G", "grad_norm": 4.75280, "iter": "20/60", "loss": 0.05933, "lr": 0.0000545383, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:08:10][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47168, "dt_data": 0.00048, "dt_net": 0.47119, "epoch": "269/300", "eta": "0:14:51", "gpu_mem": "10.07G", "grad_norm": 2.00222, "iter": "30/60", "loss": 0.01743, "lr": 0.0000539712, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:08:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.30535, "dt_data": 0.00035, "dt_net": 1.30500, "epoch": "269/300", "eta": "0:40:54", "gpu_mem": "10.07G", "grad_norm": 1.25632, "iter": "40/60", "loss": 0.02146, "lr": 0.0000534070, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:08:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47527, "dt_data": 0.00036, "dt_net": 0.47491, "epoch": "269/300", "eta": "0:14:48", "gpu_mem": "10.07G", "grad_norm": 2.42317, "iter": "50/60", "loss": 0.03242, "lr": 0.0000528457, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:08:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46891, "dt_data": 0.00020, "dt_net": 0.46871, "epoch": "269/300", "eta": "0:14:32", "gpu_mem": "10.07G", "grad_norm": 1.23333, "iter": "60/60", "loss": 0.02214, "lr": 0.0000522873, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:08:28][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.69095, "dt_data": 0.69095, "dt_net": 0.46871, "epoch": "269/300", "eta": "0:21:25", "gpu_mem": "10.07G", "grad_norm": 1.23333, "loss": 0.03871, "lr": 0.0000522873, "top1_acc": 98.95833, "top1_err": 1.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:08:28][INFO] train_net.py:  708: Epoch 268 takes 47.34s. Epochs from 0 to 268 take 47.98s in average and 47.96s in median.
[06/12 22:08:28][INFO] train_net.py:  714: For epoch 268, each iteraction takes 0.79s in average. From epoch 0 to 268, each iteraction takes 0.80s in average.
[06/12 22:08:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47491, "dt_data": 0.00056, "dt_net": 0.47434, "epoch": "270/300", "eta": "0:14:38", "gpu_mem": "10.07G", "grad_norm": 0.65974, "iter": "10/60", "loss": 0.02288, "lr": 0.0000517317, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:08:51][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46859, "dt_data": 0.00032, "dt_net": 0.46827, "epoch": "270/300", "eta": "0:14:22", "gpu_mem": "10.07G", "grad_norm": 2.60287, "iter": "20/60", "loss": 0.01933, "lr": 0.0000511791, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:08:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47535, "dt_data": 0.00063, "dt_net": 0.47471, "epoch": "270/300", "eta": "0:14:29", "gpu_mem": "10.07G", "grad_norm": 0.21358, "iter": "30/60", "loss": 0.01846, "lr": 0.0000506293, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:09:03][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47500, "dt_data": 0.00050, "dt_net": 0.47450, "epoch": "270/300", "eta": "0:14:24", "gpu_mem": "10.07G", "grad_norm": 0.64878, "iter": "40/60", "loss": 0.01443, "lr": 0.0000500825, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:09:09][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47016, "dt_data": 0.00041, "dt_net": 0.46975, "epoch": "270/300", "eta": "0:14:10", "gpu_mem": "10.07G", "grad_norm": 2.32853, "iter": "50/60", "loss": 0.04113, "lr": 0.0000495385, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:09:15][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46885, "dt_data": 0.00019, "dt_net": 0.46866, "epoch": "270/300", "eta": "0:14:03", "gpu_mem": "10.07G", "grad_norm": 4.99796, "iter": "60/60", "loss": 0.02403, "lr": 0.0000489974, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:09:15][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.68365, "dt_data": 0.68365, "dt_net": 0.46866, "epoch": "270/300", "eta": "0:20:30", "gpu_mem": "10.07G", "grad_norm": 4.99796, "loss": 0.04136, "lr": 0.0000489974, "top1_acc": 98.64583, "top1_err": 1.61458, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:09:15][INFO] train_net.py:  708: Epoch 269 takes 46.83s. Epochs from 0 to 269 take 47.98s in average and 47.95s in median.
[06/12 22:09:15][INFO] train_net.py:  714: For epoch 269, each iteraction takes 0.78s in average. From epoch 0 to 269, each iteraction takes 0.80s in average.
[06/12 22:09:15][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 22:10:17][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "270/300", "eta": "0:00:02", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.41733, "top1_acc": 76.56250, "top1_err": 23.43750, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 22:10:20][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "val_epoch", "epoch": "270/300", "gpu_mem": "10.07G", "min_top1_err": 21.99170, "min_top5_err": 2.07469, "time_diff": 0.60972, "top1_acc": 77.38589, "top1_err": 22.61411, "top5_acc": 96.68050, "top5_err": 3.31950}
[06/12 22:10:38][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.23428, "dt_data": 0.77258, "dt_net": 0.46169, "epoch": "271/300", "eta": "0:36:49", "gpu_mem": "10.07G", "grad_norm": 0.45426, "iter": "10/60", "loss": 0.02298, "lr": 0.0000484593, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:10:44][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47936, "dt_data": 0.00050, "dt_net": 0.47887, "epoch": "271/300", "eta": "0:14:13", "gpu_mem": "10.07G", "grad_norm": 1.90164, "iter": "20/60", "loss": 0.02351, "lr": 0.0000479240, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:10:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.82502, "dt_data": 0.35380, "dt_net": 0.47121, "epoch": "271/300", "eta": "0:24:20", "gpu_mem": "10.07G", "grad_norm": 0.13099, "iter": "30/60", "loss": 0.01314, "lr": 0.0000473916, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:10:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47097, "dt_data": 0.00065, "dt_net": 0.47032, "epoch": "271/300", "eta": "0:13:48", "gpu_mem": "10.07G", "grad_norm": 2.79144, "iter": "40/60", "loss": 0.01571, "lr": 0.0000468621, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:11:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.97166, "dt_data": 0.50133, "dt_net": 0.47033, "epoch": "271/300", "eta": "0:28:20", "gpu_mem": "10.07G", "grad_norm": 3.07965, "iter": "50/60", "loss": 0.01222, "lr": 0.0000463355, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:11:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46703, "dt_data": 0.00016, "dt_net": 0.46687, "epoch": "271/300", "eta": "0:13:32", "gpu_mem": "10.07G", "grad_norm": 1.11225, "iter": "60/60", "loss": 0.02537, "lr": 0.0000458119, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:11:08][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.69388, "dt_data": 0.69388, "dt_net": 0.46687, "epoch": "271/300", "eta": "0:20:07", "gpu_mem": "10.07G", "grad_norm": 1.11225, "loss": 0.03081, "lr": 0.0000458119, "top1_acc": 98.85417, "top1_err": 1.09375, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:11:08][INFO] train_net.py:  708: Epoch 270 takes 47.99s. Epochs from 0 to 270 take 47.98s in average and 47.96s in median.
[06/12 22:11:08][INFO] train_net.py:  714: For epoch 270, each iteraction takes 0.80s in average. From epoch 0 to 270, each iteraction takes 0.80s in average.
[06/12 22:11:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46936, "dt_data": 0.00043, "dt_net": 0.46892, "epoch": "272/300", "eta": "0:13:31", "gpu_mem": "10.07G", "grad_norm": 0.43775, "iter": "10/60", "loss": 0.00829, "lr": 0.0000452911, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:11:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47052, "dt_data": 0.00039, "dt_net": 0.47013, "epoch": "272/300", "eta": "0:13:29", "gpu_mem": "10.07G", "grad_norm": 3.30385, "iter": "20/60", "loss": 0.01582, "lr": 0.0000447733, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:11:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46923, "dt_data": 0.00033, "dt_net": 0.46890, "epoch": "272/300", "eta": "0:13:22", "gpu_mem": "10.07G", "grad_norm": 1.87586, "iter": "30/60", "loss": 0.03249, "lr": 0.0000442583, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:11:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47455, "dt_data": 0.00078, "dt_net": 0.47377, "epoch": "272/300", "eta": "0:13:26", "gpu_mem": "10.07G", "grad_norm": 0.19256, "iter": "40/60", "loss": 0.01253, "lr": 0.0000437463, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:11:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48116, "dt_data": 0.00061, "dt_net": 0.48054, "epoch": "272/300", "eta": "0:13:33", "gpu_mem": "10.07G", "grad_norm": 1.75696, "iter": "50/60", "loss": 0.01999, "lr": 0.0000432372, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:11:54][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46938, "dt_data": 0.00016, "dt_net": 0.46921, "epoch": "272/300", "eta": "0:13:08", "gpu_mem": "10.07G", "grad_norm": 1.68892, "iter": "60/60", "loss": 0.02546, "lr": 0.0000427310, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:11:55][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.70337, "dt_data": 0.70337, "dt_net": 0.46921, "epoch": "272/300", "eta": "0:19:41", "gpu_mem": "10.07G", "grad_norm": 1.68892, "loss": 0.03139, "lr": 0.0000427310, "top1_acc": 98.75000, "top1_err": 1.40625, "top5_acc": 100.00000, "top5_err": 0.05208}
[06/12 22:11:55][INFO] train_net.py:  708: Epoch 271 takes 46.99s. Epochs from 0 to 271 take 47.97s in average and 47.95s in median.
[06/12 22:11:55][INFO] train_net.py:  714: For epoch 271, each iteraction takes 0.78s in average. From epoch 0 to 271, each iteraction takes 0.80s in average.
[06/12 22:12:12][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.72625, "dt_data": 0.25327, "dt_net": 0.47298, "epoch": "273/300", "eta": "0:20:12", "gpu_mem": "10.07G", "grad_norm": 1.51041, "iter": "10/60", "loss": 0.02635, "lr": 0.0000422277, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:12:18][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46896, "dt_data": 0.00043, "dt_net": 0.46853, "epoch": "273/300", "eta": "0:12:58", "gpu_mem": "10.07G", "grad_norm": 13.18245, "iter": "20/60", "loss": 0.03350, "lr": 0.0000417273, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:12:24][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.91631, "dt_data": 0.44207, "dt_net": 0.47425, "epoch": "273/300", "eta": "0:25:11", "gpu_mem": "10.07G", "grad_norm": 3.28300, "iter": "30/60", "loss": 0.02056, "lr": 0.0000412298, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:12:30][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47452, "dt_data": 0.00039, "dt_net": 0.47413, "epoch": "273/300", "eta": "0:12:58", "gpu_mem": "10.07G", "grad_norm": 2.15084, "iter": "40/60", "loss": 0.04004, "lr": 0.0000407353, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:12:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.10547, "dt_data": 0.63369, "dt_net": 0.47178, "epoch": "273/300", "eta": "0:30:01", "gpu_mem": "10.07G", "grad_norm": 0.07767, "iter": "50/60", "loss": 0.01444, "lr": 0.0000402437, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:12:42][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47011, "dt_data": 0.00016, "dt_net": 0.46995, "epoch": "273/300", "eta": "0:12:41", "gpu_mem": "10.07G", "grad_norm": 0.97691, "iter": "60/60", "loss": 0.01749, "lr": 0.0000397550, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:12:43][INFO] logging.py:  101: json_stats: {"RAM": "13.48/31.07G", "_type": "train_epoch", "dt": 0.69701, "dt_data": 0.69701, "dt_net": 0.46995, "epoch": "273/300", "eta": "0:18:49", "gpu_mem": "10.07G", "grad_norm": 0.97691, "loss": 0.03733, "lr": 0.0000397550, "top1_acc": 98.75000, "top1_err": 1.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:12:43][INFO] train_net.py:  708: Epoch 272 takes 48.60s. Epochs from 0 to 272 take 47.97s in average and 47.96s in median.
[06/12 22:12:43][INFO] train_net.py:  714: For epoch 272, each iteraction takes 0.81s in average. From epoch 0 to 272, each iteraction takes 0.80s in average.
[06/12 22:13:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47306, "dt_data": 0.00034, "dt_net": 0.47271, "epoch": "274/300", "eta": "0:12:41", "gpu_mem": "10.07G", "grad_norm": 8.62438, "iter": "10/60", "loss": 0.04441, "lr": 0.0000392693, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:13:06][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46974, "dt_data": 0.00047, "dt_net": 0.46927, "epoch": "274/300", "eta": "0:12:31", "gpu_mem": "10.07G", "grad_norm": 1.12370, "iter": "20/60", "loss": 0.00909, "lr": 0.0000387864, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:13:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47568, "dt_data": 0.00034, "dt_net": 0.47535, "epoch": "274/300", "eta": "0:12:36", "gpu_mem": "10.07G", "grad_norm": 1.70318, "iter": "30/60", "loss": 0.03439, "lr": 0.0000383065, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:13:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47269, "dt_data": 0.00037, "dt_net": 0.47231, "epoch": "274/300", "eta": "0:12:26", "gpu_mem": "10.07G", "grad_norm": 2.67380, "iter": "40/60", "loss": 0.02434, "lr": 0.0000378295, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:13:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47694, "dt_data": 0.00083, "dt_net": 0.47611, "epoch": "274/300", "eta": "0:12:28", "gpu_mem": "10.07G", "grad_norm": 0.35371, "iter": "50/60", "loss": 0.01745, "lr": 0.0000373555, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:13:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47052, "dt_data": 0.00016, "dt_net": 0.47036, "epoch": "274/300", "eta": "0:12:14", "gpu_mem": "10.07G", "grad_norm": 0.88072, "iter": "60/60", "loss": 0.00778, "lr": 0.0000368844, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:13:31][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.68341, "dt_data": 0.68341, "dt_net": 0.47036, "epoch": "274/300", "eta": "0:17:46", "gpu_mem": "10.07G", "grad_norm": 0.88072, "loss": 0.03377, "lr": 0.0000368844, "top1_acc": 98.75000, "top1_err": 1.30208, "top5_acc": 100.00000, "top5_err": 0.05208}
[06/12 22:13:31][INFO] train_net.py:  708: Epoch 273 takes 48.08s. Epochs from 0 to 273 take 47.97s in average and 47.96s in median.
[06/12 22:13:31][INFO] train_net.py:  714: For epoch 273, each iteraction takes 0.80s in average. From epoch 0 to 273, each iteraction takes 0.80s in average.
[06/12 22:13:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47258, "dt_data": 0.00042, "dt_net": 0.47216, "epoch": "275/300", "eta": "0:12:12", "gpu_mem": "10.07G", "grad_norm": 1.53672, "iter": "10/60", "loss": 0.02118, "lr": 0.0000364162, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:13:54][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47378, "dt_data": 0.00036, "dt_net": 0.47342, "epoch": "275/300", "eta": "0:12:09", "gpu_mem": "10.07G", "grad_norm": 1.07256, "iter": "20/60", "loss": 0.01181, "lr": 0.0000359510, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:14:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47291, "dt_data": 0.00036, "dt_net": 0.47255, "epoch": "275/300", "eta": "0:12:03", "gpu_mem": "10.07G", "grad_norm": 1.04679, "iter": "30/60", "loss": 0.02509, "lr": 0.0000354887, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:14:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47498, "dt_data": 0.00037, "dt_net": 0.47461, "epoch": "275/300", "eta": "0:12:01", "gpu_mem": "10.07G", "grad_norm": 8.22458, "iter": "40/60", "loss": 0.03960, "lr": 0.0000350293, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:14:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47519, "dt_data": 0.00068, "dt_net": 0.47450, "epoch": "275/300", "eta": "0:11:57", "gpu_mem": "10.07G", "grad_norm": 1.41762, "iter": "50/60", "loss": 0.02111, "lr": 0.0000345729, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:14:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47032, "dt_data": 0.00017, "dt_net": 0.47015, "epoch": "275/300", "eta": "0:11:45", "gpu_mem": "10.07G", "grad_norm": 2.74275, "iter": "60/60", "loss": 0.02339, "lr": 0.0000341194, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:14:20][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.69417, "dt_data": 0.69417, "dt_net": 0.47015, "epoch": "275/300", "eta": "0:17:21", "gpu_mem": "10.07G", "grad_norm": 2.74275, "loss": 0.03481, "lr": 0.0000341194, "top1_acc": 98.22917, "top1_err": 1.25000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:14:20][INFO] train_net.py:  708: Epoch 274 takes 48.74s. Epochs from 0 to 274 take 47.98s in average and 47.96s in median.
[06/12 22:14:20][INFO] train_net.py:  714: For epoch 274, each iteraction takes 0.81s in average. From epoch 0 to 274, each iteraction takes 0.80s in average.
[06/12 22:14:20][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 22:15:22][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "275/300", "eta": "0:00:01", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.22803, "top1_acc": 79.68750, "top1_err": 20.31250, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 22:15:24][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "val_epoch", "epoch": "275/300", "gpu_mem": "10.07G", "min_top1_err": 21.99170, "min_top5_err": 2.07469, "time_diff": 0.59943, "top1_acc": 75.51867, "top1_err": 24.48133, "top5_acc": 95.43568, "top5_err": 4.56432}
[06/12 22:15:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46593, "dt_data": 0.00030, "dt_net": 0.46562, "epoch": "276/300", "eta": "0:11:34", "gpu_mem": "10.07G", "grad_norm": 1.13216, "iter": "10/60", "loss": 0.02643, "lr": 0.0000336688, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:15:47][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.14969, "dt_data": 0.00040, "dt_net": 1.14929, "epoch": "276/300", "eta": "0:28:21", "gpu_mem": "10.07G", "grad_norm": 0.04264, "iter": "20/60", "loss": 0.01239, "lr": 0.0000332212, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:15:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47440, "dt_data": 0.00034, "dt_net": 0.47406, "epoch": "276/300", "eta": "0:11:37", "gpu_mem": "10.07G", "grad_norm": 0.93712, "iter": "30/60", "loss": 0.00926, "lr": 0.0000327766, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:15:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.92740, "dt_data": 0.00039, "dt_net": 0.92701, "epoch": "276/300", "eta": "0:22:34", "gpu_mem": "10.07G", "grad_norm": 4.11279, "iter": "40/60", "loss": 0.02619, "lr": 0.0000323348, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:16:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47281, "dt_data": 0.00071, "dt_net": 0.47209, "epoch": "276/300", "eta": "0:11:25", "gpu_mem": "10.07G", "grad_norm": 1.85889, "iter": "50/60", "loss": 0.00435, "lr": 0.0000318961, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:16:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.59780, "dt_data": 0.00019, "dt_net": 0.59761, "epoch": "276/300", "eta": "0:14:20", "gpu_mem": "10.07G", "grad_norm": 1.05014, "iter": "60/60", "loss": 0.01796, "lr": 0.0000314603, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:16:11][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.70084, "dt_data": 0.70084, "dt_net": 0.59761, "epoch": "276/300", "eta": "0:16:49", "gpu_mem": "10.07G", "grad_norm": 1.05014, "loss": 0.02508, "lr": 0.0000314603, "top1_acc": 99.89583, "top1_err": 0.57292, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:16:11][INFO] train_net.py:  708: Epoch 275 takes 46.76s. Epochs from 0 to 275 take 47.97s in average and 47.96s in median.
[06/12 22:16:11][INFO] train_net.py:  714: For epoch 275, each iteraction takes 0.78s in average. From epoch 0 to 275, each iteraction takes 0.80s in average.
[06/12 22:16:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47323, "dt_data": 0.00034, "dt_net": 0.47289, "epoch": "277/300", "eta": "0:11:16", "gpu_mem": "10.07G", "grad_norm": 2.27729, "iter": "10/60", "loss": 0.04327, "lr": 0.0000310274, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:16:34][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47278, "dt_data": 0.00040, "dt_net": 0.47239, "epoch": "277/300", "eta": "0:11:11", "gpu_mem": "10.07G", "grad_norm": 0.23497, "iter": "20/60", "loss": 0.00620, "lr": 0.0000305975, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:16:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47281, "dt_data": 0.00045, "dt_net": 0.47236, "epoch": "277/300", "eta": "0:11:06", "gpu_mem": "10.07G", "grad_norm": 7.32480, "iter": "30/60", "loss": 0.03070, "lr": 0.0000301705, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:16:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47654, "dt_data": 0.00051, "dt_net": 0.47603, "epoch": "277/300", "eta": "0:11:07", "gpu_mem": "10.07G", "grad_norm": 3.37914, "iter": "40/60", "loss": 0.05536, "lr": 0.0000297465, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:16:53][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48235, "dt_data": 0.00053, "dt_net": 0.48182, "epoch": "277/300", "eta": "0:11:10", "gpu_mem": "10.07G", "grad_norm": 2.86551, "iter": "50/60", "loss": 0.03522, "lr": 0.0000293255, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:16:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47058, "dt_data": 0.00016, "dt_net": 0.47042, "epoch": "277/300", "eta": "0:10:49", "gpu_mem": "10.07G", "grad_norm": 3.69808, "iter": "60/60", "loss": 0.00861, "lr": 0.0000289074, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:16:59][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.68870, "dt_data": 0.68870, "dt_net": 0.47042, "epoch": "277/300", "eta": "0:15:50", "gpu_mem": "10.07G", "grad_norm": 3.69808, "loss": 0.04215, "lr": 0.0000289074, "top1_acc": 98.33333, "top1_err": 1.66667, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:16:59][INFO] train_net.py:  708: Epoch 276 takes 47.75s. Epochs from 0 to 276 take 47.97s in average and 47.96s in median.
[06/12 22:16:59][INFO] train_net.py:  714: For epoch 276, each iteraction takes 0.80s in average. From epoch 0 to 276, each iteraction takes 0.80s in average.
[06/12 22:17:17][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46823, "dt_data": 0.00034, "dt_net": 0.46788, "epoch": "278/300", "eta": "0:10:41", "gpu_mem": "10.07G", "grad_norm": 0.25237, "iter": "10/60", "loss": 0.04653, "lr": 0.0000284922, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:17:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48138, "dt_data": 0.00072, "dt_net": 0.48065, "epoch": "278/300", "eta": "0:10:54", "gpu_mem": "10.07G", "grad_norm": 10.00467, "iter": "20/60", "loss": 0.03543, "lr": 0.0000280801, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:17:29][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47132, "dt_data": 0.00043, "dt_net": 0.47089, "epoch": "278/300", "eta": "0:10:36", "gpu_mem": "10.07G", "grad_norm": 2.18559, "iter": "30/60", "loss": 0.03898, "lr": 0.0000276708, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:17:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47252, "dt_data": 0.00071, "dt_net": 0.47180, "epoch": "278/300", "eta": "0:10:33", "gpu_mem": "10.07G", "grad_norm": 0.34063, "iter": "40/60", "loss": 0.01053, "lr": 0.0000272646, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:17:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47297, "dt_data": 0.00044, "dt_net": 0.47253, "epoch": "278/300", "eta": "0:10:29", "gpu_mem": "10.07G", "grad_norm": 0.62044, "iter": "50/60", "loss": 0.01910, "lr": 0.0000268613, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:17:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46867, "dt_data": 0.00020, "dt_net": 0.46847, "epoch": "278/300", "eta": "0:10:18", "gpu_mem": "10.07G", "grad_norm": 1.16483, "iter": "60/60", "loss": 0.01891, "lr": 0.0000264610, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:17:47][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.70636, "dt_data": 0.70636, "dt_net": 0.46847, "epoch": "278/300", "eta": "0:15:32", "gpu_mem": "10.07G", "grad_norm": 1.16483, "loss": 0.04024, "lr": 0.0000264610, "top1_acc": 98.43750, "top1_err": 1.61458, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:17:47][INFO] train_net.py:  708: Epoch 277 takes 47.79s. Epochs from 0 to 277 take 47.97s in average and 47.95s in median.
[06/12 22:17:47][INFO] train_net.py:  714: For epoch 277, each iteraction takes 0.80s in average. From epoch 0 to 277, each iteraction takes 0.80s in average.
[06/12 22:18:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46967, "dt_data": 0.00033, "dt_net": 0.46934, "epoch": "279/300", "eta": "0:10:15", "gpu_mem": "10.07G", "grad_norm": 1.00514, "iter": "10/60", "loss": 0.03255, "lr": 0.0000260636, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:18:10][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47378, "dt_data": 0.00049, "dt_net": 0.47329, "epoch": "279/300", "eta": "0:10:15", "gpu_mem": "10.07G", "grad_norm": 0.46520, "iter": "20/60", "loss": 0.00698, "lr": 0.0000256692, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:18:17][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47335, "dt_data": 0.00040, "dt_net": 0.47294, "epoch": "279/300", "eta": "0:10:10", "gpu_mem": "10.07G", "grad_norm": 8.20790, "iter": "30/60", "loss": 0.02876, "lr": 0.0000252778, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:18:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47416, "dt_data": 0.00071, "dt_net": 0.47344, "epoch": "279/300", "eta": "0:10:06", "gpu_mem": "10.07G", "grad_norm": 8.26881, "iter": "40/60", "loss": 0.01588, "lr": 0.0000248893, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:18:29][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47355, "dt_data": 0.00039, "dt_net": 0.47316, "epoch": "279/300", "eta": "0:10:01", "gpu_mem": "10.07G", "grad_norm": 2.45416, "iter": "50/60", "loss": 0.02810, "lr": 0.0000245038, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:18:34][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47153, "dt_data": 0.00020, "dt_net": 0.47133, "epoch": "279/300", "eta": "0:09:54", "gpu_mem": "10.07G", "grad_norm": 4.55543, "iter": "60/60", "loss": 0.02881, "lr": 0.0000241213, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:18:34][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.70229, "dt_data": 0.70229, "dt_net": 0.47133, "epoch": "279/300", "eta": "0:14:44", "gpu_mem": "10.07G", "grad_norm": 4.55543, "loss": 0.03605, "lr": 0.0000241213, "top1_acc": 98.75000, "top1_err": 1.45833, "top5_acc": 100.00000, "top5_err": 0.05208}
[06/12 22:18:34][INFO] train_net.py:  708: Epoch 278 takes 47.67s. Epochs from 0 to 278 take 47.97s in average and 47.94s in median.
[06/12 22:18:34][INFO] train_net.py:  714: For epoch 278, each iteraction takes 0.79s in average. From epoch 0 to 278, each iteraction takes 0.80s in average.
[06/12 22:18:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47070, "dt_data": 0.00042, "dt_net": 0.47028, "epoch": "280/300", "eta": "0:09:48", "gpu_mem": "10.07G", "grad_norm": 0.15766, "iter": "10/60", "loss": 0.01038, "lr": 0.0000237418, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:18:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47595, "dt_data": 0.00111, "dt_net": 0.47482, "epoch": "280/300", "eta": "0:09:50", "gpu_mem": "10.07G", "grad_norm": 4.12312, "iter": "20/60", "loss": 0.01820, "lr": 0.0000233652, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:19:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47230, "dt_data": 0.00042, "dt_net": 0.47188, "epoch": "280/300", "eta": "0:09:40", "gpu_mem": "10.07G", "grad_norm": 0.56020, "iter": "30/60", "loss": 0.02654, "lr": 0.0000229916, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:19:10][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47212, "dt_data": 0.00052, "dt_net": 0.47160, "epoch": "280/300", "eta": "0:09:35", "gpu_mem": "10.07G", "grad_norm": 3.90576, "iter": "40/60", "loss": 0.02521, "lr": 0.0000226210, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:19:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.60631, "dt_data": 0.00036, "dt_net": 0.60595, "epoch": "280/300", "eta": "0:12:13", "gpu_mem": "10.07G", "grad_norm": 0.53829, "iter": "50/60", "loss": 0.02367, "lr": 0.0000222534, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:19:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46960, "dt_data": 0.00017, "dt_net": 0.46942, "epoch": "280/300", "eta": "0:09:23", "gpu_mem": "10.07G", "grad_norm": 6.05135, "iter": "60/60", "loss": 0.01718, "lr": 0.0000218887, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:19:23][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.70058, "dt_data": 0.70058, "dt_net": 0.46942, "epoch": "280/300", "eta": "0:14:00", "gpu_mem": "10.07G", "grad_norm": 6.05135, "loss": 0.03826, "lr": 0.0000218887, "top1_acc": 98.22917, "top1_err": 1.35417, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:19:23][INFO] train_net.py:  708: Epoch 279 takes 48.47s. Epochs from 0 to 279 take 47.97s in average and 47.95s in median.
[06/12 22:19:23][INFO] train_net.py:  714: For epoch 279, each iteraction takes 0.81s in average. From epoch 0 to 279, each iteraction takes 0.80s in average.
[06/12 22:19:23][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 22:20:23][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "280/300", "eta": "0:00:00", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.12969, "top1_acc": 81.25000, "top1_err": 18.75000, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 22:20:26][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "val_epoch", "epoch": "280/300", "gpu_mem": "10.07G", "min_top1_err": 21.99170, "min_top5_err": 2.07469, "time_diff": 0.62987, "top1_acc": 76.97095, "top1_err": 23.02905, "top5_acc": 96.26556, "top5_err": 3.73444}
[06/12 22:20:44][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.50350, "dt_data": 0.00059, "dt_net": 0.50291, "epoch": "281/300", "eta": "0:09:59", "gpu_mem": "10.07G", "grad_norm": 3.95218, "iter": "10/60", "loss": 0.01832, "lr": 0.0000215270, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:20:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46835, "dt_data": 0.00060, "dt_net": 0.46775, "epoch": "281/300", "eta": "0:09:12", "gpu_mem": "10.07G", "grad_norm": 1.13562, "iter": "20/60", "loss": 0.01493, "lr": 0.0000211683, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:20:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47073, "dt_data": 0.00035, "dt_net": 0.47038, "epoch": "281/300", "eta": "0:09:10", "gpu_mem": "10.07G", "grad_norm": 3.44124, "iter": "30/60", "loss": 0.02077, "lr": 0.0000208126, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:21:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48228, "dt_data": 0.00050, "dt_net": 0.48178, "epoch": "281/300", "eta": "0:09:19", "gpu_mem": "10.07G", "grad_norm": 5.82324, "iter": "40/60", "loss": 0.01411, "lr": 0.0000204599, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:21:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47217, "dt_data": 0.00051, "dt_net": 0.47166, "epoch": "281/300", "eta": "0:09:02", "gpu_mem": "10.07G", "grad_norm": 2.69359, "iter": "50/60", "loss": 0.03147, "lr": 0.0000201101, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:21:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46690, "dt_data": 0.00018, "dt_net": 0.46671, "epoch": "281/300", "eta": "0:08:52", "gpu_mem": "10.07G", "grad_norm": 2.56894, "iter": "60/60", "loss": 0.00826, "lr": 0.0000197633, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:21:14][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.71154, "dt_data": 0.71154, "dt_net": 0.46671, "epoch": "281/300", "eta": "0:13:31", "gpu_mem": "10.07G", "grad_norm": 2.56894, "loss": 0.02787, "lr": 0.0000197633, "top1_acc": 98.95833, "top1_err": 0.93750, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:21:14][INFO] train_net.py:  708: Epoch 280 takes 47.75s. Epochs from 0 to 280 take 47.97s in average and 47.94s in median.
[06/12 22:21:14][INFO] train_net.py:  714: For epoch 280, each iteraction takes 0.80s in average. From epoch 0 to 280, each iteraction takes 0.80s in average.
[06/12 22:21:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46595, "dt_data": 0.00033, "dt_net": 0.46561, "epoch": "282/300", "eta": "0:08:46", "gpu_mem": "10.07G", "grad_norm": 3.14913, "iter": "10/60", "loss": 0.00899, "lr": 0.0000194196, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:21:38][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46951, "dt_data": 0.00034, "dt_net": 0.46917, "epoch": "282/300", "eta": "0:08:45", "gpu_mem": "10.07G", "grad_norm": 3.41494, "iter": "20/60", "loss": 0.03650, "lr": 0.0000190788, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:21:44][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47673, "dt_data": 0.00048, "dt_net": 0.47625, "epoch": "282/300", "eta": "0:08:49", "gpu_mem": "10.07G", "grad_norm": 8.11580, "iter": "30/60", "loss": 0.02643, "lr": 0.0000187410, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:21:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.55200, "dt_data": 0.07160, "dt_net": 0.48040, "epoch": "282/300", "eta": "0:10:07", "gpu_mem": "10.07G", "grad_norm": 4.38231, "iter": "40/60", "loss": 0.03736, "lr": 0.0000184061, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:21:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47317, "dt_data": 0.00090, "dt_net": 0.47227, "epoch": "282/300", "eta": "0:08:35", "gpu_mem": "10.07G", "grad_norm": 0.18146, "iter": "50/60", "loss": 0.01118, "lr": 0.0000180743, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:22:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46817, "dt_data": 0.00019, "dt_net": 0.46799, "epoch": "282/300", "eta": "0:08:25", "gpu_mem": "10.07G", "grad_norm": 0.78132, "iter": "60/60", "loss": 0.02679, "lr": 0.0000177455, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:22:02][INFO] logging.py:  101: json_stats: {"RAM": "13.48/31.07G", "_type": "train_epoch", "dt": 0.70099, "dt_data": 0.70099, "dt_net": 0.46799, "epoch": "282/300", "eta": "0:12:37", "gpu_mem": "10.07G", "grad_norm": 0.78132, "loss": 0.04223, "lr": 0.0000177455, "top1_acc": 98.33333, "top1_err": 1.45833, "top5_acc": 100.00000, "top5_err": 0.05208}
[06/12 22:22:02][INFO] train_net.py:  708: Epoch 281 takes 47.32s. Epochs from 0 to 281 take 47.97s in average and 47.94s in median.
[06/12 22:22:02][INFO] train_net.py:  714: For epoch 281, each iteraction takes 0.79s in average. From epoch 0 to 281, each iteraction takes 0.80s in average.
[06/12 22:22:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47249, "dt_data": 0.00040, "dt_net": 0.47208, "epoch": "283/300", "eta": "0:08:25", "gpu_mem": "10.07G", "grad_norm": 1.28005, "iter": "10/60", "loss": 0.05009, "lr": 0.0000174196, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:22:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47084, "dt_data": 0.00039, "dt_net": 0.47045, "epoch": "283/300", "eta": "0:08:19", "gpu_mem": "10.07G", "grad_norm": 0.43099, "iter": "20/60", "loss": 0.01381, "lr": 0.0000170968, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:22:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47287, "dt_data": 0.00068, "dt_net": 0.47218, "epoch": "283/300", "eta": "0:08:16", "gpu_mem": "10.07G", "grad_norm": 0.16347, "iter": "30/60", "loss": 0.00455, "lr": 0.0000167769, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:22:36][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47442, "dt_data": 0.00047, "dt_net": 0.47395, "epoch": "283/300", "eta": "0:08:13", "gpu_mem": "10.07G", "grad_norm": 3.75893, "iter": "40/60", "loss": 0.05821, "lr": 0.0000164601, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:22:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47812, "dt_data": 0.00030, "dt_net": 0.47782, "epoch": "283/300", "eta": "0:08:12", "gpu_mem": "10.07G", "grad_norm": 5.43646, "iter": "50/60", "loss": 0.02747, "lr": 0.0000161462, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:22:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46996, "dt_data": 0.00017, "dt_net": 0.46980, "epoch": "283/300", "eta": "0:07:59", "gpu_mem": "10.07G", "grad_norm": 0.66342, "iter": "60/60", "loss": 0.00977, "lr": 0.0000158353, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:22:50][INFO] logging.py:  101: json_stats: {"RAM": "13.48/31.07G", "_type": "train_epoch", "dt": 0.69120, "dt_data": 0.69120, "dt_net": 0.46980, "epoch": "283/300", "eta": "0:11:44", "gpu_mem": "10.07G", "grad_norm": 0.66342, "loss": 0.04245, "lr": 0.0000158353, "top1_acc": 98.22917, "top1_err": 1.66667, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:22:50][INFO] train_net.py:  708: Epoch 282 takes 48.22s. Epochs from 0 to 282 take 47.97s in average and 47.94s in median.
[06/12 22:22:50][INFO] train_net.py:  714: For epoch 282, each iteraction takes 0.80s in average. From epoch 0 to 282, each iteraction takes 0.80s in average.
[06/12 22:23:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.71540, "dt_data": 0.00041, "dt_net": 0.71498, "epoch": "284/300", "eta": "0:12:02", "gpu_mem": "10.07G", "grad_norm": 0.26554, "iter": "10/60", "loss": 0.02021, "lr": 0.0000155274, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:23:12][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47648, "dt_data": 0.00035, "dt_net": 0.47613, "epoch": "284/300", "eta": "0:07:56", "gpu_mem": "10.07G", "grad_norm": 0.85659, "iter": "20/60", "loss": 0.03626, "lr": 0.0000152226, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:23:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.57889, "dt_data": 0.00042, "dt_net": 0.57846, "epoch": "284/300", "eta": "0:09:33", "gpu_mem": "10.07G", "grad_norm": 0.74223, "iter": "30/60", "loss": 0.01869, "lr": 0.0000149207, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:23:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47748, "dt_data": 0.00130, "dt_net": 0.47617, "epoch": "284/300", "eta": "0:07:47", "gpu_mem": "10.07G", "grad_norm": 0.14903, "iter": "40/60", "loss": 0.02473, "lr": 0.0000146218, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:23:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.73613, "dt_data": 0.00036, "dt_net": 0.73577, "epoch": "284/300", "eta": "0:11:54", "gpu_mem": "10.07G", "grad_norm": 2.64185, "iter": "50/60", "loss": 0.01937, "lr": 0.0000143260, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:23:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46897, "dt_data": 0.00016, "dt_net": 0.46881, "epoch": "284/300", "eta": "0:07:30", "gpu_mem": "10.07G", "grad_norm": 2.10602, "iter": "60/60", "loss": 0.03026, "lr": 0.0000140331, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:23:37][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.69373, "dt_data": 0.69373, "dt_net": 0.46881, "epoch": "284/300", "eta": "0:11:05", "gpu_mem": "10.07G", "grad_norm": 2.10602, "loss": 0.04350, "lr": 0.0000140331, "top1_acc": 98.85417, "top1_err": 1.25000, "top5_acc": 100.00000, "top5_err": 0.05208}
[06/12 22:23:37][INFO] train_net.py:  708: Epoch 283 takes 47.53s. Epochs from 0 to 283 take 47.97s in average and 47.94s in median.
[06/12 22:23:37][INFO] train_net.py:  714: For epoch 283, each iteraction takes 0.79s in average. From epoch 0 to 283, each iteraction takes 0.80s in average.
[06/12 22:23:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47323, "dt_data": 0.00036, "dt_net": 0.47287, "epoch": "285/300", "eta": "0:07:29", "gpu_mem": "10.07G", "grad_norm": 0.36239, "iter": "10/60", "loss": 0.01323, "lr": 0.0000137432, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:24:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47647, "dt_data": 0.00043, "dt_net": 0.47603, "epoch": "285/300", "eta": "0:07:27", "gpu_mem": "10.07G", "grad_norm": 0.24423, "iter": "20/60", "loss": 0.02001, "lr": 0.0000134564, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:24:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48195, "dt_data": 0.00041, "dt_net": 0.48154, "epoch": "285/300", "eta": "0:07:28", "gpu_mem": "10.07G", "grad_norm": 0.72709, "iter": "30/60", "loss": 0.01412, "lr": 0.0000131725, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:24:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48722, "dt_data": 0.00074, "dt_net": 0.48648, "epoch": "285/300", "eta": "0:07:28", "gpu_mem": "10.07G", "grad_norm": 0.14306, "iter": "40/60", "loss": 0.04131, "lr": 0.0000128917, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:24:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48105, "dt_data": 0.00062, "dt_net": 0.48043, "epoch": "285/300", "eta": "0:07:17", "gpu_mem": "10.07G", "grad_norm": 1.97059, "iter": "50/60", "loss": 0.02230, "lr": 0.0000126138, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:24:24][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46968, "dt_data": 0.00019, "dt_net": 0.46949, "epoch": "285/300", "eta": "0:07:02", "gpu_mem": "10.07G", "grad_norm": 1.52614, "iter": "60/60", "loss": 0.01450, "lr": 0.0000123390, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:24:25][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.68106, "dt_data": 0.68106, "dt_net": 0.46949, "epoch": "285/300", "eta": "0:10:12", "gpu_mem": "10.07G", "grad_norm": 1.52614, "loss": 0.03639, "lr": 0.0000123390, "top1_acc": 98.33333, "top1_err": 1.45833, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:24:25][INFO] train_net.py:  708: Epoch 284 takes 47.62s. Epochs from 0 to 284 take 47.97s in average and 47.94s in median.
[06/12 22:24:25][INFO] train_net.py:  714: For epoch 284, each iteraction takes 0.79s in average. From epoch 0 to 284, each iteraction takes 0.80s in average.
[06/12 22:24:25][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 22:25:27][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "285/300", "eta": "0:00:06", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 1.06743, "top1_acc": 75.00000, "top1_err": 25.00000, "top5_acc": 98.43750, "top5_err": 1.56250}
[06/12 22:25:29][INFO] logging.py:  101: json_stats: {"RAM": "13.48/31.07G", "_type": "val_epoch", "epoch": "285/300", "gpu_mem": "10.07G", "min_top1_err": 21.99170, "min_top5_err": 2.07469, "time_diff": 0.61127, "top1_acc": 73.23651, "top1_err": 26.76349, "top5_acc": 95.85062, "top5_err": 4.14938}
[06/12 22:25:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46446, "dt_data": 0.00050, "dt_net": 0.46396, "epoch": "286/300", "eta": "0:06:53", "gpu_mem": "10.07G", "grad_norm": 1.35841, "iter": "10/60", "loss": 0.01316, "lr": 0.0000120672, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:25:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46870, "dt_data": 0.00038, "dt_net": 0.46832, "epoch": "286/300", "eta": "0:06:52", "gpu_mem": "10.07G", "grad_norm": 0.77859, "iter": "20/60", "loss": 0.03649, "lr": 0.0000117983, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:25:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.08104, "dt_data": 0.61537, "dt_net": 0.46566, "epoch": "286/300", "eta": "0:15:40", "gpu_mem": "10.07G", "grad_norm": 0.77999, "iter": "30/60", "loss": 0.01862, "lr": 0.0000115325, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:26:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47898, "dt_data": 0.00040, "dt_net": 0.47858, "epoch": "286/300", "eta": "0:06:51", "gpu_mem": "10.07G", "grad_norm": 8.42898, "iter": "40/60", "loss": 0.01518, "lr": 0.0000112697, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:26:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.39627, "dt_data": 0.92797, "dt_net": 0.46829, "epoch": "286/300", "eta": "0:19:46", "gpu_mem": "10.07G", "grad_norm": 6.83044, "iter": "50/60", "loss": 0.01560, "lr": 0.0000110099, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:26:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46920, "dt_data": 0.00017, "dt_net": 0.46903, "epoch": "286/300", "eta": "0:06:34", "gpu_mem": "10.07G", "grad_norm": 0.16072, "iter": "60/60", "loss": 0.03141, "lr": 0.0000107532, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:26:17][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.69592, "dt_data": 0.69592, "dt_net": 0.46903, "epoch": "286/300", "eta": "0:09:44", "gpu_mem": "10.07G", "grad_norm": 0.16072, "loss": 0.03707, "lr": 0.0000107532, "top1_acc": 98.95833, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:26:17][INFO] train_net.py:  708: Epoch 285 takes 47.60s. Epochs from 0 to 285 take 47.97s in average and 47.94s in median.
[06/12 22:26:17][INFO] train_net.py:  714: For epoch 285, each iteraction takes 0.79s in average. From epoch 0 to 285, each iteraction takes 0.80s in average.
[06/12 22:26:34][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.55597, "dt_data": 0.08469, "dt_net": 0.47128, "epoch": "287/300", "eta": "0:07:41", "gpu_mem": "10.07G", "grad_norm": 3.04660, "iter": "10/60", "loss": 0.02451, "lr": 0.0000104994, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:26:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47320, "dt_data": 0.00055, "dt_net": 0.47265, "epoch": "287/300", "eta": "0:06:28", "gpu_mem": "10.07G", "grad_norm": 0.52083, "iter": "20/60", "loss": 0.03566, "lr": 0.0000102487, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:26:45][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.67958, "dt_data": 0.20499, "dt_net": 0.47459, "epoch": "287/300", "eta": "0:09:10", "gpu_mem": "10.07G", "grad_norm": 2.99165, "iter": "30/60", "loss": 0.03634, "lr": 0.0000100009, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:26:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47641, "dt_data": 0.00089, "dt_net": 0.47552, "epoch": "287/300", "eta": "0:06:21", "gpu_mem": "10.07G", "grad_norm": 1.02208, "iter": "40/60", "loss": 0.00820, "lr": 0.0000097562, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:26:59][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.13484, "dt_data": 0.66496, "dt_net": 0.46987, "epoch": "287/300", "eta": "0:14:56", "gpu_mem": "10.07G", "grad_norm": 8.66563, "iter": "50/60", "loss": 0.02540, "lr": 0.0000095145, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:27:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46919, "dt_data": 0.00027, "dt_net": 0.46892, "epoch": "287/300", "eta": "0:06:05", "gpu_mem": "10.07G", "grad_norm": 5.97037, "iter": "60/60", "loss": 0.04257, "lr": 0.0000092759, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:27:05][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.69139, "dt_data": 0.69139, "dt_net": 0.46892, "epoch": "287/300", "eta": "0:08:59", "gpu_mem": "10.07G", "grad_norm": 5.97037, "loss": 0.04367, "lr": 0.0000092759, "top1_acc": 98.64583, "top1_err": 1.71875, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:27:05][INFO] train_net.py:  708: Epoch 286 takes 47.55s. Epochs from 0 to 286 take 47.96s in average and 47.93s in median.
[06/12 22:27:05][INFO] train_net.py:  714: For epoch 286, each iteraction takes 0.79s in average. From epoch 0 to 286, each iteraction takes 0.80s in average.
[06/12 22:27:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.90901, "dt_data": 0.00048, "dt_net": 0.90853, "epoch": "288/300", "eta": "0:11:39", "gpu_mem": "10.07G", "grad_norm": 3.70167, "iter": "10/60", "loss": 0.00849, "lr": 0.0000090402, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:27:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47451, "dt_data": 0.00043, "dt_net": 0.47408, "epoch": "288/300", "eta": "0:06:00", "gpu_mem": "10.07G", "grad_norm": 2.68322, "iter": "20/60", "loss": 0.02621, "lr": 0.0000088076, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:27:34][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47363, "dt_data": 0.00039, "dt_net": 0.47324, "epoch": "288/300", "eta": "0:05:55", "gpu_mem": "10.07G", "grad_norm": 7.17853, "iter": "30/60", "loss": 0.03773, "lr": 0.0000085779, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:27:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47803, "dt_data": 0.00054, "dt_net": 0.47749, "epoch": "288/300", "eta": "0:05:53", "gpu_mem": "10.07G", "grad_norm": 0.58038, "iter": "40/60", "loss": 0.01443, "lr": 0.0000083513, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:27:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46965, "dt_data": 0.00036, "dt_net": 0.46929, "epoch": "288/300", "eta": "0:05:42", "gpu_mem": "10.07G", "grad_norm": 0.19009, "iter": "50/60", "loss": 0.01763, "lr": 0.0000081277, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:27:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47046, "dt_data": 0.00016, "dt_net": 0.47029, "epoch": "288/300", "eta": "0:05:38", "gpu_mem": "10.07G", "grad_norm": 6.91141, "iter": "60/60", "loss": 0.05441, "lr": 0.0000079072, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:27:52][INFO] logging.py:  101: json_stats: {"RAM": "13.48/31.07G", "_type": "train_epoch", "dt": 0.69665, "dt_data": 0.69665, "dt_net": 0.47029, "epoch": "288/300", "eta": "0:08:21", "gpu_mem": "10.07G", "grad_norm": 6.91141, "loss": 0.04282, "lr": 0.0000079072, "top1_acc": 98.64583, "top1_err": 1.51042, "top5_acc": 99.89583, "top5_err": 0.05208}
[06/12 22:27:52][INFO] train_net.py:  708: Epoch 287 takes 47.70s. Epochs from 0 to 287 take 47.96s in average and 47.93s in median.
[06/12 22:27:52][INFO] train_net.py:  714: For epoch 287, each iteraction takes 0.80s in average. From epoch 0 to 287, each iteraction takes 0.80s in average.
[06/12 22:28:10][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47419, "dt_data": 0.00037, "dt_net": 0.47382, "epoch": "289/300", "eta": "0:05:36", "gpu_mem": "10.07G", "grad_norm": 0.33003, "iter": "10/60", "loss": 0.01571, "lr": 0.0000076896, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:28:15][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47292, "dt_data": 0.00036, "dt_net": 0.47255, "epoch": "289/300", "eta": "0:05:31", "gpu_mem": "10.07G", "grad_norm": 0.42301, "iter": "20/60", "loss": 0.02514, "lr": 0.0000074751, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:28:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47409, "dt_data": 0.00036, "dt_net": 0.47372, "epoch": "289/300", "eta": "0:05:27", "gpu_mem": "10.07G", "grad_norm": 0.24775, "iter": "30/60", "loss": 0.02426, "lr": 0.0000072636, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:28:27][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48126, "dt_data": 0.00143, "dt_net": 0.47982, "epoch": "289/300", "eta": "0:05:27", "gpu_mem": "10.07G", "grad_norm": 5.56717, "iter": "40/60", "loss": 0.03222, "lr": 0.0000070552, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:28:33][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47448, "dt_data": 0.00072, "dt_net": 0.47376, "epoch": "289/300", "eta": "0:05:17", "gpu_mem": "10.07G", "grad_norm": 0.74687, "iter": "50/60", "loss": 0.02900, "lr": 0.0000068497, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:28:39][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47182, "dt_data": 0.00019, "dt_net": 0.47163, "epoch": "289/300", "eta": "0:05:11", "gpu_mem": "10.07G", "grad_norm": 0.18817, "iter": "60/60", "loss": 0.01102, "lr": 0.0000066473, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:28:40][INFO] logging.py:  101: json_stats: {"RAM": "13.48/31.07G", "_type": "train_epoch", "dt": 0.68518, "dt_data": 0.68518, "dt_net": 0.47163, "epoch": "289/300", "eta": "0:07:32", "gpu_mem": "10.07G", "grad_norm": 0.18817, "loss": 0.03613, "lr": 0.0000066473, "top1_acc": 98.12500, "top1_err": 1.66667, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:28:40][INFO] train_net.py:  708: Epoch 288 takes 47.48s. Epochs from 0 to 288 take 47.96s in average and 47.93s in median.
[06/12 22:28:40][INFO] train_net.py:  714: For epoch 288, each iteraction takes 0.79s in average. From epoch 0 to 288, each iteraction takes 0.80s in average.
[06/12 22:28:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47182, "dt_data": 0.00044, "dt_net": 0.47138, "epoch": "290/300", "eta": "0:05:06", "gpu_mem": "10.07G", "grad_norm": 3.15661, "iter": "10/60", "loss": 0.01647, "lr": 0.0000064479, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:29:03][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48851, "dt_data": 0.00065, "dt_net": 0.48786, "epoch": "290/300", "eta": "0:05:12", "gpu_mem": "10.07G", "grad_norm": 3.99330, "iter": "20/60", "loss": 0.02261, "lr": 0.0000062516, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:29:10][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 1.14080, "dt_data": 0.00037, "dt_net": 1.14043, "epoch": "290/300", "eta": "0:11:58", "gpu_mem": "10.07G", "grad_norm": 2.37268, "iter": "30/60", "loss": 0.02170, "lr": 0.0000060582, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:29:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47568, "dt_data": 0.00039, "dt_net": 0.47530, "epoch": "290/300", "eta": "0:04:54", "gpu_mem": "10.07G", "grad_norm": 5.34074, "iter": "40/60", "loss": 0.04319, "lr": 0.0000058679, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:29:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.57067, "dt_data": 0.00035, "dt_net": 0.57032, "epoch": "290/300", "eta": "0:05:48", "gpu_mem": "10.07G", "grad_norm": 0.67637, "iter": "50/60", "loss": 0.01606, "lr": 0.0000056806, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:29:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47139, "dt_data": 0.00017, "dt_net": 0.47122, "epoch": "290/300", "eta": "0:04:42", "gpu_mem": "10.07G", "grad_norm": 7.10685, "iter": "60/60", "loss": 0.02449, "lr": 0.0000054964, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:29:28][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.68797, "dt_data": 0.68797, "dt_net": 0.47122, "epoch": "290/300", "eta": "0:06:52", "gpu_mem": "10.07G", "grad_norm": 7.10685, "loss": 0.03456, "lr": 0.0000054964, "top1_acc": 98.75000, "top1_err": 1.09375, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:29:28][INFO] train_net.py:  708: Epoch 289 takes 48.59s. Epochs from 0 to 289 take 47.96s in average and 47.93s in median.
[06/12 22:29:28][INFO] train_net.py:  714: For epoch 289, each iteraction takes 0.81s in average. From epoch 0 to 289, each iteraction takes 0.80s in average.
[06/12 22:29:28][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 22:30:29][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "290/300", "eta": "0:00:01", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.22611, "top1_acc": 76.56250, "top1_err": 23.43750, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 22:30:32][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "val_epoch", "epoch": "290/300", "gpu_mem": "10.07G", "min_top1_err": 21.99170, "min_top5_err": 2.07469, "time_diff": 0.60795, "top1_acc": 74.68880, "top1_err": 25.31120, "top5_acc": 96.68050, "top5_err": 3.31950}
[06/12 22:30:50][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46670, "dt_data": 0.00049, "dt_net": 0.46622, "epoch": "291/300", "eta": "0:04:35", "gpu_mem": "10.07G", "grad_norm": 3.39793, "iter": "10/60", "loss": 0.01705, "lr": 0.0000053151, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:30:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46661, "dt_data": 0.00032, "dt_net": 0.46629, "epoch": "291/300", "eta": "0:04:30", "gpu_mem": "10.07G", "grad_norm": 0.82168, "iter": "20/60", "loss": 0.01908, "lr": 0.0000051369, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:31:02][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47047, "dt_data": 0.00041, "dt_net": 0.47006, "epoch": "291/300", "eta": "0:04:28", "gpu_mem": "10.07G", "grad_norm": 3.12973, "iter": "30/60", "loss": 0.01927, "lr": 0.0000049618, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:31:08][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47030, "dt_data": 0.00065, "dt_net": 0.46965, "epoch": "291/300", "eta": "0:04:23", "gpu_mem": "10.07G", "grad_norm": 1.44299, "iter": "40/60", "loss": 0.01508, "lr": 0.0000047896, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:31:14][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47091, "dt_data": 0.00034, "dt_net": 0.47056, "epoch": "291/300", "eta": "0:04:18", "gpu_mem": "10.07G", "grad_norm": 7.37498, "iter": "50/60", "loss": 0.04810, "lr": 0.0000046205, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:31:19][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46594, "dt_data": 0.00019, "dt_net": 0.46575, "epoch": "291/300", "eta": "0:04:11", "gpu_mem": "10.07G", "grad_norm": 3.87293, "iter": "60/60", "loss": 0.01158, "lr": 0.0000044545, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:31:20][INFO] logging.py:  101: json_stats: {"RAM": "13.46/31.07G", "_type": "train_epoch", "dt": 0.69948, "dt_data": 0.69948, "dt_net": 0.46575, "epoch": "291/300", "eta": "0:06:17", "gpu_mem": "10.07G", "grad_norm": 3.87293, "loss": 0.03158, "lr": 0.0000044545, "top1_acc": 98.85417, "top1_err": 1.09375, "top5_acc": 99.89583, "top5_err": 0.05208}
[06/12 22:31:20][INFO] train_net.py:  708: Epoch 290 takes 47.81s. Epochs from 0 to 290 take 47.96s in average and 47.93s in median.
[06/12 22:31:20][INFO] train_net.py:  714: For epoch 290, each iteraction takes 0.80s in average. From epoch 0 to 290, each iteraction takes 0.80s in average.
[06/12 22:31:36][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.63427, "dt_data": 0.00062, "dt_net": 0.63365, "epoch": "292/300", "eta": "0:05:36", "gpu_mem": "10.07G", "grad_norm": 0.11292, "iter": "10/60", "loss": 0.03515, "lr": 0.0000042914, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:31:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46922, "dt_data": 0.00035, "dt_net": 0.46886, "epoch": "292/300", "eta": "0:04:03", "gpu_mem": "10.07G", "grad_norm": 1.28495, "iter": "20/60", "loss": 0.00962, "lr": 0.0000041314, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:31:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.81240, "dt_data": 0.34277, "dt_net": 0.46962, "epoch": "292/300", "eta": "0:06:54", "gpu_mem": "10.07G", "grad_norm": 1.55234, "iter": "30/60", "loss": 0.01723, "lr": 0.0000039745, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:31:54][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47066, "dt_data": 0.00046, "dt_net": 0.47019, "epoch": "292/300", "eta": "0:03:55", "gpu_mem": "10.07G", "grad_norm": 1.29207, "iter": "40/60", "loss": 0.00966, "lr": 0.0000038205, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:32:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47473, "dt_data": 0.00050, "dt_net": 0.47423, "epoch": "292/300", "eta": "0:03:52", "gpu_mem": "10.07G", "grad_norm": 1.63192, "iter": "50/60", "loss": 0.02389, "lr": 0.0000036696, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:32:07][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46903, "dt_data": 0.00017, "dt_net": 0.46886, "epoch": "292/300", "eta": "0:03:45", "gpu_mem": "10.07G", "grad_norm": 4.01811, "iter": "60/60", "loss": 0.01239, "lr": 0.0000035218, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:32:07][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.69388, "dt_data": 0.69388, "dt_net": 0.46886, "epoch": "292/300", "eta": "0:05:33", "gpu_mem": "10.07G", "grad_norm": 4.01811, "loss": 0.03091, "lr": 0.0000035218, "top1_acc": 98.64583, "top1_err": 1.04167, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:32:07][INFO] train_net.py:  708: Epoch 291 takes 47.33s. Epochs from 0 to 291 take 47.96s in average and 47.93s in median.
[06/12 22:32:07][INFO] train_net.py:  714: For epoch 291, each iteraction takes 0.79s in average. From epoch 0 to 291, each iteraction takes 0.80s in average.
[06/12 22:32:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47369, "dt_data": 0.00047, "dt_net": 0.47322, "epoch": "293/300", "eta": "0:03:42", "gpu_mem": "10.07G", "grad_norm": 3.64103, "iter": "10/60", "loss": 0.04126, "lr": 0.0000033769, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:32:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47088, "dt_data": 0.00036, "dt_net": 0.47052, "epoch": "293/300", "eta": "0:03:36", "gpu_mem": "10.07G", "grad_norm": 2.23532, "iter": "20/60", "loss": 0.03830, "lr": 0.0000032351, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:32:38][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47619, "dt_data": 0.00034, "dt_net": 0.47586, "epoch": "293/300", "eta": "0:03:34", "gpu_mem": "10.07G", "grad_norm": 2.33316, "iter": "30/60", "loss": 0.04205, "lr": 0.0000030964, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:32:43][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48839, "dt_data": 0.00046, "dt_net": 0.48792, "epoch": "293/300", "eta": "0:03:34", "gpu_mem": "10.07G", "grad_norm": 3.51174, "iter": "40/60", "loss": 0.02098, "lr": 0.0000029607, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:32:49][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47135, "dt_data": 0.00045, "dt_net": 0.47090, "epoch": "293/300", "eta": "0:03:22", "gpu_mem": "10.07G", "grad_norm": 7.60433, "iter": "50/60", "loss": 0.04187, "lr": 0.0000028280, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:32:55][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47266, "dt_data": 0.00019, "dt_net": 0.47247, "epoch": "293/300", "eta": "0:03:18", "gpu_mem": "10.07G", "grad_norm": 0.24199, "iter": "60/60", "loss": 0.00931, "lr": 0.0000026983, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:32:55][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.69229, "dt_data": 0.69229, "dt_net": 0.47247, "epoch": "293/300", "eta": "0:04:50", "gpu_mem": "10.07G", "grad_norm": 0.24199, "loss": 0.04389, "lr": 0.0000026983, "top1_acc": 98.64583, "top1_err": 1.61458, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:32:55][INFO] train_net.py:  708: Epoch 292 takes 47.98s. Epochs from 0 to 292 take 47.96s in average and 47.93s in median.
[06/12 22:32:55][INFO] train_net.py:  714: For epoch 292, each iteraction takes 0.80s in average. From epoch 0 to 292, each iteraction takes 0.80s in average.
[06/12 22:33:13][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47219, "dt_data": 0.00049, "dt_net": 0.47170, "epoch": "294/300", "eta": "0:03:13", "gpu_mem": "10.07G", "grad_norm": 2.99304, "iter": "10/60", "loss": 0.02333, "lr": 0.0000025717, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:33:18][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47448, "dt_data": 0.00037, "dt_net": 0.47411, "epoch": "294/300", "eta": "0:03:09", "gpu_mem": "10.07G", "grad_norm": 1.38780, "iter": "20/60", "loss": 0.02274, "lr": 0.0000024481, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:33:25][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47292, "dt_data": 0.00042, "dt_net": 0.47250, "epoch": "294/300", "eta": "0:03:04", "gpu_mem": "10.07G", "grad_norm": 1.17390, "iter": "30/60", "loss": 0.03040, "lr": 0.0000023276, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:33:31][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47572, "dt_data": 0.00089, "dt_net": 0.47482, "epoch": "294/300", "eta": "0:03:00", "gpu_mem": "10.07G", "grad_norm": 4.85351, "iter": "40/60", "loss": 0.06987, "lr": 0.0000022101, "top1_acc": 93.75000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:33:37][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47502, "dt_data": 0.00039, "dt_net": 0.47463, "epoch": "294/300", "eta": "0:02:55", "gpu_mem": "10.07G", "grad_norm": 3.56843, "iter": "50/60", "loss": 0.02360, "lr": 0.0000020957, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:33:42][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47052, "dt_data": 0.00017, "dt_net": 0.47036, "epoch": "294/300", "eta": "0:02:49", "gpu_mem": "10.07G", "grad_norm": 0.11466, "iter": "60/60", "loss": 0.03411, "lr": 0.0000019842, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:33:43][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.71174, "dt_data": 0.71174, "dt_net": 0.47036, "epoch": "294/300", "eta": "0:04:16", "gpu_mem": "10.07G", "grad_norm": 0.11466, "loss": 0.04479, "lr": 0.0000019842, "top1_acc": 98.54167, "top1_err": 1.77083, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:33:43][INFO] train_net.py:  708: Epoch 293 takes 47.96s. Epochs from 0 to 293 take 47.96s in average and 47.93s in median.
[06/12 22:33:43][INFO] train_net.py:  714: For epoch 293, each iteraction takes 0.80s in average. From epoch 0 to 293, each iteraction takes 0.80s in average.
[06/12 22:34:01][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47040, "dt_data": 0.00033, "dt_net": 0.47006, "epoch": "295/300", "eta": "0:02:44", "gpu_mem": "10.07G", "grad_norm": 0.70980, "iter": "10/60", "loss": 0.00659, "lr": 0.0000018759, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:34:06][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48272, "dt_data": 0.00037, "dt_net": 0.48235, "epoch": "295/300", "eta": "0:02:44", "gpu_mem": "10.07G", "grad_norm": 2.26170, "iter": "20/60", "loss": 0.01947, "lr": 0.0000017705, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:34:12][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47260, "dt_data": 0.00037, "dt_net": 0.47223, "epoch": "295/300", "eta": "0:02:35", "gpu_mem": "10.07G", "grad_norm": 1.86399, "iter": "30/60", "loss": 0.03223, "lr": 0.0000016682, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:34:18][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47105, "dt_data": 0.00041, "dt_net": 0.47064, "epoch": "295/300", "eta": "0:02:30", "gpu_mem": "10.07G", "grad_norm": 4.62152, "iter": "40/60", "loss": 0.03481, "lr": 0.0000015690, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:34:24][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47897, "dt_data": 0.00045, "dt_net": 0.47852, "epoch": "295/300", "eta": "0:02:28", "gpu_mem": "10.07G", "grad_norm": 0.10858, "iter": "50/60", "loss": 0.03555, "lr": 0.0000014728, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:34:30][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46907, "dt_data": 0.00018, "dt_net": 0.46889, "epoch": "295/300", "eta": "0:02:20", "gpu_mem": "10.07G", "grad_norm": 0.89458, "iter": "60/60", "loss": 0.01250, "lr": 0.0000013796, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:34:31][INFO] logging.py:  101: json_stats: {"RAM": "13.48/31.07G", "_type": "train_epoch", "dt": 0.67949, "dt_data": 0.67949, "dt_net": 0.46889, "epoch": "295/300", "eta": "0:03:23", "gpu_mem": "10.07G", "grad_norm": 0.89458, "loss": 0.04356, "lr": 0.0000013796, "top1_acc": 98.33333, "top1_err": 1.40625, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:34:31][INFO] train_net.py:  708: Epoch 294 takes 47.83s. Epochs from 0 to 294 take 47.96s in average and 47.93s in median.
[06/12 22:34:31][INFO] train_net.py:  714: For epoch 294, each iteraction takes 0.80s in average. From epoch 0 to 294, each iteraction takes 0.80s in average.
[06/12 22:34:31][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 22:35:32][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "295/300", "eta": "0:00:01", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.17190, "top1_acc": 76.56250, "top1_err": 23.43750, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 22:35:35][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "val_epoch", "epoch": "295/300", "gpu_mem": "10.07G", "min_top1_err": 21.99170, "min_top5_err": 2.07469, "time_diff": 0.60815, "top1_acc": 75.31120, "top1_err": 24.68880, "top5_acc": 95.85062, "top5_err": 4.14938}
[06/12 22:35:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46637, "dt_data": 0.00038, "dt_net": 0.46599, "epoch": "296/300", "eta": "0:02:15", "gpu_mem": "10.07G", "grad_norm": 5.26817, "iter": "10/60", "loss": 0.04462, "lr": 0.0000012895, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:35:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48100, "dt_data": 0.00032, "dt_net": 0.48068, "epoch": "296/300", "eta": "0:02:14", "gpu_mem": "10.07G", "grad_norm": 0.89404, "iter": "20/60", "loss": 0.00834, "lr": 0.0000012024, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:36:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46778, "dt_data": 0.00035, "dt_net": 0.46743, "epoch": "296/300", "eta": "0:02:06", "gpu_mem": "10.07G", "grad_norm": 2.49056, "iter": "30/60", "loss": 0.03981, "lr": 0.0000011184, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:36:10][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47090, "dt_data": 0.00053, "dt_net": 0.47036, "epoch": "296/300", "eta": "0:02:02", "gpu_mem": "10.07G", "grad_norm": 4.49903, "iter": "40/60", "loss": 0.01298, "lr": 0.0000010374, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:36:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47667, "dt_data": 0.00069, "dt_net": 0.47596, "epoch": "296/300", "eta": "0:01:59", "gpu_mem": "10.07G", "grad_norm": 1.39737, "iter": "50/60", "loss": 0.02324, "lr": 9.594E-7, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:36:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46557, "dt_data": 0.00017, "dt_net": 0.46540, "epoch": "296/300", "eta": "0:01:51", "gpu_mem": "10.07G", "grad_norm": 0.58670, "iter": "60/60", "loss": 0.02082, "lr": 8.845E-7, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:36:22][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.66934, "dt_data": 0.66934, "dt_net": 0.46540, "epoch": "296/300", "eta": "0:02:40", "gpu_mem": "10.07G", "grad_norm": 0.58670, "loss": 0.03372, "lr": 8.845E-7, "top1_acc": 98.33333, "top1_err": 1.30208, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:36:22][INFO] train_net.py:  708: Epoch 295 takes 47.43s. Epochs from 0 to 295 take 47.96s in average and 47.93s in median.
[06/12 22:36:22][INFO] train_net.py:  714: For epoch 295, each iteraction takes 0.79s in average. From epoch 0 to 295, each iteraction takes 0.80s in average.
[06/12 22:36:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46692, "dt_data": 0.00050, "dt_net": 0.46642, "epoch": "297/300", "eta": "0:01:47", "gpu_mem": "10.07G", "grad_norm": 5.28477, "iter": "10/60", "loss": 0.03228, "lr": 8.126E-7, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:36:45][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46734, "dt_data": 0.00049, "dt_net": 0.46684, "epoch": "297/300", "eta": "0:01:42", "gpu_mem": "10.07G", "grad_norm": 2.71478, "iter": "20/60", "loss": 0.02347, "lr": 7.438E-7, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:36:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47267, "dt_data": 0.00077, "dt_net": 0.47190, "epoch": "297/300", "eta": "0:01:39", "gpu_mem": "10.07G", "grad_norm": 1.15404, "iter": "30/60", "loss": 0.01731, "lr": 6.780E-7, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:36:57][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47077, "dt_data": 0.00046, "dt_net": 0.47031, "epoch": "297/300", "eta": "0:01:34", "gpu_mem": "10.07G", "grad_norm": 0.30506, "iter": "40/60", "loss": 0.02634, "lr": 6.153E-7, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:37:04][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47037, "dt_data": 0.00033, "dt_net": 0.47004, "epoch": "297/300", "eta": "0:01:29", "gpu_mem": "10.07G", "grad_norm": 3.51836, "iter": "50/60", "loss": 0.00951, "lr": 5.556E-7, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:37:09][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47083, "dt_data": 0.00020, "dt_net": 0.47064, "epoch": "297/300", "eta": "0:01:24", "gpu_mem": "10.07G", "grad_norm": 2.85421, "iter": "60/60", "loss": 0.05347, "lr": 4.989E-7, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:37:10][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.68816, "dt_data": 0.68816, "dt_net": 0.47064, "epoch": "297/300", "eta": "0:02:03", "gpu_mem": "10.07G", "grad_norm": 2.85421, "loss": 0.03693, "lr": 4.989E-7, "top1_acc": 98.54167, "top1_err": 1.25000, "top5_acc": 99.89583, "top5_err": 0.05208}
[06/12 22:37:10][INFO] train_net.py:  708: Epoch 296 takes 47.75s. Epochs from 0 to 296 take 47.96s in average and 47.93s in median.
[06/12 22:37:10][INFO] train_net.py:  714: For epoch 296, each iteraction takes 0.80s in average. From epoch 0 to 296, each iteraction takes 0.80s in average.
[06/12 22:37:28][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47664, "dt_data": 0.00062, "dt_net": 0.47602, "epoch": "298/300", "eta": "0:01:21", "gpu_mem": "10.07G", "grad_norm": 0.27381, "iter": "10/60", "loss": 0.05301, "lr": 4.453E-7, "top1_acc": 96.87500, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:37:34][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47285, "dt_data": 0.00041, "dt_net": 0.47243, "epoch": "298/300", "eta": "0:01:15", "gpu_mem": "10.07G", "grad_norm": 1.82162, "iter": "20/60", "loss": 0.04081, "lr": 3.948E-7, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:37:40][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47098, "dt_data": 0.00035, "dt_net": 0.47062, "epoch": "298/300", "eta": "0:01:10", "gpu_mem": "10.07G", "grad_norm": 0.08889, "iter": "30/60", "loss": 0.00581, "lr": 3.473E-7, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:37:46][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47633, "dt_data": 0.00067, "dt_net": 0.47566, "epoch": "298/300", "eta": "0:01:06", "gpu_mem": "10.07G", "grad_norm": 3.42176, "iter": "40/60", "loss": 0.02140, "lr": 3.028E-7, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:37:52][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.48498, "dt_data": 0.00064, "dt_net": 0.48433, "epoch": "298/300", "eta": "0:01:03", "gpu_mem": "10.07G", "grad_norm": 0.23626, "iter": "50/60", "loss": 0.02108, "lr": 2.614E-7, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:37:58][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46884, "dt_data": 0.00017, "dt_net": 0.46867, "epoch": "298/300", "eta": "0:00:56", "gpu_mem": "10.07G", "grad_norm": 2.69444, "iter": "60/60", "loss": 0.02658, "lr": 2.230E-7, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:37:59][INFO] logging.py:  101: json_stats: {"RAM": "13.48/31.07G", "_type": "train_epoch", "dt": 0.69451, "dt_data": 0.69451, "dt_net": 0.46867, "epoch": "298/300", "eta": "0:01:23", "gpu_mem": "10.07G", "grad_norm": 2.69444, "loss": 0.03370, "lr": 2.230E-7, "top1_acc": 98.33333, "top1_err": 1.61458, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:37:59][INFO] train_net.py:  708: Epoch 297 takes 48.41s. Epochs from 0 to 297 take 47.96s in average and 47.93s in median.
[06/12 22:37:59][INFO] train_net.py:  714: For epoch 297, each iteraction takes 0.81s in average. From epoch 0 to 297, each iteraction takes 0.80s in average.
[06/12 22:38:17][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47083, "dt_data": 0.00058, "dt_net": 0.47024, "epoch": "299/300", "eta": "0:00:51", "gpu_mem": "10.07G", "grad_norm": 2.81031, "iter": "10/60", "loss": 0.03766, "lr": 1.877E-7, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:38:23][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47214, "dt_data": 0.00045, "dt_net": 0.47169, "epoch": "299/300", "eta": "0:00:47", "gpu_mem": "10.07G", "grad_norm": 0.36832, "iter": "20/60", "loss": 0.02661, "lr": 1.554E-7, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:38:29][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47049, "dt_data": 0.00038, "dt_net": 0.47011, "epoch": "299/300", "eta": "0:00:42", "gpu_mem": "10.07G", "grad_norm": 6.02522, "iter": "30/60", "loss": 0.03894, "lr": 1.261E-7, "top1_acc": 100.00000, "top1_err": 1.56250, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:38:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47891, "dt_data": 0.00064, "dt_net": 0.47827, "epoch": "299/300", "eta": "0:00:38", "gpu_mem": "10.07G", "grad_norm": 0.73503, "iter": "40/60", "loss": 0.00471, "lr": 9.99E-8, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:38:41][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47147, "dt_data": 0.00043, "dt_net": 0.47104, "epoch": "299/300", "eta": "0:00:33", "gpu_mem": "10.07G", "grad_norm": 2.50506, "iter": "50/60", "loss": 0.02838, "lr": 7.68E-8, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:38:47][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46934, "dt_data": 0.00016, "dt_net": 0.46918, "epoch": "299/300", "eta": "0:00:28", "gpu_mem": "10.07G", "grad_norm": 0.13219, "iter": "60/60", "loss": 0.02784, "lr": 5.67E-8, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:38:47][INFO] logging.py:  101: json_stats: {"RAM": "13.48/31.07G", "_type": "train_epoch", "dt": 0.70452, "dt_data": 0.70452, "dt_net": 0.46918, "epoch": "299/300", "eta": "0:00:42", "gpu_mem": "10.07G", "grad_norm": 0.13219, "loss": 0.03916, "lr": 5.67E-8, "top1_acc": 98.64583, "top1_err": 1.35417, "top5_acc": 99.89583, "top5_err": 0.05208}
[06/12 22:38:47][INFO] train_net.py:  708: Epoch 298 takes 48.61s. Epochs from 0 to 298 take 47.96s in average and 47.93s in median.
[06/12 22:38:47][INFO] train_net.py:  714: For epoch 298, each iteraction takes 0.81s in average. From epoch 0 to 298, each iteraction takes 0.80s in average.
[06/12 22:39:05][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46770, "dt_data": 0.00046, "dt_net": 0.46723, "epoch": "300/300", "eta": "0:00:23", "gpu_mem": "10.07G", "grad_norm": 0.23557, "iter": "10/60", "loss": 0.01790, "lr": 3.96E-8, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:39:11][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47053, "dt_data": 0.00037, "dt_net": 0.47015, "epoch": "300/300", "eta": "0:00:18", "gpu_mem": "10.07G", "grad_norm": 4.37006, "iter": "20/60", "loss": 0.02604, "lr": 2.56E-8, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:39:16][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47516, "dt_data": 0.00043, "dt_net": 0.47473, "epoch": "300/300", "eta": "0:00:14", "gpu_mem": "10.07G", "grad_norm": 11.66352, "iter": "30/60", "loss": 0.04569, "lr": 1.46E-8, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:39:22][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47748, "dt_data": 0.00039, "dt_net": 0.47709, "epoch": "300/300", "eta": "0:00:09", "gpu_mem": "10.07G", "grad_norm": 7.01737, "iter": "40/60", "loss": 0.01359, "lr": 6.7E-9, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:39:29][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.47268, "dt_data": 0.00050, "dt_net": 0.47218, "epoch": "300/300", "eta": "0:00:04", "gpu_mem": "10.07G", "grad_norm": 2.67294, "iter": "50/60", "loss": 0.02374, "lr": 1.8E-9, "top1_acc": 100.00000, "top1_err": 0.00000, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:39:35][INFO] logging.py:  101: json_stats: {"_type": "train_iter_", "dt": 0.46928, "dt_data": 0.00017, "dt_net": 0.46911, "epoch": "300/300", "eta": "0:00:00", "gpu_mem": "10.07G", "grad_norm": 9.05487, "iter": "60/60", "loss": 0.04596, "lr": 0E-10, "top1_acc": 100.00000, "top1_err": 3.12500, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:39:35][INFO] logging.py:  101: json_stats: {"RAM": "13.47/31.07G", "_type": "train_epoch", "dt": 0.70056, "dt_data": 0.70056, "dt_net": 0.46911, "epoch": "300/300", "eta": "0:00:00", "gpu_mem": "10.07G", "grad_norm": 9.05487, "loss": 0.04004, "lr": 0E-10, "top1_acc": 98.54167, "top1_err": 1.51042, "top5_acc": 100.00000, "top5_err": 0.00000}
[06/12 22:39:35][INFO] train_net.py:  708: Epoch 299 takes 48.20s. Epochs from 0 to 299 take 47.96s in average and 47.93s in median.
[06/12 22:39:35][INFO] train_net.py:  714: For epoch 299, each iteraction takes 0.80s in average. From epoch 0 to 299, each iteraction takes 0.80s in average.
[06/12 22:39:35][INFO] precise_bn.py:  129: Computing precise BN statistics for 110 BN layers ...
[06/12 22:40:38][INFO] logging.py:  101: json_stats: {"_type": "val_iter", "epoch": "300/300", "eta": "0:00:01", "gpu_mem": "10.07G", "iter": "10/16", "time_diff": 0.32377, "top1_acc": 79.68750, "top1_err": 20.31250, "top5_acc": 96.87500, "top5_err": 3.12500}
[06/12 22:40:41][INFO] logging.py:  101: json_stats: {"RAM": "14.21/31.07G", "_type": "val_epoch", "epoch": "300/300", "gpu_mem": "10.07G", "min_top1_err": 21.99170, "min_top5_err": 2.07469, "time_diff": 0.58478, "top1_acc": 75.72614, "top1_err": 24.27386, "top5_acc": 96.47303, "top5_err": 3.52697}
[06/12 22:40:41][INFO] train_net.py:  792: training done: _p33.68_f25.29 _t0.80_m10.07 _a78.01 Top5 Acc: 97.93 MEM: 10.07 f: 25.2904
